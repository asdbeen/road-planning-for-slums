[2024-09-02 01:48:15,286] data_dir:data\punggol_1
[2024-09-02 01:48:15,287] id: punggol_1
[2024-09-02 01:48:15,287] seed: 0
[2024-09-02 01:48:15,287] objectives_plan: 
[2024-09-02 01:48:15,287] init_plan: 
[2024-09-02 01:48:15,287] env_specs: {}
[2024-09-02 01:48:15,287] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-09-02 01:48:15,287] obs_specs: {}
[2024-09-02 01:48:15,287] agent_specs: {'batch_stage': False}
[2024-09-02 01:48:15,287] gamma: 0.9
[2024-09-02 01:48:15,287] tau: 0.0
[2024-09-02 01:48:15,287] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-09-02 01:48:15,288] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-09-02 01:48:15,288] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-09-02 01:48:15,288] lr: 0.0004
[2024-09-02 01:48:15,288] weightdecay: 0.0
[2024-09-02 01:48:15,288] eps: 1e-05
[2024-09-02 01:48:15,288] value_pred_coef: 0.5
[2024-09-02 01:48:15,288] entropy_coef: 0.01
[2024-09-02 01:48:15,288] clip_epsilon: 0.2
[2024-09-02 01:48:15,288] max_num_iterations: 100
[2024-09-02 01:48:15,288] num_episodes_per_iteration: 1200
[2024-09-02 01:48:15,288] max_sequence_length: 33
[2024-09-02 01:48:15,288] num_optim_epoch: 4
[2024-09-02 01:48:15,288] mini_batch_size: 1024
[2024-09-02 01:48:15,288] save_model_interval: 1
[2024-09-02 01:48:15,731] loading model from checkpoint: C:\Users\jingz\OneDrive\Documents\GitHub\road-planning-for-slums\train_data\punggol_1\rl-ngnn\punggol_1\0\models/iteration_0001.p
[2024-09-02 01:55:56,066] 1	T_sample 445.73	T_update 5.60	T_eval 8.99	ETA 12:31:51	train_R_eps -698.14	eval_R_eps -1.81	punggol_1	 4878.710623802585	
[2024-09-02 01:55:56,076] save best checkpoint with rewards -1.81!
[2024-09-02 02:03:34,728] 2	T_sample 444.31	T_update 5.39	T_eval 8.92	ETA 12:21:26	train_R_eps -666.14	eval_R_eps -1.79	punggol_1	 4878.710623802585	
[2024-09-02 02:03:34,747] save best checkpoint with rewards -1.79!
[2024-09-02 02:11:18,641] 3	T_sample 448.34	T_update 5.64	T_eval 9.88	ETA 12:22:11	train_R_eps -685.74	eval_R_eps -1.91	punggol_1	 4878.710623802585	
[2024-09-02 02:19:01,073] 4	T_sample 449.09	T_update 5.64	T_eval 7.68	ETA 12:12:09	train_R_eps -691.89	eval_R_eps -1.81	punggol_1	 4878.710623802585	
[2024-09-02 02:26:34,283] 5	T_sample 443.11	T_update 5.38	T_eval 4.69	ETA 11:49:59	train_R_eps -566.99	eval_R_eps -1.69	punggol_1	 4878.710623802585	
[2024-09-02 02:26:34,291] save best checkpoint with rewards -1.69!
[2024-09-02 02:34:15,267] 6	T_sample 450.79	T_update 5.37	T_eval 4.79	ETA 11:54:28	train_R_eps -552.25	eval_R_eps -1.69	punggol_1	 4878.710623802585	
[2024-09-02 02:41:45,317] 7	T_sample 439.28	T_update 5.40	T_eval 5.33	ETA 11:30:02	train_R_eps -471.16	eval_R_eps -1.67	punggol_1	 4878.710623802585	
[2024-09-02 02:41:45,326] save best checkpoint with rewards -1.67!
[2024-09-02 02:49:08,482] 8	T_sample 432.99	T_update 5.61	T_eval 4.53	ETA 11:12:04	train_R_eps -355.43	eval_R_eps -1.64	punggol_1	 4878.710623802585	
[2024-09-02 02:49:08,489] save best checkpoint with rewards -1.64!
[2024-09-02 02:56:24,633] 9	T_sample 426.30	T_update 5.27	T_eval 4.55	ETA 10:54:10	train_R_eps -216.86	eval_R_eps -1.64	punggol_1	 4878.710623802585	
[2024-09-02 03:03:31,961] 10	T_sample 417.55	T_update 5.30	T_eval 4.45	ETA 10:33:50	train_R_eps -101.96	eval_R_eps -1.64	punggol_1	 4878.710623802585	
[2024-09-02 03:10:49,363] 11	T_sample 427.52	T_update 5.42	T_eval 4.44	ETA 10:41:29	train_R_eps -20.13	eval_R_eps -1.64	punggol_1	 4878.710623802585	
[2024-09-02 03:18:03,597] 12	T_sample 424.25	T_update 5.37	T_eval 4.58	ETA 10:29:35	train_R_eps -17.75	eval_R_eps -1.64	punggol_1	 4878.710623802585	
[2024-09-02 03:25:23,267] 13	T_sample 430.40	T_update 5.49	T_eval 3.76	ETA 10:30:09	train_R_eps -1.65	eval_R_eps -1.63	punggol_1	 4878.710623802585	
[2024-09-02 03:25:23,284] save best checkpoint with rewards -1.63!
[2024-09-02 03:32:55,821] 14	T_sample 443.04	T_update 5.58	T_eval 3.88	ETA 10:41:03	train_R_eps -10.89	eval_R_eps -1.63	punggol_1	 4878.710623802585	
[2024-09-02 03:40:22,081] 15	T_sample 437.01	T_update 5.39	T_eval 3.83	ETA 10:24:44	train_R_eps -5.21	eval_R_eps -1.63	punggol_1	 4878.710623802585	
[2024-09-02 03:47:44,004] 16	T_sample 432.74	T_update 5.37	T_eval 3.77	ETA 10:11:17	train_R_eps -1.60	eval_R_eps -1.63	punggol_1	 4878.710623802585	
[2024-09-02 03:55:00,705] 17	T_sample 427.12	T_update 5.73	T_eval 3.83	ETA 9:56:47	train_R_eps -3.34	eval_R_eps -1.63	punggol_1	 4878.710623802585	
[2024-09-02 04:02:20,511] 18	T_sample 430.58	T_update 5.37	T_eval 3.82	ETA 9:53:42	train_R_eps -1.60	eval_R_eps -1.63	punggol_1	 4878.710623802585	
[2024-09-02 04:09:33,032] 19	T_sample 423.39	T_update 5.32	T_eval 3.78	ETA 9:36:39	train_R_eps -1.59	eval_R_eps -1.63	punggol_1	 4878.710623802585	
[2024-09-02 04:16:53,357] 20	T_sample 431.00	T_update 5.51	T_eval 3.77	ETA 9:39:43	train_R_eps -4.96	eval_R_eps -1.63	punggol_1	 4878.710623802585	
[2024-09-02 04:24:01,399] 21	T_sample 418.68	T_update 5.48	T_eval 3.86	ETA 9:16:25	train_R_eps -1.59	eval_R_eps -1.63	punggol_1	 4878.710623802585	
[2024-09-02 04:31:22,891] 22	T_sample 432.07	T_update 5.37	T_eval 3.84	ETA 9:26:19	train_R_eps -4.92	eval_R_eps -1.63	punggol_1	 4878.710623802585	
[2024-09-02 04:38:32,523] 23	T_sample 420.53	T_update 5.30	T_eval 3.75	ETA 9:04:09	train_R_eps -4.86	eval_R_eps -1.63	punggol_1	 4878.710623802585	
[2024-09-02 04:45:55,186] 24	T_sample 433.55	T_update 5.33	T_eval 3.75	ETA 9:13:18	train_R_eps -5.02	eval_R_eps -1.63	punggol_1	 4878.710623802585	
[2024-09-02 04:53:05,119] 25	T_sample 420.48	T_update 5.69	T_eval 3.72	ETA 8:50:12	train_R_eps -6.38	eval_R_eps -1.63	punggol_1	 4878.710623802585	
[2024-09-02 04:53:05,138] save best checkpoint with rewards -1.63!
[2024-09-02 05:00:25,446] 26	T_sample 431.30	T_update 5.31	T_eval 3.67	ETA 8:55:40	train_R_eps -8.32	eval_R_eps -1.63	punggol_1	 4878.710623802585	
[2024-09-02 05:07:39,893] 27	T_sample 425.35	T_update 5.31	T_eval 3.75	ETA 8:41:17	train_R_eps -1.59	eval_R_eps -1.63	punggol_1	 4878.710623802585	
[2024-09-02 05:15:08,661] 28	T_sample 439.39	T_update 5.68	T_eval 3.66	ETA 8:51:00	train_R_eps -1.59	eval_R_eps -1.63	punggol_1	 4878.710623802585	
[2024-09-02 05:22:32,458] 29	T_sample 434.53	T_update 5.44	T_eval 3.79	ETA 8:37:43	train_R_eps -1.59	eval_R_eps -1.52	punggol_1	 4878.710623802585	
[2024-09-02 05:22:32,466] save best checkpoint with rewards -1.52!
[2024-09-02 05:29:56,656] 30	T_sample 434.94	T_update 5.45	T_eval 3.77	ETA 8:30:47	train_R_eps -4.86	eval_R_eps -1.52	punggol_1	 4878.710623802585	
[2024-09-02 05:37:12,949] 31	T_sample 426.84	T_update 5.66	T_eval 3.76	ETA 8:14:25	train_R_eps -6.39	eval_R_eps -1.52	punggol_1	 4878.710623802585	
[2024-09-02 05:44:26,044] 32	T_sample 424.30	T_update 5.13	T_eval 3.64	ETA 8:03:35	train_R_eps -1.58	eval_R_eps -1.49	punggol_1	 4878.710623802585	
[2024-09-02 05:44:26,065] save best checkpoint with rewards -1.49!
[2024-09-02 05:51:42,422] 33	T_sample 427.40	T_update 5.18	T_eval 3.75	ETA 7:59:58	train_R_eps -4.86	eval_R_eps -1.49	punggol_1	 4878.710623802585	
[2024-09-02 05:58:56,419] 34	T_sample 424.83	T_update 5.55	T_eval 3.58	ETA 7:50:07	train_R_eps -4.71	eval_R_eps -1.49	punggol_1	 4878.710623802585	
[2024-09-02 06:06:23,415] 35	T_sample 438.10	T_update 5.28	T_eval 3.59	ETA 7:56:46	train_R_eps -3.22	eval_R_eps -1.49	punggol_1	 4878.710623802585	
[2024-09-02 06:13:38,035] 36	T_sample 425.72	T_update 5.26	T_eval 3.60	ETA 7:36:19	train_R_eps -4.77	eval_R_eps -1.49	punggol_1	 4878.710623802585	
[2024-09-02 06:21:03,611] 37	T_sample 436.27	T_update 5.56	T_eval 3.72	ETA 7:40:24	train_R_eps -10.01	eval_R_eps -1.49	punggol_1	 4878.710623802585	
[2024-09-02 06:28:26,599] 38	T_sample 434.26	T_update 5.08	T_eval 3.60	ETA 7:30:20	train_R_eps -18.56	eval_R_eps -1.49	punggol_1	 4878.710623802585	
[2024-09-02 06:35:51,320] 39	T_sample 435.76	T_update 5.25	T_eval 3.67	ETA 7:24:41	train_R_eps -6.54	eval_R_eps -1.49	punggol_1	 4878.710623802585	
[2024-09-02 06:42:59,408] 40	T_sample 418.78	T_update 5.70	T_eval 3.59	ETA 7:00:56	train_R_eps -4.56	eval_R_eps -1.49	punggol_1	 4878.710623802585	
[2024-09-02 06:50:17,904] 41	T_sample 429.99	T_update 5.15	T_eval 3.32	ETA 7:03:51	train_R_eps -1.56	eval_R_eps -1.47	punggol_1	 4878.710623802585	
[2024-09-02 06:50:17,919] save best checkpoint with rewards -1.47!
[2024-09-02 06:57:32,905] 42	T_sample 426.47	T_update 5.15	T_eval 3.33	ETA 6:53:12	train_R_eps -1.56	eval_R_eps -1.47	punggol_1	 4878.710623802585	
[2024-09-02 07:04:50,511] 43	T_sample 428.96	T_update 5.22	T_eval 3.40	ETA 6:48:24	train_R_eps -14.45	eval_R_eps -1.47	punggol_1	 4878.710623802585	
[2024-09-02 07:11:55,647] 44	T_sample 416.44	T_update 5.33	T_eval 3.32	ETA 6:29:40	train_R_eps -1.55	eval_R_eps -1.47	punggol_1	 4878.710623802585	
[2024-09-02 07:19:20,281] 45	T_sample 435.68	T_update 5.59	T_eval 3.33	ETA 6:40:08	train_R_eps -6.19	eval_R_eps -1.47	punggol_1	 4878.710623802585	
[2024-09-02 07:26:38,096] 46	T_sample 429.28	T_update 5.17	T_eval 3.34	ETA 6:26:43	train_R_eps -1.55	eval_R_eps -1.47	punggol_1	 4878.710623802585	
[2024-09-02 07:33:54,312] 47	T_sample 427.31	T_update 5.19	T_eval 3.69	ETA 6:18:02	train_R_eps -4.53	eval_R_eps -1.49	punggol_1	 4878.710623802585	
[2024-09-02 07:41:01,842] 48	T_sample 418.45	T_update 5.63	T_eval 3.41	ETA 6:03:22	train_R_eps -1.53	eval_R_eps -1.47	punggol_1	 4878.710623802585	
[2024-09-02 07:48:13,258] 49	T_sample 422.78	T_update 5.29	T_eval 3.31	ETA 5:59:29	train_R_eps -5.75	eval_R_eps -1.47	punggol_1	 4878.710623802585	
[2024-09-02 07:55:31,806] 50	T_sample 430.03	T_update 5.16	T_eval 3.33	ETA 5:58:08	train_R_eps -4.48	eval_R_eps -1.47	punggol_1	 4878.710623802585	
[2024-09-02 08:02:52,238] 51	T_sample 431.70	T_update 5.39	T_eval 3.31	ETA 5:52:19	train_R_eps -10.44	eval_R_eps -1.47	punggol_1	 4878.710623802585	
[2024-09-02 08:10:12,191] 52	T_sample 431.38	T_update 5.23	T_eval 3.32	ETA 5:44:37	train_R_eps -4.44	eval_R_eps -1.47	punggol_1	 4878.710623802585	
[2024-09-02 08:17:35,396] 53	T_sample 434.67	T_update 5.18	T_eval 3.32	ETA 5:39:46	train_R_eps -5.89	eval_R_eps -1.47	punggol_1	 4878.710623802585	
[2024-09-02 08:24:44,255] 54	T_sample 420.27	T_update 5.13	T_eval 3.43	ETA 5:21:37	train_R_eps -1.53	eval_R_eps -1.47	punggol_1	 4878.710623802585	
[2024-09-02 08:32:08,965] 55	T_sample 436.00	T_update 5.17	T_eval 3.51	ETA 5:26:06	train_R_eps -1.53	eval_R_eps -1.43	punggol_1	 4878.710623802585	
[2024-09-02 08:32:08,983] save best checkpoint with rewards -1.43!
[2024-09-02 08:39:24,990] 56	T_sample 427.34	T_update 5.11	T_eval 3.53	ETA 5:12:27	train_R_eps -7.28	eval_R_eps -1.43	punggol_1	 4878.710623802585	
[2024-09-02 08:46:54,763] 57	T_sample 440.68	T_update 5.54	T_eval 3.53	ETA 5:14:49	train_R_eps -10.37	eval_R_eps -1.43	punggol_1	 4878.710623802585	
[2024-09-02 08:54:20,782] 58	T_sample 437.21	T_update 5.23	T_eval 3.54	ETA 5:04:45	train_R_eps -8.84	eval_R_eps -1.43	punggol_1	 4878.710623802585	
[2024-09-02 09:01:40,018] 59	T_sample 430.47	T_update 5.14	T_eval 3.59	ETA 4:52:48	train_R_eps -7.33	eval_R_eps -1.43	punggol_1	 4878.710623802585	
[2024-09-02 09:09:02,292] 60	T_sample 432.99	T_update 5.63	T_eval 3.63	ETA 4:47:28	train_R_eps -4.29	eval_R_eps -1.43	punggol_1	 4878.710623802585	
[2024-09-02 09:16:25,093] 61	T_sample 434.03	T_update 5.20	T_eval 3.53	ETA 4:40:25	train_R_eps -4.40	eval_R_eps -1.43	punggol_1	 4878.710623802585	
[2024-09-02 09:23:54,592] 62	T_sample 440.62	T_update 5.29	T_eval 3.55	ETA 4:37:10	train_R_eps -4.33	eval_R_eps -1.43	punggol_1	 4878.710623802585	
[2024-09-02 09:31:19,227] 63	T_sample 435.60	T_update 5.49	T_eval 3.52	ETA 4:26:46	train_R_eps -3.04	eval_R_eps -1.43	punggol_1	 4878.710623802585	
[2024-09-02 09:38:36,061] 64	T_sample 428.12	T_update 5.16	T_eval 3.52	ETA 4:14:48	train_R_eps -1.52	eval_R_eps -1.43	punggol_1	 4878.710623802585	
[2024-09-02 09:45:59,293] 65	T_sample 434.47	T_update 5.14	T_eval 3.59	ETA 4:11:09	train_R_eps -4.48	eval_R_eps -1.43	punggol_1	 4878.710623802585	
[2024-09-02 09:53:20,301] 66	T_sample 431.76	T_update 5.67	T_eval 3.54	ETA 4:02:32	train_R_eps -1.52	eval_R_eps -1.43	punggol_1	 4878.710623802585	
[2024-09-02 10:00:48,621] 67	T_sample 439.57	T_update 5.13	T_eval 3.59	ETA 3:59:05	train_R_eps -1.53	eval_R_eps -1.43	punggol_1	 4878.710623802585	
[2024-09-02 10:08:06,826] 68	T_sample 429.53	T_update 5.12	T_eval 3.52	ETA 3:46:23	train_R_eps -1.53	eval_R_eps -1.44	punggol_1	 4878.710623802585	
[2024-10-02 18:42:24,341] data_dir:data/punggol_1
[2024-10-02 18:42:24,342] id: punggol_1
[2024-10-02 18:42:24,342] seed: 0
[2024-10-02 18:42:24,342] objectives_plan: 
[2024-10-02 18:42:24,342] init_plan: 
[2024-10-02 18:42:24,342] env_specs: {}
[2024-10-02 18:42:24,342] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-02 18:42:24,342] obs_specs: {}
[2024-10-02 18:42:24,342] agent_specs: {'batch_stage': False}
[2024-10-02 18:42:24,342] gamma: 0.9
[2024-10-02 18:42:24,342] tau: 0.0
[2024-10-02 18:42:24,342] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-02 18:42:24,342] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-02 18:42:24,342] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-02 18:42:24,342] lr: 0.0004
[2024-10-02 18:42:24,342] weightdecay: 0.0
[2024-10-02 18:42:24,342] eps: 1e-05
[2024-10-02 18:42:24,342] value_pred_coef: 0.5
[2024-10-02 18:42:24,342] entropy_coef: 0.01
[2024-10-02 18:42:24,342] clip_epsilon: 0.2
[2024-10-02 18:42:24,342] max_num_iterations: 3
[2024-10-02 18:42:24,342] num_episodes_per_iteration: 1200
[2024-10-02 18:42:24,342] max_sequence_length: 33
[2024-10-02 18:42:24,342] num_optim_epoch: 4
[2024-10-02 18:42:24,342] mini_batch_size: 1024
[2024-10-02 18:42:24,342] save_model_interval: 1
[2024-10-02 18:42:24,994] loading model from checkpoint: /Users/chenzebin/Documents/GitHub/road-planning-for-slums/train_data/punggol_1/rl-ngnn/punggol_1/0/models/iteration_0001.p
[2024-10-02 18:43:03,854] data_dir:data/punggol_1
[2024-10-02 18:43:03,854] id: punggol_1
[2024-10-02 18:43:03,854] seed: 0
[2024-10-02 18:43:03,854] objectives_plan: 
[2024-10-02 18:43:03,854] init_plan: 
[2024-10-02 18:43:03,854] env_specs: {}
[2024-10-02 18:43:03,854] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-02 18:43:03,854] obs_specs: {}
[2024-10-02 18:43:03,854] agent_specs: {'batch_stage': False}
[2024-10-02 18:43:03,854] gamma: 0.9
[2024-10-02 18:43:03,854] tau: 0.0
[2024-10-02 18:43:03,855] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-02 18:43:03,855] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-02 18:43:03,855] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-02 18:43:03,855] lr: 0.0004
[2024-10-02 18:43:03,855] weightdecay: 0.0
[2024-10-02 18:43:03,855] eps: 1e-05
[2024-10-02 18:43:03,855] value_pred_coef: 0.5
[2024-10-02 18:43:03,855] entropy_coef: 0.01
[2024-10-02 18:43:03,855] clip_epsilon: 0.2
[2024-10-02 18:43:03,855] max_num_iterations: 3
[2024-10-02 18:43:03,855] num_episodes_per_iteration: 1200
[2024-10-02 18:43:03,855] max_sequence_length: 33
[2024-10-02 18:43:03,855] num_optim_epoch: 4
[2024-10-02 18:43:03,855] mini_batch_size: 1024
[2024-10-02 18:43:03,855] save_model_interval: 1
[2024-10-02 18:43:04,439] loading model from checkpoint: /Users/chenzebin/Documents/GitHub/road-planning-for-slums/train_data/punggol_1/rl-ngnn/punggol_1/0/models/iteration_0001.p
[2024-10-02 18:43:46,019] data_dir:data/punggol_1
[2024-10-02 18:43:46,019] id: punggol_1
[2024-10-02 18:43:46,019] seed: 0
[2024-10-02 18:43:46,019] objectives_plan: 
[2024-10-02 18:43:46,019] init_plan: 
[2024-10-02 18:43:46,019] env_specs: {}
[2024-10-02 18:43:46,019] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-02 18:43:46,019] obs_specs: {}
[2024-10-02 18:43:46,019] agent_specs: {'batch_stage': False}
[2024-10-02 18:43:46,019] gamma: 0.9
[2024-10-02 18:43:46,019] tau: 0.0
[2024-10-02 18:43:46,019] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-02 18:43:46,019] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-02 18:43:46,019] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-02 18:43:46,019] lr: 0.0004
[2024-10-02 18:43:46,019] weightdecay: 0.0
[2024-10-02 18:43:46,019] eps: 1e-05
[2024-10-02 18:43:46,019] value_pred_coef: 0.5
[2024-10-02 18:43:46,019] entropy_coef: 0.01
[2024-10-02 18:43:46,019] clip_epsilon: 0.2
[2024-10-02 18:43:46,019] max_num_iterations: 3
[2024-10-02 18:43:46,019] num_episodes_per_iteration: 1200
[2024-10-02 18:43:46,019] max_sequence_length: 33
[2024-10-02 18:43:46,019] num_optim_epoch: 4
[2024-10-02 18:43:46,019] mini_batch_size: 1024
[2024-10-02 18:43:46,019] save_model_interval: 1
[2024-10-02 18:43:46,610] loading model from checkpoint: /Users/chenzebin/Documents/GitHub/road-planning-for-slums/train_data/punggol_1/rl-ngnn/punggol_1/0/models/iteration_0001.p
[2024-10-15 11:14:59,090] data_dir:data/punggol_1
[2024-10-15 11:14:59,090] id: punggol_1
[2024-10-15 11:14:59,090] seed: 0
[2024-10-15 11:14:59,090] objectives_plan: 
[2024-10-15 11:14:59,090] init_plan: 
[2024-10-15 11:14:59,090] env_specs: {}
[2024-10-15 11:14:59,090] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-15 11:14:59,090] obs_specs: {}
[2024-10-15 11:14:59,090] agent_specs: {'batch_stage': False}
[2024-10-15 11:14:59,090] gamma: 0.9
[2024-10-15 11:14:59,090] tau: 0.0
[2024-10-15 11:14:59,090] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-15 11:14:59,090] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-15 11:14:59,090] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-15 11:14:59,090] lr: 0.0004
[2024-10-15 11:14:59,090] weightdecay: 0.0
[2024-10-15 11:14:59,090] eps: 1e-05
[2024-10-15 11:14:59,090] value_pred_coef: 0.5
[2024-10-15 11:14:59,090] entropy_coef: 0.01
[2024-10-15 11:14:59,090] clip_epsilon: 0.2
[2024-10-15 11:14:59,090] max_num_iterations: 3
[2024-10-15 11:14:59,090] num_episodes_per_iteration: 1200
[2024-10-15 11:14:59,090] max_sequence_length: 33
[2024-10-15 11:14:59,090] num_optim_epoch: 4
[2024-10-15 11:14:59,090] mini_batch_size: 1024
[2024-10-15 11:14:59,090] save_model_interval: 1
[2024-10-15 11:16:19,091] 0	T_sample 72.23	T_update 1.12	T_eval 6.18	ETA 0:02:39	train_R_eps -637.61	eval_R_eps -1.86	punggol_1	 1.650230965910593	
[2024-10-15 11:16:19,096] save best checkpoint with rewards -1.86!
[2024-10-15 11:17:36,940] 1	T_sample 70.83	T_update 0.85	T_eval 6.13	ETA 0:01:18	train_R_eps -676.86	eval_R_eps -1.89	punggol_1	 1.7069402701581047	
[2024-10-15 11:18:55,255] 2	T_sample 71.77	T_update 0.89	T_eval 5.63	ETA 0:00:00	train_R_eps -638.03	eval_R_eps -1.92	punggol_1	 1.7962276057935327	
[2024-10-15 12:50:17,818] data_dir:data/punggol_1
[2024-10-15 12:50:17,818] id: punggol_1
[2024-10-15 12:50:17,818] seed: 0
[2024-10-15 12:50:17,818] objectives_plan: 
[2024-10-15 12:50:17,818] init_plan: 
[2024-10-15 12:50:17,818] env_specs: {}
[2024-10-15 12:50:17,818] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-15 12:50:17,818] obs_specs: {}
[2024-10-15 12:50:17,818] agent_specs: {'batch_stage': False}
[2024-10-15 12:50:17,818] gamma: 0.9
[2024-10-15 12:50:17,818] tau: 0.0
[2024-10-15 12:50:17,818] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-15 12:50:17,818] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-15 12:50:17,818] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-15 12:50:17,818] lr: 0.0004
[2024-10-15 12:50:17,818] weightdecay: 0.0
[2024-10-15 12:50:17,818] eps: 1e-05
[2024-10-15 12:50:17,818] value_pred_coef: 0.5
[2024-10-15 12:50:17,818] entropy_coef: 0.01
[2024-10-15 12:50:17,818] clip_epsilon: 0.2
[2024-10-15 12:50:17,818] max_num_iterations: 3
[2024-10-15 12:50:17,818] num_episodes_per_iteration: 1200
[2024-10-15 12:50:17,818] max_sequence_length: 33
[2024-10-15 12:50:17,818] num_optim_epoch: 4
[2024-10-15 12:50:17,818] mini_batch_size: 1024
[2024-10-15 12:50:17,818] save_model_interval: 1
[2024-10-15 12:51:35,421] 0	T_sample 70.08	T_update 1.09	T_eval 5.96	ETA 0:02:34	train_R_eps -646.53	eval_R_eps -1.85	punggol_1	 1.739379403475711	
[2024-10-15 12:51:35,425] save best checkpoint with rewards -1.85!
[2024-10-15 12:52:50,737] 1	T_sample 68.63	T_update 0.81	T_eval 5.85	ETA 0:01:15	train_R_eps -667.53	eval_R_eps -1.89	punggol_1	 1.7452933814865264	
[2024-10-15 13:27:42,125] data_dir:data/punggol_1
[2024-10-15 13:27:42,125] id: punggol_1
[2024-10-15 13:27:42,125] seed: 0
[2024-10-15 13:27:42,125] objectives_plan: 
[2024-10-15 13:27:42,125] init_plan: 
[2024-10-15 13:27:42,125] env_specs: {}
[2024-10-15 13:27:42,125] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-15 13:27:42,125] obs_specs: {}
[2024-10-15 13:27:42,125] agent_specs: {'batch_stage': False}
[2024-10-15 13:27:42,125] gamma: 0.9
[2024-10-15 13:27:42,125] tau: 0.0
[2024-10-15 13:27:42,125] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-15 13:27:42,125] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-15 13:27:42,125] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-15 13:27:42,125] lr: 0.0004
[2024-10-15 13:27:42,125] weightdecay: 0.0
[2024-10-15 13:27:42,125] eps: 1e-05
[2024-10-15 13:27:42,125] value_pred_coef: 0.5
[2024-10-15 13:27:42,125] entropy_coef: 0.01
[2024-10-15 13:27:42,125] clip_epsilon: 0.2
[2024-10-15 13:27:42,125] max_num_iterations: 3
[2024-10-15 13:27:42,125] num_episodes_per_iteration: 1200
[2024-10-15 13:27:42,125] max_sequence_length: 33
[2024-10-15 13:27:42,125] num_optim_epoch: 4
[2024-10-15 13:27:42,125] mini_batch_size: 1024
[2024-10-15 13:27:42,125] save_model_interval: 1
[2024-10-15 14:06:53,216] data_dir:data/punggol_1
[2024-10-15 14:06:53,216] id: punggol_1
[2024-10-15 14:06:53,216] seed: 0
[2024-10-15 14:06:53,216] objectives_plan: 
[2024-10-15 14:06:53,216] init_plan: 
[2024-10-15 14:06:53,216] env_specs: {}
[2024-10-15 14:06:53,216] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-15 14:06:53,216] obs_specs: {}
[2024-10-15 14:06:53,216] agent_specs: {'batch_stage': False}
[2024-10-15 14:06:53,216] gamma: 0.9
[2024-10-15 14:06:53,216] tau: 0.0
[2024-10-15 14:06:53,216] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-15 14:06:53,216] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-15 14:06:53,216] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-15 14:06:53,216] lr: 0.0004
[2024-10-15 14:06:53,216] weightdecay: 0.0
[2024-10-15 14:06:53,216] eps: 1e-05
[2024-10-15 14:06:53,216] value_pred_coef: 0.5
[2024-10-15 14:06:53,216] entropy_coef: 0.01
[2024-10-15 14:06:53,216] clip_epsilon: 0.2
[2024-10-15 14:06:53,216] max_num_iterations: 3
[2024-10-15 14:06:53,216] num_episodes_per_iteration: 1200
[2024-10-15 14:06:53,216] max_sequence_length: 33
[2024-10-15 14:06:53,216] num_optim_epoch: 4
[2024-10-15 14:06:53,216] mini_batch_size: 1024
[2024-10-15 14:06:53,216] save_model_interval: 1
[2024-10-15 14:08:10,220] 0	T_sample 69.52	T_update 1.08	T_eval 5.95	ETA 0:02:33	train_R_eps -646.53	eval_R_eps -1.85	punggol_1	 1.739379403475711	
[2024-10-15 14:08:10,225] save best checkpoint with rewards -1.85!
[2024-10-15 17:08:41,082] data_dir:data/punggol_1
[2024-10-15 17:08:41,082] id: punggol_1
[2024-10-15 17:08:41,082] seed: 0
[2024-10-15 17:08:41,082] objectives_plan: 
[2024-10-15 17:08:41,082] init_plan: 
[2024-10-15 17:08:41,082] env_specs: {}
[2024-10-15 17:08:41,082] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-15 17:08:41,082] obs_specs: {}
[2024-10-15 17:08:41,082] agent_specs: {'batch_stage': False}
[2024-10-15 17:08:41,082] gamma: 0.9
[2024-10-15 17:08:41,082] tau: 0.0
[2024-10-15 17:08:41,082] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-15 17:08:41,082] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-15 17:08:41,082] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-15 17:08:41,082] lr: 0.0004
[2024-10-15 17:08:41,082] weightdecay: 0.0
[2024-10-15 17:08:41,082] eps: 1e-05
[2024-10-15 17:08:41,082] value_pred_coef: 0.5
[2024-10-15 17:08:41,082] entropy_coef: 0.01
[2024-10-15 17:08:41,082] clip_epsilon: 0.2
[2024-10-15 17:08:41,082] max_num_iterations: 3
[2024-10-15 17:08:41,082] num_episodes_per_iteration: 1200
[2024-10-15 17:08:41,082] max_sequence_length: 33
[2024-10-15 17:08:41,082] num_optim_epoch: 4
[2024-10-15 17:08:41,082] mini_batch_size: 1024
[2024-10-15 17:08:41,082] save_model_interval: 1
[2024-10-15 17:09:23,980] 0	T_sample 36.05	T_update 0.35	T_eval 6.04	ETA 0:01:25	train_R_eps -632.54	eval_R_eps -1.85	punggol_1	 1.7344388133626432	
[2024-10-15 17:09:23,984] save best checkpoint with rewards -1.85!
[2024-10-15 17:10:23,146] data_dir:data/punggol_1
[2024-10-15 17:10:23,146] id: punggol_1
[2024-10-15 17:10:23,146] seed: 0
[2024-10-15 17:10:23,146] objectives_plan: 
[2024-10-15 17:10:23,146] init_plan: 
[2024-10-15 17:10:23,146] env_specs: {}
[2024-10-15 17:10:23,146] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-15 17:10:23,146] obs_specs: {}
[2024-10-15 17:10:23,146] agent_specs: {'batch_stage': False}
[2024-10-15 17:10:23,146] gamma: 0.9
[2024-10-15 17:10:23,146] tau: 0.0
[2024-10-15 17:10:23,146] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-15 17:10:23,146] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-15 17:10:23,146] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-15 17:10:23,146] lr: 0.0004
[2024-10-15 17:10:23,146] weightdecay: 0.0
[2024-10-15 17:10:23,146] eps: 1e-05
[2024-10-15 17:10:23,146] value_pred_coef: 0.5
[2024-10-15 17:10:23,146] entropy_coef: 0.01
[2024-10-15 17:10:23,146] clip_epsilon: 0.2
[2024-10-15 17:10:23,146] max_num_iterations: 3
[2024-10-15 17:10:23,146] num_episodes_per_iteration: 1200
[2024-10-15 17:10:23,146] max_sequence_length: 33
[2024-10-15 17:10:23,146] num_optim_epoch: 4
[2024-10-15 17:10:23,146] mini_batch_size: 1024
[2024-10-15 17:10:23,146] save_model_interval: 1
[2024-10-15 17:10:51,657] 0	T_sample 21.72	T_update 0.31	T_eval 6.03	ETA 0:00:56	train_R_eps -771.93	eval_R_eps -1.85	punggol_1	 1.7344388133626432	
[2024-10-15 17:10:51,661] save best checkpoint with rewards -1.85!
[2024-10-15 17:11:52,609] data_dir:data/punggol_1
[2024-10-15 17:11:52,609] id: punggol_1
[2024-10-15 17:11:52,609] seed: 0
[2024-10-15 17:11:52,609] objectives_plan: 
[2024-10-15 17:11:52,609] init_plan: 
[2024-10-15 17:11:52,609] env_specs: {}
[2024-10-15 17:11:52,609] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-15 17:11:52,609] obs_specs: {}
[2024-10-15 17:11:52,609] agent_specs: {'batch_stage': False}
[2024-10-15 17:11:52,609] gamma: 0.9
[2024-10-15 17:11:52,609] tau: 0.0
[2024-10-15 17:11:52,609] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-15 17:11:52,609] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-15 17:11:52,609] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-15 17:11:52,609] lr: 0.0004
[2024-10-15 17:11:52,609] weightdecay: 0.0
[2024-10-15 17:11:52,609] eps: 1e-05
[2024-10-15 17:11:52,609] value_pred_coef: 0.5
[2024-10-15 17:11:52,609] entropy_coef: 0.01
[2024-10-15 17:11:52,609] clip_epsilon: 0.2
[2024-10-15 17:11:52,609] max_num_iterations: 3
[2024-10-15 17:11:52,609] num_episodes_per_iteration: 1200
[2024-10-15 17:11:52,609] max_sequence_length: 33
[2024-10-15 17:11:52,609] num_optim_epoch: 4
[2024-10-15 17:11:52,609] mini_batch_size: 1024
[2024-10-15 17:11:52,609] save_model_interval: 1
[2024-10-15 17:12:21,119] 0	T_sample 21.74	T_update 0.31	T_eval 6.01	ETA 0:00:56	train_R_eps -771.93	eval_R_eps -1.85	punggol_1	 1.7344388133626432	
[2024-10-15 17:12:21,123] save best checkpoint with rewards -1.85!
[2024-10-15 17:12:49,034] 1	T_sample 21.81	T_update 0.10	T_eval 6.00	ETA 0:00:28	train_R_eps -531.43	eval_R_eps -1.85	punggol_1	 1.7344388133626432	
[2024-10-15 17:13:17,915] 2	T_sample 22.69	T_update 0.10	T_eval 6.09	ETA 0:00:00	train_R_eps -649.98	eval_R_eps -1.85	punggol_1	 1.7344388133626432	
[2024-10-15 17:13:59,699] data_dir:data/punggol_1
[2024-10-15 17:13:59,699] id: punggol_1
[2024-10-15 17:13:59,699] seed: 0
[2024-10-15 17:13:59,699] objectives_plan: 
[2024-10-15 17:13:59,699] init_plan: 
[2024-10-15 17:13:59,700] env_specs: {}
[2024-10-15 17:13:59,700] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-15 17:13:59,700] obs_specs: {}
[2024-10-15 17:13:59,700] agent_specs: {'batch_stage': False}
[2024-10-15 17:13:59,700] gamma: 0.9
[2024-10-15 17:13:59,700] tau: 0.0
[2024-10-15 17:13:59,700] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-15 17:13:59,700] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-15 17:13:59,700] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-15 17:13:59,700] lr: 0.0004
[2024-10-15 17:13:59,700] weightdecay: 0.0
[2024-10-15 17:13:59,700] eps: 1e-05
[2024-10-15 17:13:59,700] value_pred_coef: 0.5
[2024-10-15 17:13:59,700] entropy_coef: 0.01
[2024-10-15 17:13:59,700] clip_epsilon: 0.2
[2024-10-15 17:13:59,700] max_num_iterations: 3
[2024-10-15 17:13:59,700] num_episodes_per_iteration: 1200
[2024-10-15 17:13:59,700] max_sequence_length: 33
[2024-10-15 17:13:59,700] num_optim_epoch: 4
[2024-10-15 17:13:59,700] mini_batch_size: 1024
[2024-10-15 17:13:59,700] save_model_interval: 1
[2024-10-15 17:14:28,164] 0	T_sample 21.66	T_update 0.31	T_eval 6.03	ETA 0:00:56	train_R_eps -771.93	eval_R_eps -1.85	punggol_1	 1.7344388133626432	
[2024-10-15 17:14:28,168] save best checkpoint with rewards -1.85!
[2024-10-15 17:14:57,777] data_dir:data/punggol_1
[2024-10-15 17:14:57,777] id: punggol_1
[2024-10-15 17:14:57,777] seed: 0
[2024-10-15 17:14:57,777] objectives_plan: 
[2024-10-15 17:14:57,777] init_plan: 
[2024-10-15 17:14:57,777] env_specs: {}
[2024-10-15 17:14:57,777] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-15 17:14:57,777] obs_specs: {}
[2024-10-15 17:14:57,777] agent_specs: {'batch_stage': False}
[2024-10-15 17:14:57,777] gamma: 0.9
[2024-10-15 17:14:57,777] tau: 0.0
[2024-10-15 17:14:57,777] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-15 17:14:57,777] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-15 17:14:57,777] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-15 17:14:57,777] lr: 0.0004
[2024-10-15 17:14:57,777] weightdecay: 0.0
[2024-10-15 17:14:57,777] eps: 1e-05
[2024-10-15 17:14:57,777] value_pred_coef: 0.5
[2024-10-15 17:14:57,777] entropy_coef: 0.01
[2024-10-15 17:14:57,777] clip_epsilon: 0.2
[2024-10-15 17:14:57,777] max_num_iterations: 3
[2024-10-15 17:14:57,777] num_episodes_per_iteration: 1200
[2024-10-15 17:14:57,777] max_sequence_length: 33
[2024-10-15 17:14:57,777] num_optim_epoch: 4
[2024-10-15 17:14:57,777] mini_batch_size: 1024
[2024-10-15 17:14:57,777] save_model_interval: 1
[2024-10-15 17:20:41,682] 0	T_sample 333.44	T_update 3.87	T_eval 6.14	ETA 0:11:27	train_R_eps -723.97	eval_R_eps -1.86	punggol_1	 1.730611916978815	
[2024-10-15 17:20:41,688] save best checkpoint with rewards -1.86!
[2024-10-16 15:05:39,334] data_dir:data/punggol_1
[2024-10-16 15:05:39,334] id: punggol_1
[2024-10-16 15:05:39,334] seed: 0
[2024-10-16 15:05:39,334] objectives_plan: 
[2024-10-16 15:05:39,334] init_plan: 
[2024-10-16 15:05:39,334] env_specs: {}
[2024-10-16 15:05:39,334] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-16 15:05:39,334] obs_specs: {}
[2024-10-16 15:05:39,334] agent_specs: {'batch_stage': False}
[2024-10-16 15:05:39,334] gamma: 0.9
[2024-10-16 15:05:39,334] tau: 0.0
[2024-10-16 15:05:39,334] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-16 15:05:39,334] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-16 15:05:39,334] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-16 15:05:39,334] lr: 0.0004
[2024-10-16 15:05:39,334] weightdecay: 0.0
[2024-10-16 15:05:39,334] eps: 1e-05
[2024-10-16 15:05:39,334] value_pred_coef: 0.5
[2024-10-16 15:05:39,334] entropy_coef: 0.01
[2024-10-16 15:05:39,334] clip_epsilon: 0.2
[2024-10-16 15:05:39,334] max_num_iterations: 2
[2024-10-16 15:05:39,334] num_episodes_per_iteration: 1200
[2024-10-16 15:05:39,334] max_sequence_length: 33
[2024-10-16 15:05:39,334] num_optim_epoch: 4
[2024-10-16 15:05:39,334] mini_batch_size: 1024
[2024-10-16 15:05:39,334] save_model_interval: 1
[2024-10-16 15:05:56,824] 0	T_sample 10.58	T_update 0.52	T_eval 5.93	ETA 0:00:17	train_R_eps -498.18	eval_R_eps -1.88	punggol_1	 1.739379403475711	
[2024-10-16 15:05:56,829] save best checkpoint with rewards -1.88!
[2024-10-16 15:06:14,671] 1	T_sample 11.77	T_update 0.21	T_eval 5.86	ETA 0:00:00	train_R_eps -1045.69	eval_R_eps -1.87	punggol_1	 1.744602312737949	
[2024-10-16 15:06:14,675] save best checkpoint with rewards -1.87!
[2024-10-16 15:25:12,746] data_dir:data/punggol_1
[2024-10-16 15:25:12,747] id: punggol_1
[2024-10-16 15:25:12,747] seed: 0
[2024-10-16 15:25:12,747] objectives_plan: 
[2024-10-16 15:25:12,747] init_plan: 
[2024-10-16 15:25:12,747] env_specs: {}
[2024-10-16 15:25:12,747] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-16 15:25:12,747] obs_specs: {}
[2024-10-16 15:25:12,747] agent_specs: {'batch_stage': False}
[2024-10-16 15:25:12,747] gamma: 0.9
[2024-10-16 15:25:12,747] tau: 0.0
[2024-10-16 15:25:12,747] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-16 15:25:12,747] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-16 15:25:12,747] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-16 15:25:12,747] lr: 0.0004
[2024-10-16 15:25:12,747] weightdecay: 0.0
[2024-10-16 15:25:12,747] eps: 1e-05
[2024-10-16 15:25:12,747] value_pred_coef: 0.5
[2024-10-16 15:25:12,747] entropy_coef: 0.01
[2024-10-16 15:25:12,747] clip_epsilon: 0.2
[2024-10-16 15:25:12,747] max_num_iterations: 2
[2024-10-16 15:25:12,747] num_episodes_per_iteration: 1200
[2024-10-16 15:25:12,747] max_sequence_length: 33
[2024-10-16 15:25:12,747] num_optim_epoch: 4
[2024-10-16 15:25:12,747] mini_batch_size: 1024
[2024-10-16 15:25:12,747] save_model_interval: 1
[2024-10-16 15:25:31,750] data_dir:data/punggol_1
[2024-10-16 15:25:31,750] id: punggol_1
[2024-10-16 15:25:31,750] seed: 0
[2024-10-16 15:25:31,750] objectives_plan: 
[2024-10-16 15:25:31,750] init_plan: 
[2024-10-16 15:25:31,750] env_specs: {}
[2024-10-16 15:25:31,750] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-16 15:25:31,750] obs_specs: {}
[2024-10-16 15:25:31,750] agent_specs: {'batch_stage': False}
[2024-10-16 15:25:31,750] gamma: 0.9
[2024-10-16 15:25:31,750] tau: 0.0
[2024-10-16 15:25:31,750] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-16 15:25:31,750] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-16 15:25:31,750] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-16 15:25:31,750] lr: 0.0004
[2024-10-16 15:25:31,750] weightdecay: 0.0
[2024-10-16 15:25:31,750] eps: 1e-05
[2024-10-16 15:25:31,750] value_pred_coef: 0.5
[2024-10-16 15:25:31,750] entropy_coef: 0.01
[2024-10-16 15:25:31,750] clip_epsilon: 0.2
[2024-10-16 15:25:31,750] max_num_iterations: 2
[2024-10-16 15:25:31,750] num_episodes_per_iteration: 1200
[2024-10-16 15:25:31,750] max_sequence_length: 33
[2024-10-16 15:25:31,750] num_optim_epoch: 4
[2024-10-16 15:25:31,750] mini_batch_size: 1024
[2024-10-16 15:25:31,750] save_model_interval: 1
[2024-10-16 15:25:49,127] 0	T_sample 10.58	T_update 0.43	T_eval 5.91	ETA 0:00:17	train_R_eps -498.18	eval_R_eps -1.88	punggol_1	 1.739379403475711	
[2024-10-16 15:25:49,131] save best checkpoint with rewards -1.88!
[2024-10-16 15:26:07,032] 1	T_sample 11.85	T_update 0.16	T_eval 5.88	ETA 0:00:00	train_R_eps -1045.69	eval_R_eps -1.87	punggol_1	 1.744602312737949	
[2024-10-16 15:26:07,036] save best checkpoint with rewards -1.87!
[2024-10-16 15:34:24,204] data_dir:data/punggol_1
[2024-10-16 15:34:24,204] id: punggol_1
[2024-10-16 15:34:24,204] seed: 0
[2024-10-16 15:34:24,204] objectives_plan: 
[2024-10-16 15:34:24,204] init_plan: 
[2024-10-16 15:34:24,204] env_specs: {}
[2024-10-16 15:34:24,204] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-16 15:34:24,204] obs_specs: {}
[2024-10-16 15:34:24,204] agent_specs: {'batch_stage': False}
[2024-10-16 15:34:24,204] gamma: 0.9
[2024-10-16 15:34:24,204] tau: 0.0
[2024-10-16 15:34:24,204] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-16 15:34:24,204] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-16 15:34:24,204] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-16 15:34:24,204] lr: 0.0004
[2024-10-16 15:34:24,204] weightdecay: 0.0
[2024-10-16 15:34:24,204] eps: 1e-05
[2024-10-16 15:34:24,204] value_pred_coef: 0.5
[2024-10-16 15:34:24,204] entropy_coef: 0.01
[2024-10-16 15:34:24,204] clip_epsilon: 0.2
[2024-10-16 15:34:24,204] max_num_iterations: 2
[2024-10-16 15:34:24,204] num_episodes_per_iteration: 1200
[2024-10-16 15:34:24,204] max_sequence_length: 33
[2024-10-16 15:34:24,204] num_optim_epoch: 4
[2024-10-16 15:34:24,204] mini_batch_size: 1024
[2024-10-16 15:34:24,204] save_model_interval: 1
[2024-10-16 15:34:41,546] 0	T_sample 10.57	T_update 0.46	T_eval 5.85	ETA 0:00:17	train_R_eps -498.18	eval_R_eps -1.88	punggol_1	 1.739379403475711	
[2024-10-16 15:34:41,550] save best checkpoint with rewards -1.88!
[2024-10-16 15:34:59,144] 1	T_sample 11.65	T_update 0.15	T_eval 5.79	ETA 0:00:00	train_R_eps -1045.69	eval_R_eps -1.87	punggol_1	 1.744602312737949	
[2024-10-16 15:34:59,147] save best checkpoint with rewards -1.87!
[2024-10-16 15:35:30,416] data_dir:data/punggol_1
[2024-10-16 15:35:30,416] id: punggol_1
[2024-10-16 15:35:30,416] seed: 0
[2024-10-16 15:35:30,416] objectives_plan: 
[2024-10-16 15:35:30,416] init_plan: 
[2024-10-16 15:35:30,416] env_specs: {}
[2024-10-16 15:35:30,416] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-16 15:35:30,416] obs_specs: {}
[2024-10-16 15:35:30,416] agent_specs: {'batch_stage': False}
[2024-10-16 15:35:30,416] gamma: 0.9
[2024-10-16 15:35:30,416] tau: 0.0
[2024-10-16 15:35:30,416] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-16 15:35:30,416] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-16 15:35:30,416] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-16 15:35:30,416] lr: 0.0004
[2024-10-16 15:35:30,416] weightdecay: 0.0
[2024-10-16 15:35:30,416] eps: 1e-05
[2024-10-16 15:35:30,416] value_pred_coef: 0.5
[2024-10-16 15:35:30,416] entropy_coef: 0.01
[2024-10-16 15:35:30,416] clip_epsilon: 0.2
[2024-10-16 15:35:30,416] max_num_iterations: 2
[2024-10-16 15:35:30,416] num_episodes_per_iteration: 1200
[2024-10-16 15:35:30,416] max_sequence_length: 33
[2024-10-16 15:35:30,416] num_optim_epoch: 4
[2024-10-16 15:35:30,416] mini_batch_size: 1024
[2024-10-16 15:35:30,416] save_model_interval: 1
[2024-10-16 15:35:39,846] data_dir:data/punggol_1
[2024-10-16 15:35:39,846] id: punggol_1
[2024-10-16 15:35:39,846] seed: 0
[2024-10-16 15:35:39,846] objectives_plan: 
[2024-10-16 15:35:39,846] init_plan: 
[2024-10-16 15:35:39,846] env_specs: {}
[2024-10-16 15:35:39,847] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-16 15:35:39,847] obs_specs: {}
[2024-10-16 15:35:39,847] agent_specs: {'batch_stage': False}
[2024-10-16 15:35:39,847] gamma: 0.9
[2024-10-16 15:35:39,847] tau: 0.0
[2024-10-16 15:35:39,847] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-16 15:35:39,847] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-16 15:35:39,847] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-16 15:35:39,847] lr: 0.0004
[2024-10-16 15:35:39,847] weightdecay: 0.0
[2024-10-16 15:35:39,847] eps: 1e-05
[2024-10-16 15:35:39,847] value_pred_coef: 0.5
[2024-10-16 15:35:39,847] entropy_coef: 0.01
[2024-10-16 15:35:39,847] clip_epsilon: 0.2
[2024-10-16 15:35:39,847] max_num_iterations: 2
[2024-10-16 15:35:39,847] num_episodes_per_iteration: 1200
[2024-10-16 15:35:39,847] max_sequence_length: 33
[2024-10-16 15:35:39,847] num_optim_epoch: 4
[2024-10-16 15:35:39,847] mini_batch_size: 1024
[2024-10-16 15:35:39,847] save_model_interval: 1
[2024-10-16 15:35:57,276] 0	T_sample 10.56	T_update 0.45	T_eval 5.96	ETA 0:00:17	train_R_eps -498.18	eval_R_eps -1.88	punggol_1	 1.739379403475711	
[2024-10-16 15:35:57,280] save best checkpoint with rewards -1.88!
[2024-10-16 15:36:15,023] 1	T_sample 11.66	T_update 0.20	T_eval 5.87	ETA 0:00:00	train_R_eps -1045.69	eval_R_eps -1.87	punggol_1	 1.744602312737949	
[2024-10-16 15:36:15,027] save best checkpoint with rewards -1.87!
[2024-10-16 15:39:53,103] data_dir:data/punggol_1
[2024-10-16 15:39:53,103] id: punggol_1
[2024-10-16 15:39:53,103] seed: 0
[2024-10-16 15:39:53,103] objectives_plan: 
[2024-10-16 15:39:53,103] init_plan: 
[2024-10-16 15:39:53,103] env_specs: {}
[2024-10-16 15:39:53,103] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-16 15:39:53,103] obs_specs: {}
[2024-10-16 15:39:53,103] agent_specs: {'batch_stage': False}
[2024-10-16 15:39:53,103] gamma: 0.9
[2024-10-16 15:39:53,103] tau: 0.0
[2024-10-16 15:39:53,103] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-16 15:39:53,103] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-16 15:39:53,103] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-16 15:39:53,103] lr: 0.0004
[2024-10-16 15:39:53,103] weightdecay: 0.0
[2024-10-16 15:39:53,103] eps: 1e-05
[2024-10-16 15:39:53,103] value_pred_coef: 0.5
[2024-10-16 15:39:53,103] entropy_coef: 0.01
[2024-10-16 15:39:53,103] clip_epsilon: 0.2
[2024-10-16 15:39:53,103] max_num_iterations: 2
[2024-10-16 15:39:53,103] num_episodes_per_iteration: 1200
[2024-10-16 15:39:53,103] max_sequence_length: 33
[2024-10-16 15:39:53,103] num_optim_epoch: 4
[2024-10-16 15:39:53,103] mini_batch_size: 1024
[2024-10-16 15:39:53,103] save_model_interval: 1
[2024-10-16 15:40:49,339] data_dir:data/punggol_1
[2024-10-16 15:40:49,339] id: punggol_1
[2024-10-16 15:40:49,339] seed: 0
[2024-10-16 15:40:49,339] objectives_plan: 
[2024-10-16 15:40:49,339] init_plan: 
[2024-10-16 15:40:49,339] env_specs: {}
[2024-10-16 15:40:49,339] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-16 15:40:49,339] obs_specs: {}
[2024-10-16 15:40:49,339] agent_specs: {'batch_stage': False}
[2024-10-16 15:40:49,339] gamma: 0.9
[2024-10-16 15:40:49,339] tau: 0.0
[2024-10-16 15:40:49,339] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-16 15:40:49,339] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-16 15:40:49,339] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-16 15:40:49,339] lr: 0.0004
[2024-10-16 15:40:49,339] weightdecay: 0.0
[2024-10-16 15:40:49,339] eps: 1e-05
[2024-10-16 15:40:49,339] value_pred_coef: 0.5
[2024-10-16 15:40:49,339] entropy_coef: 0.01
[2024-10-16 15:40:49,339] clip_epsilon: 0.2
[2024-10-16 15:40:49,339] max_num_iterations: 2
[2024-10-16 15:40:49,339] num_episodes_per_iteration: 1200
[2024-10-16 15:40:49,339] max_sequence_length: 33
[2024-10-16 15:40:49,339] num_optim_epoch: 4
[2024-10-16 15:40:49,339] mini_batch_size: 1024
[2024-10-16 15:40:49,339] save_model_interval: 1
[2024-10-16 15:41:07,008] 0	T_sample 10.72	T_update 0.47	T_eval 6.03	ETA 0:00:17	train_R_eps -498.18	eval_R_eps -1.88	punggol_1	 1.739379403475711	
[2024-10-16 15:41:07,013] save best checkpoint with rewards -1.88!
[2024-10-16 15:58:21,287] data_dir:data/punggol_1
[2024-10-16 15:58:21,287] id: punggol_1
[2024-10-16 15:58:21,287] seed: 0
[2024-10-16 15:58:21,287] objectives_plan: 
[2024-10-16 15:58:21,287] init_plan: 
[2024-10-16 15:58:21,287] env_specs: {}
[2024-10-16 15:58:21,287] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-16 15:58:21,287] obs_specs: {}
[2024-10-16 15:58:21,287] agent_specs: {'batch_stage': False}
[2024-10-16 15:58:21,287] gamma: 0.9
[2024-10-16 15:58:21,287] tau: 0.0
[2024-10-16 15:58:21,287] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-16 15:58:21,287] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-16 15:58:21,287] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-16 15:58:21,287] lr: 0.0004
[2024-10-16 15:58:21,287] weightdecay: 0.0
[2024-10-16 15:58:21,287] eps: 1e-05
[2024-10-16 15:58:21,287] value_pred_coef: 0.5
[2024-10-16 15:58:21,287] entropy_coef: 0.01
[2024-10-16 15:58:21,287] clip_epsilon: 0.2
[2024-10-16 15:58:21,287] max_num_iterations: 2
[2024-10-16 15:58:21,287] num_episodes_per_iteration: 1200
[2024-10-16 15:58:21,287] max_sequence_length: 33
[2024-10-16 15:58:21,287] num_optim_epoch: 4
[2024-10-16 15:58:21,287] mini_batch_size: 1024
[2024-10-16 15:58:21,287] save_model_interval: 1
[2024-10-16 15:58:38,677] 0	T_sample 10.48	T_update 0.52	T_eval 5.94	ETA 0:00:17	train_R_eps -498.18	eval_R_eps -1.88	punggol_1	 1.739379403475711	
[2024-10-16 15:58:38,681] save best checkpoint with rewards -1.88!
[2024-10-16 15:58:56,415] 1	T_sample 11.65	T_update 0.23	T_eval 5.84	ETA 0:00:00	train_R_eps -1045.69	eval_R_eps -1.87	punggol_1	 1.744602312737949	
[2024-10-16 15:58:56,419] save best checkpoint with rewards -1.87!
[2024-10-16 18:41:27,670] data_dir:data/punggol_1
[2024-10-16 18:41:27,671] id: punggol_1
[2024-10-16 18:41:27,671] seed: 0
[2024-10-16 18:41:27,671] objectives_plan: 
[2024-10-16 18:41:27,671] init_plan: 
[2024-10-16 18:41:27,671] env_specs: {}
[2024-10-16 18:41:27,671] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-16 18:41:27,671] obs_specs: {}
[2024-10-16 18:41:27,671] agent_specs: {'batch_stage': False}
[2024-10-16 18:41:27,671] gamma: 0.9
[2024-10-16 18:41:27,671] tau: 0.0
[2024-10-16 18:41:27,671] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-16 18:41:27,671] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-16 18:41:27,671] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-16 18:41:27,671] lr: 0.0004
[2024-10-16 18:41:27,671] weightdecay: 0.0
[2024-10-16 18:41:27,671] eps: 1e-05
[2024-10-16 18:41:27,671] value_pred_coef: 0.5
[2024-10-16 18:41:27,671] entropy_coef: 0.01
[2024-10-16 18:41:27,671] clip_epsilon: 0.2
[2024-10-16 18:41:27,671] max_num_iterations: 2
[2024-10-16 18:41:27,671] num_episodes_per_iteration: 1200
[2024-10-16 18:41:27,671] max_sequence_length: 33
[2024-10-16 18:41:27,671] num_optim_epoch: 4
[2024-10-16 18:41:27,671] mini_batch_size: 1024
[2024-10-16 18:41:27,671] save_model_interval: 1
[2024-10-16 18:41:38,436] 0	T_sample 3.38	T_update 0.76	T_eval 6.17	ETA 0:00:10	train_R_eps -564.01	eval_R_eps -1.86	punggol_1	 1.7290220692461413	
[2024-10-16 18:41:38,440] save best checkpoint with rewards -1.86!
[2024-10-16 18:41:48,325] 1	T_sample 3.27	T_update 0.46	T_eval 6.14	ETA 0:00:00	train_R_eps -1.75	eval_R_eps -1.88	punggol_1	 1.7343006987460121	
[2024-10-16 19:02:38,713] data_dir:data/punggol_1
[2024-10-16 19:02:38,713] id: punggol_1
[2024-10-16 19:02:38,713] seed: 0
[2024-10-16 19:02:38,713] objectives_plan: 
[2024-10-16 19:02:38,713] init_plan: 
[2024-10-16 19:02:38,713] env_specs: {}
[2024-10-16 19:02:38,713] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-16 19:02:38,713] obs_specs: {}
[2024-10-16 19:02:38,713] agent_specs: {'batch_stage': False}
[2024-10-16 19:02:38,713] gamma: 0.9
[2024-10-16 19:02:38,713] tau: 0.0
[2024-10-16 19:02:38,713] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-16 19:02:38,713] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-16 19:02:38,713] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-16 19:02:38,713] lr: 0.0004
[2024-10-16 19:02:38,713] weightdecay: 0.0
[2024-10-16 19:02:38,713] eps: 1e-05
[2024-10-16 19:02:38,713] value_pred_coef: 0.5
[2024-10-16 19:02:38,713] entropy_coef: 0.01
[2024-10-16 19:02:38,713] clip_epsilon: 0.2
[2024-10-16 19:02:38,713] max_num_iterations: 2
[2024-10-16 19:02:38,713] num_episodes_per_iteration: 1200
[2024-10-16 19:02:38,713] max_sequence_length: 33
[2024-10-16 19:02:38,713] num_optim_epoch: 4
[2024-10-16 19:02:38,713] mini_batch_size: 1024
[2024-10-16 19:02:38,713] save_model_interval: 1
[2024-10-16 19:02:49,336] 0	T_sample 3.35	T_update 0.75	T_eval 6.07	ETA 0:00:10	train_R_eps -564.01	eval_R_eps -1.86	punggol_1	 1.7290220692461413	
[2024-10-16 19:02:49,340] save best checkpoint with rewards -1.86!
[2024-10-16 19:03:06,372] data_dir:data/punggol_1
[2024-10-16 19:03:06,373] id: punggol_1
[2024-10-16 19:03:06,373] seed: 0
[2024-10-16 19:03:06,373] objectives_plan: 
[2024-10-16 19:03:06,373] init_plan: 
[2024-10-16 19:03:06,373] env_specs: {}
[2024-10-16 19:03:06,373] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-16 19:03:06,373] obs_specs: {}
[2024-10-16 19:03:06,373] agent_specs: {'batch_stage': False}
[2024-10-16 19:03:06,373] gamma: 0.9
[2024-10-16 19:03:06,373] tau: 0.0
[2024-10-16 19:03:06,373] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-16 19:03:06,373] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-16 19:03:06,373] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-16 19:03:06,373] lr: 0.0004
[2024-10-16 19:03:06,373] weightdecay: 0.0
[2024-10-16 19:03:06,373] eps: 1e-05
[2024-10-16 19:03:06,373] value_pred_coef: 0.5
[2024-10-16 19:03:06,373] entropy_coef: 0.01
[2024-10-16 19:03:06,373] clip_epsilon: 0.2
[2024-10-16 19:03:06,373] max_num_iterations: 2
[2024-10-16 19:03:06,373] num_episodes_per_iteration: 1200
[2024-10-16 19:03:06,373] max_sequence_length: 33
[2024-10-16 19:03:06,373] num_optim_epoch: 4
[2024-10-16 19:03:06,373] mini_batch_size: 1024
[2024-10-16 19:03:06,373] save_model_interval: 1
[2024-10-16 19:03:58,604] data_dir:data/punggol_1
[2024-10-16 19:03:58,604] id: punggol_1
[2024-10-16 19:03:58,604] seed: 0
[2024-10-16 19:03:58,604] objectives_plan: 
[2024-10-16 19:03:58,604] init_plan: 
[2024-10-16 19:03:58,604] env_specs: {}
[2024-10-16 19:03:58,605] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-16 19:03:58,605] obs_specs: {}
[2024-10-16 19:03:58,605] agent_specs: {'batch_stage': False}
[2024-10-16 19:03:58,605] gamma: 0.9
[2024-10-16 19:03:58,605] tau: 0.0
[2024-10-16 19:03:58,605] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-16 19:03:58,605] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-16 19:03:58,605] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-16 19:03:58,605] lr: 0.0004
[2024-10-16 19:03:58,605] weightdecay: 0.0
[2024-10-16 19:03:58,605] eps: 1e-05
[2024-10-16 19:03:58,605] value_pred_coef: 0.5
[2024-10-16 19:03:58,605] entropy_coef: 0.01
[2024-10-16 19:03:58,605] clip_epsilon: 0.2
[2024-10-16 19:03:58,605] max_num_iterations: 2
[2024-10-16 19:03:58,605] num_episodes_per_iteration: 1200
[2024-10-16 19:03:58,605] max_sequence_length: 33
[2024-10-16 19:03:58,605] num_optim_epoch: 4
[2024-10-16 19:03:58,605] mini_batch_size: 1024
[2024-10-16 19:03:58,605] save_model_interval: 1
[2024-10-16 19:04:09,193] 0	T_sample 3.37	T_update 0.76	T_eval 6.01	ETA 0:00:10	train_R_eps -564.01	eval_R_eps -1.86	punggol_1	 1.7290220692461413	
[2024-10-16 19:04:09,197] save best checkpoint with rewards -1.86!
[2024-10-16 19:04:27,002] data_dir:data/punggol_1
[2024-10-16 19:04:27,003] id: punggol_1
[2024-10-16 19:04:27,003] seed: 0
[2024-10-16 19:04:27,003] objectives_plan: 
[2024-10-16 19:04:27,003] init_plan: 
[2024-10-16 19:04:27,003] env_specs: {}
[2024-10-16 19:04:27,003] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-16 19:04:27,003] obs_specs: {}
[2024-10-16 19:04:27,003] agent_specs: {'batch_stage': False}
[2024-10-16 19:04:27,003] gamma: 0.9
[2024-10-16 19:04:27,003] tau: 0.0
[2024-10-16 19:04:27,003] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-16 19:04:27,003] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-16 19:04:27,003] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-16 19:04:27,003] lr: 0.0004
[2024-10-16 19:04:27,003] weightdecay: 0.0
[2024-10-16 19:04:27,003] eps: 1e-05
[2024-10-16 19:04:27,003] value_pred_coef: 0.5
[2024-10-16 19:04:27,003] entropy_coef: 0.01
[2024-10-16 19:04:27,003] clip_epsilon: 0.2
[2024-10-16 19:04:27,003] max_num_iterations: 2
[2024-10-16 19:04:27,003] num_episodes_per_iteration: 1200
[2024-10-16 19:04:27,003] max_sequence_length: 33
[2024-10-16 19:04:27,003] num_optim_epoch: 4
[2024-10-16 19:04:27,003] mini_batch_size: 1024
[2024-10-16 19:04:27,003] save_model_interval: 1
[2024-10-16 19:04:37,688] 0	T_sample 3.36	T_update 0.80	T_eval 6.08	ETA 0:00:10	train_R_eps -564.01	eval_R_eps -1.86	punggol_1	 1.7290220692461413	
[2024-10-16 19:04:37,692] save best checkpoint with rewards -1.86!
[2024-10-16 19:04:44,075] data_dir:data/punggol_1
[2024-10-16 19:04:44,075] id: punggol_1
[2024-10-16 19:04:44,075] seed: 0
[2024-10-16 19:04:44,075] objectives_plan: 
[2024-10-16 19:04:44,075] init_plan: 
[2024-10-16 19:04:44,075] env_specs: {}
[2024-10-16 19:04:44,075] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-16 19:04:44,075] obs_specs: {}
[2024-10-16 19:04:44,075] agent_specs: {'batch_stage': False}
[2024-10-16 19:04:44,075] gamma: 0.9
[2024-10-16 19:04:44,075] tau: 0.0
[2024-10-16 19:04:44,075] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-16 19:04:44,075] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-16 19:04:44,075] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-16 19:04:44,075] lr: 0.0004
[2024-10-16 19:04:44,075] weightdecay: 0.0
[2024-10-16 19:04:44,076] eps: 1e-05
[2024-10-16 19:04:44,076] value_pred_coef: 0.5
[2024-10-16 19:04:44,076] entropy_coef: 0.01
[2024-10-16 19:04:44,076] clip_epsilon: 0.2
[2024-10-16 19:04:44,076] max_num_iterations: 2
[2024-10-16 19:04:44,076] num_episodes_per_iteration: 1200
[2024-10-16 19:04:44,076] max_sequence_length: 33
[2024-10-16 19:04:44,076] num_optim_epoch: 4
[2024-10-16 19:04:44,076] mini_batch_size: 1024
[2024-10-16 19:04:44,076] save_model_interval: 1
[2024-10-16 19:05:47,433] data_dir:data/punggol_1
[2024-10-16 19:05:47,433] id: punggol_1
[2024-10-16 19:05:47,433] seed: 0
[2024-10-16 19:05:47,433] objectives_plan: 
[2024-10-16 19:05:47,433] init_plan: 
[2024-10-16 19:05:47,433] env_specs: {}
[2024-10-16 19:05:47,433] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-16 19:05:47,433] obs_specs: {}
[2024-10-16 19:05:47,433] agent_specs: {'batch_stage': False}
[2024-10-16 19:05:47,433] gamma: 0.9
[2024-10-16 19:05:47,433] tau: 0.0
[2024-10-16 19:05:47,433] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-16 19:05:47,433] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-16 19:05:47,433] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-16 19:05:47,433] lr: 0.0004
[2024-10-16 19:05:47,433] weightdecay: 0.0
[2024-10-16 19:05:47,433] eps: 1e-05
[2024-10-16 19:05:47,433] value_pred_coef: 0.5
[2024-10-16 19:05:47,433] entropy_coef: 0.01
[2024-10-16 19:05:47,433] clip_epsilon: 0.2
[2024-10-16 19:05:47,433] max_num_iterations: 2
[2024-10-16 19:05:47,433] num_episodes_per_iteration: 1200
[2024-10-16 19:05:47,433] max_sequence_length: 33
[2024-10-16 19:05:47,433] num_optim_epoch: 4
[2024-10-16 19:05:47,433] mini_batch_size: 1024
[2024-10-16 19:05:47,433] save_model_interval: 1
[2024-10-16 19:05:58,105] 0	T_sample 3.42	T_update 0.76	T_eval 6.03	ETA 0:00:10	train_R_eps -564.01	eval_R_eps -1.86	punggol_1	 1.7290220692461413	
[2024-10-16 19:05:58,109] save best checkpoint with rewards -1.86!
[2024-10-17 13:05:08,964] data_dir:data/punggol_1
[2024-10-17 13:05:08,964] id: punggol_1
[2024-10-17 13:05:08,964] seed: 0
[2024-10-17 13:05:08,965] objectives_plan: 
[2024-10-17 13:05:08,965] init_plan: 
[2024-10-17 13:05:08,965] env_specs: {}
[2024-10-17 13:05:08,965] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-17 13:05:08,965] obs_specs: {}
[2024-10-17 13:05:08,965] agent_specs: {'batch_stage': False}
[2024-10-17 13:05:08,965] gamma: 0.9
[2024-10-17 13:05:08,965] tau: 0.0
[2024-10-17 13:05:08,965] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-17 13:05:08,965] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-17 13:05:08,965] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-17 13:05:08,965] lr: 0.0004
[2024-10-17 13:05:08,965] weightdecay: 0.0
[2024-10-17 13:05:08,965] eps: 1e-05
[2024-10-17 13:05:08,965] value_pred_coef: 0.5
[2024-10-17 13:05:08,965] entropy_coef: 0.01
[2024-10-17 13:05:08,965] clip_epsilon: 0.2
[2024-10-17 13:05:08,965] max_num_iterations: 2
[2024-10-17 13:05:08,965] num_episodes_per_iteration: 1200
[2024-10-17 13:05:08,965] max_sequence_length: 33
[2024-10-17 13:05:08,965] num_optim_epoch: 4
[2024-10-17 13:05:08,965] mini_batch_size: 1024
[2024-10-17 13:05:08,965] save_model_interval: 1
[2024-10-17 13:05:19,515] 0	T_sample 3.34	T_update 0.76	T_eval 6.00	ETA 0:00:10	train_R_eps -564.01	eval_R_eps -1.86	punggol_1	 1.7290220692461413	
[2024-10-17 13:05:19,519] save best checkpoint with rewards -1.86!
[2024-10-17 13:18:31,133] data_dir:data/punggol_1
[2024-10-17 13:18:31,133] id: punggol_1
[2024-10-17 13:18:31,134] seed: 0
[2024-10-17 13:18:31,134] objectives_plan: 
[2024-10-17 13:18:31,134] init_plan: 
[2024-10-17 13:18:31,134] env_specs: {}
[2024-10-17 13:18:31,134] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-17 13:18:31,134] obs_specs: {}
[2024-10-17 13:18:31,134] agent_specs: {'batch_stage': False}
[2024-10-17 13:18:31,134] gamma: 0.9
[2024-10-17 13:18:31,134] tau: 0.0
[2024-10-17 13:18:31,134] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-17 13:18:31,134] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-17 13:18:31,134] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-17 13:18:31,134] lr: 0.0004
[2024-10-17 13:18:31,134] weightdecay: 0.0
[2024-10-17 13:18:31,134] eps: 1e-05
[2024-10-17 13:18:31,134] value_pred_coef: 0.5
[2024-10-17 13:18:31,134] entropy_coef: 0.01
[2024-10-17 13:18:31,134] clip_epsilon: 0.2
[2024-10-17 13:18:31,134] max_num_iterations: 2
[2024-10-17 13:18:31,134] num_episodes_per_iteration: 1200
[2024-10-17 13:18:31,134] max_sequence_length: 33
[2024-10-17 13:18:31,134] num_optim_epoch: 4
[2024-10-17 13:18:31,134] mini_batch_size: 1024
[2024-10-17 13:18:31,134] save_model_interval: 1
[2024-10-17 13:18:41,649] 0	T_sample 3.31	T_update 0.77	T_eval 5.98	ETA 0:00:10	train_R_eps -564.01	eval_R_eps -1.86	punggol_1	 1.7290220692461413	
[2024-10-17 13:18:41,654] save best checkpoint with rewards -1.86!
[2024-10-17 13:18:51,442] 1	T_sample 3.28	T_update 0.46	T_eval 6.04	ETA 0:00:00	train_R_eps -1.75	eval_R_eps -1.88	punggol_1	 1.7343006987460121	
[2024-10-17 13:37:49,252] data_dir:data/punggol_1
[2024-10-17 13:37:49,252] id: punggol_1
[2024-10-17 13:37:49,252] seed: 0
[2024-10-17 13:37:49,252] objectives_plan: 
[2024-10-17 13:37:49,252] init_plan: 
[2024-10-17 13:37:49,253] env_specs: {}
[2024-10-17 13:37:49,253] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-10-17 13:37:49,253] obs_specs: {}
[2024-10-17 13:37:49,253] agent_specs: {'batch_stage': False}
[2024-10-17 13:37:49,253] gamma: 0.9
[2024-10-17 13:37:49,253] tau: 0.0
[2024-10-17 13:37:49,253] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-17 13:37:49,253] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-17 13:37:49,253] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-17 13:37:49,253] lr: 0.0004
[2024-10-17 13:37:49,253] weightdecay: 0.0
[2024-10-17 13:37:49,253] eps: 1e-05
[2024-10-17 13:37:49,253] value_pred_coef: 0.5
[2024-10-17 13:37:49,253] entropy_coef: 0.01
[2024-10-17 13:37:49,253] clip_epsilon: 0.2
[2024-10-17 13:37:49,253] max_num_iterations: 2
[2024-10-17 13:37:49,253] num_episodes_per_iteration: 1200
[2024-10-17 13:37:49,253] max_sequence_length: 33
[2024-10-17 13:37:49,253] num_optim_epoch: 4
[2024-10-17 13:37:49,253] mini_batch_size: 1024
[2024-10-17 13:37:49,253] save_model_interval: 1
[2024-10-17 13:37:59,166] 0	T_sample 3.18	T_update 0.39	T_eval 5.88	ETA 0:00:09	train_R_eps -564.01	eval_R_eps -1.86	punggol_1	 1.7290220692461413	
[2024-10-17 13:37:59,170] save best checkpoint with rewards -1.86!
[2024-10-17 13:38:08,213] 1	T_sample 3.13	T_update 0.08	T_eval 5.83	ETA 0:00:00	train_R_eps -1.75	eval_R_eps -1.88	punggol_1	 1.7343006987460121	
[2024-10-17 13:39:36,777] data_dir:data/punggol_1
[2024-10-17 13:39:36,777] id: punggol_1
[2024-10-17 13:39:36,777] seed: 0
[2024-10-17 13:39:36,777] objectives_plan: 
[2024-10-17 13:39:36,777] init_plan: 
[2024-10-17 13:39:36,777] env_specs: {}
[2024-10-17 13:39:36,777] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.1}
[2024-10-17 13:39:36,777] obs_specs: {}
[2024-10-17 13:39:36,777] agent_specs: {'batch_stage': False}
[2024-10-17 13:39:36,777] gamma: 0.9
[2024-10-17 13:39:36,777] tau: 0.0
[2024-10-17 13:39:36,777] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-17 13:39:36,777] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-17 13:39:36,777] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-17 13:39:36,777] lr: 0.0004
[2024-10-17 13:39:36,778] weightdecay: 0.0
[2024-10-17 13:39:36,778] eps: 1e-05
[2024-10-17 13:39:36,778] value_pred_coef: 0.5
[2024-10-17 13:39:36,778] entropy_coef: 0.01
[2024-10-17 13:39:36,778] clip_epsilon: 0.2
[2024-10-17 13:39:36,778] max_num_iterations: 2
[2024-10-17 13:39:36,778] num_episodes_per_iteration: 1200
[2024-10-17 13:39:36,778] max_sequence_length: 33
[2024-10-17 13:39:36,778] num_optim_epoch: 4
[2024-10-17 13:39:36,778] mini_batch_size: 1024
[2024-10-17 13:39:36,778] save_model_interval: 1
[2024-10-17 13:39:41,792] 0	T_sample 3.09	T_update 0.38	T_eval 1.09	ETA 0:00:05	train_R_eps -2304.18	eval_R_eps -2470.22	punggol_1	 3415.5448544124592	
[2024-10-17 13:39:46,049] 1	T_sample 3.00	T_update 0.15	T_eval 1.10	ETA 0:00:00	train_R_eps -2437.17	eval_R_eps -2470.22	punggol_1	 3415.5448544124592	
[2024-10-17 13:41:05,981] data_dir:data/punggol_1
[2024-10-17 13:41:05,982] id: punggol_1
[2024-10-17 13:41:05,982] seed: 0
[2024-10-17 13:41:05,982] objectives_plan: 
[2024-10-17 13:41:05,982] init_plan: 
[2024-10-17 13:41:05,982] env_specs: {}
[2024-10-17 13:41:05,982] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.1}
[2024-10-17 13:41:05,982] obs_specs: {}
[2024-10-17 13:41:05,982] agent_specs: {'batch_stage': False}
[2024-10-17 13:41:05,982] gamma: 0.9
[2024-10-17 13:41:05,982] tau: 0.0
[2024-10-17 13:41:05,982] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-17 13:41:05,982] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-17 13:41:05,982] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-17 13:41:05,982] lr: 0.0004
[2024-10-17 13:41:05,982] weightdecay: 0.0
[2024-10-17 13:41:05,982] eps: 1e-05
[2024-10-17 13:41:05,982] value_pred_coef: 0.5
[2024-10-17 13:41:05,982] entropy_coef: 0.01
[2024-10-17 13:41:05,982] clip_epsilon: 0.2
[2024-10-17 13:41:05,982] max_num_iterations: 2
[2024-10-17 13:41:05,982] num_episodes_per_iteration: 1200
[2024-10-17 13:41:05,982] max_sequence_length: 33
[2024-10-17 13:41:05,982] num_optim_epoch: 4
[2024-10-17 13:41:05,982] mini_batch_size: 1024
[2024-10-17 13:41:05,982] save_model_interval: 1
[2024-10-17 13:41:10,988] 0	T_sample 3.09	T_update 0.37	T_eval 1.09	ETA 0:00:05	train_R_eps -2304.18	eval_R_eps -2470.22	punggol_1	 3415.5448544124592	
[2024-10-17 13:41:15,177] 1	T_sample 3.01	T_update 0.08	T_eval 1.10	ETA 0:00:00	train_R_eps -2437.17	eval_R_eps -2470.22	punggol_1	 3415.5448544124592	
[2024-10-17 13:41:57,956] data_dir:data/punggol_1
[2024-10-17 13:41:57,956] id: punggol_1
[2024-10-17 13:41:57,956] seed: 0
[2024-10-17 13:41:57,956] objectives_plan: 
[2024-10-17 13:41:57,956] init_plan: 
[2024-10-17 13:41:57,956] env_specs: {}
[2024-10-17 13:41:57,956] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.1}
[2024-10-17 13:41:57,956] obs_specs: {}
[2024-10-17 13:41:57,956] agent_specs: {'batch_stage': False}
[2024-10-17 13:41:57,956] gamma: 0.9
[2024-10-17 13:41:57,956] tau: 0.0
[2024-10-17 13:41:57,956] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-17 13:41:57,956] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-17 13:41:57,956] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-17 13:41:57,956] lr: 0.0004
[2024-10-17 13:41:57,956] weightdecay: 0.0
[2024-10-17 13:41:57,956] eps: 1e-05
[2024-10-17 13:41:57,956] value_pred_coef: 0.5
[2024-10-17 13:41:57,956] entropy_coef: 0.01
[2024-10-17 13:41:57,956] clip_epsilon: 0.2
[2024-10-17 13:41:57,956] max_num_iterations: 2
[2024-10-17 13:41:57,956] num_episodes_per_iteration: 1200
[2024-10-17 13:41:57,956] max_sequence_length: 33
[2024-10-17 13:41:57,956] num_optim_epoch: 4
[2024-10-17 13:41:57,956] mini_batch_size: 1024
[2024-10-17 13:41:57,956] save_model_interval: 1
[2024-10-17 13:42:03,590] 0	T_sample 3.69	T_update 0.40	T_eval 1.10	ETA 0:00:05	train_R_eps -2331.85	eval_R_eps -2470.22	punggol_1	 3415.5448544124592	
[2024-10-17 13:42:08,470] 1	T_sample 3.68	T_update 0.09	T_eval 1.10	ETA 0:00:00	train_R_eps -2415.47	eval_R_eps -2470.22	punggol_1	 3415.5448544124592	
[2024-10-17 13:43:28,877] data_dir:data/punggol_1
[2024-10-17 13:43:28,877] id: punggol_1
[2024-10-17 13:43:28,877] seed: 0
[2024-10-17 13:43:28,877] objectives_plan: 
[2024-10-17 13:43:28,877] init_plan: 
[2024-10-17 13:43:28,877] env_specs: {}
[2024-10-17 13:43:28,877] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.1}
[2024-10-17 13:43:28,877] obs_specs: {}
[2024-10-17 13:43:28,877] agent_specs: {'batch_stage': False}
[2024-10-17 13:43:28,877] gamma: 0.9
[2024-10-17 13:43:28,877] tau: 0.0
[2024-10-17 13:43:28,877] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-17 13:43:28,877] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-17 13:43:28,877] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-17 13:43:28,877] lr: 0.0004
[2024-10-17 13:43:28,877] weightdecay: 0.0
[2024-10-17 13:43:28,877] eps: 1e-05
[2024-10-17 13:43:28,877] value_pred_coef: 0.5
[2024-10-17 13:43:28,877] entropy_coef: 0.01
[2024-10-17 13:43:28,877] clip_epsilon: 0.2
[2024-10-17 13:43:28,877] max_num_iterations: 2
[2024-10-17 13:43:28,877] num_episodes_per_iteration: 1200
[2024-10-17 13:43:28,877] max_sequence_length: 33
[2024-10-17 13:43:28,877] num_optim_epoch: 4
[2024-10-17 13:43:28,877] mini_batch_size: 1024
[2024-10-17 13:43:28,877] save_model_interval: 1
[2024-10-17 13:43:33,934] 0	T_sample 3.12	T_update 0.38	T_eval 1.10	ETA 0:00:05	train_R_eps -2304.18	eval_R_eps -2470.22	punggol_1	 3415.5448544124592	
[2024-10-17 13:43:38,143] 1	T_sample 3.02	T_update 0.08	T_eval 1.11	ETA 0:00:00	train_R_eps -2437.17	eval_R_eps -2470.22	punggol_1	 3415.5448544124592	
[2024-10-17 14:16:41,938] data_dir:data/punggol_1
[2024-10-17 14:16:41,938] id: punggol_1
[2024-10-17 14:16:41,938] seed: 0
[2024-10-17 14:16:41,938] objectives_plan: 
[2024-10-17 14:16:41,938] init_plan: 
[2024-10-17 14:16:41,938] env_specs: {}
[2024-10-17 14:16:41,938] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.1}
[2024-10-17 14:16:41,938] obs_specs: {}
[2024-10-17 14:16:41,938] agent_specs: {'batch_stage': False}
[2024-10-17 14:16:41,938] gamma: 0.9
[2024-10-17 14:16:41,938] tau: 0.0
[2024-10-17 14:16:41,938] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-17 14:16:41,938] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-17 14:16:41,938] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-17 14:16:41,938] lr: 0.0004
[2024-10-17 14:16:41,938] weightdecay: 0.0
[2024-10-17 14:16:41,938] eps: 1e-05
[2024-10-17 14:16:41,938] value_pred_coef: 0.5
[2024-10-17 14:16:41,938] entropy_coef: 0.01
[2024-10-17 14:16:41,938] clip_epsilon: 0.2
[2024-10-17 14:16:41,938] max_num_iterations: 2
[2024-10-17 14:16:41,938] num_episodes_per_iteration: 1200
[2024-10-17 14:16:41,938] max_sequence_length: 33
[2024-10-17 14:16:41,938] num_optim_epoch: 4
[2024-10-17 14:16:41,938] mini_batch_size: 1024
[2024-10-17 14:16:41,938] save_model_interval: 1
[2024-10-17 14:16:47,039] 0	T_sample 3.17	T_update 0.38	T_eval 1.11	ETA 0:00:05	train_R_eps -2304.18	eval_R_eps -2470.22	punggol_1	 3415.5448544124592	
[2024-10-17 14:16:51,333] 1	T_sample 3.08	T_update 0.09	T_eval 1.12	ETA 0:00:00	train_R_eps -2437.17	eval_R_eps -2470.22	punggol_1	 3415.5448544124592	
[2024-10-17 14:18:50,259] data_dir:data/punggol_1
[2024-10-17 14:18:50,259] id: punggol_1
[2024-10-17 14:18:50,259] seed: 0
[2024-10-17 14:18:50,259] objectives_plan: 
[2024-10-17 14:18:50,259] init_plan: 
[2024-10-17 14:18:50,259] env_specs: {}
[2024-10-17 14:18:50,259] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.1}
[2024-10-17 14:18:50,259] obs_specs: {}
[2024-10-17 14:18:50,259] agent_specs: {'batch_stage': False}
[2024-10-17 14:18:50,259] gamma: 0.9
[2024-10-17 14:18:50,259] tau: 0.0
[2024-10-17 14:18:50,259] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-17 14:18:50,259] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-17 14:18:50,259] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-17 14:18:50,259] lr: 0.0004
[2024-10-17 14:18:50,259] weightdecay: 0.0
[2024-10-17 14:18:50,259] eps: 1e-05
[2024-10-17 14:18:50,259] value_pred_coef: 0.5
[2024-10-17 14:18:50,259] entropy_coef: 0.01
[2024-10-17 14:18:50,259] clip_epsilon: 0.2
[2024-10-17 14:18:50,259] max_num_iterations: 2
[2024-10-17 14:18:50,259] num_episodes_per_iteration: 1200
[2024-10-17 14:18:50,259] max_sequence_length: 33
[2024-10-17 14:18:50,259] num_optim_epoch: 4
[2024-10-17 14:18:50,259] mini_batch_size: 1024
[2024-10-17 14:18:50,259] save_model_interval: 1
[2024-10-17 14:18:55,309] 0	T_sample 3.09	T_update 0.42	T_eval 1.09	ETA 0:00:05	train_R_eps -2304.18	eval_R_eps -2470.22	punggol_1	 3415.5448544124592	
[2024-10-17 14:18:59,507] 1	T_sample 3.02	T_update 0.08	T_eval 1.09	ETA 0:00:00	train_R_eps -2437.17	eval_R_eps -2470.22	punggol_1	 3415.5448544124592	
[2024-10-17 14:19:03,548] data_dir:data/punggol_1
[2024-10-17 14:19:03,548] id: punggol_1
[2024-10-17 14:19:03,548] seed: 0
[2024-10-17 14:19:03,548] objectives_plan: 
[2024-10-17 14:19:03,548] init_plan: 
[2024-10-17 14:19:03,548] env_specs: {}
[2024-10-17 14:19:03,548] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.1}
[2024-10-17 14:19:03,548] obs_specs: {}
[2024-10-17 14:19:03,548] agent_specs: {'batch_stage': False}
[2024-10-17 14:19:03,548] gamma: 0.9
[2024-10-17 14:19:03,548] tau: 0.0
[2024-10-17 14:19:03,548] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-17 14:19:03,548] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-17 14:19:03,548] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-17 14:19:03,548] lr: 0.0004
[2024-10-17 14:19:03,548] weightdecay: 0.0
[2024-10-17 14:19:03,548] eps: 1e-05
[2024-10-17 14:19:03,548] value_pred_coef: 0.5
[2024-10-17 14:19:03,548] entropy_coef: 0.01
[2024-10-17 14:19:03,548] clip_epsilon: 0.2
[2024-10-17 14:19:03,548] max_num_iterations: 2
[2024-10-17 14:19:03,548] num_episodes_per_iteration: 1200
[2024-10-17 14:19:03,548] max_sequence_length: 33
[2024-10-17 14:19:03,548] num_optim_epoch: 4
[2024-10-17 14:19:03,548] mini_batch_size: 1024
[2024-10-17 14:19:03,548] save_model_interval: 1
[2024-10-17 14:19:08,635] 0	T_sample 3.11	T_update 0.42	T_eval 1.11	ETA 0:00:05	train_R_eps -2304.18	eval_R_eps -2470.22	punggol_1	 3415.5448544124592	
[2024-10-17 14:19:12,842] 1	T_sample 3.02	T_update 0.08	T_eval 1.10	ETA 0:00:00	train_R_eps -2437.17	eval_R_eps -2470.22	punggol_1	 3415.5448544124592	
[2024-10-17 14:22:25,917] data_dir:data/punggol_1
[2024-10-17 14:22:25,917] id: punggol_1
[2024-10-17 14:22:25,917] seed: 0
[2024-10-17 14:22:25,917] objectives_plan: 
[2024-10-17 14:22:25,917] init_plan: 
[2024-10-17 14:22:25,917] env_specs: {}
[2024-10-17 14:22:25,917] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.1}
[2024-10-17 14:22:25,917] obs_specs: {}
[2024-10-17 14:22:25,917] agent_specs: {'batch_stage': False}
[2024-10-17 14:22:25,917] gamma: 0.9
[2024-10-17 14:22:25,917] tau: 0.0
[2024-10-17 14:22:25,917] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-10-17 14:22:25,917] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-10-17 14:22:25,917] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-10-17 14:22:25,917] lr: 0.0004
[2024-10-17 14:22:25,917] weightdecay: 0.0
[2024-10-17 14:22:25,917] eps: 1e-05
[2024-10-17 14:22:25,917] value_pred_coef: 0.5
[2024-10-17 14:22:25,917] entropy_coef: 0.01
[2024-10-17 14:22:25,917] clip_epsilon: 0.2
[2024-10-17 14:22:25,917] max_num_iterations: 2
[2024-10-17 14:22:25,917] num_episodes_per_iteration: 1200
[2024-10-17 14:22:25,917] max_sequence_length: 33
[2024-10-17 14:22:25,917] num_optim_epoch: 4
[2024-10-17 14:22:25,917] mini_batch_size: 1024
[2024-10-17 14:22:25,917] save_model_interval: 1
[2024-10-17 14:22:31,041] 0	T_sample 3.14	T_update 0.43	T_eval 1.10	ETA 0:00:05	train_R_eps -2304.18	eval_R_eps -2470.22	punggol_1	 3415.5448544124592	
[2024-10-17 14:22:35,318] 1	T_sample 3.07	T_update 0.09	T_eval 1.12	ETA 0:00:00	train_R_eps -2437.17	eval_R_eps -2470.22	punggol_1	 3415.5448544124592	
