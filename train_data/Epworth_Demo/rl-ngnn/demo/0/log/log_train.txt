[2024-06-27 11:11:18,547] data_dir:data/Epworth_Before
[2024-06-27 11:11:18,547] id: demo
[2024-06-27 11:11:18,547] seed: 0
[2024-06-27 11:11:18,547] objectives_plan: 
[2024-06-27 11:11:18,547] init_plan: 
[2024-06-27 11:11:18,547] env_specs: {}
[2024-06-27 11:11:18,547] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-06-27 11:11:18,561] obs_specs: {}
[2024-06-27 11:11:18,561] agent_specs: {'batch_stage': False}
[2024-06-27 11:11:18,562] gamma: 0.9
[2024-06-27 11:11:18,563] tau: 0.0
[2024-06-27 11:11:18,563] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-06-27 11:11:18,563] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-06-27 11:11:18,563] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-06-27 11:11:18,563] lr: 0.0004
[2024-06-27 11:11:18,563] weightdecay: 0.0
[2024-06-27 11:11:18,563] eps: 1e-05
[2024-06-27 11:11:18,563] value_pred_coef: 0.5
[2024-06-27 11:11:18,563] entropy_coef: 0.01
[2024-06-27 11:11:18,563] clip_epsilon: 0.2
[2024-06-27 11:11:18,563] max_num_iterations: 100
[2024-06-27 11:11:18,563] num_episodes_per_iteration: 1200
[2024-06-27 11:11:18,563] max_sequence_length: 33
[2024-06-27 11:11:18,563] num_optim_epoch: 4
[2024-06-27 11:11:18,563] mini_batch_size: 1024
[2024-06-27 11:11:18,563] save_model_interval: 1
[2024-06-27 11:14:14,564] data_dir:data/Epworth_Before
[2024-06-27 11:14:14,564] id: demo
[2024-06-27 11:14:14,564] seed: 0
[2024-06-27 11:14:14,564] objectives_plan: 
[2024-06-27 11:14:14,564] init_plan: 
[2024-06-27 11:14:14,564] env_specs: {}
[2024-06-27 11:14:14,564] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-06-27 11:14:14,564] obs_specs: {}
[2024-06-27 11:14:14,564] agent_specs: {'batch_stage': False}
[2024-06-27 11:14:14,569] gamma: 0.9
[2024-06-27 11:14:14,569] tau: 0.0
[2024-06-27 11:14:14,569] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-06-27 11:14:14,569] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-06-27 11:14:14,569] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-06-27 11:14:14,569] lr: 0.0004
[2024-06-27 11:14:14,570] weightdecay: 0.0
[2024-06-27 11:14:14,570] eps: 1e-05
[2024-06-27 11:14:14,570] value_pred_coef: 0.5
[2024-06-27 11:14:14,570] entropy_coef: 0.01
[2024-06-27 11:14:14,570] clip_epsilon: 0.2
[2024-06-27 11:14:14,570] max_num_iterations: 100
[2024-06-27 11:14:14,570] num_episodes_per_iteration: 1200
[2024-06-27 11:14:14,571] max_sequence_length: 33
[2024-06-27 11:14:14,571] num_optim_epoch: 4
[2024-06-27 11:14:14,571] mini_batch_size: 1024
[2024-06-27 11:14:14,571] save_model_interval: 1
[2024-06-27 11:16:17,014] data_dir:data/Epworth_Before
[2024-06-27 11:16:17,014] id: demo
[2024-06-27 11:16:17,014] seed: 0
[2024-06-27 11:16:17,014] objectives_plan: 
[2024-06-27 11:16:17,014] init_plan: 
[2024-06-27 11:16:17,014] env_specs: {}
[2024-06-27 11:16:17,014] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-06-27 11:16:17,029] obs_specs: {}
[2024-06-27 11:16:17,029] agent_specs: {'batch_stage': False}
[2024-06-27 11:16:17,029] gamma: 0.9
[2024-06-27 11:16:17,029] tau: 0.0
[2024-06-27 11:16:17,029] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-06-27 11:16:17,030] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-06-27 11:16:17,030] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-06-27 11:16:17,030] lr: 0.0004
[2024-06-27 11:16:17,030] weightdecay: 0.0
[2024-06-27 11:16:17,031] eps: 1e-05
[2024-06-27 11:16:17,031] value_pred_coef: 0.5
[2024-06-27 11:16:17,031] entropy_coef: 0.01
[2024-06-27 11:16:17,031] clip_epsilon: 0.2
[2024-06-27 11:16:17,032] max_num_iterations: 100
[2024-06-27 11:16:17,032] num_episodes_per_iteration: 1200
[2024-06-27 11:16:17,032] max_sequence_length: 33
[2024-06-27 11:16:17,033] num_optim_epoch: 4
[2024-06-27 11:16:17,033] mini_batch_size: 1024
[2024-06-27 11:16:17,033] save_model_interval: 1
[2024-06-27 11:17:16,872] data_dir:data/Epworth_Before
[2024-06-27 11:17:16,872] id: demo
[2024-06-27 11:17:16,872] seed: 0
[2024-06-27 11:17:16,872] objectives_plan: 
[2024-06-27 11:17:16,872] init_plan: 
[2024-06-27 11:17:16,872] env_specs: {}
[2024-06-27 11:17:16,872] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-06-27 11:17:16,872] obs_specs: {}
[2024-06-27 11:17:16,872] agent_specs: {'batch_stage': False}
[2024-06-27 11:17:16,872] gamma: 0.9
[2024-06-27 11:17:16,872] tau: 0.0
[2024-06-27 11:17:16,872] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-06-27 11:17:16,872] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-06-27 11:17:16,872] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-06-27 11:17:16,872] lr: 0.0004
[2024-06-27 11:17:16,872] weightdecay: 0.0
[2024-06-27 11:17:16,872] eps: 1e-05
[2024-06-27 11:17:16,872] value_pred_coef: 0.5
[2024-06-27 11:17:16,872] entropy_coef: 0.01
[2024-06-27 11:17:16,872] clip_epsilon: 0.2
[2024-06-27 11:17:16,872] max_num_iterations: 100
[2024-06-27 11:17:16,872] num_episodes_per_iteration: 1200
[2024-06-27 11:17:16,872] max_sequence_length: 33
[2024-06-27 11:17:16,872] num_optim_epoch: 4
[2024-06-27 11:17:16,872] mini_batch_size: 1024
[2024-06-27 11:17:16,872] save_model_interval: 1
[2024-06-27 11:17:39,184] data_dir:data/Epworth_Before
[2024-06-27 11:17:39,184] id: demo
[2024-06-27 11:17:39,184] seed: 0
[2024-06-27 11:17:39,184] objectives_plan: 
[2024-06-27 11:17:39,184] init_plan: 
[2024-06-27 11:17:39,184] env_specs: {}
[2024-06-27 11:17:39,184] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-06-27 11:17:39,184] obs_specs: {}
[2024-06-27 11:17:39,184] agent_specs: {'batch_stage': False}
[2024-06-27 11:17:39,184] gamma: 0.9
[2024-06-27 11:17:39,184] tau: 0.0
[2024-06-27 11:17:39,184] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-06-27 11:17:39,184] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-06-27 11:17:39,184] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-06-27 11:17:39,184] lr: 0.0004
[2024-06-27 11:17:39,184] weightdecay: 0.0
[2024-06-27 11:17:39,184] eps: 1e-05
[2024-06-27 11:17:39,184] value_pred_coef: 0.5
[2024-06-27 11:17:39,184] entropy_coef: 0.01
[2024-06-27 11:17:39,184] clip_epsilon: 0.2
[2024-06-27 11:17:39,184] max_num_iterations: 100
[2024-06-27 11:17:39,184] num_episodes_per_iteration: 1200
[2024-06-27 11:17:39,184] max_sequence_length: 33
[2024-06-27 11:17:39,184] num_optim_epoch: 4
[2024-06-27 11:17:39,184] mini_batch_size: 1024
[2024-06-27 11:17:39,184] save_model_interval: 1
[2024-06-27 11:24:13,219] data_dir:data/Epworth_Before
[2024-06-27 11:24:13,220] id: demo
[2024-06-27 11:24:13,220] seed: 0
[2024-06-27 11:24:13,221] objectives_plan: 
[2024-06-27 11:24:13,221] init_plan: 
[2024-06-27 11:24:13,221] env_specs: {}
[2024-06-27 11:24:13,221] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-06-27 11:24:13,221] obs_specs: {}
[2024-06-27 11:24:13,221] agent_specs: {'batch_stage': False}
[2024-06-27 11:24:13,222] gamma: 0.9
[2024-06-27 11:24:13,222] tau: 0.0
[2024-06-27 11:24:13,222] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-06-27 11:24:13,222] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-06-27 11:24:13,222] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-06-27 11:24:13,223] lr: 0.0004
[2024-06-27 11:24:13,223] weightdecay: 0.0
[2024-06-27 11:24:13,223] eps: 1e-05
[2024-06-27 11:24:13,223] value_pred_coef: 0.5
[2024-06-27 11:24:13,223] entropy_coef: 0.01
[2024-06-27 11:24:13,223] clip_epsilon: 0.2
[2024-06-27 11:24:13,223] max_num_iterations: 100
[2024-06-27 11:24:13,223] num_episodes_per_iteration: 1200
[2024-06-27 11:24:13,223] max_sequence_length: 33
[2024-06-27 11:24:13,224] num_optim_epoch: 4
[2024-06-27 11:24:13,224] mini_batch_size: 1024
[2024-06-27 11:24:13,224] save_model_interval: 1
[2024-06-27 11:26:27,211] data_dir:data/Epworth_Before
[2024-06-27 11:26:27,211] id: demo
[2024-06-27 11:26:27,211] seed: 0
[2024-06-27 11:26:27,211] objectives_plan: 
[2024-06-27 11:26:27,212] init_plan: 
[2024-06-27 11:26:27,212] env_specs: {}
[2024-06-27 11:26:27,212] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-06-27 11:26:27,212] obs_specs: {}
[2024-06-27 11:26:27,212] agent_specs: {'batch_stage': False}
[2024-06-27 11:26:27,212] gamma: 0.9
[2024-06-27 11:26:27,212] tau: 0.0
[2024-06-27 11:26:27,212] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-06-27 11:26:27,212] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-06-27 11:26:27,212] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-06-27 11:26:27,213] lr: 0.0004
[2024-06-27 11:26:27,213] weightdecay: 0.0
[2024-06-27 11:26:27,214] eps: 1e-05
[2024-06-27 11:26:27,214] value_pred_coef: 0.5
[2024-06-27 11:26:27,214] entropy_coef: 0.01
[2024-06-27 11:26:27,214] clip_epsilon: 0.2
[2024-06-27 11:26:27,214] max_num_iterations: 100
[2024-06-27 11:26:27,215] num_episodes_per_iteration: 1200
[2024-06-27 11:26:27,215] max_sequence_length: 33
[2024-06-27 11:26:27,215] num_optim_epoch: 4
[2024-06-27 11:26:27,215] mini_batch_size: 1024
[2024-06-27 11:26:27,215] save_model_interval: 1
[2024-06-27 11:27:45,875] data_dir:data/Epworth_Before
[2024-06-27 11:27:45,876] id: demo
[2024-06-27 11:27:45,876] seed: 0
[2024-06-27 11:27:45,877] objectives_plan: 
[2024-06-27 11:27:45,877] init_plan: 
[2024-06-27 11:27:45,877] env_specs: {}
[2024-06-27 11:27:45,878] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-06-27 11:27:45,878] obs_specs: {}
[2024-06-27 11:27:45,878] agent_specs: {'batch_stage': False}
[2024-06-27 11:27:45,878] gamma: 0.9
[2024-06-27 11:27:45,879] tau: 0.0
[2024-06-27 11:27:45,879] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-06-27 11:27:45,879] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-06-27 11:27:45,879] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-06-27 11:27:45,880] lr: 0.0004
[2024-06-27 11:27:45,880] weightdecay: 0.0
[2024-06-27 11:27:45,880] eps: 1e-05
[2024-06-27 11:27:45,880] value_pred_coef: 0.5
[2024-06-27 11:27:45,880] entropy_coef: 0.01
[2024-06-27 11:27:45,881] clip_epsilon: 0.2
[2024-06-27 11:27:45,881] max_num_iterations: 100
[2024-06-27 11:27:45,881] num_episodes_per_iteration: 1200
[2024-06-27 11:27:45,881] max_sequence_length: 33
[2024-06-27 11:27:45,881] num_optim_epoch: 4
[2024-06-27 11:27:45,882] mini_batch_size: 1024
[2024-06-27 11:27:45,882] save_model_interval: 1
[2024-06-27 11:36:55,439] 0	T_sample 490.53	T_update 53.34	T_eval 4.79	ETA 15:05:17	train_R_eps -0.59	eval_R_eps -0.51	demo
[2024-06-27 11:39:09,358] data_dir:data/Epworth_Before
[2024-06-27 11:39:09,358] id: demo
[2024-06-27 11:39:09,358] seed: 0
[2024-06-27 11:39:09,358] objectives_plan: 
[2024-06-27 11:39:09,358] init_plan: 
[2024-06-27 11:39:09,358] env_specs: {}
[2024-06-27 11:39:09,359] reward_specs: {'dis_weight': 0.5, 'cost_weight': 0.5, 'build_ration': 0.5}
[2024-06-27 11:39:09,359] obs_specs: {}
[2024-06-27 11:39:09,359] agent_specs: {'batch_stage': False}
[2024-06-27 11:39:09,359] gamma: 0.9
[2024-06-27 11:39:09,360] tau: 0.0
[2024-06-27 11:39:09,360] state_encoder_specs: {'state_encoder_hidden_size': [16, 4], 'gcn_node_dim': 16, 'num_gcn_layers': 2, 'num_edge_fc_layers': 1, 'max_num_nodes': 1000, 'max_num_edges': 3000, 'num_attention_heads': 1}
[2024-06-27 11:39:09,360] policy_specs: {'policy_land_use_head_hidden_size': [32, 1], 'policy_road_head_hidden_size': [32, 1]}
[2024-06-27 11:39:09,360] value_specs: {'value_head_hidden_size': [32, 32, 1]}
[2024-06-27 11:39:09,360] lr: 0.0004
[2024-06-27 11:39:09,360] weightdecay: 0.0
[2024-06-27 11:39:09,360] eps: 1e-05
[2024-06-27 11:39:09,360] value_pred_coef: 0.5
[2024-06-27 11:39:09,360] entropy_coef: 0.01
[2024-06-27 11:39:09,360] clip_epsilon: 0.2
[2024-06-27 11:39:09,361] max_num_iterations: 100
[2024-06-27 11:39:09,361] num_episodes_per_iteration: 1200
[2024-06-27 11:39:09,361] max_sequence_length: 33
[2024-06-27 11:39:09,361] num_optim_epoch: 4
[2024-06-27 11:39:09,361] mini_batch_size: 1024
[2024-06-27 11:39:09,361] save_model_interval: 1
[2024-06-27 11:48:49,927] 0	T_sample 520.03	T_update 55.49	T_eval 4.18	ETA 15:56:31	train_R_eps -0.59	eval_R_eps -0.51	demo
[2024-06-27 11:48:49,937] save best checkpoint with rewards -0.51!
[2024-06-27 11:58:45,092] 1	T_sample 532.75	T_update 57.92	T_eval 4.36	ETA 16:11:52	train_R_eps -0.58	eval_R_eps -0.48	demo
[2024-06-27 11:58:45,099] save best checkpoint with rewards -0.48!
[2024-06-27 12:08:35,418] 2	T_sample 531.74	T_update 54.35	T_eval 4.13	ETA 15:54:11	train_R_eps -0.56	eval_R_eps -0.47	demo
[2024-06-27 12:08:35,427] save best checkpoint with rewards -0.47!
[2024-06-27 12:18:20,016] 3	T_sample 526.06	T_update 54.29	T_eval 4.14	ETA 15:35:11	train_R_eps -0.54	eval_R_eps -0.47	demo
[2024-06-27 12:28:12,583] 4	T_sample 534.24	T_update 54.08	T_eval 4.14	ETA 15:38:04	train_R_eps -0.53	eval_R_eps -0.46	demo
[2024-06-27 12:28:12,590] save best checkpoint with rewards -0.46!
