Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.4959e-01,  2.3544e-01,  1.6261e-01, -1.7926e-01,  1.1951e-04,
         -5.4087e-03,  1.1917e-01, -2.1412e-01,  3.7155e-03,  8.3298e-02,
          1.2723e-01,  2.6141e-02, -1.2392e-01, -2.4000e-01,  1.3513e-01,
          2.2824e-01],
        [-7.5480e-02, -2.2341e-01,  7.3146e-02, -1.7527e-01, -1.6334e-01,
          6.8146e-02, -2.3741e-02, -1.7005e-02,  2.2424e-01, -4.3851e-02,
          1.5218e-01, -7.7806e-02,  1.8603e-01,  7.6268e-02,  2.2277e-01,
          8.7195e-02],
        [-8.8554e-02,  1.0896e-01,  2.1299e-01,  4.7383e-02,  1.1526e-01,
         -1.7588e-01,  1.3546e-01, -2.3632e-01,  2.2101e-01,  1.0326e-01,
          1.6452e-02, -2.3399e-01,  2.2734e-01,  1.5941e-01,  2.3047e-01,
          9.8278e-02],
        [ 8.4194e-02, -6.4758e-02, -1.0245e-01,  9.9101e-02,  8.6701e-02,
         -8.1050e-03,  3.9765e-02,  8.5878e-02, -2.4159e-01, -2.2109e-01,
         -6.6551e-02,  1.7026e-01,  1.2197e-01, -2.3862e-01, -7.5062e-02,
         -2.6426e-02],
        [ 8.2110e-02,  2.0453e-01,  5.4679e-03, -1.9460e-01,  1.5340e-02,
         -9.6540e-02, -1.5279e-01,  1.3847e-01, -3.3588e-02,  1.1813e-01,
          1.9466e-01,  2.4570e-02,  1.4081e-01, -1.1807e-01,  1.3955e-01,
          9.9876e-03],
        [ 1.6613e-01,  2.3901e-01, -1.8911e-01,  2.3733e-01,  1.9084e-01,
         -2.0139e-01,  7.3285e-02, -2.0353e-01,  8.1097e-02,  3.8660e-02,
         -2.3865e-01,  9.0755e-02, -6.8670e-02,  2.4919e-01,  2.4400e-01,
          8.6303e-02],
        [ 1.9706e-01,  9.0295e-02,  2.3652e-01, -2.3082e-02,  6.1788e-02,
         -4.1296e-02, -4.3721e-03, -7.5417e-02, -9.8939e-02,  1.4462e-01,
          1.0728e-01, -1.1036e-01, -2.2033e-01,  1.2224e-01, -2.2997e-01,
         -1.1063e-02],
        [-2.1511e-01,  2.0933e-01,  2.0357e-01, -2.0546e-01, -2.3243e-01,
         -1.4781e-01,  6.8985e-02, -1.2502e-01, -5.9537e-02, -6.3370e-02,
          4.5858e-02, -1.1825e-01,  1.1370e-01, -1.7890e-01, -2.2253e-02,
          2.0956e-01],
        [-1.3804e-01,  1.9180e-01,  1.3012e-01, -8.0755e-02,  8.6691e-02,
         -1.6889e-01,  2.0121e-02,  7.0815e-02,  2.1624e-01, -1.3989e-01,
         -1.4218e-01, -1.2478e-01, -2.4354e-01,  5.0557e-02, -2.0694e-01,
         -6.7111e-02],
        [-1.1155e-01,  1.3978e-02,  7.5837e-02, -1.8167e-01, -7.3804e-02,
         -2.4035e-02, -1.4452e-01,  5.7753e-02,  9.2549e-02, -1.7817e-01,
          1.9658e-01,  1.7765e-01, -7.5106e-02,  3.7198e-02,  3.0439e-02,
         -3.4493e-02],
        [-1.6778e-01,  2.0601e-01,  1.2303e-01, -2.0892e-01, -1.9375e-01,
          2.3774e-01,  3.9901e-02, -5.7436e-02,  1.6943e-01,  7.1820e-02,
          8.9743e-02,  1.9833e-01, -1.9512e-02,  2.3822e-01, -1.7561e-01,
         -1.5213e-01],
        [ 4.2360e-02, -3.0351e-02,  1.4266e-01, -6.7982e-02,  3.9312e-02,
         -5.1947e-02,  1.8769e-01, -1.6398e-02,  3.8373e-03,  1.8315e-01,
          2.4304e-01,  2.3921e-01, -2.4443e-01, -1.4127e-01, -5.4287e-02,
         -5.1611e-02],
        [ 1.4461e-01,  1.1291e-01, -2.0563e-02,  5.9224e-03,  5.3564e-02,
          2.1551e-01,  1.2955e-01, -1.2610e-01, -1.2807e-01,  7.9062e-02,
         -2.5286e-02, -1.6039e-01, -2.4197e-01,  3.5810e-02, -7.3006e-02,
         -1.4546e-01],
        [ 4.7027e-02,  2.4345e-01,  2.0765e-01,  1.4254e-01, -1.8855e-01,
          1.4268e-01,  1.2930e-01,  8.3411e-02, -6.2276e-02, -4.3533e-03,
         -1.3560e-01, -5.6314e-02, -4.1154e-02, -3.5414e-02, -2.4880e-01,
          8.8197e-02],
        [-2.0455e-01, -1.8696e-01,  1.0159e-01, -2.0464e-01,  2.3850e-01,
          2.3939e-01, -7.9446e-02, -4.3085e-02, -1.9126e-01,  1.5456e-02,
          4.5709e-02, -1.3714e-01,  7.8396e-02, -9.6213e-03, -7.3695e-02,
         -8.6492e-04],
        [-2.4233e-01, -1.7611e-01,  3.3092e-02,  2.4143e-01, -1.4818e-01,
          1.6027e-01,  2.2880e-02, -1.0756e-01,  2.7391e-04,  1.1986e-01,
          2.9743e-02,  2.2130e-01, -4.7314e-02, -1.6695e-01,  2.2591e-01,
         -7.1400e-02],
        [ 1.5863e-01,  1.6490e-01,  4.4276e-02, -2.0519e-01, -2.4544e-01,
          1.1868e-01,  6.1123e-02,  1.4547e-01, -2.2035e-01, -3.4443e-02,
          2.1600e-01,  1.3135e-01,  2.0776e-01,  1.9628e-01, -6.1342e-02,
         -1.7025e-01],
        [-1.4907e-01,  8.4907e-02, -9.9234e-02,  9.9149e-04,  3.9896e-02,
          1.5519e-01,  1.3943e-01,  1.4269e-01,  1.0161e-02,  1.4114e-01,
         -1.1704e-01, -1.0006e-01, -3.9583e-02, -1.4518e-01,  2.2300e-01,
         -3.8309e-02],
        [ 7.2681e-02, -7.7727e-03, -3.4193e-03, -1.3325e-01, -1.8354e-02,
         -2.2362e-01, -1.1955e-01,  1.9239e-01, -2.3449e-01,  4.1140e-02,
          3.9828e-02, -2.3928e-01,  4.8829e-02,  1.1608e-01,  1.8107e-01,
          4.6794e-02],
        [ 1.9542e-01,  9.4101e-03,  9.5256e-02,  7.3802e-02, -1.8433e-01,
         -5.4879e-02, -1.7605e-01,  1.9425e-01,  1.1926e-01, -1.0603e-01,
         -4.5749e-02,  6.6739e-02, -2.1798e-01,  7.0592e-03,  1.1925e-01,
          3.1325e-02],
        [-2.3003e-02,  1.6073e-01,  1.0875e-01, -2.2225e-01,  1.4713e-01,
         -1.9718e-01,  1.4043e-01,  2.1051e-01,  2.3040e-02, -8.4493e-02,
         -1.2914e-01, -1.1101e-01, -4.6083e-02, -1.0365e-01,  2.4818e-01,
         -1.0784e-01],
        [ 1.0380e-01, -2.3183e-01,  1.2671e-01,  2.1273e-01, -1.7922e-01,
         -6.3786e-02,  5.9585e-02, -2.3931e-01, -1.5818e-01,  8.6946e-02,
          2.3541e-01, -7.4686e-02, -2.2768e-03, -2.4133e-01, -2.3996e-01,
          2.1742e-01],
        [ 2.1215e-01, -7.6192e-02, -9.8855e-02, -1.6184e-02,  1.1600e-01,
         -2.4160e-01, -1.3848e-01, -8.2418e-02, -1.0881e-01, -6.6043e-03,
          1.8235e-01,  5.4585e-02, -2.2625e-01,  2.3122e-01,  2.0130e-01,
          7.8714e-02],
        [ 1.2237e-01,  9.3457e-02,  2.0492e-01, -2.4045e-01, -1.5563e-01,
         -3.1748e-02, -4.7555e-02, -1.6603e-01, -2.3975e-01, -1.9093e-01,
         -3.8828e-02,  2.1222e-01,  1.6574e-01,  7.2061e-02, -1.5355e-01,
         -1.0057e-01],
        [ 2.4084e-02, -2.3173e-01, -1.1413e-02,  5.0838e-02,  2.2602e-01,
         -6.5625e-02,  2.4539e-01,  1.8861e-02, -1.7345e-01,  2.3628e-01,
          2.1674e-01, -1.9754e-01, -1.4502e-01,  1.1954e-01, -1.5383e-01,
          1.6999e-01],
        [-1.1928e-01, -7.7591e-02, -7.1767e-02,  2.3851e-01, -8.4540e-02,
         -4.8611e-02,  1.5127e-01, -1.7105e-01, -1.2042e-03, -1.9311e-01,
         -2.3074e-01, -5.7078e-02,  2.7636e-02,  2.1319e-01, -2.3975e-01,
         -7.1936e-02],
        [ 6.5789e-02,  9.4403e-02,  1.4606e-01, -2.0102e-01, -6.1118e-02,
          5.7808e-02, -2.0040e-01,  1.2598e-01, -2.3854e-01,  1.5600e-01,
          8.1279e-02, -7.1012e-02,  8.1105e-02,  2.1174e-01,  1.8391e-01,
          1.5164e-01],
        [-1.4553e-01,  7.1840e-02,  1.8761e-01,  4.4093e-02,  1.6552e-01,
         -1.5505e-01,  1.7571e-01, -8.2927e-03, -2.2430e-01, -6.4806e-02,
          2.2096e-01, -8.7336e-02, -4.3299e-02, -1.0001e-01, -1.3593e-01,
          4.3312e-02],
        [ 1.5166e-01,  2.9561e-02, -1.5419e-02,  1.4462e-02, -1.8747e-01,
         -1.3172e-01,  1.2510e-02, -1.9982e-01,  1.2383e-01,  3.8105e-02,
          2.6324e-03, -1.6043e-02,  2.1115e-01,  2.2816e-01,  1.2207e-01,
          1.2417e-01],
        [-1.2122e-01,  1.0220e-01, -1.6909e-01,  1.0804e-01, -1.7752e-01,
         -1.3674e-03,  1.8120e-01,  1.6601e-01,  2.2105e-01,  8.5281e-02,
          9.7044e-02,  6.7042e-02,  1.8255e-01,  1.3119e-01,  7.3767e-02,
         -8.7229e-02],
        [-1.2099e-01, -6.1809e-02,  1.1931e-01, -1.3609e-01,  6.8302e-02,
          2.1873e-01,  2.1169e-01, -1.8406e-01,  7.1259e-02,  1.6347e-01,
         -2.2708e-01,  1.5978e-01, -1.5577e-01, -1.8076e-01, -1.0597e-01,
         -9.4034e-02],
        [-1.0336e-01,  7.1975e-02,  9.6850e-02,  9.7162e-02,  1.7261e-01,
         -1.5818e-01, -2.3738e-01, -2.0056e-01, -1.3741e-01, -1.1435e-01,
          1.0985e-01, -1.8092e-01, -1.8279e-01,  1.3388e-01, -1.5907e-01,
          4.6891e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1906,  0.0954,  0.1562, -0.2103,  0.0850, -0.1311,  0.1587,  0.2249,
        -0.2109,  0.0935,  0.1688,  0.2273,  0.1888,  0.0492,  0.0146,  0.0515,
        -0.1490, -0.0490, -0.0039, -0.1582, -0.0111, -0.0332, -0.0875, -0.0768,
        -0.2490,  0.2382,  0.1232,  0.1807, -0.2128, -0.2448,  0.1859, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0276,  0.0886,  0.0113, -0.0059,  0.1050,  0.1412, -0.0493, -0.1509,
         -0.0969,  0.1263,  0.0154,  0.1514, -0.0618, -0.1675,  0.0549, -0.0753,
         -0.1057,  0.1102,  0.0123, -0.0151,  0.1722,  0.1540, -0.1444, -0.1625,
         -0.0874, -0.1373, -0.0929,  0.1193, -0.1176,  0.1621,  0.0552,  0.0077]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0274,  0.0338,  0.0515,  ...,  0.0370, -0.1580, -0.1137],
        [-0.0412, -0.1228,  0.0849,  ..., -0.0255, -0.1542,  0.0871],
        [-0.0916,  0.0727,  0.1131,  ...,  0.1516,  0.0694,  0.0345],
        ...,
        [ 0.0835, -0.0818,  0.0083,  ..., -0.1147, -0.0697, -0.1180],
        [ 0.0086, -0.1214, -0.0074,  ..., -0.1376, -0.0348,  0.1557],
        [-0.1369,  0.0661,  0.0410,  ..., -0.0287, -0.1442, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0587,  0.0692, -0.1074, -0.1128, -0.0456,  0.0102, -0.1318,  0.0737,
        -0.0301,  0.0931,  0.0477, -0.0256, -0.0145,  0.0492, -0.0832, -0.0415,
         0.0733, -0.1429, -0.0319,  0.0333, -0.0826,  0.0758,  0.0793, -0.0232,
        -0.0515,  0.0775,  0.0090, -0.1238,  0.0923,  0.1576,  0.1370, -0.0883],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1641, -0.0737, -0.1340,  ..., -0.0192, -0.1329,  0.1699],
        [-0.0956,  0.0925,  0.0408,  ...,  0.0663, -0.1323,  0.1671],
        [ 0.0220, -0.1643, -0.1021,  ..., -0.0583,  0.1139,  0.0584],
        ...,
        [ 0.0230, -0.0144,  0.1370,  ...,  0.1392, -0.1018,  0.1490],
        [ 0.0984, -0.0202, -0.0055,  ...,  0.1521,  0.1041, -0.0493],
        [ 0.1011, -0.0131,  0.1673,  ...,  0.1591,  0.0347,  0.0616]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0691,  0.1030,  0.0027, -0.0455, -0.0609, -0.1135, -0.0068, -0.0992,
         0.1055, -0.1266,  0.1537, -0.1561,  0.1472,  0.0200, -0.1666,  0.0530,
        -0.1138, -0.1400,  0.0093, -0.0503,  0.0436,  0.1398, -0.1621,  0.1758,
        -0.0980, -0.0349,  0.1146, -0.0738, -0.0891, -0.0414,  0.0691, -0.0077],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1610,  0.0763, -0.1613, -0.1273,  0.0139, -0.0068, -0.0537,  0.0581,
          0.0742, -0.1026, -0.0353,  0.0633,  0.0641, -0.0159,  0.0889,  0.0632,
         -0.1659, -0.1689,  0.0059,  0.0605, -0.1260, -0.0910, -0.1689,  0.0335,
          0.1281,  0.1566, -0.1439,  0.1365, -0.0708, -0.1557,  0.1134,  0.1485]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0091], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.4959e-01,  2.3544e-01,  1.6261e-01, -1.7926e-01,  1.1951e-04,
         -5.4087e-03,  1.1917e-01, -2.1412e-01,  3.7155e-03,  8.3298e-02,
          1.2723e-01,  2.6141e-02, -1.2392e-01, -2.4000e-01,  1.3513e-01,
          2.2824e-01],
        [-7.5480e-02, -2.2341e-01,  7.3146e-02, -1.7527e-01, -1.6334e-01,
          6.8146e-02, -2.3741e-02, -1.7005e-02,  2.2424e-01, -4.3851e-02,
          1.5218e-01, -7.7806e-02,  1.8603e-01,  7.6268e-02,  2.2277e-01,
          8.7195e-02],
        [-8.8554e-02,  1.0896e-01,  2.1299e-01,  4.7383e-02,  1.1526e-01,
         -1.7588e-01,  1.3546e-01, -2.3632e-01,  2.2101e-01,  1.0326e-01,
          1.6452e-02, -2.3399e-01,  2.2734e-01,  1.5941e-01,  2.3047e-01,
          9.8278e-02],
        [ 8.4194e-02, -6.4758e-02, -1.0245e-01,  9.9101e-02,  8.6701e-02,
         -8.1050e-03,  3.9765e-02,  8.5878e-02, -2.4159e-01, -2.2109e-01,
         -6.6551e-02,  1.7026e-01,  1.2197e-01, -2.3862e-01, -7.5062e-02,
         -2.6426e-02],
        [ 8.2110e-02,  2.0453e-01,  5.4679e-03, -1.9460e-01,  1.5340e-02,
         -9.6540e-02, -1.5279e-01,  1.3847e-01, -3.3588e-02,  1.1813e-01,
          1.9466e-01,  2.4570e-02,  1.4081e-01, -1.1807e-01,  1.3955e-01,
          9.9876e-03],
        [ 1.6613e-01,  2.3901e-01, -1.8911e-01,  2.3733e-01,  1.9084e-01,
         -2.0139e-01,  7.3285e-02, -2.0353e-01,  8.1097e-02,  3.8660e-02,
         -2.3865e-01,  9.0755e-02, -6.8670e-02,  2.4919e-01,  2.4400e-01,
          8.6303e-02],
        [ 1.9706e-01,  9.0295e-02,  2.3652e-01, -2.3082e-02,  6.1788e-02,
         -4.1296e-02, -4.3721e-03, -7.5417e-02, -9.8939e-02,  1.4462e-01,
          1.0728e-01, -1.1036e-01, -2.2033e-01,  1.2224e-01, -2.2997e-01,
         -1.1063e-02],
        [-2.1511e-01,  2.0933e-01,  2.0357e-01, -2.0546e-01, -2.3243e-01,
         -1.4781e-01,  6.8985e-02, -1.2502e-01, -5.9537e-02, -6.3370e-02,
          4.5858e-02, -1.1825e-01,  1.1370e-01, -1.7890e-01, -2.2253e-02,
          2.0956e-01],
        [-1.3804e-01,  1.9180e-01,  1.3012e-01, -8.0755e-02,  8.6691e-02,
         -1.6889e-01,  2.0121e-02,  7.0815e-02,  2.1624e-01, -1.3989e-01,
         -1.4218e-01, -1.2478e-01, -2.4354e-01,  5.0557e-02, -2.0694e-01,
         -6.7111e-02],
        [-1.1155e-01,  1.3978e-02,  7.5837e-02, -1.8167e-01, -7.3804e-02,
         -2.4035e-02, -1.4452e-01,  5.7753e-02,  9.2549e-02, -1.7817e-01,
          1.9658e-01,  1.7765e-01, -7.5106e-02,  3.7198e-02,  3.0439e-02,
         -3.4493e-02],
        [-1.6778e-01,  2.0601e-01,  1.2303e-01, -2.0892e-01, -1.9375e-01,
          2.3774e-01,  3.9901e-02, -5.7436e-02,  1.6943e-01,  7.1820e-02,
          8.9743e-02,  1.9833e-01, -1.9512e-02,  2.3822e-01, -1.7561e-01,
         -1.5213e-01],
        [ 4.2360e-02, -3.0351e-02,  1.4266e-01, -6.7982e-02,  3.9312e-02,
         -5.1947e-02,  1.8769e-01, -1.6398e-02,  3.8373e-03,  1.8315e-01,
          2.4304e-01,  2.3921e-01, -2.4443e-01, -1.4127e-01, -5.4287e-02,
         -5.1611e-02],
        [ 1.4461e-01,  1.1291e-01, -2.0563e-02,  5.9224e-03,  5.3564e-02,
          2.1551e-01,  1.2955e-01, -1.2610e-01, -1.2807e-01,  7.9062e-02,
         -2.5286e-02, -1.6039e-01, -2.4197e-01,  3.5810e-02, -7.3006e-02,
         -1.4546e-01],
        [ 4.7027e-02,  2.4345e-01,  2.0765e-01,  1.4254e-01, -1.8855e-01,
          1.4268e-01,  1.2930e-01,  8.3411e-02, -6.2276e-02, -4.3533e-03,
         -1.3560e-01, -5.6314e-02, -4.1154e-02, -3.5414e-02, -2.4880e-01,
          8.8197e-02],
        [-2.0455e-01, -1.8696e-01,  1.0159e-01, -2.0464e-01,  2.3850e-01,
          2.3939e-01, -7.9446e-02, -4.3085e-02, -1.9126e-01,  1.5456e-02,
          4.5709e-02, -1.3714e-01,  7.8396e-02, -9.6213e-03, -7.3695e-02,
         -8.6492e-04],
        [-2.4233e-01, -1.7611e-01,  3.3092e-02,  2.4143e-01, -1.4818e-01,
          1.6027e-01,  2.2880e-02, -1.0756e-01,  2.7391e-04,  1.1986e-01,
          2.9743e-02,  2.2130e-01, -4.7314e-02, -1.6695e-01,  2.2591e-01,
         -7.1400e-02],
        [ 1.5863e-01,  1.6490e-01,  4.4276e-02, -2.0519e-01, -2.4544e-01,
          1.1868e-01,  6.1123e-02,  1.4547e-01, -2.2035e-01, -3.4443e-02,
          2.1600e-01,  1.3135e-01,  2.0776e-01,  1.9628e-01, -6.1342e-02,
         -1.7025e-01],
        [-1.4907e-01,  8.4907e-02, -9.9234e-02,  9.9149e-04,  3.9896e-02,
          1.5519e-01,  1.3943e-01,  1.4269e-01,  1.0161e-02,  1.4114e-01,
         -1.1704e-01, -1.0006e-01, -3.9583e-02, -1.4518e-01,  2.2300e-01,
         -3.8309e-02],
        [ 7.2681e-02, -7.7727e-03, -3.4193e-03, -1.3325e-01, -1.8354e-02,
         -2.2362e-01, -1.1955e-01,  1.9239e-01, -2.3449e-01,  4.1140e-02,
          3.9828e-02, -2.3928e-01,  4.8829e-02,  1.1608e-01,  1.8107e-01,
          4.6794e-02],
        [ 1.9542e-01,  9.4101e-03,  9.5256e-02,  7.3802e-02, -1.8433e-01,
         -5.4879e-02, -1.7605e-01,  1.9425e-01,  1.1926e-01, -1.0603e-01,
         -4.5749e-02,  6.6739e-02, -2.1798e-01,  7.0592e-03,  1.1925e-01,
          3.1325e-02],
        [-2.3003e-02,  1.6073e-01,  1.0875e-01, -2.2225e-01,  1.4713e-01,
         -1.9718e-01,  1.4043e-01,  2.1051e-01,  2.3040e-02, -8.4493e-02,
         -1.2914e-01, -1.1101e-01, -4.6083e-02, -1.0365e-01,  2.4818e-01,
         -1.0784e-01],
        [ 1.0380e-01, -2.3183e-01,  1.2671e-01,  2.1273e-01, -1.7922e-01,
         -6.3786e-02,  5.9585e-02, -2.3931e-01, -1.5818e-01,  8.6946e-02,
          2.3541e-01, -7.4686e-02, -2.2768e-03, -2.4133e-01, -2.3996e-01,
          2.1742e-01],
        [ 2.1215e-01, -7.6192e-02, -9.8855e-02, -1.6184e-02,  1.1600e-01,
         -2.4160e-01, -1.3848e-01, -8.2418e-02, -1.0881e-01, -6.6043e-03,
          1.8235e-01,  5.4585e-02, -2.2625e-01,  2.3122e-01,  2.0130e-01,
          7.8714e-02],
        [ 1.2237e-01,  9.3457e-02,  2.0492e-01, -2.4045e-01, -1.5563e-01,
         -3.1748e-02, -4.7555e-02, -1.6603e-01, -2.3975e-01, -1.9093e-01,
         -3.8828e-02,  2.1222e-01,  1.6574e-01,  7.2061e-02, -1.5355e-01,
         -1.0057e-01],
        [ 2.4084e-02, -2.3173e-01, -1.1413e-02,  5.0838e-02,  2.2602e-01,
         -6.5625e-02,  2.4539e-01,  1.8861e-02, -1.7345e-01,  2.3628e-01,
          2.1674e-01, -1.9754e-01, -1.4502e-01,  1.1954e-01, -1.5383e-01,
          1.6999e-01],
        [-1.1928e-01, -7.7591e-02, -7.1767e-02,  2.3851e-01, -8.4540e-02,
         -4.8611e-02,  1.5127e-01, -1.7105e-01, -1.2042e-03, -1.9311e-01,
         -2.3074e-01, -5.7078e-02,  2.7636e-02,  2.1319e-01, -2.3975e-01,
         -7.1936e-02],
        [ 6.5789e-02,  9.4403e-02,  1.4606e-01, -2.0102e-01, -6.1118e-02,
          5.7808e-02, -2.0040e-01,  1.2598e-01, -2.3854e-01,  1.5600e-01,
          8.1279e-02, -7.1012e-02,  8.1105e-02,  2.1174e-01,  1.8391e-01,
          1.5164e-01],
        [-1.4553e-01,  7.1840e-02,  1.8761e-01,  4.4093e-02,  1.6552e-01,
         -1.5505e-01,  1.7571e-01, -8.2927e-03, -2.2430e-01, -6.4806e-02,
          2.2096e-01, -8.7336e-02, -4.3299e-02, -1.0001e-01, -1.3593e-01,
          4.3312e-02],
        [ 1.5166e-01,  2.9561e-02, -1.5419e-02,  1.4462e-02, -1.8747e-01,
         -1.3172e-01,  1.2510e-02, -1.9982e-01,  1.2383e-01,  3.8105e-02,
          2.6324e-03, -1.6043e-02,  2.1115e-01,  2.2816e-01,  1.2207e-01,
          1.2417e-01],
        [-1.2122e-01,  1.0220e-01, -1.6909e-01,  1.0804e-01, -1.7752e-01,
         -1.3674e-03,  1.8120e-01,  1.6601e-01,  2.2105e-01,  8.5281e-02,
          9.7044e-02,  6.7042e-02,  1.8255e-01,  1.3119e-01,  7.3767e-02,
         -8.7229e-02],
        [-1.2099e-01, -6.1809e-02,  1.1931e-01, -1.3609e-01,  6.8302e-02,
          2.1873e-01,  2.1169e-01, -1.8406e-01,  7.1259e-02,  1.6347e-01,
         -2.2708e-01,  1.5978e-01, -1.5577e-01, -1.8076e-01, -1.0597e-01,
         -9.4034e-02],
        [-1.0336e-01,  7.1975e-02,  9.6850e-02,  9.7162e-02,  1.7261e-01,
         -1.5818e-01, -2.3738e-01, -2.0056e-01, -1.3741e-01, -1.1435e-01,
          1.0985e-01, -1.8092e-01, -1.8279e-01,  1.3388e-01, -1.5907e-01,
          4.6891e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1906,  0.0954,  0.1562, -0.2103,  0.0850, -0.1311,  0.1587,  0.2249,
        -0.2109,  0.0935,  0.1688,  0.2273,  0.1888,  0.0492,  0.0146,  0.0515,
        -0.1490, -0.0490, -0.0039, -0.1582, -0.0111, -0.0332, -0.0875, -0.0768,
        -0.2490,  0.2382,  0.1232,  0.1807, -0.2128, -0.2448,  0.1859, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0276,  0.0886,  0.0113, -0.0059,  0.1050,  0.1412, -0.0493, -0.1509,
         -0.0969,  0.1263,  0.0154,  0.1514, -0.0618, -0.1675,  0.0549, -0.0753,
         -0.1057,  0.1102,  0.0123, -0.0151,  0.1722,  0.1540, -0.1444, -0.1625,
         -0.0874, -0.1373, -0.0929,  0.1193, -0.1176,  0.1621,  0.0552,  0.0077]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0274,  0.0338,  0.0515,  ...,  0.0370, -0.1580, -0.1137],
        [-0.0412, -0.1228,  0.0849,  ..., -0.0255, -0.1542,  0.0871],
        [-0.0916,  0.0727,  0.1131,  ...,  0.1516,  0.0694,  0.0345],
        ...,
        [ 0.0835, -0.0818,  0.0083,  ..., -0.1147, -0.0697, -0.1180],
        [ 0.0086, -0.1214, -0.0074,  ..., -0.1376, -0.0348,  0.1557],
        [-0.1369,  0.0661,  0.0410,  ..., -0.0287, -0.1442, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0587,  0.0692, -0.1074, -0.1128, -0.0456,  0.0102, -0.1318,  0.0737,
        -0.0301,  0.0931,  0.0477, -0.0256, -0.0145,  0.0492, -0.0832, -0.0415,
         0.0733, -0.1429, -0.0319,  0.0333, -0.0826,  0.0758,  0.0793, -0.0232,
        -0.0515,  0.0775,  0.0090, -0.1238,  0.0923,  0.1576,  0.1370, -0.0883],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1641, -0.0737, -0.1340,  ..., -0.0192, -0.1329,  0.1699],
        [-0.0956,  0.0925,  0.0408,  ...,  0.0663, -0.1323,  0.1671],
        [ 0.0220, -0.1643, -0.1021,  ..., -0.0583,  0.1139,  0.0584],
        ...,
        [ 0.0230, -0.0144,  0.1370,  ...,  0.1392, -0.1018,  0.1490],
        [ 0.0984, -0.0202, -0.0055,  ...,  0.1521,  0.1041, -0.0493],
        [ 0.1011, -0.0131,  0.1673,  ...,  0.1591,  0.0347,  0.0616]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0691,  0.1030,  0.0027, -0.0455, -0.0609, -0.1135, -0.0068, -0.0992,
         0.1055, -0.1266,  0.1537, -0.1561,  0.1472,  0.0200, -0.1666,  0.0530,
        -0.1138, -0.1400,  0.0093, -0.0503,  0.0436,  0.1398, -0.1621,  0.1758,
        -0.0980, -0.0349,  0.1146, -0.0738, -0.0891, -0.0414,  0.0691, -0.0077],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1610,  0.0763, -0.1613, -0.1273,  0.0139, -0.0068, -0.0537,  0.0581,
          0.0742, -0.1026, -0.0353,  0.0633,  0.0641, -0.0159,  0.0889,  0.0632,
         -0.1659, -0.1689,  0.0059,  0.0605, -0.1260, -0.0910, -0.1689,  0.0335,
          0.1281,  0.1566, -0.1439,  0.1365, -0.0708, -0.1557,  0.1134,  0.1485]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0091], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.4959e-01,  2.3544e-01,  1.6261e-01, -1.7926e-01,  1.1951e-04,
         -5.4087e-03,  1.1917e-01, -2.1412e-01,  3.7155e-03,  8.3298e-02,
          1.2723e-01,  2.6141e-02, -1.2392e-01, -2.4000e-01,  1.3513e-01,
          2.2824e-01],
        [-7.5480e-02, -2.2341e-01,  7.3146e-02, -1.7527e-01, -1.6334e-01,
          6.8146e-02, -2.3741e-02, -1.7005e-02,  2.2424e-01, -4.3851e-02,
          1.5218e-01, -7.7806e-02,  1.8603e-01,  7.6268e-02,  2.2277e-01,
          8.7195e-02],
        [-8.8554e-02,  1.0896e-01,  2.1299e-01,  4.7383e-02,  1.1526e-01,
         -1.7588e-01,  1.3546e-01, -2.3632e-01,  2.2101e-01,  1.0326e-01,
          1.6452e-02, -2.3399e-01,  2.2734e-01,  1.5941e-01,  2.3047e-01,
          9.8278e-02],
        [ 8.4194e-02, -6.4758e-02, -1.0245e-01,  9.9101e-02,  8.6701e-02,
         -8.1050e-03,  3.9765e-02,  8.5878e-02, -2.4159e-01, -2.2109e-01,
         -6.6551e-02,  1.7026e-01,  1.2197e-01, -2.3862e-01, -7.5062e-02,
         -2.6426e-02],
        [ 8.2110e-02,  2.0453e-01,  5.4679e-03, -1.9460e-01,  1.5340e-02,
         -9.6540e-02, -1.5279e-01,  1.3847e-01, -3.3588e-02,  1.1813e-01,
          1.9466e-01,  2.4570e-02,  1.4081e-01, -1.1807e-01,  1.3955e-01,
          9.9876e-03],
        [ 1.6613e-01,  2.3901e-01, -1.8911e-01,  2.3733e-01,  1.9084e-01,
         -2.0139e-01,  7.3285e-02, -2.0353e-01,  8.1097e-02,  3.8660e-02,
         -2.3865e-01,  9.0755e-02, -6.8670e-02,  2.4919e-01,  2.4400e-01,
          8.6303e-02],
        [ 1.9706e-01,  9.0295e-02,  2.3652e-01, -2.3082e-02,  6.1788e-02,
         -4.1296e-02, -4.3721e-03, -7.5417e-02, -9.8939e-02,  1.4462e-01,
          1.0728e-01, -1.1036e-01, -2.2033e-01,  1.2224e-01, -2.2997e-01,
         -1.1063e-02],
        [-2.1511e-01,  2.0933e-01,  2.0357e-01, -2.0546e-01, -2.3243e-01,
         -1.4781e-01,  6.8985e-02, -1.2502e-01, -5.9537e-02, -6.3370e-02,
          4.5858e-02, -1.1825e-01,  1.1370e-01, -1.7890e-01, -2.2253e-02,
          2.0956e-01],
        [-1.3804e-01,  1.9180e-01,  1.3012e-01, -8.0755e-02,  8.6691e-02,
         -1.6889e-01,  2.0121e-02,  7.0815e-02,  2.1624e-01, -1.3989e-01,
         -1.4218e-01, -1.2478e-01, -2.4354e-01,  5.0557e-02, -2.0694e-01,
         -6.7111e-02],
        [-1.1155e-01,  1.3978e-02,  7.5837e-02, -1.8167e-01, -7.3804e-02,
         -2.4035e-02, -1.4452e-01,  5.7753e-02,  9.2549e-02, -1.7817e-01,
          1.9658e-01,  1.7765e-01, -7.5106e-02,  3.7198e-02,  3.0439e-02,
         -3.4493e-02],
        [-1.6778e-01,  2.0601e-01,  1.2303e-01, -2.0892e-01, -1.9375e-01,
          2.3774e-01,  3.9901e-02, -5.7436e-02,  1.6943e-01,  7.1820e-02,
          8.9743e-02,  1.9833e-01, -1.9512e-02,  2.3822e-01, -1.7561e-01,
         -1.5213e-01],
        [ 4.2360e-02, -3.0351e-02,  1.4266e-01, -6.7982e-02,  3.9312e-02,
         -5.1947e-02,  1.8769e-01, -1.6398e-02,  3.8373e-03,  1.8315e-01,
          2.4304e-01,  2.3921e-01, -2.4443e-01, -1.4127e-01, -5.4287e-02,
         -5.1611e-02],
        [ 1.4461e-01,  1.1291e-01, -2.0563e-02,  5.9224e-03,  5.3564e-02,
          2.1551e-01,  1.2955e-01, -1.2610e-01, -1.2807e-01,  7.9062e-02,
         -2.5286e-02, -1.6039e-01, -2.4197e-01,  3.5810e-02, -7.3006e-02,
         -1.4546e-01],
        [ 4.7027e-02,  2.4345e-01,  2.0765e-01,  1.4254e-01, -1.8855e-01,
          1.4268e-01,  1.2930e-01,  8.3411e-02, -6.2276e-02, -4.3533e-03,
         -1.3560e-01, -5.6314e-02, -4.1154e-02, -3.5414e-02, -2.4880e-01,
          8.8197e-02],
        [-2.0455e-01, -1.8696e-01,  1.0159e-01, -2.0464e-01,  2.3850e-01,
          2.3939e-01, -7.9446e-02, -4.3085e-02, -1.9126e-01,  1.5456e-02,
          4.5709e-02, -1.3714e-01,  7.8396e-02, -9.6213e-03, -7.3695e-02,
         -8.6492e-04],
        [-2.4233e-01, -1.7611e-01,  3.3092e-02,  2.4143e-01, -1.4818e-01,
          1.6027e-01,  2.2880e-02, -1.0756e-01,  2.7391e-04,  1.1986e-01,
          2.9743e-02,  2.2130e-01, -4.7314e-02, -1.6695e-01,  2.2591e-01,
         -7.1400e-02],
        [ 1.5863e-01,  1.6490e-01,  4.4276e-02, -2.0519e-01, -2.4544e-01,
          1.1868e-01,  6.1123e-02,  1.4547e-01, -2.2035e-01, -3.4443e-02,
          2.1600e-01,  1.3135e-01,  2.0776e-01,  1.9628e-01, -6.1342e-02,
         -1.7025e-01],
        [-1.4907e-01,  8.4907e-02, -9.9234e-02,  9.9149e-04,  3.9896e-02,
          1.5519e-01,  1.3943e-01,  1.4269e-01,  1.0161e-02,  1.4114e-01,
         -1.1704e-01, -1.0006e-01, -3.9583e-02, -1.4518e-01,  2.2300e-01,
         -3.8309e-02],
        [ 7.2681e-02, -7.7727e-03, -3.4193e-03, -1.3325e-01, -1.8354e-02,
         -2.2362e-01, -1.1955e-01,  1.9239e-01, -2.3449e-01,  4.1140e-02,
          3.9828e-02, -2.3928e-01,  4.8829e-02,  1.1608e-01,  1.8107e-01,
          4.6794e-02],
        [ 1.9542e-01,  9.4101e-03,  9.5256e-02,  7.3802e-02, -1.8433e-01,
         -5.4879e-02, -1.7605e-01,  1.9425e-01,  1.1926e-01, -1.0603e-01,
         -4.5749e-02,  6.6739e-02, -2.1798e-01,  7.0592e-03,  1.1925e-01,
          3.1325e-02],
        [-2.3003e-02,  1.6073e-01,  1.0875e-01, -2.2225e-01,  1.4713e-01,
         -1.9718e-01,  1.4043e-01,  2.1051e-01,  2.3040e-02, -8.4493e-02,
         -1.2914e-01, -1.1101e-01, -4.6083e-02, -1.0365e-01,  2.4818e-01,
         -1.0784e-01],
        [ 1.0380e-01, -2.3183e-01,  1.2671e-01,  2.1273e-01, -1.7922e-01,
         -6.3786e-02,  5.9585e-02, -2.3931e-01, -1.5818e-01,  8.6946e-02,
          2.3541e-01, -7.4686e-02, -2.2768e-03, -2.4133e-01, -2.3996e-01,
          2.1742e-01],
        [ 2.1215e-01, -7.6192e-02, -9.8855e-02, -1.6184e-02,  1.1600e-01,
         -2.4160e-01, -1.3848e-01, -8.2418e-02, -1.0881e-01, -6.6043e-03,
          1.8235e-01,  5.4585e-02, -2.2625e-01,  2.3122e-01,  2.0130e-01,
          7.8714e-02],
        [ 1.2237e-01,  9.3457e-02,  2.0492e-01, -2.4045e-01, -1.5563e-01,
         -3.1748e-02, -4.7555e-02, -1.6603e-01, -2.3975e-01, -1.9093e-01,
         -3.8828e-02,  2.1222e-01,  1.6574e-01,  7.2061e-02, -1.5355e-01,
         -1.0057e-01],
        [ 2.4084e-02, -2.3173e-01, -1.1413e-02,  5.0838e-02,  2.2602e-01,
         -6.5625e-02,  2.4539e-01,  1.8861e-02, -1.7345e-01,  2.3628e-01,
          2.1674e-01, -1.9754e-01, -1.4502e-01,  1.1954e-01, -1.5383e-01,
          1.6999e-01],
        [-1.1928e-01, -7.7591e-02, -7.1767e-02,  2.3851e-01, -8.4540e-02,
         -4.8611e-02,  1.5127e-01, -1.7105e-01, -1.2042e-03, -1.9311e-01,
         -2.3074e-01, -5.7078e-02,  2.7636e-02,  2.1319e-01, -2.3975e-01,
         -7.1936e-02],
        [ 6.5789e-02,  9.4403e-02,  1.4606e-01, -2.0102e-01, -6.1118e-02,
          5.7808e-02, -2.0040e-01,  1.2598e-01, -2.3854e-01,  1.5600e-01,
          8.1279e-02, -7.1012e-02,  8.1105e-02,  2.1174e-01,  1.8391e-01,
          1.5164e-01],
        [-1.4553e-01,  7.1840e-02,  1.8761e-01,  4.4093e-02,  1.6552e-01,
         -1.5505e-01,  1.7571e-01, -8.2927e-03, -2.2430e-01, -6.4806e-02,
          2.2096e-01, -8.7336e-02, -4.3299e-02, -1.0001e-01, -1.3593e-01,
          4.3312e-02],
        [ 1.5166e-01,  2.9561e-02, -1.5419e-02,  1.4462e-02, -1.8747e-01,
         -1.3172e-01,  1.2510e-02, -1.9982e-01,  1.2383e-01,  3.8105e-02,
          2.6324e-03, -1.6043e-02,  2.1115e-01,  2.2816e-01,  1.2207e-01,
          1.2417e-01],
        [-1.2122e-01,  1.0220e-01, -1.6909e-01,  1.0804e-01, -1.7752e-01,
         -1.3674e-03,  1.8120e-01,  1.6601e-01,  2.2105e-01,  8.5281e-02,
          9.7044e-02,  6.7042e-02,  1.8255e-01,  1.3119e-01,  7.3767e-02,
         -8.7229e-02],
        [-1.2099e-01, -6.1809e-02,  1.1931e-01, -1.3609e-01,  6.8302e-02,
          2.1873e-01,  2.1169e-01, -1.8406e-01,  7.1259e-02,  1.6347e-01,
         -2.2708e-01,  1.5978e-01, -1.5577e-01, -1.8076e-01, -1.0597e-01,
         -9.4034e-02],
        [-1.0336e-01,  7.1975e-02,  9.6850e-02,  9.7162e-02,  1.7261e-01,
         -1.5818e-01, -2.3738e-01, -2.0056e-01, -1.3741e-01, -1.1435e-01,
          1.0985e-01, -1.8092e-01, -1.8279e-01,  1.3388e-01, -1.5907e-01,
          4.6891e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1906,  0.0954,  0.1562, -0.2103,  0.0850, -0.1311,  0.1587,  0.2249,
        -0.2109,  0.0935,  0.1688,  0.2273,  0.1888,  0.0492,  0.0146,  0.0515,
        -0.1490, -0.0490, -0.0039, -0.1582, -0.0111, -0.0332, -0.0875, -0.0768,
        -0.2490,  0.2382,  0.1232,  0.1807, -0.2128, -0.2448,  0.1859, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0276,  0.0886,  0.0113, -0.0059,  0.1050,  0.1412, -0.0493, -0.1509,
         -0.0969,  0.1263,  0.0154,  0.1514, -0.0618, -0.1675,  0.0549, -0.0753,
         -0.1057,  0.1102,  0.0123, -0.0151,  0.1722,  0.1540, -0.1444, -0.1625,
         -0.0874, -0.1373, -0.0929,  0.1193, -0.1176,  0.1621,  0.0552,  0.0077]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0274,  0.0338,  0.0515,  ...,  0.0370, -0.1580, -0.1137],
        [-0.0412, -0.1228,  0.0849,  ..., -0.0255, -0.1542,  0.0871],
        [-0.0916,  0.0727,  0.1131,  ...,  0.1516,  0.0694,  0.0345],
        ...,
        [ 0.0835, -0.0818,  0.0083,  ..., -0.1147, -0.0697, -0.1180],
        [ 0.0086, -0.1214, -0.0074,  ..., -0.1376, -0.0348,  0.1557],
        [-0.1369,  0.0661,  0.0410,  ..., -0.0287, -0.1442, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0587,  0.0692, -0.1074, -0.1128, -0.0456,  0.0102, -0.1318,  0.0737,
        -0.0301,  0.0931,  0.0477, -0.0256, -0.0145,  0.0492, -0.0832, -0.0415,
         0.0733, -0.1429, -0.0319,  0.0333, -0.0826,  0.0758,  0.0793, -0.0232,
        -0.0515,  0.0775,  0.0090, -0.1238,  0.0923,  0.1576,  0.1370, -0.0883],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1641, -0.0737, -0.1340,  ..., -0.0192, -0.1329,  0.1699],
        [-0.0956,  0.0925,  0.0408,  ...,  0.0663, -0.1323,  0.1671],
        [ 0.0220, -0.1643, -0.1021,  ..., -0.0583,  0.1139,  0.0584],
        ...,
        [ 0.0230, -0.0144,  0.1370,  ...,  0.1392, -0.1018,  0.1490],
        [ 0.0984, -0.0202, -0.0055,  ...,  0.1521,  0.1041, -0.0493],
        [ 0.1011, -0.0131,  0.1673,  ...,  0.1591,  0.0347,  0.0616]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0691,  0.1030,  0.0027, -0.0455, -0.0609, -0.1135, -0.0068, -0.0992,
         0.1055, -0.1266,  0.1537, -0.1561,  0.1472,  0.0200, -0.1666,  0.0530,
        -0.1138, -0.1400,  0.0093, -0.0503,  0.0436,  0.1398, -0.1621,  0.1758,
        -0.0980, -0.0349,  0.1146, -0.0738, -0.0891, -0.0414,  0.0691, -0.0077],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1610,  0.0763, -0.1613, -0.1273,  0.0139, -0.0068, -0.0537,  0.0581,
          0.0742, -0.1026, -0.0353,  0.0633,  0.0641, -0.0159,  0.0889,  0.0632,
         -0.1659, -0.1689,  0.0059,  0.0605, -0.1260, -0.0910, -0.1689,  0.0335,
          0.1281,  0.1566, -0.1439,  0.1365, -0.0708, -0.1557,  0.1134,  0.1485]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0091], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.4959e-01,  2.3544e-01,  1.6261e-01, -1.7926e-01,  1.1951e-04,
         -5.4087e-03,  1.1917e-01, -2.1412e-01,  3.7155e-03,  8.3298e-02,
          1.2723e-01,  2.6141e-02, -1.2392e-01, -2.4000e-01,  1.3513e-01,
          2.2824e-01],
        [-7.5480e-02, -2.2341e-01,  7.3146e-02, -1.7527e-01, -1.6334e-01,
          6.8146e-02, -2.3741e-02, -1.7005e-02,  2.2424e-01, -4.3851e-02,
          1.5218e-01, -7.7806e-02,  1.8603e-01,  7.6268e-02,  2.2277e-01,
          8.7195e-02],
        [-8.8554e-02,  1.0896e-01,  2.1299e-01,  4.7383e-02,  1.1526e-01,
         -1.7588e-01,  1.3546e-01, -2.3632e-01,  2.2101e-01,  1.0326e-01,
          1.6452e-02, -2.3399e-01,  2.2734e-01,  1.5941e-01,  2.3047e-01,
          9.8278e-02],
        [ 8.4194e-02, -6.4758e-02, -1.0245e-01,  9.9101e-02,  8.6701e-02,
         -8.1050e-03,  3.9765e-02,  8.5878e-02, -2.4159e-01, -2.2109e-01,
         -6.6551e-02,  1.7026e-01,  1.2197e-01, -2.3862e-01, -7.5062e-02,
         -2.6426e-02],
        [ 8.2110e-02,  2.0453e-01,  5.4679e-03, -1.9460e-01,  1.5340e-02,
         -9.6540e-02, -1.5279e-01,  1.3847e-01, -3.3588e-02,  1.1813e-01,
          1.9466e-01,  2.4570e-02,  1.4081e-01, -1.1807e-01,  1.3955e-01,
          9.9876e-03],
        [ 1.6613e-01,  2.3901e-01, -1.8911e-01,  2.3733e-01,  1.9084e-01,
         -2.0139e-01,  7.3285e-02, -2.0353e-01,  8.1097e-02,  3.8660e-02,
         -2.3865e-01,  9.0755e-02, -6.8670e-02,  2.4919e-01,  2.4400e-01,
          8.6303e-02],
        [ 1.9706e-01,  9.0295e-02,  2.3652e-01, -2.3082e-02,  6.1788e-02,
         -4.1296e-02, -4.3721e-03, -7.5417e-02, -9.8939e-02,  1.4462e-01,
          1.0728e-01, -1.1036e-01, -2.2033e-01,  1.2224e-01, -2.2997e-01,
         -1.1063e-02],
        [-2.1511e-01,  2.0933e-01,  2.0357e-01, -2.0546e-01, -2.3243e-01,
         -1.4781e-01,  6.8985e-02, -1.2502e-01, -5.9537e-02, -6.3370e-02,
          4.5858e-02, -1.1825e-01,  1.1370e-01, -1.7890e-01, -2.2253e-02,
          2.0956e-01],
        [-1.3804e-01,  1.9180e-01,  1.3012e-01, -8.0755e-02,  8.6691e-02,
         -1.6889e-01,  2.0121e-02,  7.0815e-02,  2.1624e-01, -1.3989e-01,
         -1.4218e-01, -1.2478e-01, -2.4354e-01,  5.0557e-02, -2.0694e-01,
         -6.7111e-02],
        [-1.1155e-01,  1.3978e-02,  7.5837e-02, -1.8167e-01, -7.3804e-02,
         -2.4035e-02, -1.4452e-01,  5.7753e-02,  9.2549e-02, -1.7817e-01,
          1.9658e-01,  1.7765e-01, -7.5106e-02,  3.7198e-02,  3.0439e-02,
         -3.4493e-02],
        [-1.6778e-01,  2.0601e-01,  1.2303e-01, -2.0892e-01, -1.9375e-01,
          2.3774e-01,  3.9901e-02, -5.7436e-02,  1.6943e-01,  7.1820e-02,
          8.9743e-02,  1.9833e-01, -1.9512e-02,  2.3822e-01, -1.7561e-01,
         -1.5213e-01],
        [ 4.2360e-02, -3.0351e-02,  1.4266e-01, -6.7982e-02,  3.9312e-02,
         -5.1947e-02,  1.8769e-01, -1.6398e-02,  3.8373e-03,  1.8315e-01,
          2.4304e-01,  2.3921e-01, -2.4443e-01, -1.4127e-01, -5.4287e-02,
         -5.1611e-02],
        [ 1.4461e-01,  1.1291e-01, -2.0563e-02,  5.9224e-03,  5.3564e-02,
          2.1551e-01,  1.2955e-01, -1.2610e-01, -1.2807e-01,  7.9062e-02,
         -2.5286e-02, -1.6039e-01, -2.4197e-01,  3.5810e-02, -7.3006e-02,
         -1.4546e-01],
        [ 4.7027e-02,  2.4345e-01,  2.0765e-01,  1.4254e-01, -1.8855e-01,
          1.4268e-01,  1.2930e-01,  8.3411e-02, -6.2276e-02, -4.3533e-03,
         -1.3560e-01, -5.6314e-02, -4.1154e-02, -3.5414e-02, -2.4880e-01,
          8.8197e-02],
        [-2.0455e-01, -1.8696e-01,  1.0159e-01, -2.0464e-01,  2.3850e-01,
          2.3939e-01, -7.9446e-02, -4.3085e-02, -1.9126e-01,  1.5456e-02,
          4.5709e-02, -1.3714e-01,  7.8396e-02, -9.6213e-03, -7.3695e-02,
         -8.6492e-04],
        [-2.4233e-01, -1.7611e-01,  3.3092e-02,  2.4143e-01, -1.4818e-01,
          1.6027e-01,  2.2880e-02, -1.0756e-01,  2.7391e-04,  1.1986e-01,
          2.9743e-02,  2.2130e-01, -4.7314e-02, -1.6695e-01,  2.2591e-01,
         -7.1400e-02],
        [ 1.5863e-01,  1.6490e-01,  4.4276e-02, -2.0519e-01, -2.4544e-01,
          1.1868e-01,  6.1123e-02,  1.4547e-01, -2.2035e-01, -3.4443e-02,
          2.1600e-01,  1.3135e-01,  2.0776e-01,  1.9628e-01, -6.1342e-02,
         -1.7025e-01],
        [-1.4907e-01,  8.4907e-02, -9.9234e-02,  9.9149e-04,  3.9896e-02,
          1.5519e-01,  1.3943e-01,  1.4269e-01,  1.0161e-02,  1.4114e-01,
         -1.1704e-01, -1.0006e-01, -3.9583e-02, -1.4518e-01,  2.2300e-01,
         -3.8309e-02],
        [ 7.2681e-02, -7.7727e-03, -3.4193e-03, -1.3325e-01, -1.8354e-02,
         -2.2362e-01, -1.1955e-01,  1.9239e-01, -2.3449e-01,  4.1140e-02,
          3.9828e-02, -2.3928e-01,  4.8829e-02,  1.1608e-01,  1.8107e-01,
          4.6794e-02],
        [ 1.9542e-01,  9.4101e-03,  9.5256e-02,  7.3802e-02, -1.8433e-01,
         -5.4879e-02, -1.7605e-01,  1.9425e-01,  1.1926e-01, -1.0603e-01,
         -4.5749e-02,  6.6739e-02, -2.1798e-01,  7.0592e-03,  1.1925e-01,
          3.1325e-02],
        [-2.3003e-02,  1.6073e-01,  1.0875e-01, -2.2225e-01,  1.4713e-01,
         -1.9718e-01,  1.4043e-01,  2.1051e-01,  2.3040e-02, -8.4493e-02,
         -1.2914e-01, -1.1101e-01, -4.6083e-02, -1.0365e-01,  2.4818e-01,
         -1.0784e-01],
        [ 1.0380e-01, -2.3183e-01,  1.2671e-01,  2.1273e-01, -1.7922e-01,
         -6.3786e-02,  5.9585e-02, -2.3931e-01, -1.5818e-01,  8.6946e-02,
          2.3541e-01, -7.4686e-02, -2.2768e-03, -2.4133e-01, -2.3996e-01,
          2.1742e-01],
        [ 2.1215e-01, -7.6192e-02, -9.8855e-02, -1.6184e-02,  1.1600e-01,
         -2.4160e-01, -1.3848e-01, -8.2418e-02, -1.0881e-01, -6.6043e-03,
          1.8235e-01,  5.4585e-02, -2.2625e-01,  2.3122e-01,  2.0130e-01,
          7.8714e-02],
        [ 1.2237e-01,  9.3457e-02,  2.0492e-01, -2.4045e-01, -1.5563e-01,
         -3.1748e-02, -4.7555e-02, -1.6603e-01, -2.3975e-01, -1.9093e-01,
         -3.8828e-02,  2.1222e-01,  1.6574e-01,  7.2061e-02, -1.5355e-01,
         -1.0057e-01],
        [ 2.4084e-02, -2.3173e-01, -1.1413e-02,  5.0838e-02,  2.2602e-01,
         -6.5625e-02,  2.4539e-01,  1.8861e-02, -1.7345e-01,  2.3628e-01,
          2.1674e-01, -1.9754e-01, -1.4502e-01,  1.1954e-01, -1.5383e-01,
          1.6999e-01],
        [-1.1928e-01, -7.7591e-02, -7.1767e-02,  2.3851e-01, -8.4540e-02,
         -4.8611e-02,  1.5127e-01, -1.7105e-01, -1.2042e-03, -1.9311e-01,
         -2.3074e-01, -5.7078e-02,  2.7636e-02,  2.1319e-01, -2.3975e-01,
         -7.1936e-02],
        [ 6.5789e-02,  9.4403e-02,  1.4606e-01, -2.0102e-01, -6.1118e-02,
          5.7808e-02, -2.0040e-01,  1.2598e-01, -2.3854e-01,  1.5600e-01,
          8.1279e-02, -7.1012e-02,  8.1105e-02,  2.1174e-01,  1.8391e-01,
          1.5164e-01],
        [-1.4553e-01,  7.1840e-02,  1.8761e-01,  4.4093e-02,  1.6552e-01,
         -1.5505e-01,  1.7571e-01, -8.2927e-03, -2.2430e-01, -6.4806e-02,
          2.2096e-01, -8.7336e-02, -4.3299e-02, -1.0001e-01, -1.3593e-01,
          4.3312e-02],
        [ 1.5166e-01,  2.9561e-02, -1.5419e-02,  1.4462e-02, -1.8747e-01,
         -1.3172e-01,  1.2510e-02, -1.9982e-01,  1.2383e-01,  3.8105e-02,
          2.6324e-03, -1.6043e-02,  2.1115e-01,  2.2816e-01,  1.2207e-01,
          1.2417e-01],
        [-1.2122e-01,  1.0220e-01, -1.6909e-01,  1.0804e-01, -1.7752e-01,
         -1.3674e-03,  1.8120e-01,  1.6601e-01,  2.2105e-01,  8.5281e-02,
          9.7044e-02,  6.7042e-02,  1.8255e-01,  1.3119e-01,  7.3767e-02,
         -8.7229e-02],
        [-1.2099e-01, -6.1809e-02,  1.1931e-01, -1.3609e-01,  6.8302e-02,
          2.1873e-01,  2.1169e-01, -1.8406e-01,  7.1259e-02,  1.6347e-01,
         -2.2708e-01,  1.5978e-01, -1.5577e-01, -1.8076e-01, -1.0597e-01,
         -9.4034e-02],
        [-1.0336e-01,  7.1975e-02,  9.6850e-02,  9.7162e-02,  1.7261e-01,
         -1.5818e-01, -2.3738e-01, -2.0056e-01, -1.3741e-01, -1.1435e-01,
          1.0985e-01, -1.8092e-01, -1.8279e-01,  1.3388e-01, -1.5907e-01,
          4.6891e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1906,  0.0954,  0.1562, -0.2103,  0.0850, -0.1311,  0.1587,  0.2249,
        -0.2109,  0.0935,  0.1688,  0.2273,  0.1888,  0.0492,  0.0146,  0.0515,
        -0.1490, -0.0490, -0.0039, -0.1582, -0.0111, -0.0332, -0.0875, -0.0768,
        -0.2490,  0.2382,  0.1232,  0.1807, -0.2128, -0.2448,  0.1859, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0276,  0.0886,  0.0113, -0.0059,  0.1050,  0.1412, -0.0493, -0.1509,
         -0.0969,  0.1263,  0.0154,  0.1514, -0.0618, -0.1675,  0.0549, -0.0753,
         -0.1057,  0.1102,  0.0123, -0.0151,  0.1722,  0.1540, -0.1444, -0.1625,
         -0.0874, -0.1373, -0.0929,  0.1193, -0.1176,  0.1621,  0.0552,  0.0077]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0274,  0.0338,  0.0515,  ...,  0.0370, -0.1580, -0.1137],
        [-0.0412, -0.1228,  0.0849,  ..., -0.0255, -0.1542,  0.0871],
        [-0.0916,  0.0727,  0.1131,  ...,  0.1516,  0.0694,  0.0345],
        ...,
        [ 0.0835, -0.0818,  0.0083,  ..., -0.1147, -0.0697, -0.1180],
        [ 0.0086, -0.1214, -0.0074,  ..., -0.1376, -0.0348,  0.1557],
        [-0.1369,  0.0661,  0.0410,  ..., -0.0287, -0.1442, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0587,  0.0692, -0.1074, -0.1128, -0.0456,  0.0102, -0.1318,  0.0737,
        -0.0301,  0.0931,  0.0477, -0.0256, -0.0145,  0.0492, -0.0832, -0.0415,
         0.0733, -0.1429, -0.0319,  0.0333, -0.0826,  0.0758,  0.0793, -0.0232,
        -0.0515,  0.0775,  0.0090, -0.1238,  0.0923,  0.1576,  0.1370, -0.0883],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1641, -0.0737, -0.1340,  ..., -0.0192, -0.1329,  0.1699],
        [-0.0956,  0.0925,  0.0408,  ...,  0.0663, -0.1323,  0.1671],
        [ 0.0220, -0.1643, -0.1021,  ..., -0.0583,  0.1139,  0.0584],
        ...,
        [ 0.0230, -0.0144,  0.1370,  ...,  0.1392, -0.1018,  0.1490],
        [ 0.0984, -0.0202, -0.0055,  ...,  0.1521,  0.1041, -0.0493],
        [ 0.1011, -0.0131,  0.1673,  ...,  0.1591,  0.0347,  0.0616]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0691,  0.1030,  0.0027, -0.0455, -0.0609, -0.1135, -0.0068, -0.0992,
         0.1055, -0.1266,  0.1537, -0.1561,  0.1472,  0.0200, -0.1666,  0.0530,
        -0.1138, -0.1400,  0.0093, -0.0503,  0.0436,  0.1398, -0.1621,  0.1758,
        -0.0980, -0.0349,  0.1146, -0.0738, -0.0891, -0.0414,  0.0691, -0.0077],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1610,  0.0763, -0.1613, -0.1273,  0.0139, -0.0068, -0.0537,  0.0581,
          0.0742, -0.1026, -0.0353,  0.0633,  0.0641, -0.0159,  0.0889,  0.0632,
         -0.1659, -0.1689,  0.0059,  0.0605, -0.1260, -0.0910, -0.1689,  0.0335,
          0.1281,  0.1566, -0.1439,  0.1365, -0.0708, -0.1557,  0.1134,  0.1485]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0091], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.4959e-01,  2.3544e-01,  1.6261e-01, -1.7926e-01,  1.1951e-04,
         -5.4087e-03,  1.1917e-01, -2.1412e-01,  3.7155e-03,  8.3298e-02,
          1.2723e-01,  2.6141e-02, -1.2392e-01, -2.4000e-01,  1.3513e-01,
          2.2824e-01],
        [-7.5480e-02, -2.2341e-01,  7.3146e-02, -1.7527e-01, -1.6334e-01,
          6.8146e-02, -2.3741e-02, -1.7005e-02,  2.2424e-01, -4.3851e-02,
          1.5218e-01, -7.7806e-02,  1.8603e-01,  7.6268e-02,  2.2277e-01,
          8.7195e-02],
        [-8.8554e-02,  1.0896e-01,  2.1299e-01,  4.7383e-02,  1.1526e-01,
         -1.7588e-01,  1.3546e-01, -2.3632e-01,  2.2101e-01,  1.0326e-01,
          1.6452e-02, -2.3399e-01,  2.2734e-01,  1.5941e-01,  2.3047e-01,
          9.8278e-02],
        [ 8.4194e-02, -6.4758e-02, -1.0245e-01,  9.9101e-02,  8.6701e-02,
         -8.1050e-03,  3.9765e-02,  8.5878e-02, -2.4159e-01, -2.2109e-01,
         -6.6551e-02,  1.7026e-01,  1.2197e-01, -2.3862e-01, -7.5062e-02,
         -2.6426e-02],
        [ 8.2110e-02,  2.0453e-01,  5.4679e-03, -1.9460e-01,  1.5340e-02,
         -9.6540e-02, -1.5279e-01,  1.3847e-01, -3.3588e-02,  1.1813e-01,
          1.9466e-01,  2.4570e-02,  1.4081e-01, -1.1807e-01,  1.3955e-01,
          9.9876e-03],
        [ 1.6613e-01,  2.3901e-01, -1.8911e-01,  2.3733e-01,  1.9084e-01,
         -2.0139e-01,  7.3285e-02, -2.0353e-01,  8.1097e-02,  3.8660e-02,
         -2.3865e-01,  9.0755e-02, -6.8670e-02,  2.4919e-01,  2.4400e-01,
          8.6303e-02],
        [ 1.9706e-01,  9.0295e-02,  2.3652e-01, -2.3082e-02,  6.1788e-02,
         -4.1296e-02, -4.3721e-03, -7.5417e-02, -9.8939e-02,  1.4462e-01,
          1.0728e-01, -1.1036e-01, -2.2033e-01,  1.2224e-01, -2.2997e-01,
         -1.1063e-02],
        [-2.1511e-01,  2.0933e-01,  2.0357e-01, -2.0546e-01, -2.3243e-01,
         -1.4781e-01,  6.8985e-02, -1.2502e-01, -5.9537e-02, -6.3370e-02,
          4.5858e-02, -1.1825e-01,  1.1370e-01, -1.7890e-01, -2.2253e-02,
          2.0956e-01],
        [-1.3804e-01,  1.9180e-01,  1.3012e-01, -8.0755e-02,  8.6691e-02,
         -1.6889e-01,  2.0121e-02,  7.0815e-02,  2.1624e-01, -1.3989e-01,
         -1.4218e-01, -1.2478e-01, -2.4354e-01,  5.0557e-02, -2.0694e-01,
         -6.7111e-02],
        [-1.1155e-01,  1.3978e-02,  7.5837e-02, -1.8167e-01, -7.3804e-02,
         -2.4035e-02, -1.4452e-01,  5.7753e-02,  9.2549e-02, -1.7817e-01,
          1.9658e-01,  1.7765e-01, -7.5106e-02,  3.7198e-02,  3.0439e-02,
         -3.4493e-02],
        [-1.6778e-01,  2.0601e-01,  1.2303e-01, -2.0892e-01, -1.9375e-01,
          2.3774e-01,  3.9901e-02, -5.7436e-02,  1.6943e-01,  7.1820e-02,
          8.9743e-02,  1.9833e-01, -1.9512e-02,  2.3822e-01, -1.7561e-01,
         -1.5213e-01],
        [ 4.2360e-02, -3.0351e-02,  1.4266e-01, -6.7982e-02,  3.9312e-02,
         -5.1947e-02,  1.8769e-01, -1.6398e-02,  3.8373e-03,  1.8315e-01,
          2.4304e-01,  2.3921e-01, -2.4443e-01, -1.4127e-01, -5.4287e-02,
         -5.1611e-02],
        [ 1.4461e-01,  1.1291e-01, -2.0563e-02,  5.9224e-03,  5.3564e-02,
          2.1551e-01,  1.2955e-01, -1.2610e-01, -1.2807e-01,  7.9062e-02,
         -2.5286e-02, -1.6039e-01, -2.4197e-01,  3.5810e-02, -7.3006e-02,
         -1.4546e-01],
        [ 4.7027e-02,  2.4345e-01,  2.0765e-01,  1.4254e-01, -1.8855e-01,
          1.4268e-01,  1.2930e-01,  8.3411e-02, -6.2276e-02, -4.3533e-03,
         -1.3560e-01, -5.6314e-02, -4.1154e-02, -3.5414e-02, -2.4880e-01,
          8.8197e-02],
        [-2.0455e-01, -1.8696e-01,  1.0159e-01, -2.0464e-01,  2.3850e-01,
          2.3939e-01, -7.9446e-02, -4.3085e-02, -1.9126e-01,  1.5456e-02,
          4.5709e-02, -1.3714e-01,  7.8396e-02, -9.6213e-03, -7.3695e-02,
         -8.6492e-04],
        [-2.4233e-01, -1.7611e-01,  3.3092e-02,  2.4143e-01, -1.4818e-01,
          1.6027e-01,  2.2880e-02, -1.0756e-01,  2.7391e-04,  1.1986e-01,
          2.9743e-02,  2.2130e-01, -4.7314e-02, -1.6695e-01,  2.2591e-01,
         -7.1400e-02],
        [ 1.5863e-01,  1.6490e-01,  4.4276e-02, -2.0519e-01, -2.4544e-01,
          1.1868e-01,  6.1123e-02,  1.4547e-01, -2.2035e-01, -3.4443e-02,
          2.1600e-01,  1.3135e-01,  2.0776e-01,  1.9628e-01, -6.1342e-02,
         -1.7025e-01],
        [-1.4907e-01,  8.4907e-02, -9.9234e-02,  9.9149e-04,  3.9896e-02,
          1.5519e-01,  1.3943e-01,  1.4269e-01,  1.0161e-02,  1.4114e-01,
         -1.1704e-01, -1.0006e-01, -3.9583e-02, -1.4518e-01,  2.2300e-01,
         -3.8309e-02],
        [ 7.2681e-02, -7.7727e-03, -3.4193e-03, -1.3325e-01, -1.8354e-02,
         -2.2362e-01, -1.1955e-01,  1.9239e-01, -2.3449e-01,  4.1140e-02,
          3.9828e-02, -2.3928e-01,  4.8829e-02,  1.1608e-01,  1.8107e-01,
          4.6794e-02],
        [ 1.9542e-01,  9.4101e-03,  9.5256e-02,  7.3802e-02, -1.8433e-01,
         -5.4879e-02, -1.7605e-01,  1.9425e-01,  1.1926e-01, -1.0603e-01,
         -4.5749e-02,  6.6739e-02, -2.1798e-01,  7.0592e-03,  1.1925e-01,
          3.1325e-02],
        [-2.3003e-02,  1.6073e-01,  1.0875e-01, -2.2225e-01,  1.4713e-01,
         -1.9718e-01,  1.4043e-01,  2.1051e-01,  2.3040e-02, -8.4493e-02,
         -1.2914e-01, -1.1101e-01, -4.6083e-02, -1.0365e-01,  2.4818e-01,
         -1.0784e-01],
        [ 1.0380e-01, -2.3183e-01,  1.2671e-01,  2.1273e-01, -1.7922e-01,
         -6.3786e-02,  5.9585e-02, -2.3931e-01, -1.5818e-01,  8.6946e-02,
          2.3541e-01, -7.4686e-02, -2.2768e-03, -2.4133e-01, -2.3996e-01,
          2.1742e-01],
        [ 2.1215e-01, -7.6192e-02, -9.8855e-02, -1.6184e-02,  1.1600e-01,
         -2.4160e-01, -1.3848e-01, -8.2418e-02, -1.0881e-01, -6.6043e-03,
          1.8235e-01,  5.4585e-02, -2.2625e-01,  2.3122e-01,  2.0130e-01,
          7.8714e-02],
        [ 1.2237e-01,  9.3457e-02,  2.0492e-01, -2.4045e-01, -1.5563e-01,
         -3.1748e-02, -4.7555e-02, -1.6603e-01, -2.3975e-01, -1.9093e-01,
         -3.8828e-02,  2.1222e-01,  1.6574e-01,  7.2061e-02, -1.5355e-01,
         -1.0057e-01],
        [ 2.4084e-02, -2.3173e-01, -1.1413e-02,  5.0838e-02,  2.2602e-01,
         -6.5625e-02,  2.4539e-01,  1.8861e-02, -1.7345e-01,  2.3628e-01,
          2.1674e-01, -1.9754e-01, -1.4502e-01,  1.1954e-01, -1.5383e-01,
          1.6999e-01],
        [-1.1928e-01, -7.7591e-02, -7.1767e-02,  2.3851e-01, -8.4540e-02,
         -4.8611e-02,  1.5127e-01, -1.7105e-01, -1.2042e-03, -1.9311e-01,
         -2.3074e-01, -5.7078e-02,  2.7636e-02,  2.1319e-01, -2.3975e-01,
         -7.1936e-02],
        [ 6.5789e-02,  9.4403e-02,  1.4606e-01, -2.0102e-01, -6.1118e-02,
          5.7808e-02, -2.0040e-01,  1.2598e-01, -2.3854e-01,  1.5600e-01,
          8.1279e-02, -7.1012e-02,  8.1105e-02,  2.1174e-01,  1.8391e-01,
          1.5164e-01],
        [-1.4553e-01,  7.1840e-02,  1.8761e-01,  4.4093e-02,  1.6552e-01,
         -1.5505e-01,  1.7571e-01, -8.2927e-03, -2.2430e-01, -6.4806e-02,
          2.2096e-01, -8.7336e-02, -4.3299e-02, -1.0001e-01, -1.3593e-01,
          4.3312e-02],
        [ 1.5166e-01,  2.9561e-02, -1.5419e-02,  1.4462e-02, -1.8747e-01,
         -1.3172e-01,  1.2510e-02, -1.9982e-01,  1.2383e-01,  3.8105e-02,
          2.6324e-03, -1.6043e-02,  2.1115e-01,  2.2816e-01,  1.2207e-01,
          1.2417e-01],
        [-1.2122e-01,  1.0220e-01, -1.6909e-01,  1.0804e-01, -1.7752e-01,
         -1.3674e-03,  1.8120e-01,  1.6601e-01,  2.2105e-01,  8.5281e-02,
          9.7044e-02,  6.7042e-02,  1.8255e-01,  1.3119e-01,  7.3767e-02,
         -8.7229e-02],
        [-1.2099e-01, -6.1809e-02,  1.1931e-01, -1.3609e-01,  6.8302e-02,
          2.1873e-01,  2.1169e-01, -1.8406e-01,  7.1259e-02,  1.6347e-01,
         -2.2708e-01,  1.5978e-01, -1.5577e-01, -1.8076e-01, -1.0597e-01,
         -9.4034e-02],
        [-1.0336e-01,  7.1975e-02,  9.6850e-02,  9.7162e-02,  1.7261e-01,
         -1.5818e-01, -2.3738e-01, -2.0056e-01, -1.3741e-01, -1.1435e-01,
          1.0985e-01, -1.8092e-01, -1.8279e-01,  1.3388e-01, -1.5907e-01,
          4.6891e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1906,  0.0954,  0.1562, -0.2103,  0.0850, -0.1311,  0.1587,  0.2249,
        -0.2109,  0.0935,  0.1688,  0.2273,  0.1888,  0.0492,  0.0146,  0.0515,
        -0.1490, -0.0490, -0.0039, -0.1582, -0.0111, -0.0332, -0.0875, -0.0768,
        -0.2490,  0.2382,  0.1232,  0.1807, -0.2128, -0.2448,  0.1859, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0276,  0.0886,  0.0113, -0.0059,  0.1050,  0.1412, -0.0493, -0.1509,
         -0.0969,  0.1263,  0.0154,  0.1514, -0.0618, -0.1675,  0.0549, -0.0753,
         -0.1057,  0.1102,  0.0123, -0.0151,  0.1722,  0.1540, -0.1444, -0.1625,
         -0.0874, -0.1373, -0.0929,  0.1193, -0.1176,  0.1621,  0.0552,  0.0077]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0274,  0.0338,  0.0515,  ...,  0.0370, -0.1580, -0.1137],
        [-0.0412, -0.1228,  0.0849,  ..., -0.0255, -0.1542,  0.0871],
        [-0.0916,  0.0727,  0.1131,  ...,  0.1516,  0.0694,  0.0345],
        ...,
        [ 0.0835, -0.0818,  0.0083,  ..., -0.1147, -0.0697, -0.1180],
        [ 0.0086, -0.1214, -0.0074,  ..., -0.1376, -0.0348,  0.1557],
        [-0.1369,  0.0661,  0.0410,  ..., -0.0287, -0.1442, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0587,  0.0692, -0.1074, -0.1128, -0.0456,  0.0102, -0.1318,  0.0737,
        -0.0301,  0.0931,  0.0477, -0.0256, -0.0145,  0.0492, -0.0832, -0.0415,
         0.0733, -0.1429, -0.0319,  0.0333, -0.0826,  0.0758,  0.0793, -0.0232,
        -0.0515,  0.0775,  0.0090, -0.1238,  0.0923,  0.1576,  0.1370, -0.0883],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1641, -0.0737, -0.1340,  ..., -0.0192, -0.1329,  0.1699],
        [-0.0956,  0.0925,  0.0408,  ...,  0.0663, -0.1323,  0.1671],
        [ 0.0220, -0.1643, -0.1021,  ..., -0.0583,  0.1139,  0.0584],
        ...,
        [ 0.0230, -0.0144,  0.1370,  ...,  0.1392, -0.1018,  0.1490],
        [ 0.0984, -0.0202, -0.0055,  ...,  0.1521,  0.1041, -0.0493],
        [ 0.1011, -0.0131,  0.1673,  ...,  0.1591,  0.0347,  0.0616]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0691,  0.1030,  0.0027, -0.0455, -0.0609, -0.1135, -0.0068, -0.0992,
         0.1055, -0.1266,  0.1537, -0.1561,  0.1472,  0.0200, -0.1666,  0.0530,
        -0.1138, -0.1400,  0.0093, -0.0503,  0.0436,  0.1398, -0.1621,  0.1758,
        -0.0980, -0.0349,  0.1146, -0.0738, -0.0891, -0.0414,  0.0691, -0.0077],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1610,  0.0763, -0.1613, -0.1273,  0.0139, -0.0068, -0.0537,  0.0581,
          0.0742, -0.1026, -0.0353,  0.0633,  0.0641, -0.0159,  0.0889,  0.0632,
         -0.1659, -0.1689,  0.0059,  0.0605, -0.1260, -0.0910, -0.1689,  0.0335,
          0.1281,  0.1566, -0.1439,  0.1365, -0.0708, -0.1557,  0.1134,  0.1485]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0091], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.4959e-01,  2.3544e-01,  1.6261e-01, -1.7926e-01,  1.1951e-04,
         -5.4087e-03,  1.1917e-01, -2.1412e-01,  3.7155e-03,  8.3298e-02,
          1.2723e-01,  2.6141e-02, -1.2392e-01, -2.4000e-01,  1.3513e-01,
          2.2824e-01],
        [-7.5480e-02, -2.2341e-01,  7.3146e-02, -1.7527e-01, -1.6334e-01,
          6.8146e-02, -2.3741e-02, -1.7005e-02,  2.2424e-01, -4.3851e-02,
          1.5218e-01, -7.7806e-02,  1.8603e-01,  7.6268e-02,  2.2277e-01,
          8.7195e-02],
        [-8.8554e-02,  1.0896e-01,  2.1299e-01,  4.7383e-02,  1.1526e-01,
         -1.7588e-01,  1.3546e-01, -2.3632e-01,  2.2101e-01,  1.0326e-01,
          1.6452e-02, -2.3399e-01,  2.2734e-01,  1.5941e-01,  2.3047e-01,
          9.8278e-02],
        [ 8.4194e-02, -6.4758e-02, -1.0245e-01,  9.9101e-02,  8.6701e-02,
         -8.1050e-03,  3.9765e-02,  8.5878e-02, -2.4159e-01, -2.2109e-01,
         -6.6551e-02,  1.7026e-01,  1.2197e-01, -2.3862e-01, -7.5062e-02,
         -2.6426e-02],
        [ 8.2110e-02,  2.0453e-01,  5.4679e-03, -1.9460e-01,  1.5340e-02,
         -9.6540e-02, -1.5279e-01,  1.3847e-01, -3.3588e-02,  1.1813e-01,
          1.9466e-01,  2.4570e-02,  1.4081e-01, -1.1807e-01,  1.3955e-01,
          9.9876e-03],
        [ 1.6613e-01,  2.3901e-01, -1.8911e-01,  2.3733e-01,  1.9084e-01,
         -2.0139e-01,  7.3285e-02, -2.0353e-01,  8.1097e-02,  3.8660e-02,
         -2.3865e-01,  9.0755e-02, -6.8670e-02,  2.4919e-01,  2.4400e-01,
          8.6303e-02],
        [ 1.9706e-01,  9.0295e-02,  2.3652e-01, -2.3082e-02,  6.1788e-02,
         -4.1296e-02, -4.3721e-03, -7.5417e-02, -9.8939e-02,  1.4462e-01,
          1.0728e-01, -1.1036e-01, -2.2033e-01,  1.2224e-01, -2.2997e-01,
         -1.1063e-02],
        [-2.1511e-01,  2.0933e-01,  2.0357e-01, -2.0546e-01, -2.3243e-01,
         -1.4781e-01,  6.8985e-02, -1.2502e-01, -5.9537e-02, -6.3370e-02,
          4.5858e-02, -1.1825e-01,  1.1370e-01, -1.7890e-01, -2.2253e-02,
          2.0956e-01],
        [-1.3804e-01,  1.9180e-01,  1.3012e-01, -8.0755e-02,  8.6691e-02,
         -1.6889e-01,  2.0121e-02,  7.0815e-02,  2.1624e-01, -1.3989e-01,
         -1.4218e-01, -1.2478e-01, -2.4354e-01,  5.0557e-02, -2.0694e-01,
         -6.7111e-02],
        [-1.1155e-01,  1.3978e-02,  7.5837e-02, -1.8167e-01, -7.3804e-02,
         -2.4035e-02, -1.4452e-01,  5.7753e-02,  9.2549e-02, -1.7817e-01,
          1.9658e-01,  1.7765e-01, -7.5106e-02,  3.7198e-02,  3.0439e-02,
         -3.4493e-02],
        [-1.6778e-01,  2.0601e-01,  1.2303e-01, -2.0892e-01, -1.9375e-01,
          2.3774e-01,  3.9901e-02, -5.7436e-02,  1.6943e-01,  7.1820e-02,
          8.9743e-02,  1.9833e-01, -1.9512e-02,  2.3822e-01, -1.7561e-01,
         -1.5213e-01],
        [ 4.2360e-02, -3.0351e-02,  1.4266e-01, -6.7982e-02,  3.9312e-02,
         -5.1947e-02,  1.8769e-01, -1.6398e-02,  3.8373e-03,  1.8315e-01,
          2.4304e-01,  2.3921e-01, -2.4443e-01, -1.4127e-01, -5.4287e-02,
         -5.1611e-02],
        [ 1.4461e-01,  1.1291e-01, -2.0563e-02,  5.9224e-03,  5.3564e-02,
          2.1551e-01,  1.2955e-01, -1.2610e-01, -1.2807e-01,  7.9062e-02,
         -2.5286e-02, -1.6039e-01, -2.4197e-01,  3.5810e-02, -7.3006e-02,
         -1.4546e-01],
        [ 4.7027e-02,  2.4345e-01,  2.0765e-01,  1.4254e-01, -1.8855e-01,
          1.4268e-01,  1.2930e-01,  8.3411e-02, -6.2276e-02, -4.3533e-03,
         -1.3560e-01, -5.6314e-02, -4.1154e-02, -3.5414e-02, -2.4880e-01,
          8.8197e-02],
        [-2.0455e-01, -1.8696e-01,  1.0159e-01, -2.0464e-01,  2.3850e-01,
          2.3939e-01, -7.9446e-02, -4.3085e-02, -1.9126e-01,  1.5456e-02,
          4.5709e-02, -1.3714e-01,  7.8396e-02, -9.6213e-03, -7.3695e-02,
         -8.6492e-04],
        [-2.4233e-01, -1.7611e-01,  3.3092e-02,  2.4143e-01, -1.4818e-01,
          1.6027e-01,  2.2880e-02, -1.0756e-01,  2.7391e-04,  1.1986e-01,
          2.9743e-02,  2.2130e-01, -4.7314e-02, -1.6695e-01,  2.2591e-01,
         -7.1400e-02],
        [ 1.5863e-01,  1.6490e-01,  4.4276e-02, -2.0519e-01, -2.4544e-01,
          1.1868e-01,  6.1123e-02,  1.4547e-01, -2.2035e-01, -3.4443e-02,
          2.1600e-01,  1.3135e-01,  2.0776e-01,  1.9628e-01, -6.1342e-02,
         -1.7025e-01],
        [-1.4907e-01,  8.4907e-02, -9.9234e-02,  9.9149e-04,  3.9896e-02,
          1.5519e-01,  1.3943e-01,  1.4269e-01,  1.0161e-02,  1.4114e-01,
         -1.1704e-01, -1.0006e-01, -3.9583e-02, -1.4518e-01,  2.2300e-01,
         -3.8309e-02],
        [ 7.2681e-02, -7.7727e-03, -3.4193e-03, -1.3325e-01, -1.8354e-02,
         -2.2362e-01, -1.1955e-01,  1.9239e-01, -2.3449e-01,  4.1140e-02,
          3.9828e-02, -2.3928e-01,  4.8829e-02,  1.1608e-01,  1.8107e-01,
          4.6794e-02],
        [ 1.9542e-01,  9.4101e-03,  9.5256e-02,  7.3802e-02, -1.8433e-01,
         -5.4879e-02, -1.7605e-01,  1.9425e-01,  1.1926e-01, -1.0603e-01,
         -4.5749e-02,  6.6739e-02, -2.1798e-01,  7.0592e-03,  1.1925e-01,
          3.1325e-02],
        [-2.3003e-02,  1.6073e-01,  1.0875e-01, -2.2225e-01,  1.4713e-01,
         -1.9718e-01,  1.4043e-01,  2.1051e-01,  2.3040e-02, -8.4493e-02,
         -1.2914e-01, -1.1101e-01, -4.6083e-02, -1.0365e-01,  2.4818e-01,
         -1.0784e-01],
        [ 1.0380e-01, -2.3183e-01,  1.2671e-01,  2.1273e-01, -1.7922e-01,
         -6.3786e-02,  5.9585e-02, -2.3931e-01, -1.5818e-01,  8.6946e-02,
          2.3541e-01, -7.4686e-02, -2.2768e-03, -2.4133e-01, -2.3996e-01,
          2.1742e-01],
        [ 2.1215e-01, -7.6192e-02, -9.8855e-02, -1.6184e-02,  1.1600e-01,
         -2.4160e-01, -1.3848e-01, -8.2418e-02, -1.0881e-01, -6.6043e-03,
          1.8235e-01,  5.4585e-02, -2.2625e-01,  2.3122e-01,  2.0130e-01,
          7.8714e-02],
        [ 1.2237e-01,  9.3457e-02,  2.0492e-01, -2.4045e-01, -1.5563e-01,
         -3.1748e-02, -4.7555e-02, -1.6603e-01, -2.3975e-01, -1.9093e-01,
         -3.8828e-02,  2.1222e-01,  1.6574e-01,  7.2061e-02, -1.5355e-01,
         -1.0057e-01],
        [ 2.4084e-02, -2.3173e-01, -1.1413e-02,  5.0838e-02,  2.2602e-01,
         -6.5625e-02,  2.4539e-01,  1.8861e-02, -1.7345e-01,  2.3628e-01,
          2.1674e-01, -1.9754e-01, -1.4502e-01,  1.1954e-01, -1.5383e-01,
          1.6999e-01],
        [-1.1928e-01, -7.7591e-02, -7.1767e-02,  2.3851e-01, -8.4540e-02,
         -4.8611e-02,  1.5127e-01, -1.7105e-01, -1.2042e-03, -1.9311e-01,
         -2.3074e-01, -5.7078e-02,  2.7636e-02,  2.1319e-01, -2.3975e-01,
         -7.1936e-02],
        [ 6.5789e-02,  9.4403e-02,  1.4606e-01, -2.0102e-01, -6.1118e-02,
          5.7808e-02, -2.0040e-01,  1.2598e-01, -2.3854e-01,  1.5600e-01,
          8.1279e-02, -7.1012e-02,  8.1105e-02,  2.1174e-01,  1.8391e-01,
          1.5164e-01],
        [-1.4553e-01,  7.1840e-02,  1.8761e-01,  4.4093e-02,  1.6552e-01,
         -1.5505e-01,  1.7571e-01, -8.2927e-03, -2.2430e-01, -6.4806e-02,
          2.2096e-01, -8.7336e-02, -4.3299e-02, -1.0001e-01, -1.3593e-01,
          4.3312e-02],
        [ 1.5166e-01,  2.9561e-02, -1.5419e-02,  1.4462e-02, -1.8747e-01,
         -1.3172e-01,  1.2510e-02, -1.9982e-01,  1.2383e-01,  3.8105e-02,
          2.6324e-03, -1.6043e-02,  2.1115e-01,  2.2816e-01,  1.2207e-01,
          1.2417e-01],
        [-1.2122e-01,  1.0220e-01, -1.6909e-01,  1.0804e-01, -1.7752e-01,
         -1.3674e-03,  1.8120e-01,  1.6601e-01,  2.2105e-01,  8.5281e-02,
          9.7044e-02,  6.7042e-02,  1.8255e-01,  1.3119e-01,  7.3767e-02,
         -8.7229e-02],
        [-1.2099e-01, -6.1809e-02,  1.1931e-01, -1.3609e-01,  6.8302e-02,
          2.1873e-01,  2.1169e-01, -1.8406e-01,  7.1259e-02,  1.6347e-01,
         -2.2708e-01,  1.5978e-01, -1.5577e-01, -1.8076e-01, -1.0597e-01,
         -9.4034e-02],
        [-1.0336e-01,  7.1975e-02,  9.6850e-02,  9.7162e-02,  1.7261e-01,
         -1.5818e-01, -2.3738e-01, -2.0056e-01, -1.3741e-01, -1.1435e-01,
          1.0985e-01, -1.8092e-01, -1.8279e-01,  1.3388e-01, -1.5907e-01,
          4.6891e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1906,  0.0954,  0.1562, -0.2103,  0.0850, -0.1311,  0.1587,  0.2249,
        -0.2109,  0.0935,  0.1688,  0.2273,  0.1888,  0.0492,  0.0146,  0.0515,
        -0.1490, -0.0490, -0.0039, -0.1582, -0.0111, -0.0332, -0.0875, -0.0768,
        -0.2490,  0.2382,  0.1232,  0.1807, -0.2128, -0.2448,  0.1859, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0276,  0.0886,  0.0113, -0.0059,  0.1050,  0.1412, -0.0493, -0.1509,
         -0.0969,  0.1263,  0.0154,  0.1514, -0.0618, -0.1675,  0.0549, -0.0753,
         -0.1057,  0.1102,  0.0123, -0.0151,  0.1722,  0.1540, -0.1444, -0.1625,
         -0.0874, -0.1373, -0.0929,  0.1193, -0.1176,  0.1621,  0.0552,  0.0077]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0274,  0.0338,  0.0515,  ...,  0.0370, -0.1580, -0.1137],
        [-0.0412, -0.1228,  0.0849,  ..., -0.0255, -0.1542,  0.0871],
        [-0.0916,  0.0727,  0.1131,  ...,  0.1516,  0.0694,  0.0345],
        ...,
        [ 0.0835, -0.0818,  0.0083,  ..., -0.1147, -0.0697, -0.1180],
        [ 0.0086, -0.1214, -0.0074,  ..., -0.1376, -0.0348,  0.1557],
        [-0.1369,  0.0661,  0.0410,  ..., -0.0287, -0.1442, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0587,  0.0692, -0.1074, -0.1128, -0.0456,  0.0102, -0.1318,  0.0737,
        -0.0301,  0.0931,  0.0477, -0.0256, -0.0145,  0.0492, -0.0832, -0.0415,
         0.0733, -0.1429, -0.0319,  0.0333, -0.0826,  0.0758,  0.0793, -0.0232,
        -0.0515,  0.0775,  0.0090, -0.1238,  0.0923,  0.1576,  0.1370, -0.0883],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1641, -0.0737, -0.1340,  ..., -0.0192, -0.1329,  0.1699],
        [-0.0956,  0.0925,  0.0408,  ...,  0.0663, -0.1323,  0.1671],
        [ 0.0220, -0.1643, -0.1021,  ..., -0.0583,  0.1139,  0.0584],
        ...,
        [ 0.0230, -0.0144,  0.1370,  ...,  0.1392, -0.1018,  0.1490],
        [ 0.0984, -0.0202, -0.0055,  ...,  0.1521,  0.1041, -0.0493],
        [ 0.1011, -0.0131,  0.1673,  ...,  0.1591,  0.0347,  0.0616]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0691,  0.1030,  0.0027, -0.0455, -0.0609, -0.1135, -0.0068, -0.0992,
         0.1055, -0.1266,  0.1537, -0.1561,  0.1472,  0.0200, -0.1666,  0.0530,
        -0.1138, -0.1400,  0.0093, -0.0503,  0.0436,  0.1398, -0.1621,  0.1758,
        -0.0980, -0.0349,  0.1146, -0.0738, -0.0891, -0.0414,  0.0691, -0.0077],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1610,  0.0763, -0.1613, -0.1273,  0.0139, -0.0068, -0.0537,  0.0581,
          0.0742, -0.1026, -0.0353,  0.0633,  0.0641, -0.0159,  0.0889,  0.0632,
         -0.1659, -0.1689,  0.0059,  0.0605, -0.1260, -0.0910, -0.1689,  0.0335,
          0.1281,  0.1566, -0.1439,  0.1365, -0.0708, -0.1557,  0.1134,  0.1485]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0091], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.4959e-01,  2.3544e-01,  1.6261e-01, -1.7926e-01,  1.1951e-04,
         -5.4087e-03,  1.1917e-01, -2.1412e-01,  3.7155e-03,  8.3298e-02,
          1.2723e-01,  2.6141e-02, -1.2392e-01, -2.4000e-01,  1.3513e-01,
          2.2824e-01],
        [-7.5480e-02, -2.2341e-01,  7.3146e-02, -1.7527e-01, -1.6334e-01,
          6.8146e-02, -2.3741e-02, -1.7005e-02,  2.2424e-01, -4.3851e-02,
          1.5218e-01, -7.7806e-02,  1.8603e-01,  7.6268e-02,  2.2277e-01,
          8.7195e-02],
        [-8.8554e-02,  1.0896e-01,  2.1299e-01,  4.7383e-02,  1.1526e-01,
         -1.7588e-01,  1.3546e-01, -2.3632e-01,  2.2101e-01,  1.0326e-01,
          1.6452e-02, -2.3399e-01,  2.2734e-01,  1.5941e-01,  2.3047e-01,
          9.8278e-02],
        [ 8.4194e-02, -6.4758e-02, -1.0245e-01,  9.9101e-02,  8.6701e-02,
         -8.1050e-03,  3.9765e-02,  8.5878e-02, -2.4159e-01, -2.2109e-01,
         -6.6551e-02,  1.7026e-01,  1.2197e-01, -2.3862e-01, -7.5062e-02,
         -2.6426e-02],
        [ 8.2110e-02,  2.0453e-01,  5.4679e-03, -1.9460e-01,  1.5340e-02,
         -9.6540e-02, -1.5279e-01,  1.3847e-01, -3.3588e-02,  1.1813e-01,
          1.9466e-01,  2.4570e-02,  1.4081e-01, -1.1807e-01,  1.3955e-01,
          9.9876e-03],
        [ 1.6613e-01,  2.3901e-01, -1.8911e-01,  2.3733e-01,  1.9084e-01,
         -2.0139e-01,  7.3285e-02, -2.0353e-01,  8.1097e-02,  3.8660e-02,
         -2.3865e-01,  9.0755e-02, -6.8670e-02,  2.4919e-01,  2.4400e-01,
          8.6303e-02],
        [ 1.9706e-01,  9.0295e-02,  2.3652e-01, -2.3082e-02,  6.1788e-02,
         -4.1296e-02, -4.3721e-03, -7.5417e-02, -9.8939e-02,  1.4462e-01,
          1.0728e-01, -1.1036e-01, -2.2033e-01,  1.2224e-01, -2.2997e-01,
         -1.1063e-02],
        [-2.1511e-01,  2.0933e-01,  2.0357e-01, -2.0546e-01, -2.3243e-01,
         -1.4781e-01,  6.8985e-02, -1.2502e-01, -5.9537e-02, -6.3370e-02,
          4.5858e-02, -1.1825e-01,  1.1370e-01, -1.7890e-01, -2.2253e-02,
          2.0956e-01],
        [-1.3804e-01,  1.9180e-01,  1.3012e-01, -8.0755e-02,  8.6691e-02,
         -1.6889e-01,  2.0121e-02,  7.0815e-02,  2.1624e-01, -1.3989e-01,
         -1.4218e-01, -1.2478e-01, -2.4354e-01,  5.0557e-02, -2.0694e-01,
         -6.7111e-02],
        [-1.1155e-01,  1.3978e-02,  7.5837e-02, -1.8167e-01, -7.3804e-02,
         -2.4035e-02, -1.4452e-01,  5.7753e-02,  9.2549e-02, -1.7817e-01,
          1.9658e-01,  1.7765e-01, -7.5106e-02,  3.7198e-02,  3.0439e-02,
         -3.4493e-02],
        [-1.6778e-01,  2.0601e-01,  1.2303e-01, -2.0892e-01, -1.9375e-01,
          2.3774e-01,  3.9901e-02, -5.7436e-02,  1.6943e-01,  7.1820e-02,
          8.9743e-02,  1.9833e-01, -1.9512e-02,  2.3822e-01, -1.7561e-01,
         -1.5213e-01],
        [ 4.2360e-02, -3.0351e-02,  1.4266e-01, -6.7982e-02,  3.9312e-02,
         -5.1947e-02,  1.8769e-01, -1.6398e-02,  3.8373e-03,  1.8315e-01,
          2.4304e-01,  2.3921e-01, -2.4443e-01, -1.4127e-01, -5.4287e-02,
         -5.1611e-02],
        [ 1.4461e-01,  1.1291e-01, -2.0563e-02,  5.9224e-03,  5.3564e-02,
          2.1551e-01,  1.2955e-01, -1.2610e-01, -1.2807e-01,  7.9062e-02,
         -2.5286e-02, -1.6039e-01, -2.4197e-01,  3.5810e-02, -7.3006e-02,
         -1.4546e-01],
        [ 4.7027e-02,  2.4345e-01,  2.0765e-01,  1.4254e-01, -1.8855e-01,
          1.4268e-01,  1.2930e-01,  8.3411e-02, -6.2276e-02, -4.3533e-03,
         -1.3560e-01, -5.6314e-02, -4.1154e-02, -3.5414e-02, -2.4880e-01,
          8.8197e-02],
        [-2.0455e-01, -1.8696e-01,  1.0159e-01, -2.0464e-01,  2.3850e-01,
          2.3939e-01, -7.9446e-02, -4.3085e-02, -1.9126e-01,  1.5456e-02,
          4.5709e-02, -1.3714e-01,  7.8396e-02, -9.6213e-03, -7.3695e-02,
         -8.6492e-04],
        [-2.4233e-01, -1.7611e-01,  3.3092e-02,  2.4143e-01, -1.4818e-01,
          1.6027e-01,  2.2880e-02, -1.0756e-01,  2.7391e-04,  1.1986e-01,
          2.9743e-02,  2.2130e-01, -4.7314e-02, -1.6695e-01,  2.2591e-01,
         -7.1400e-02],
        [ 1.5863e-01,  1.6490e-01,  4.4276e-02, -2.0519e-01, -2.4544e-01,
          1.1868e-01,  6.1123e-02,  1.4547e-01, -2.2035e-01, -3.4443e-02,
          2.1600e-01,  1.3135e-01,  2.0776e-01,  1.9628e-01, -6.1342e-02,
         -1.7025e-01],
        [-1.4907e-01,  8.4907e-02, -9.9234e-02,  9.9149e-04,  3.9896e-02,
          1.5519e-01,  1.3943e-01,  1.4269e-01,  1.0161e-02,  1.4114e-01,
         -1.1704e-01, -1.0006e-01, -3.9583e-02, -1.4518e-01,  2.2300e-01,
         -3.8309e-02],
        [ 7.2681e-02, -7.7727e-03, -3.4193e-03, -1.3325e-01, -1.8354e-02,
         -2.2362e-01, -1.1955e-01,  1.9239e-01, -2.3449e-01,  4.1140e-02,
          3.9828e-02, -2.3928e-01,  4.8829e-02,  1.1608e-01,  1.8107e-01,
          4.6794e-02],
        [ 1.9542e-01,  9.4101e-03,  9.5256e-02,  7.3802e-02, -1.8433e-01,
         -5.4879e-02, -1.7605e-01,  1.9425e-01,  1.1926e-01, -1.0603e-01,
         -4.5749e-02,  6.6739e-02, -2.1798e-01,  7.0592e-03,  1.1925e-01,
          3.1325e-02],
        [-2.3003e-02,  1.6073e-01,  1.0875e-01, -2.2225e-01,  1.4713e-01,
         -1.9718e-01,  1.4043e-01,  2.1051e-01,  2.3040e-02, -8.4493e-02,
         -1.2914e-01, -1.1101e-01, -4.6083e-02, -1.0365e-01,  2.4818e-01,
         -1.0784e-01],
        [ 1.0380e-01, -2.3183e-01,  1.2671e-01,  2.1273e-01, -1.7922e-01,
         -6.3786e-02,  5.9585e-02, -2.3931e-01, -1.5818e-01,  8.6946e-02,
          2.3541e-01, -7.4686e-02, -2.2768e-03, -2.4133e-01, -2.3996e-01,
          2.1742e-01],
        [ 2.1215e-01, -7.6192e-02, -9.8855e-02, -1.6184e-02,  1.1600e-01,
         -2.4160e-01, -1.3848e-01, -8.2418e-02, -1.0881e-01, -6.6043e-03,
          1.8235e-01,  5.4585e-02, -2.2625e-01,  2.3122e-01,  2.0130e-01,
          7.8714e-02],
        [ 1.2237e-01,  9.3457e-02,  2.0492e-01, -2.4045e-01, -1.5563e-01,
         -3.1748e-02, -4.7555e-02, -1.6603e-01, -2.3975e-01, -1.9093e-01,
         -3.8828e-02,  2.1222e-01,  1.6574e-01,  7.2061e-02, -1.5355e-01,
         -1.0057e-01],
        [ 2.4084e-02, -2.3173e-01, -1.1413e-02,  5.0838e-02,  2.2602e-01,
         -6.5625e-02,  2.4539e-01,  1.8861e-02, -1.7345e-01,  2.3628e-01,
          2.1674e-01, -1.9754e-01, -1.4502e-01,  1.1954e-01, -1.5383e-01,
          1.6999e-01],
        [-1.1928e-01, -7.7591e-02, -7.1767e-02,  2.3851e-01, -8.4540e-02,
         -4.8611e-02,  1.5127e-01, -1.7105e-01, -1.2042e-03, -1.9311e-01,
         -2.3074e-01, -5.7078e-02,  2.7636e-02,  2.1319e-01, -2.3975e-01,
         -7.1936e-02],
        [ 6.5789e-02,  9.4403e-02,  1.4606e-01, -2.0102e-01, -6.1118e-02,
          5.7808e-02, -2.0040e-01,  1.2598e-01, -2.3854e-01,  1.5600e-01,
          8.1279e-02, -7.1012e-02,  8.1105e-02,  2.1174e-01,  1.8391e-01,
          1.5164e-01],
        [-1.4553e-01,  7.1840e-02,  1.8761e-01,  4.4093e-02,  1.6552e-01,
         -1.5505e-01,  1.7571e-01, -8.2927e-03, -2.2430e-01, -6.4806e-02,
          2.2096e-01, -8.7336e-02, -4.3299e-02, -1.0001e-01, -1.3593e-01,
          4.3312e-02],
        [ 1.5166e-01,  2.9561e-02, -1.5419e-02,  1.4462e-02, -1.8747e-01,
         -1.3172e-01,  1.2510e-02, -1.9982e-01,  1.2383e-01,  3.8105e-02,
          2.6324e-03, -1.6043e-02,  2.1115e-01,  2.2816e-01,  1.2207e-01,
          1.2417e-01],
        [-1.2122e-01,  1.0220e-01, -1.6909e-01,  1.0804e-01, -1.7752e-01,
         -1.3674e-03,  1.8120e-01,  1.6601e-01,  2.2105e-01,  8.5281e-02,
          9.7044e-02,  6.7042e-02,  1.8255e-01,  1.3119e-01,  7.3767e-02,
         -8.7229e-02],
        [-1.2099e-01, -6.1809e-02,  1.1931e-01, -1.3609e-01,  6.8302e-02,
          2.1873e-01,  2.1169e-01, -1.8406e-01,  7.1259e-02,  1.6347e-01,
         -2.2708e-01,  1.5978e-01, -1.5577e-01, -1.8076e-01, -1.0597e-01,
         -9.4034e-02],
        [-1.0336e-01,  7.1975e-02,  9.6850e-02,  9.7162e-02,  1.7261e-01,
         -1.5818e-01, -2.3738e-01, -2.0056e-01, -1.3741e-01, -1.1435e-01,
          1.0985e-01, -1.8092e-01, -1.8279e-01,  1.3388e-01, -1.5907e-01,
          4.6891e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1906,  0.0954,  0.1562, -0.2103,  0.0850, -0.1311,  0.1587,  0.2249,
        -0.2109,  0.0935,  0.1688,  0.2273,  0.1888,  0.0492,  0.0146,  0.0515,
        -0.1490, -0.0490, -0.0039, -0.1582, -0.0111, -0.0332, -0.0875, -0.0768,
        -0.2490,  0.2382,  0.1232,  0.1807, -0.2128, -0.2448,  0.1859, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0276,  0.0886,  0.0113, -0.0059,  0.1050,  0.1412, -0.0493, -0.1509,
         -0.0969,  0.1263,  0.0154,  0.1514, -0.0618, -0.1675,  0.0549, -0.0753,
         -0.1057,  0.1102,  0.0123, -0.0151,  0.1722,  0.1540, -0.1444, -0.1625,
         -0.0874, -0.1373, -0.0929,  0.1193, -0.1176,  0.1621,  0.0552,  0.0077]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0274,  0.0338,  0.0515,  ...,  0.0370, -0.1580, -0.1137],
        [-0.0412, -0.1228,  0.0849,  ..., -0.0255, -0.1542,  0.0871],
        [-0.0916,  0.0727,  0.1131,  ...,  0.1516,  0.0694,  0.0345],
        ...,
        [ 0.0835, -0.0818,  0.0083,  ..., -0.1147, -0.0697, -0.1180],
        [ 0.0086, -0.1214, -0.0074,  ..., -0.1376, -0.0348,  0.1557],
        [-0.1369,  0.0661,  0.0410,  ..., -0.0287, -0.1442, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0587,  0.0692, -0.1074, -0.1128, -0.0456,  0.0102, -0.1318,  0.0737,
        -0.0301,  0.0931,  0.0477, -0.0256, -0.0145,  0.0492, -0.0832, -0.0415,
         0.0733, -0.1429, -0.0319,  0.0333, -0.0826,  0.0758,  0.0793, -0.0232,
        -0.0515,  0.0775,  0.0090, -0.1238,  0.0923,  0.1576,  0.1370, -0.0883],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1641, -0.0737, -0.1340,  ..., -0.0192, -0.1329,  0.1699],
        [-0.0956,  0.0925,  0.0408,  ...,  0.0663, -0.1323,  0.1671],
        [ 0.0220, -0.1643, -0.1021,  ..., -0.0583,  0.1139,  0.0584],
        ...,
        [ 0.0230, -0.0144,  0.1370,  ...,  0.1392, -0.1018,  0.1490],
        [ 0.0984, -0.0202, -0.0055,  ...,  0.1521,  0.1041, -0.0493],
        [ 0.1011, -0.0131,  0.1673,  ...,  0.1591,  0.0347,  0.0616]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0691,  0.1030,  0.0027, -0.0455, -0.0609, -0.1135, -0.0068, -0.0992,
         0.1055, -0.1266,  0.1537, -0.1561,  0.1472,  0.0200, -0.1666,  0.0530,
        -0.1138, -0.1400,  0.0093, -0.0503,  0.0436,  0.1398, -0.1621,  0.1758,
        -0.0980, -0.0349,  0.1146, -0.0738, -0.0891, -0.0414,  0.0691, -0.0077],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1610,  0.0763, -0.1613, -0.1273,  0.0139, -0.0068, -0.0537,  0.0581,
          0.0742, -0.1026, -0.0353,  0.0633,  0.0641, -0.0159,  0.0889,  0.0632,
         -0.1659, -0.1689,  0.0059,  0.0605, -0.1260, -0.0910, -0.1689,  0.0335,
          0.1281,  0.1566, -0.1439,  0.1365, -0.0708, -0.1557,  0.1134,  0.1485]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0091], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.4959e-01,  2.3544e-01,  1.6261e-01, -1.7926e-01,  1.1951e-04,
         -5.4087e-03,  1.1917e-01, -2.1412e-01,  3.7155e-03,  8.3298e-02,
          1.2723e-01,  2.6141e-02, -1.2392e-01, -2.4000e-01,  1.3513e-01,
          2.2824e-01],
        [-7.5480e-02, -2.2341e-01,  7.3146e-02, -1.7527e-01, -1.6334e-01,
          6.8146e-02, -2.3741e-02, -1.7005e-02,  2.2424e-01, -4.3851e-02,
          1.5218e-01, -7.7806e-02,  1.8603e-01,  7.6268e-02,  2.2277e-01,
          8.7195e-02],
        [-8.8554e-02,  1.0896e-01,  2.1299e-01,  4.7383e-02,  1.1526e-01,
         -1.7588e-01,  1.3546e-01, -2.3632e-01,  2.2101e-01,  1.0326e-01,
          1.6452e-02, -2.3399e-01,  2.2734e-01,  1.5941e-01,  2.3047e-01,
          9.8278e-02],
        [ 8.4194e-02, -6.4758e-02, -1.0245e-01,  9.9101e-02,  8.6701e-02,
         -8.1050e-03,  3.9765e-02,  8.5878e-02, -2.4159e-01, -2.2109e-01,
         -6.6551e-02,  1.7026e-01,  1.2197e-01, -2.3862e-01, -7.5062e-02,
         -2.6426e-02],
        [ 8.2110e-02,  2.0453e-01,  5.4679e-03, -1.9460e-01,  1.5340e-02,
         -9.6540e-02, -1.5279e-01,  1.3847e-01, -3.3588e-02,  1.1813e-01,
          1.9466e-01,  2.4570e-02,  1.4081e-01, -1.1807e-01,  1.3955e-01,
          9.9876e-03],
        [ 1.6613e-01,  2.3901e-01, -1.8911e-01,  2.3733e-01,  1.9084e-01,
         -2.0139e-01,  7.3285e-02, -2.0353e-01,  8.1097e-02,  3.8660e-02,
         -2.3865e-01,  9.0755e-02, -6.8670e-02,  2.4919e-01,  2.4400e-01,
          8.6303e-02],
        [ 1.9706e-01,  9.0295e-02,  2.3652e-01, -2.3082e-02,  6.1788e-02,
         -4.1296e-02, -4.3721e-03, -7.5417e-02, -9.8939e-02,  1.4462e-01,
          1.0728e-01, -1.1036e-01, -2.2033e-01,  1.2224e-01, -2.2997e-01,
         -1.1063e-02],
        [-2.1511e-01,  2.0933e-01,  2.0357e-01, -2.0546e-01, -2.3243e-01,
         -1.4781e-01,  6.8985e-02, -1.2502e-01, -5.9537e-02, -6.3370e-02,
          4.5858e-02, -1.1825e-01,  1.1370e-01, -1.7890e-01, -2.2253e-02,
          2.0956e-01],
        [-1.3804e-01,  1.9180e-01,  1.3012e-01, -8.0755e-02,  8.6691e-02,
         -1.6889e-01,  2.0121e-02,  7.0815e-02,  2.1624e-01, -1.3989e-01,
         -1.4218e-01, -1.2478e-01, -2.4354e-01,  5.0557e-02, -2.0694e-01,
         -6.7111e-02],
        [-1.1155e-01,  1.3978e-02,  7.5837e-02, -1.8167e-01, -7.3804e-02,
         -2.4035e-02, -1.4452e-01,  5.7753e-02,  9.2549e-02, -1.7817e-01,
          1.9658e-01,  1.7765e-01, -7.5106e-02,  3.7198e-02,  3.0439e-02,
         -3.4493e-02],
        [-1.6778e-01,  2.0601e-01,  1.2303e-01, -2.0892e-01, -1.9375e-01,
          2.3774e-01,  3.9901e-02, -5.7436e-02,  1.6943e-01,  7.1820e-02,
          8.9743e-02,  1.9833e-01, -1.9512e-02,  2.3822e-01, -1.7561e-01,
         -1.5213e-01],
        [ 4.2360e-02, -3.0351e-02,  1.4266e-01, -6.7982e-02,  3.9312e-02,
         -5.1947e-02,  1.8769e-01, -1.6398e-02,  3.8373e-03,  1.8315e-01,
          2.4304e-01,  2.3921e-01, -2.4443e-01, -1.4127e-01, -5.4287e-02,
         -5.1611e-02],
        [ 1.4461e-01,  1.1291e-01, -2.0563e-02,  5.9224e-03,  5.3564e-02,
          2.1551e-01,  1.2955e-01, -1.2610e-01, -1.2807e-01,  7.9062e-02,
         -2.5286e-02, -1.6039e-01, -2.4197e-01,  3.5810e-02, -7.3006e-02,
         -1.4546e-01],
        [ 4.7027e-02,  2.4345e-01,  2.0765e-01,  1.4254e-01, -1.8855e-01,
          1.4268e-01,  1.2930e-01,  8.3411e-02, -6.2276e-02, -4.3533e-03,
         -1.3560e-01, -5.6314e-02, -4.1154e-02, -3.5414e-02, -2.4880e-01,
          8.8197e-02],
        [-2.0455e-01, -1.8696e-01,  1.0159e-01, -2.0464e-01,  2.3850e-01,
          2.3939e-01, -7.9446e-02, -4.3085e-02, -1.9126e-01,  1.5456e-02,
          4.5709e-02, -1.3714e-01,  7.8396e-02, -9.6213e-03, -7.3695e-02,
         -8.6492e-04],
        [-2.4233e-01, -1.7611e-01,  3.3092e-02,  2.4143e-01, -1.4818e-01,
          1.6027e-01,  2.2880e-02, -1.0756e-01,  2.7391e-04,  1.1986e-01,
          2.9743e-02,  2.2130e-01, -4.7314e-02, -1.6695e-01,  2.2591e-01,
         -7.1400e-02],
        [ 1.5863e-01,  1.6490e-01,  4.4276e-02, -2.0519e-01, -2.4544e-01,
          1.1868e-01,  6.1123e-02,  1.4547e-01, -2.2035e-01, -3.4443e-02,
          2.1600e-01,  1.3135e-01,  2.0776e-01,  1.9628e-01, -6.1342e-02,
         -1.7025e-01],
        [-1.4907e-01,  8.4907e-02, -9.9234e-02,  9.9149e-04,  3.9896e-02,
          1.5519e-01,  1.3943e-01,  1.4269e-01,  1.0161e-02,  1.4114e-01,
         -1.1704e-01, -1.0006e-01, -3.9583e-02, -1.4518e-01,  2.2300e-01,
         -3.8309e-02],
        [ 7.2681e-02, -7.7727e-03, -3.4193e-03, -1.3325e-01, -1.8354e-02,
         -2.2362e-01, -1.1955e-01,  1.9239e-01, -2.3449e-01,  4.1140e-02,
          3.9828e-02, -2.3928e-01,  4.8829e-02,  1.1608e-01,  1.8107e-01,
          4.6794e-02],
        [ 1.9542e-01,  9.4101e-03,  9.5256e-02,  7.3802e-02, -1.8433e-01,
         -5.4879e-02, -1.7605e-01,  1.9425e-01,  1.1926e-01, -1.0603e-01,
         -4.5749e-02,  6.6739e-02, -2.1798e-01,  7.0592e-03,  1.1925e-01,
          3.1325e-02],
        [-2.3003e-02,  1.6073e-01,  1.0875e-01, -2.2225e-01,  1.4713e-01,
         -1.9718e-01,  1.4043e-01,  2.1051e-01,  2.3040e-02, -8.4493e-02,
         -1.2914e-01, -1.1101e-01, -4.6083e-02, -1.0365e-01,  2.4818e-01,
         -1.0784e-01],
        [ 1.0380e-01, -2.3183e-01,  1.2671e-01,  2.1273e-01, -1.7922e-01,
         -6.3786e-02,  5.9585e-02, -2.3931e-01, -1.5818e-01,  8.6946e-02,
          2.3541e-01, -7.4686e-02, -2.2768e-03, -2.4133e-01, -2.3996e-01,
          2.1742e-01],
        [ 2.1215e-01, -7.6192e-02, -9.8855e-02, -1.6184e-02,  1.1600e-01,
         -2.4160e-01, -1.3848e-01, -8.2418e-02, -1.0881e-01, -6.6043e-03,
          1.8235e-01,  5.4585e-02, -2.2625e-01,  2.3122e-01,  2.0130e-01,
          7.8714e-02],
        [ 1.2237e-01,  9.3457e-02,  2.0492e-01, -2.4045e-01, -1.5563e-01,
         -3.1748e-02, -4.7555e-02, -1.6603e-01, -2.3975e-01, -1.9093e-01,
         -3.8828e-02,  2.1222e-01,  1.6574e-01,  7.2061e-02, -1.5355e-01,
         -1.0057e-01],
        [ 2.4084e-02, -2.3173e-01, -1.1413e-02,  5.0838e-02,  2.2602e-01,
         -6.5625e-02,  2.4539e-01,  1.8861e-02, -1.7345e-01,  2.3628e-01,
          2.1674e-01, -1.9754e-01, -1.4502e-01,  1.1954e-01, -1.5383e-01,
          1.6999e-01],
        [-1.1928e-01, -7.7591e-02, -7.1767e-02,  2.3851e-01, -8.4540e-02,
         -4.8611e-02,  1.5127e-01, -1.7105e-01, -1.2042e-03, -1.9311e-01,
         -2.3074e-01, -5.7078e-02,  2.7636e-02,  2.1319e-01, -2.3975e-01,
         -7.1936e-02],
        [ 6.5789e-02,  9.4403e-02,  1.4606e-01, -2.0102e-01, -6.1118e-02,
          5.7808e-02, -2.0040e-01,  1.2598e-01, -2.3854e-01,  1.5600e-01,
          8.1279e-02, -7.1012e-02,  8.1105e-02,  2.1174e-01,  1.8391e-01,
          1.5164e-01],
        [-1.4553e-01,  7.1840e-02,  1.8761e-01,  4.4093e-02,  1.6552e-01,
         -1.5505e-01,  1.7571e-01, -8.2927e-03, -2.2430e-01, -6.4806e-02,
          2.2096e-01, -8.7336e-02, -4.3299e-02, -1.0001e-01, -1.3593e-01,
          4.3312e-02],
        [ 1.5166e-01,  2.9561e-02, -1.5419e-02,  1.4462e-02, -1.8747e-01,
         -1.3172e-01,  1.2510e-02, -1.9982e-01,  1.2383e-01,  3.8105e-02,
          2.6324e-03, -1.6043e-02,  2.1115e-01,  2.2816e-01,  1.2207e-01,
          1.2417e-01],
        [-1.2122e-01,  1.0220e-01, -1.6909e-01,  1.0804e-01, -1.7752e-01,
         -1.3674e-03,  1.8120e-01,  1.6601e-01,  2.2105e-01,  8.5281e-02,
          9.7044e-02,  6.7042e-02,  1.8255e-01,  1.3119e-01,  7.3767e-02,
         -8.7229e-02],
        [-1.2099e-01, -6.1809e-02,  1.1931e-01, -1.3609e-01,  6.8302e-02,
          2.1873e-01,  2.1169e-01, -1.8406e-01,  7.1259e-02,  1.6347e-01,
         -2.2708e-01,  1.5978e-01, -1.5577e-01, -1.8076e-01, -1.0597e-01,
         -9.4034e-02],
        [-1.0336e-01,  7.1975e-02,  9.6850e-02,  9.7162e-02,  1.7261e-01,
         -1.5818e-01, -2.3738e-01, -2.0056e-01, -1.3741e-01, -1.1435e-01,
          1.0985e-01, -1.8092e-01, -1.8279e-01,  1.3388e-01, -1.5907e-01,
          4.6891e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1906,  0.0954,  0.1562, -0.2103,  0.0850, -0.1311,  0.1587,  0.2249,
        -0.2109,  0.0935,  0.1688,  0.2273,  0.1888,  0.0492,  0.0146,  0.0515,
        -0.1490, -0.0490, -0.0039, -0.1582, -0.0111, -0.0332, -0.0875, -0.0768,
        -0.2490,  0.2382,  0.1232,  0.1807, -0.2128, -0.2448,  0.1859, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0276,  0.0886,  0.0113, -0.0059,  0.1050,  0.1412, -0.0493, -0.1509,
         -0.0969,  0.1263,  0.0154,  0.1514, -0.0618, -0.1675,  0.0549, -0.0753,
         -0.1057,  0.1102,  0.0123, -0.0151,  0.1722,  0.1540, -0.1444, -0.1625,
         -0.0874, -0.1373, -0.0929,  0.1193, -0.1176,  0.1621,  0.0552,  0.0077]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0274,  0.0338,  0.0515,  ...,  0.0370, -0.1580, -0.1137],
        [-0.0412, -0.1228,  0.0849,  ..., -0.0255, -0.1542,  0.0871],
        [-0.0916,  0.0727,  0.1131,  ...,  0.1516,  0.0694,  0.0345],
        ...,
        [ 0.0835, -0.0818,  0.0083,  ..., -0.1147, -0.0697, -0.1180],
        [ 0.0086, -0.1214, -0.0074,  ..., -0.1376, -0.0348,  0.1557],
        [-0.1369,  0.0661,  0.0410,  ..., -0.0287, -0.1442, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0587,  0.0692, -0.1074, -0.1128, -0.0456,  0.0102, -0.1318,  0.0737,
        -0.0301,  0.0931,  0.0477, -0.0256, -0.0145,  0.0492, -0.0832, -0.0415,
         0.0733, -0.1429, -0.0319,  0.0333, -0.0826,  0.0758,  0.0793, -0.0232,
        -0.0515,  0.0775,  0.0090, -0.1238,  0.0923,  0.1576,  0.1370, -0.0883],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1641, -0.0737, -0.1340,  ..., -0.0192, -0.1329,  0.1699],
        [-0.0956,  0.0925,  0.0408,  ...,  0.0663, -0.1323,  0.1671],
        [ 0.0220, -0.1643, -0.1021,  ..., -0.0583,  0.1139,  0.0584],
        ...,
        [ 0.0230, -0.0144,  0.1370,  ...,  0.1392, -0.1018,  0.1490],
        [ 0.0984, -0.0202, -0.0055,  ...,  0.1521,  0.1041, -0.0493],
        [ 0.1011, -0.0131,  0.1673,  ...,  0.1591,  0.0347,  0.0616]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0691,  0.1030,  0.0027, -0.0455, -0.0609, -0.1135, -0.0068, -0.0992,
         0.1055, -0.1266,  0.1537, -0.1561,  0.1472,  0.0200, -0.1666,  0.0530,
        -0.1138, -0.1400,  0.0093, -0.0503,  0.0436,  0.1398, -0.1621,  0.1758,
        -0.0980, -0.0349,  0.1146, -0.0738, -0.0891, -0.0414,  0.0691, -0.0077],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1610,  0.0763, -0.1613, -0.1273,  0.0139, -0.0068, -0.0537,  0.0581,
          0.0742, -0.1026, -0.0353,  0.0633,  0.0641, -0.0159,  0.0889,  0.0632,
         -0.1659, -0.1689,  0.0059,  0.0605, -0.1260, -0.0910, -0.1689,  0.0335,
          0.1281,  0.1566, -0.1439,  0.1365, -0.0708, -0.1557,  0.1134,  0.1485]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0091], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.4959e-01,  2.3544e-01,  1.6261e-01, -1.7926e-01,  1.1951e-04,
         -5.4087e-03,  1.1917e-01, -2.1412e-01,  3.7155e-03,  8.3298e-02,
          1.2723e-01,  2.6141e-02, -1.2392e-01, -2.4000e-01,  1.3513e-01,
          2.2824e-01],
        [-7.5480e-02, -2.2341e-01,  7.3146e-02, -1.7527e-01, -1.6334e-01,
          6.8146e-02, -2.3741e-02, -1.7005e-02,  2.2424e-01, -4.3851e-02,
          1.5218e-01, -7.7806e-02,  1.8603e-01,  7.6268e-02,  2.2277e-01,
          8.7195e-02],
        [-8.8554e-02,  1.0896e-01,  2.1299e-01,  4.7383e-02,  1.1526e-01,
         -1.7588e-01,  1.3546e-01, -2.3632e-01,  2.2101e-01,  1.0326e-01,
          1.6452e-02, -2.3399e-01,  2.2734e-01,  1.5941e-01,  2.3047e-01,
          9.8278e-02],
        [ 8.4194e-02, -6.4758e-02, -1.0245e-01,  9.9101e-02,  8.6701e-02,
         -8.1050e-03,  3.9765e-02,  8.5878e-02, -2.4159e-01, -2.2109e-01,
         -6.6551e-02,  1.7026e-01,  1.2197e-01, -2.3862e-01, -7.5062e-02,
         -2.6426e-02],
        [ 8.2110e-02,  2.0453e-01,  5.4679e-03, -1.9460e-01,  1.5340e-02,
         -9.6540e-02, -1.5279e-01,  1.3847e-01, -3.3588e-02,  1.1813e-01,
          1.9466e-01,  2.4570e-02,  1.4081e-01, -1.1807e-01,  1.3955e-01,
          9.9876e-03],
        [ 1.6613e-01,  2.3901e-01, -1.8911e-01,  2.3733e-01,  1.9084e-01,
         -2.0139e-01,  7.3285e-02, -2.0353e-01,  8.1097e-02,  3.8660e-02,
         -2.3865e-01,  9.0755e-02, -6.8670e-02,  2.4919e-01,  2.4400e-01,
          8.6303e-02],
        [ 1.9706e-01,  9.0295e-02,  2.3652e-01, -2.3082e-02,  6.1788e-02,
         -4.1296e-02, -4.3721e-03, -7.5417e-02, -9.8939e-02,  1.4462e-01,
          1.0728e-01, -1.1036e-01, -2.2033e-01,  1.2224e-01, -2.2997e-01,
         -1.1063e-02],
        [-2.1511e-01,  2.0933e-01,  2.0357e-01, -2.0546e-01, -2.3243e-01,
         -1.4781e-01,  6.8985e-02, -1.2502e-01, -5.9537e-02, -6.3370e-02,
          4.5858e-02, -1.1825e-01,  1.1370e-01, -1.7890e-01, -2.2253e-02,
          2.0956e-01],
        [-1.3804e-01,  1.9180e-01,  1.3012e-01, -8.0755e-02,  8.6691e-02,
         -1.6889e-01,  2.0121e-02,  7.0815e-02,  2.1624e-01, -1.3989e-01,
         -1.4218e-01, -1.2478e-01, -2.4354e-01,  5.0557e-02, -2.0694e-01,
         -6.7111e-02],
        [-1.1155e-01,  1.3978e-02,  7.5837e-02, -1.8167e-01, -7.3804e-02,
         -2.4035e-02, -1.4452e-01,  5.7753e-02,  9.2549e-02, -1.7817e-01,
          1.9658e-01,  1.7765e-01, -7.5106e-02,  3.7198e-02,  3.0439e-02,
         -3.4493e-02],
        [-1.6778e-01,  2.0601e-01,  1.2303e-01, -2.0892e-01, -1.9375e-01,
          2.3774e-01,  3.9901e-02, -5.7436e-02,  1.6943e-01,  7.1820e-02,
          8.9743e-02,  1.9833e-01, -1.9512e-02,  2.3822e-01, -1.7561e-01,
         -1.5213e-01],
        [ 4.2360e-02, -3.0351e-02,  1.4266e-01, -6.7982e-02,  3.9312e-02,
         -5.1947e-02,  1.8769e-01, -1.6398e-02,  3.8373e-03,  1.8315e-01,
          2.4304e-01,  2.3921e-01, -2.4443e-01, -1.4127e-01, -5.4287e-02,
         -5.1611e-02],
        [ 1.4461e-01,  1.1291e-01, -2.0563e-02,  5.9224e-03,  5.3564e-02,
          2.1551e-01,  1.2955e-01, -1.2610e-01, -1.2807e-01,  7.9062e-02,
         -2.5286e-02, -1.6039e-01, -2.4197e-01,  3.5810e-02, -7.3006e-02,
         -1.4546e-01],
        [ 4.7027e-02,  2.4345e-01,  2.0765e-01,  1.4254e-01, -1.8855e-01,
          1.4268e-01,  1.2930e-01,  8.3411e-02, -6.2276e-02, -4.3533e-03,
         -1.3560e-01, -5.6314e-02, -4.1154e-02, -3.5414e-02, -2.4880e-01,
          8.8197e-02],
        [-2.0455e-01, -1.8696e-01,  1.0159e-01, -2.0464e-01,  2.3850e-01,
          2.3939e-01, -7.9446e-02, -4.3085e-02, -1.9126e-01,  1.5456e-02,
          4.5709e-02, -1.3714e-01,  7.8396e-02, -9.6213e-03, -7.3695e-02,
         -8.6492e-04],
        [-2.4233e-01, -1.7611e-01,  3.3092e-02,  2.4143e-01, -1.4818e-01,
          1.6027e-01,  2.2880e-02, -1.0756e-01,  2.7391e-04,  1.1986e-01,
          2.9743e-02,  2.2130e-01, -4.7314e-02, -1.6695e-01,  2.2591e-01,
         -7.1400e-02],
        [ 1.5863e-01,  1.6490e-01,  4.4276e-02, -2.0519e-01, -2.4544e-01,
          1.1868e-01,  6.1123e-02,  1.4547e-01, -2.2035e-01, -3.4443e-02,
          2.1600e-01,  1.3135e-01,  2.0776e-01,  1.9628e-01, -6.1342e-02,
         -1.7025e-01],
        [-1.4907e-01,  8.4907e-02, -9.9234e-02,  9.9149e-04,  3.9896e-02,
          1.5519e-01,  1.3943e-01,  1.4269e-01,  1.0161e-02,  1.4114e-01,
         -1.1704e-01, -1.0006e-01, -3.9583e-02, -1.4518e-01,  2.2300e-01,
         -3.8309e-02],
        [ 7.2681e-02, -7.7727e-03, -3.4193e-03, -1.3325e-01, -1.8354e-02,
         -2.2362e-01, -1.1955e-01,  1.9239e-01, -2.3449e-01,  4.1140e-02,
          3.9828e-02, -2.3928e-01,  4.8829e-02,  1.1608e-01,  1.8107e-01,
          4.6794e-02],
        [ 1.9542e-01,  9.4101e-03,  9.5256e-02,  7.3802e-02, -1.8433e-01,
         -5.4879e-02, -1.7605e-01,  1.9425e-01,  1.1926e-01, -1.0603e-01,
         -4.5749e-02,  6.6739e-02, -2.1798e-01,  7.0592e-03,  1.1925e-01,
          3.1325e-02],
        [-2.3003e-02,  1.6073e-01,  1.0875e-01, -2.2225e-01,  1.4713e-01,
         -1.9718e-01,  1.4043e-01,  2.1051e-01,  2.3040e-02, -8.4493e-02,
         -1.2914e-01, -1.1101e-01, -4.6083e-02, -1.0365e-01,  2.4818e-01,
         -1.0784e-01],
        [ 1.0380e-01, -2.3183e-01,  1.2671e-01,  2.1273e-01, -1.7922e-01,
         -6.3786e-02,  5.9585e-02, -2.3931e-01, -1.5818e-01,  8.6946e-02,
          2.3541e-01, -7.4686e-02, -2.2768e-03, -2.4133e-01, -2.3996e-01,
          2.1742e-01],
        [ 2.1215e-01, -7.6192e-02, -9.8855e-02, -1.6184e-02,  1.1600e-01,
         -2.4160e-01, -1.3848e-01, -8.2418e-02, -1.0881e-01, -6.6043e-03,
          1.8235e-01,  5.4585e-02, -2.2625e-01,  2.3122e-01,  2.0130e-01,
          7.8714e-02],
        [ 1.2237e-01,  9.3457e-02,  2.0492e-01, -2.4045e-01, -1.5563e-01,
         -3.1748e-02, -4.7555e-02, -1.6603e-01, -2.3975e-01, -1.9093e-01,
         -3.8828e-02,  2.1222e-01,  1.6574e-01,  7.2061e-02, -1.5355e-01,
         -1.0057e-01],
        [ 2.4084e-02, -2.3173e-01, -1.1413e-02,  5.0838e-02,  2.2602e-01,
         -6.5625e-02,  2.4539e-01,  1.8861e-02, -1.7345e-01,  2.3628e-01,
          2.1674e-01, -1.9754e-01, -1.4502e-01,  1.1954e-01, -1.5383e-01,
          1.6999e-01],
        [-1.1928e-01, -7.7591e-02, -7.1767e-02,  2.3851e-01, -8.4540e-02,
         -4.8611e-02,  1.5127e-01, -1.7105e-01, -1.2042e-03, -1.9311e-01,
         -2.3074e-01, -5.7078e-02,  2.7636e-02,  2.1319e-01, -2.3975e-01,
         -7.1936e-02],
        [ 6.5789e-02,  9.4403e-02,  1.4606e-01, -2.0102e-01, -6.1118e-02,
          5.7808e-02, -2.0040e-01,  1.2598e-01, -2.3854e-01,  1.5600e-01,
          8.1279e-02, -7.1012e-02,  8.1105e-02,  2.1174e-01,  1.8391e-01,
          1.5164e-01],
        [-1.4553e-01,  7.1840e-02,  1.8761e-01,  4.4093e-02,  1.6552e-01,
         -1.5505e-01,  1.7571e-01, -8.2927e-03, -2.2430e-01, -6.4806e-02,
          2.2096e-01, -8.7336e-02, -4.3299e-02, -1.0001e-01, -1.3593e-01,
          4.3312e-02],
        [ 1.5166e-01,  2.9561e-02, -1.5419e-02,  1.4462e-02, -1.8747e-01,
         -1.3172e-01,  1.2510e-02, -1.9982e-01,  1.2383e-01,  3.8105e-02,
          2.6324e-03, -1.6043e-02,  2.1115e-01,  2.2816e-01,  1.2207e-01,
          1.2417e-01],
        [-1.2122e-01,  1.0220e-01, -1.6909e-01,  1.0804e-01, -1.7752e-01,
         -1.3674e-03,  1.8120e-01,  1.6601e-01,  2.2105e-01,  8.5281e-02,
          9.7044e-02,  6.7042e-02,  1.8255e-01,  1.3119e-01,  7.3767e-02,
         -8.7229e-02],
        [-1.2099e-01, -6.1809e-02,  1.1931e-01, -1.3609e-01,  6.8302e-02,
          2.1873e-01,  2.1169e-01, -1.8406e-01,  7.1259e-02,  1.6347e-01,
         -2.2708e-01,  1.5978e-01, -1.5577e-01, -1.8076e-01, -1.0597e-01,
         -9.4034e-02],
        [-1.0336e-01,  7.1975e-02,  9.6850e-02,  9.7162e-02,  1.7261e-01,
         -1.5818e-01, -2.3738e-01, -2.0056e-01, -1.3741e-01, -1.1435e-01,
          1.0985e-01, -1.8092e-01, -1.8279e-01,  1.3388e-01, -1.5907e-01,
          4.6891e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1906,  0.0954,  0.1562, -0.2103,  0.0850, -0.1311,  0.1587,  0.2249,
        -0.2109,  0.0935,  0.1688,  0.2273,  0.1888,  0.0492,  0.0146,  0.0515,
        -0.1490, -0.0490, -0.0039, -0.1582, -0.0111, -0.0332, -0.0875, -0.0768,
        -0.2490,  0.2382,  0.1232,  0.1807, -0.2128, -0.2448,  0.1859, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0276,  0.0886,  0.0113, -0.0059,  0.1050,  0.1412, -0.0493, -0.1509,
         -0.0969,  0.1263,  0.0154,  0.1514, -0.0618, -0.1675,  0.0549, -0.0753,
         -0.1057,  0.1102,  0.0123, -0.0151,  0.1722,  0.1540, -0.1444, -0.1625,
         -0.0874, -0.1373, -0.0929,  0.1193, -0.1176,  0.1621,  0.0552,  0.0077]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0274,  0.0338,  0.0515,  ...,  0.0370, -0.1580, -0.1137],
        [-0.0412, -0.1228,  0.0849,  ..., -0.0255, -0.1542,  0.0871],
        [-0.0916,  0.0727,  0.1131,  ...,  0.1516,  0.0694,  0.0345],
        ...,
        [ 0.0835, -0.0818,  0.0083,  ..., -0.1147, -0.0697, -0.1180],
        [ 0.0086, -0.1214, -0.0074,  ..., -0.1376, -0.0348,  0.1557],
        [-0.1369,  0.0661,  0.0410,  ..., -0.0287, -0.1442, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0587,  0.0692, -0.1074, -0.1128, -0.0456,  0.0102, -0.1318,  0.0737,
        -0.0301,  0.0931,  0.0477, -0.0256, -0.0145,  0.0492, -0.0832, -0.0415,
         0.0733, -0.1429, -0.0319,  0.0333, -0.0826,  0.0758,  0.0793, -0.0232,
        -0.0515,  0.0775,  0.0090, -0.1238,  0.0923,  0.1576,  0.1370, -0.0883],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1641, -0.0737, -0.1340,  ..., -0.0192, -0.1329,  0.1699],
        [-0.0956,  0.0925,  0.0408,  ...,  0.0663, -0.1323,  0.1671],
        [ 0.0220, -0.1643, -0.1021,  ..., -0.0583,  0.1139,  0.0584],
        ...,
        [ 0.0230, -0.0144,  0.1370,  ...,  0.1392, -0.1018,  0.1490],
        [ 0.0984, -0.0202, -0.0055,  ...,  0.1521,  0.1041, -0.0493],
        [ 0.1011, -0.0131,  0.1673,  ...,  0.1591,  0.0347,  0.0616]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0691,  0.1030,  0.0027, -0.0455, -0.0609, -0.1135, -0.0068, -0.0992,
         0.1055, -0.1266,  0.1537, -0.1561,  0.1472,  0.0200, -0.1666,  0.0530,
        -0.1138, -0.1400,  0.0093, -0.0503,  0.0436,  0.1398, -0.1621,  0.1758,
        -0.0980, -0.0349,  0.1146, -0.0738, -0.0891, -0.0414,  0.0691, -0.0077],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1610,  0.0763, -0.1613, -0.1273,  0.0139, -0.0068, -0.0537,  0.0581,
          0.0742, -0.1026, -0.0353,  0.0633,  0.0641, -0.0159,  0.0889,  0.0632,
         -0.1659, -0.1689,  0.0059,  0.0605, -0.1260, -0.0910, -0.1689,  0.0335,
          0.1281,  0.1566, -0.1439,  0.1365, -0.0708, -0.1557,  0.1134,  0.1485]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0091], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.4959e-01,  2.3544e-01,  1.6261e-01, -1.7926e-01,  1.1951e-04,
         -5.4087e-03,  1.1917e-01, -2.1412e-01,  3.7155e-03,  8.3298e-02,
          1.2723e-01,  2.6141e-02, -1.2392e-01, -2.4000e-01,  1.3513e-01,
          2.2824e-01],
        [-7.5480e-02, -2.2341e-01,  7.3146e-02, -1.7527e-01, -1.6334e-01,
          6.8146e-02, -2.3741e-02, -1.7005e-02,  2.2424e-01, -4.3851e-02,
          1.5218e-01, -7.7806e-02,  1.8603e-01,  7.6268e-02,  2.2277e-01,
          8.7195e-02],
        [-8.8554e-02,  1.0896e-01,  2.1299e-01,  4.7383e-02,  1.1526e-01,
         -1.7588e-01,  1.3546e-01, -2.3632e-01,  2.2101e-01,  1.0326e-01,
          1.6452e-02, -2.3399e-01,  2.2734e-01,  1.5941e-01,  2.3047e-01,
          9.8278e-02],
        [ 8.4194e-02, -6.4758e-02, -1.0245e-01,  9.9101e-02,  8.6701e-02,
         -8.1050e-03,  3.9765e-02,  8.5878e-02, -2.4159e-01, -2.2109e-01,
         -6.6551e-02,  1.7026e-01,  1.2197e-01, -2.3862e-01, -7.5062e-02,
         -2.6426e-02],
        [ 8.2110e-02,  2.0453e-01,  5.4679e-03, -1.9460e-01,  1.5340e-02,
         -9.6540e-02, -1.5279e-01,  1.3847e-01, -3.3588e-02,  1.1813e-01,
          1.9466e-01,  2.4570e-02,  1.4081e-01, -1.1807e-01,  1.3955e-01,
          9.9876e-03],
        [ 1.6613e-01,  2.3901e-01, -1.8911e-01,  2.3733e-01,  1.9084e-01,
         -2.0139e-01,  7.3285e-02, -2.0353e-01,  8.1097e-02,  3.8660e-02,
         -2.3865e-01,  9.0755e-02, -6.8670e-02,  2.4919e-01,  2.4400e-01,
          8.6303e-02],
        [ 1.9706e-01,  9.0295e-02,  2.3652e-01, -2.3082e-02,  6.1788e-02,
         -4.1296e-02, -4.3721e-03, -7.5417e-02, -9.8939e-02,  1.4462e-01,
          1.0728e-01, -1.1036e-01, -2.2033e-01,  1.2224e-01, -2.2997e-01,
         -1.1063e-02],
        [-2.1511e-01,  2.0933e-01,  2.0357e-01, -2.0546e-01, -2.3243e-01,
         -1.4781e-01,  6.8985e-02, -1.2502e-01, -5.9537e-02, -6.3370e-02,
          4.5858e-02, -1.1825e-01,  1.1370e-01, -1.7890e-01, -2.2253e-02,
          2.0956e-01],
        [-1.3804e-01,  1.9180e-01,  1.3012e-01, -8.0755e-02,  8.6691e-02,
         -1.6889e-01,  2.0121e-02,  7.0815e-02,  2.1624e-01, -1.3989e-01,
         -1.4218e-01, -1.2478e-01, -2.4354e-01,  5.0557e-02, -2.0694e-01,
         -6.7111e-02],
        [-1.1155e-01,  1.3978e-02,  7.5837e-02, -1.8167e-01, -7.3804e-02,
         -2.4035e-02, -1.4452e-01,  5.7753e-02,  9.2549e-02, -1.7817e-01,
          1.9658e-01,  1.7765e-01, -7.5106e-02,  3.7198e-02,  3.0439e-02,
         -3.4493e-02],
        [-1.6778e-01,  2.0601e-01,  1.2303e-01, -2.0892e-01, -1.9375e-01,
          2.3774e-01,  3.9901e-02, -5.7436e-02,  1.6943e-01,  7.1820e-02,
          8.9743e-02,  1.9833e-01, -1.9512e-02,  2.3822e-01, -1.7561e-01,
         -1.5213e-01],
        [ 4.2360e-02, -3.0351e-02,  1.4266e-01, -6.7982e-02,  3.9312e-02,
         -5.1947e-02,  1.8769e-01, -1.6398e-02,  3.8373e-03,  1.8315e-01,
          2.4304e-01,  2.3921e-01, -2.4443e-01, -1.4127e-01, -5.4287e-02,
         -5.1611e-02],
        [ 1.4461e-01,  1.1291e-01, -2.0563e-02,  5.9224e-03,  5.3564e-02,
          2.1551e-01,  1.2955e-01, -1.2610e-01, -1.2807e-01,  7.9062e-02,
         -2.5286e-02, -1.6039e-01, -2.4197e-01,  3.5810e-02, -7.3006e-02,
         -1.4546e-01],
        [ 4.7027e-02,  2.4345e-01,  2.0765e-01,  1.4254e-01, -1.8855e-01,
          1.4268e-01,  1.2930e-01,  8.3411e-02, -6.2276e-02, -4.3533e-03,
         -1.3560e-01, -5.6314e-02, -4.1154e-02, -3.5414e-02, -2.4880e-01,
          8.8197e-02],
        [-2.0455e-01, -1.8696e-01,  1.0159e-01, -2.0464e-01,  2.3850e-01,
          2.3939e-01, -7.9446e-02, -4.3085e-02, -1.9126e-01,  1.5456e-02,
          4.5709e-02, -1.3714e-01,  7.8396e-02, -9.6213e-03, -7.3695e-02,
         -8.6492e-04],
        [-2.4233e-01, -1.7611e-01,  3.3092e-02,  2.4143e-01, -1.4818e-01,
          1.6027e-01,  2.2880e-02, -1.0756e-01,  2.7391e-04,  1.1986e-01,
          2.9743e-02,  2.2130e-01, -4.7314e-02, -1.6695e-01,  2.2591e-01,
         -7.1400e-02],
        [ 1.5863e-01,  1.6490e-01,  4.4276e-02, -2.0519e-01, -2.4544e-01,
          1.1868e-01,  6.1123e-02,  1.4547e-01, -2.2035e-01, -3.4443e-02,
          2.1600e-01,  1.3135e-01,  2.0776e-01,  1.9628e-01, -6.1342e-02,
         -1.7025e-01],
        [-1.4907e-01,  8.4907e-02, -9.9234e-02,  9.9149e-04,  3.9896e-02,
          1.5519e-01,  1.3943e-01,  1.4269e-01,  1.0161e-02,  1.4114e-01,
         -1.1704e-01, -1.0006e-01, -3.9583e-02, -1.4518e-01,  2.2300e-01,
         -3.8309e-02],
        [ 7.2681e-02, -7.7727e-03, -3.4193e-03, -1.3325e-01, -1.8354e-02,
         -2.2362e-01, -1.1955e-01,  1.9239e-01, -2.3449e-01,  4.1140e-02,
          3.9828e-02, -2.3928e-01,  4.8829e-02,  1.1608e-01,  1.8107e-01,
          4.6794e-02],
        [ 1.9542e-01,  9.4101e-03,  9.5256e-02,  7.3802e-02, -1.8433e-01,
         -5.4879e-02, -1.7605e-01,  1.9425e-01,  1.1926e-01, -1.0603e-01,
         -4.5749e-02,  6.6739e-02, -2.1798e-01,  7.0592e-03,  1.1925e-01,
          3.1325e-02],
        [-2.3003e-02,  1.6073e-01,  1.0875e-01, -2.2225e-01,  1.4713e-01,
         -1.9718e-01,  1.4043e-01,  2.1051e-01,  2.3040e-02, -8.4493e-02,
         -1.2914e-01, -1.1101e-01, -4.6083e-02, -1.0365e-01,  2.4818e-01,
         -1.0784e-01],
        [ 1.0380e-01, -2.3183e-01,  1.2671e-01,  2.1273e-01, -1.7922e-01,
         -6.3786e-02,  5.9585e-02, -2.3931e-01, -1.5818e-01,  8.6946e-02,
          2.3541e-01, -7.4686e-02, -2.2768e-03, -2.4133e-01, -2.3996e-01,
          2.1742e-01],
        [ 2.1215e-01, -7.6192e-02, -9.8855e-02, -1.6184e-02,  1.1600e-01,
         -2.4160e-01, -1.3848e-01, -8.2418e-02, -1.0881e-01, -6.6043e-03,
          1.8235e-01,  5.4585e-02, -2.2625e-01,  2.3122e-01,  2.0130e-01,
          7.8714e-02],
        [ 1.2237e-01,  9.3457e-02,  2.0492e-01, -2.4045e-01, -1.5563e-01,
         -3.1748e-02, -4.7555e-02, -1.6603e-01, -2.3975e-01, -1.9093e-01,
         -3.8828e-02,  2.1222e-01,  1.6574e-01,  7.2061e-02, -1.5355e-01,
         -1.0057e-01],
        [ 2.4084e-02, -2.3173e-01, -1.1413e-02,  5.0838e-02,  2.2602e-01,
         -6.5625e-02,  2.4539e-01,  1.8861e-02, -1.7345e-01,  2.3628e-01,
          2.1674e-01, -1.9754e-01, -1.4502e-01,  1.1954e-01, -1.5383e-01,
          1.6999e-01],
        [-1.1928e-01, -7.7591e-02, -7.1767e-02,  2.3851e-01, -8.4540e-02,
         -4.8611e-02,  1.5127e-01, -1.7105e-01, -1.2042e-03, -1.9311e-01,
         -2.3074e-01, -5.7078e-02,  2.7636e-02,  2.1319e-01, -2.3975e-01,
         -7.1936e-02],
        [ 6.5789e-02,  9.4403e-02,  1.4606e-01, -2.0102e-01, -6.1118e-02,
          5.7808e-02, -2.0040e-01,  1.2598e-01, -2.3854e-01,  1.5600e-01,
          8.1279e-02, -7.1012e-02,  8.1105e-02,  2.1174e-01,  1.8391e-01,
          1.5164e-01],
        [-1.4553e-01,  7.1840e-02,  1.8761e-01,  4.4093e-02,  1.6552e-01,
         -1.5505e-01,  1.7571e-01, -8.2927e-03, -2.2430e-01, -6.4806e-02,
          2.2096e-01, -8.7336e-02, -4.3299e-02, -1.0001e-01, -1.3593e-01,
          4.3312e-02],
        [ 1.5166e-01,  2.9561e-02, -1.5419e-02,  1.4462e-02, -1.8747e-01,
         -1.3172e-01,  1.2510e-02, -1.9982e-01,  1.2383e-01,  3.8105e-02,
          2.6324e-03, -1.6043e-02,  2.1115e-01,  2.2816e-01,  1.2207e-01,
          1.2417e-01],
        [-1.2122e-01,  1.0220e-01, -1.6909e-01,  1.0804e-01, -1.7752e-01,
         -1.3674e-03,  1.8120e-01,  1.6601e-01,  2.2105e-01,  8.5281e-02,
          9.7044e-02,  6.7042e-02,  1.8255e-01,  1.3119e-01,  7.3767e-02,
         -8.7229e-02],
        [-1.2099e-01, -6.1809e-02,  1.1931e-01, -1.3609e-01,  6.8302e-02,
          2.1873e-01,  2.1169e-01, -1.8406e-01,  7.1259e-02,  1.6347e-01,
         -2.2708e-01,  1.5978e-01, -1.5577e-01, -1.8076e-01, -1.0597e-01,
         -9.4034e-02],
        [-1.0336e-01,  7.1975e-02,  9.6850e-02,  9.7162e-02,  1.7261e-01,
         -1.5818e-01, -2.3738e-01, -2.0056e-01, -1.3741e-01, -1.1435e-01,
          1.0985e-01, -1.8092e-01, -1.8279e-01,  1.3388e-01, -1.5907e-01,
          4.6891e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1906,  0.0954,  0.1562, -0.2103,  0.0850, -0.1311,  0.1587,  0.2249,
        -0.2109,  0.0935,  0.1688,  0.2273,  0.1888,  0.0492,  0.0146,  0.0515,
        -0.1490, -0.0490, -0.0039, -0.1582, -0.0111, -0.0332, -0.0875, -0.0768,
        -0.2490,  0.2382,  0.1232,  0.1807, -0.2128, -0.2448,  0.1859, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0276,  0.0886,  0.0113, -0.0059,  0.1050,  0.1412, -0.0493, -0.1509,
         -0.0969,  0.1263,  0.0154,  0.1514, -0.0618, -0.1675,  0.0549, -0.0753,
         -0.1057,  0.1102,  0.0123, -0.0151,  0.1722,  0.1540, -0.1444, -0.1625,
         -0.0874, -0.1373, -0.0929,  0.1193, -0.1176,  0.1621,  0.0552,  0.0077]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0274,  0.0338,  0.0515,  ...,  0.0370, -0.1580, -0.1137],
        [-0.0412, -0.1228,  0.0849,  ..., -0.0255, -0.1542,  0.0871],
        [-0.0916,  0.0727,  0.1131,  ...,  0.1516,  0.0694,  0.0345],
        ...,
        [ 0.0835, -0.0818,  0.0083,  ..., -0.1147, -0.0697, -0.1180],
        [ 0.0086, -0.1214, -0.0074,  ..., -0.1376, -0.0348,  0.1557],
        [-0.1369,  0.0661,  0.0410,  ..., -0.0287, -0.1442, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0587,  0.0692, -0.1074, -0.1128, -0.0456,  0.0102, -0.1318,  0.0737,
        -0.0301,  0.0931,  0.0477, -0.0256, -0.0145,  0.0492, -0.0832, -0.0415,
         0.0733, -0.1429, -0.0319,  0.0333, -0.0826,  0.0758,  0.0793, -0.0232,
        -0.0515,  0.0775,  0.0090, -0.1238,  0.0923,  0.1576,  0.1370, -0.0883],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1641, -0.0737, -0.1340,  ..., -0.0192, -0.1329,  0.1699],
        [-0.0956,  0.0925,  0.0408,  ...,  0.0663, -0.1323,  0.1671],
        [ 0.0220, -0.1643, -0.1021,  ..., -0.0583,  0.1139,  0.0584],
        ...,
        [ 0.0230, -0.0144,  0.1370,  ...,  0.1392, -0.1018,  0.1490],
        [ 0.0984, -0.0202, -0.0055,  ...,  0.1521,  0.1041, -0.0493],
        [ 0.1011, -0.0131,  0.1673,  ...,  0.1591,  0.0347,  0.0616]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0691,  0.1030,  0.0027, -0.0455, -0.0609, -0.1135, -0.0068, -0.0992,
         0.1055, -0.1266,  0.1537, -0.1561,  0.1472,  0.0200, -0.1666,  0.0530,
        -0.1138, -0.1400,  0.0093, -0.0503,  0.0436,  0.1398, -0.1621,  0.1758,
        -0.0980, -0.0349,  0.1146, -0.0738, -0.0891, -0.0414,  0.0691, -0.0077],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1610,  0.0763, -0.1613, -0.1273,  0.0139, -0.0068, -0.0537,  0.0581,
          0.0742, -0.1026, -0.0353,  0.0633,  0.0641, -0.0159,  0.0889,  0.0632,
         -0.1659, -0.1689,  0.0059,  0.0605, -0.1260, -0.0910, -0.1689,  0.0335,
          0.1281,  0.1566, -0.1439,  0.1365, -0.0708, -0.1557,  0.1134,  0.1485]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0091], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.4959e-01,  2.3544e-01,  1.6261e-01, -1.7926e-01,  1.1951e-04,
         -5.4087e-03,  1.1917e-01, -2.1412e-01,  3.7155e-03,  8.3298e-02,
          1.2723e-01,  2.6141e-02, -1.2392e-01, -2.4000e-01,  1.3513e-01,
          2.2824e-01],
        [-7.5480e-02, -2.2341e-01,  7.3146e-02, -1.7527e-01, -1.6334e-01,
          6.8146e-02, -2.3741e-02, -1.7005e-02,  2.2424e-01, -4.3851e-02,
          1.5218e-01, -7.7806e-02,  1.8603e-01,  7.6268e-02,  2.2277e-01,
          8.7195e-02],
        [-8.8554e-02,  1.0896e-01,  2.1299e-01,  4.7383e-02,  1.1526e-01,
         -1.7588e-01,  1.3546e-01, -2.3632e-01,  2.2101e-01,  1.0326e-01,
          1.6452e-02, -2.3399e-01,  2.2734e-01,  1.5941e-01,  2.3047e-01,
          9.8278e-02],
        [ 8.4194e-02, -6.4758e-02, -1.0245e-01,  9.9101e-02,  8.6701e-02,
         -8.1050e-03,  3.9765e-02,  8.5878e-02, -2.4159e-01, -2.2109e-01,
         -6.6551e-02,  1.7026e-01,  1.2197e-01, -2.3862e-01, -7.5062e-02,
         -2.6426e-02],
        [ 8.2110e-02,  2.0453e-01,  5.4679e-03, -1.9460e-01,  1.5340e-02,
         -9.6540e-02, -1.5279e-01,  1.3847e-01, -3.3588e-02,  1.1813e-01,
          1.9466e-01,  2.4570e-02,  1.4081e-01, -1.1807e-01,  1.3955e-01,
          9.9876e-03],
        [ 1.6613e-01,  2.3901e-01, -1.8911e-01,  2.3733e-01,  1.9084e-01,
         -2.0139e-01,  7.3285e-02, -2.0353e-01,  8.1097e-02,  3.8660e-02,
         -2.3865e-01,  9.0755e-02, -6.8670e-02,  2.4919e-01,  2.4400e-01,
          8.6303e-02],
        [ 1.9706e-01,  9.0295e-02,  2.3652e-01, -2.3082e-02,  6.1788e-02,
         -4.1296e-02, -4.3721e-03, -7.5417e-02, -9.8939e-02,  1.4462e-01,
          1.0728e-01, -1.1036e-01, -2.2033e-01,  1.2224e-01, -2.2997e-01,
         -1.1063e-02],
        [-2.1511e-01,  2.0933e-01,  2.0357e-01, -2.0546e-01, -2.3243e-01,
         -1.4781e-01,  6.8985e-02, -1.2502e-01, -5.9537e-02, -6.3370e-02,
          4.5858e-02, -1.1825e-01,  1.1370e-01, -1.7890e-01, -2.2253e-02,
          2.0956e-01],
        [-1.3804e-01,  1.9180e-01,  1.3012e-01, -8.0755e-02,  8.6691e-02,
         -1.6889e-01,  2.0121e-02,  7.0815e-02,  2.1624e-01, -1.3989e-01,
         -1.4218e-01, -1.2478e-01, -2.4354e-01,  5.0557e-02, -2.0694e-01,
         -6.7111e-02],
        [-1.1155e-01,  1.3978e-02,  7.5837e-02, -1.8167e-01, -7.3804e-02,
         -2.4035e-02, -1.4452e-01,  5.7753e-02,  9.2549e-02, -1.7817e-01,
          1.9658e-01,  1.7765e-01, -7.5106e-02,  3.7198e-02,  3.0439e-02,
         -3.4493e-02],
        [-1.6778e-01,  2.0601e-01,  1.2303e-01, -2.0892e-01, -1.9375e-01,
          2.3774e-01,  3.9901e-02, -5.7436e-02,  1.6943e-01,  7.1820e-02,
          8.9743e-02,  1.9833e-01, -1.9512e-02,  2.3822e-01, -1.7561e-01,
         -1.5213e-01],
        [ 4.2360e-02, -3.0351e-02,  1.4266e-01, -6.7982e-02,  3.9312e-02,
         -5.1947e-02,  1.8769e-01, -1.6398e-02,  3.8373e-03,  1.8315e-01,
          2.4304e-01,  2.3921e-01, -2.4443e-01, -1.4127e-01, -5.4287e-02,
         -5.1611e-02],
        [ 1.4461e-01,  1.1291e-01, -2.0563e-02,  5.9224e-03,  5.3564e-02,
          2.1551e-01,  1.2955e-01, -1.2610e-01, -1.2807e-01,  7.9062e-02,
         -2.5286e-02, -1.6039e-01, -2.4197e-01,  3.5810e-02, -7.3006e-02,
         -1.4546e-01],
        [ 4.7027e-02,  2.4345e-01,  2.0765e-01,  1.4254e-01, -1.8855e-01,
          1.4268e-01,  1.2930e-01,  8.3411e-02, -6.2276e-02, -4.3533e-03,
         -1.3560e-01, -5.6314e-02, -4.1154e-02, -3.5414e-02, -2.4880e-01,
          8.8197e-02],
        [-2.0455e-01, -1.8696e-01,  1.0159e-01, -2.0464e-01,  2.3850e-01,
          2.3939e-01, -7.9446e-02, -4.3085e-02, -1.9126e-01,  1.5456e-02,
          4.5709e-02, -1.3714e-01,  7.8396e-02, -9.6213e-03, -7.3695e-02,
         -8.6492e-04],
        [-2.4233e-01, -1.7611e-01,  3.3092e-02,  2.4143e-01, -1.4818e-01,
          1.6027e-01,  2.2880e-02, -1.0756e-01,  2.7391e-04,  1.1986e-01,
          2.9743e-02,  2.2130e-01, -4.7314e-02, -1.6695e-01,  2.2591e-01,
         -7.1400e-02],
        [ 1.5863e-01,  1.6490e-01,  4.4276e-02, -2.0519e-01, -2.4544e-01,
          1.1868e-01,  6.1123e-02,  1.4547e-01, -2.2035e-01, -3.4443e-02,
          2.1600e-01,  1.3135e-01,  2.0776e-01,  1.9628e-01, -6.1342e-02,
         -1.7025e-01],
        [-1.4907e-01,  8.4907e-02, -9.9234e-02,  9.9149e-04,  3.9896e-02,
          1.5519e-01,  1.3943e-01,  1.4269e-01,  1.0161e-02,  1.4114e-01,
         -1.1704e-01, -1.0006e-01, -3.9583e-02, -1.4518e-01,  2.2300e-01,
         -3.8309e-02],
        [ 7.2681e-02, -7.7727e-03, -3.4193e-03, -1.3325e-01, -1.8354e-02,
         -2.2362e-01, -1.1955e-01,  1.9239e-01, -2.3449e-01,  4.1140e-02,
          3.9828e-02, -2.3928e-01,  4.8829e-02,  1.1608e-01,  1.8107e-01,
          4.6794e-02],
        [ 1.9542e-01,  9.4101e-03,  9.5256e-02,  7.3802e-02, -1.8433e-01,
         -5.4879e-02, -1.7605e-01,  1.9425e-01,  1.1926e-01, -1.0603e-01,
         -4.5749e-02,  6.6739e-02, -2.1798e-01,  7.0592e-03,  1.1925e-01,
          3.1325e-02],
        [-2.3003e-02,  1.6073e-01,  1.0875e-01, -2.2225e-01,  1.4713e-01,
         -1.9718e-01,  1.4043e-01,  2.1051e-01,  2.3040e-02, -8.4493e-02,
         -1.2914e-01, -1.1101e-01, -4.6083e-02, -1.0365e-01,  2.4818e-01,
         -1.0784e-01],
        [ 1.0380e-01, -2.3183e-01,  1.2671e-01,  2.1273e-01, -1.7922e-01,
         -6.3786e-02,  5.9585e-02, -2.3931e-01, -1.5818e-01,  8.6946e-02,
          2.3541e-01, -7.4686e-02, -2.2768e-03, -2.4133e-01, -2.3996e-01,
          2.1742e-01],
        [ 2.1215e-01, -7.6192e-02, -9.8855e-02, -1.6184e-02,  1.1600e-01,
         -2.4160e-01, -1.3848e-01, -8.2418e-02, -1.0881e-01, -6.6043e-03,
          1.8235e-01,  5.4585e-02, -2.2625e-01,  2.3122e-01,  2.0130e-01,
          7.8714e-02],
        [ 1.2237e-01,  9.3457e-02,  2.0492e-01, -2.4045e-01, -1.5563e-01,
         -3.1748e-02, -4.7555e-02, -1.6603e-01, -2.3975e-01, -1.9093e-01,
         -3.8828e-02,  2.1222e-01,  1.6574e-01,  7.2061e-02, -1.5355e-01,
         -1.0057e-01],
        [ 2.4084e-02, -2.3173e-01, -1.1413e-02,  5.0838e-02,  2.2602e-01,
         -6.5625e-02,  2.4539e-01,  1.8861e-02, -1.7345e-01,  2.3628e-01,
          2.1674e-01, -1.9754e-01, -1.4502e-01,  1.1954e-01, -1.5383e-01,
          1.6999e-01],
        [-1.1928e-01, -7.7591e-02, -7.1767e-02,  2.3851e-01, -8.4540e-02,
         -4.8611e-02,  1.5127e-01, -1.7105e-01, -1.2042e-03, -1.9311e-01,
         -2.3074e-01, -5.7078e-02,  2.7636e-02,  2.1319e-01, -2.3975e-01,
         -7.1936e-02],
        [ 6.5789e-02,  9.4403e-02,  1.4606e-01, -2.0102e-01, -6.1118e-02,
          5.7808e-02, -2.0040e-01,  1.2598e-01, -2.3854e-01,  1.5600e-01,
          8.1279e-02, -7.1012e-02,  8.1105e-02,  2.1174e-01,  1.8391e-01,
          1.5164e-01],
        [-1.4553e-01,  7.1840e-02,  1.8761e-01,  4.4093e-02,  1.6552e-01,
         -1.5505e-01,  1.7571e-01, -8.2927e-03, -2.2430e-01, -6.4806e-02,
          2.2096e-01, -8.7336e-02, -4.3299e-02, -1.0001e-01, -1.3593e-01,
          4.3312e-02],
        [ 1.5166e-01,  2.9561e-02, -1.5419e-02,  1.4462e-02, -1.8747e-01,
         -1.3172e-01,  1.2510e-02, -1.9982e-01,  1.2383e-01,  3.8105e-02,
          2.6324e-03, -1.6043e-02,  2.1115e-01,  2.2816e-01,  1.2207e-01,
          1.2417e-01],
        [-1.2122e-01,  1.0220e-01, -1.6909e-01,  1.0804e-01, -1.7752e-01,
         -1.3674e-03,  1.8120e-01,  1.6601e-01,  2.2105e-01,  8.5281e-02,
          9.7044e-02,  6.7042e-02,  1.8255e-01,  1.3119e-01,  7.3767e-02,
         -8.7229e-02],
        [-1.2099e-01, -6.1809e-02,  1.1931e-01, -1.3609e-01,  6.8302e-02,
          2.1873e-01,  2.1169e-01, -1.8406e-01,  7.1259e-02,  1.6347e-01,
         -2.2708e-01,  1.5978e-01, -1.5577e-01, -1.8076e-01, -1.0597e-01,
         -9.4034e-02],
        [-1.0336e-01,  7.1975e-02,  9.6850e-02,  9.7162e-02,  1.7261e-01,
         -1.5818e-01, -2.3738e-01, -2.0056e-01, -1.3741e-01, -1.1435e-01,
          1.0985e-01, -1.8092e-01, -1.8279e-01,  1.3388e-01, -1.5907e-01,
          4.6891e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1906,  0.0954,  0.1562, -0.2103,  0.0850, -0.1311,  0.1587,  0.2249,
        -0.2109,  0.0935,  0.1688,  0.2273,  0.1888,  0.0492,  0.0146,  0.0515,
        -0.1490, -0.0490, -0.0039, -0.1582, -0.0111, -0.0332, -0.0875, -0.0768,
        -0.2490,  0.2382,  0.1232,  0.1807, -0.2128, -0.2448,  0.1859, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0276,  0.0886,  0.0113, -0.0059,  0.1050,  0.1412, -0.0493, -0.1509,
         -0.0969,  0.1263,  0.0154,  0.1514, -0.0618, -0.1675,  0.0549, -0.0753,
         -0.1057,  0.1102,  0.0123, -0.0151,  0.1722,  0.1540, -0.1444, -0.1625,
         -0.0874, -0.1373, -0.0929,  0.1193, -0.1176,  0.1621,  0.0552,  0.0077]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0274,  0.0338,  0.0515,  ...,  0.0370, -0.1580, -0.1137],
        [-0.0412, -0.1228,  0.0849,  ..., -0.0255, -0.1542,  0.0871],
        [-0.0916,  0.0727,  0.1131,  ...,  0.1516,  0.0694,  0.0345],
        ...,
        [ 0.0835, -0.0818,  0.0083,  ..., -0.1147, -0.0697, -0.1180],
        [ 0.0086, -0.1214, -0.0074,  ..., -0.1376, -0.0348,  0.1557],
        [-0.1369,  0.0661,  0.0410,  ..., -0.0287, -0.1442, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0587,  0.0692, -0.1074, -0.1128, -0.0456,  0.0102, -0.1318,  0.0737,
        -0.0301,  0.0931,  0.0477, -0.0256, -0.0145,  0.0492, -0.0832, -0.0415,
         0.0733, -0.1429, -0.0319,  0.0333, -0.0826,  0.0758,  0.0793, -0.0232,
        -0.0515,  0.0775,  0.0090, -0.1238,  0.0923,  0.1576,  0.1370, -0.0883],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1641, -0.0737, -0.1340,  ..., -0.0192, -0.1329,  0.1699],
        [-0.0956,  0.0925,  0.0408,  ...,  0.0663, -0.1323,  0.1671],
        [ 0.0220, -0.1643, -0.1021,  ..., -0.0583,  0.1139,  0.0584],
        ...,
        [ 0.0230, -0.0144,  0.1370,  ...,  0.1392, -0.1018,  0.1490],
        [ 0.0984, -0.0202, -0.0055,  ...,  0.1521,  0.1041, -0.0493],
        [ 0.1011, -0.0131,  0.1673,  ...,  0.1591,  0.0347,  0.0616]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0691,  0.1030,  0.0027, -0.0455, -0.0609, -0.1135, -0.0068, -0.0992,
         0.1055, -0.1266,  0.1537, -0.1561,  0.1472,  0.0200, -0.1666,  0.0530,
        -0.1138, -0.1400,  0.0093, -0.0503,  0.0436,  0.1398, -0.1621,  0.1758,
        -0.0980, -0.0349,  0.1146, -0.0738, -0.0891, -0.0414,  0.0691, -0.0077],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1610,  0.0763, -0.1613, -0.1273,  0.0139, -0.0068, -0.0537,  0.0581,
          0.0742, -0.1026, -0.0353,  0.0633,  0.0641, -0.0159,  0.0889,  0.0632,
         -0.1659, -0.1689,  0.0059,  0.0605, -0.1260, -0.0910, -0.1689,  0.0335,
          0.1281,  0.1566, -0.1439,  0.1365, -0.0708, -0.1557,  0.1134,  0.1485]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0091], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.4959e-01,  2.3544e-01,  1.6261e-01, -1.7926e-01,  1.1951e-04,
         -5.4087e-03,  1.1917e-01, -2.1412e-01,  3.7155e-03,  8.3298e-02,
          1.2723e-01,  2.6141e-02, -1.2392e-01, -2.4000e-01,  1.3513e-01,
          2.2824e-01],
        [-7.5480e-02, -2.2341e-01,  7.3146e-02, -1.7527e-01, -1.6334e-01,
          6.8146e-02, -2.3741e-02, -1.7005e-02,  2.2424e-01, -4.3851e-02,
          1.5218e-01, -7.7806e-02,  1.8603e-01,  7.6268e-02,  2.2277e-01,
          8.7195e-02],
        [-8.8554e-02,  1.0896e-01,  2.1299e-01,  4.7383e-02,  1.1526e-01,
         -1.7588e-01,  1.3546e-01, -2.3632e-01,  2.2101e-01,  1.0326e-01,
          1.6452e-02, -2.3399e-01,  2.2734e-01,  1.5941e-01,  2.3047e-01,
          9.8278e-02],
        [ 8.4194e-02, -6.4758e-02, -1.0245e-01,  9.9101e-02,  8.6701e-02,
         -8.1050e-03,  3.9765e-02,  8.5878e-02, -2.4159e-01, -2.2109e-01,
         -6.6551e-02,  1.7026e-01,  1.2197e-01, -2.3862e-01, -7.5062e-02,
         -2.6426e-02],
        [ 8.2110e-02,  2.0453e-01,  5.4679e-03, -1.9460e-01,  1.5340e-02,
         -9.6540e-02, -1.5279e-01,  1.3847e-01, -3.3588e-02,  1.1813e-01,
          1.9466e-01,  2.4570e-02,  1.4081e-01, -1.1807e-01,  1.3955e-01,
          9.9876e-03],
        [ 1.6613e-01,  2.3901e-01, -1.8911e-01,  2.3733e-01,  1.9084e-01,
         -2.0139e-01,  7.3285e-02, -2.0353e-01,  8.1097e-02,  3.8660e-02,
         -2.3865e-01,  9.0755e-02, -6.8670e-02,  2.4919e-01,  2.4400e-01,
          8.6303e-02],
        [ 1.9706e-01,  9.0295e-02,  2.3652e-01, -2.3082e-02,  6.1788e-02,
         -4.1296e-02, -4.3721e-03, -7.5417e-02, -9.8939e-02,  1.4462e-01,
          1.0728e-01, -1.1036e-01, -2.2033e-01,  1.2224e-01, -2.2997e-01,
         -1.1063e-02],
        [-2.1511e-01,  2.0933e-01,  2.0357e-01, -2.0546e-01, -2.3243e-01,
         -1.4781e-01,  6.8985e-02, -1.2502e-01, -5.9537e-02, -6.3370e-02,
          4.5858e-02, -1.1825e-01,  1.1370e-01, -1.7890e-01, -2.2253e-02,
          2.0956e-01],
        [-1.3804e-01,  1.9180e-01,  1.3012e-01, -8.0755e-02,  8.6691e-02,
         -1.6889e-01,  2.0121e-02,  7.0815e-02,  2.1624e-01, -1.3989e-01,
         -1.4218e-01, -1.2478e-01, -2.4354e-01,  5.0557e-02, -2.0694e-01,
         -6.7111e-02],
        [-1.1155e-01,  1.3978e-02,  7.5837e-02, -1.8167e-01, -7.3804e-02,
         -2.4035e-02, -1.4452e-01,  5.7753e-02,  9.2549e-02, -1.7817e-01,
          1.9658e-01,  1.7765e-01, -7.5106e-02,  3.7198e-02,  3.0439e-02,
         -3.4493e-02],
        [-1.6778e-01,  2.0601e-01,  1.2303e-01, -2.0892e-01, -1.9375e-01,
          2.3774e-01,  3.9901e-02, -5.7436e-02,  1.6943e-01,  7.1820e-02,
          8.9743e-02,  1.9833e-01, -1.9512e-02,  2.3822e-01, -1.7561e-01,
         -1.5213e-01],
        [ 4.2360e-02, -3.0351e-02,  1.4266e-01, -6.7982e-02,  3.9312e-02,
         -5.1947e-02,  1.8769e-01, -1.6398e-02,  3.8373e-03,  1.8315e-01,
          2.4304e-01,  2.3921e-01, -2.4443e-01, -1.4127e-01, -5.4287e-02,
         -5.1611e-02],
        [ 1.4461e-01,  1.1291e-01, -2.0563e-02,  5.9224e-03,  5.3564e-02,
          2.1551e-01,  1.2955e-01, -1.2610e-01, -1.2807e-01,  7.9062e-02,
         -2.5286e-02, -1.6039e-01, -2.4197e-01,  3.5810e-02, -7.3006e-02,
         -1.4546e-01],
        [ 4.7027e-02,  2.4345e-01,  2.0765e-01,  1.4254e-01, -1.8855e-01,
          1.4268e-01,  1.2930e-01,  8.3411e-02, -6.2276e-02, -4.3533e-03,
         -1.3560e-01, -5.6314e-02, -4.1154e-02, -3.5414e-02, -2.4880e-01,
          8.8197e-02],
        [-2.0455e-01, -1.8696e-01,  1.0159e-01, -2.0464e-01,  2.3850e-01,
          2.3939e-01, -7.9446e-02, -4.3085e-02, -1.9126e-01,  1.5456e-02,
          4.5709e-02, -1.3714e-01,  7.8396e-02, -9.6213e-03, -7.3695e-02,
         -8.6492e-04],
        [-2.4233e-01, -1.7611e-01,  3.3092e-02,  2.4143e-01, -1.4818e-01,
          1.6027e-01,  2.2880e-02, -1.0756e-01,  2.7391e-04,  1.1986e-01,
          2.9743e-02,  2.2130e-01, -4.7314e-02, -1.6695e-01,  2.2591e-01,
         -7.1400e-02],
        [ 1.5863e-01,  1.6490e-01,  4.4276e-02, -2.0519e-01, -2.4544e-01,
          1.1868e-01,  6.1123e-02,  1.4547e-01, -2.2035e-01, -3.4443e-02,
          2.1600e-01,  1.3135e-01,  2.0776e-01,  1.9628e-01, -6.1342e-02,
         -1.7025e-01],
        [-1.4907e-01,  8.4907e-02, -9.9234e-02,  9.9149e-04,  3.9896e-02,
          1.5519e-01,  1.3943e-01,  1.4269e-01,  1.0161e-02,  1.4114e-01,
         -1.1704e-01, -1.0006e-01, -3.9583e-02, -1.4518e-01,  2.2300e-01,
         -3.8309e-02],
        [ 7.2681e-02, -7.7727e-03, -3.4193e-03, -1.3325e-01, -1.8354e-02,
         -2.2362e-01, -1.1955e-01,  1.9239e-01, -2.3449e-01,  4.1140e-02,
          3.9828e-02, -2.3928e-01,  4.8829e-02,  1.1608e-01,  1.8107e-01,
          4.6794e-02],
        [ 1.9542e-01,  9.4101e-03,  9.5256e-02,  7.3802e-02, -1.8433e-01,
         -5.4879e-02, -1.7605e-01,  1.9425e-01,  1.1926e-01, -1.0603e-01,
         -4.5749e-02,  6.6739e-02, -2.1798e-01,  7.0592e-03,  1.1925e-01,
          3.1325e-02],
        [-2.3003e-02,  1.6073e-01,  1.0875e-01, -2.2225e-01,  1.4713e-01,
         -1.9718e-01,  1.4043e-01,  2.1051e-01,  2.3040e-02, -8.4493e-02,
         -1.2914e-01, -1.1101e-01, -4.6083e-02, -1.0365e-01,  2.4818e-01,
         -1.0784e-01],
        [ 1.0380e-01, -2.3183e-01,  1.2671e-01,  2.1273e-01, -1.7922e-01,
         -6.3786e-02,  5.9585e-02, -2.3931e-01, -1.5818e-01,  8.6946e-02,
          2.3541e-01, -7.4686e-02, -2.2768e-03, -2.4133e-01, -2.3996e-01,
          2.1742e-01],
        [ 2.1215e-01, -7.6192e-02, -9.8855e-02, -1.6184e-02,  1.1600e-01,
         -2.4160e-01, -1.3848e-01, -8.2418e-02, -1.0881e-01, -6.6043e-03,
          1.8235e-01,  5.4585e-02, -2.2625e-01,  2.3122e-01,  2.0130e-01,
          7.8714e-02],
        [ 1.2237e-01,  9.3457e-02,  2.0492e-01, -2.4045e-01, -1.5563e-01,
         -3.1748e-02, -4.7555e-02, -1.6603e-01, -2.3975e-01, -1.9093e-01,
         -3.8828e-02,  2.1222e-01,  1.6574e-01,  7.2061e-02, -1.5355e-01,
         -1.0057e-01],
        [ 2.4084e-02, -2.3173e-01, -1.1413e-02,  5.0838e-02,  2.2602e-01,
         -6.5625e-02,  2.4539e-01,  1.8861e-02, -1.7345e-01,  2.3628e-01,
          2.1674e-01, -1.9754e-01, -1.4502e-01,  1.1954e-01, -1.5383e-01,
          1.6999e-01],
        [-1.1928e-01, -7.7591e-02, -7.1767e-02,  2.3851e-01, -8.4540e-02,
         -4.8611e-02,  1.5127e-01, -1.7105e-01, -1.2042e-03, -1.9311e-01,
         -2.3074e-01, -5.7078e-02,  2.7636e-02,  2.1319e-01, -2.3975e-01,
         -7.1936e-02],
        [ 6.5789e-02,  9.4403e-02,  1.4606e-01, -2.0102e-01, -6.1118e-02,
          5.7808e-02, -2.0040e-01,  1.2598e-01, -2.3854e-01,  1.5600e-01,
          8.1279e-02, -7.1012e-02,  8.1105e-02,  2.1174e-01,  1.8391e-01,
          1.5164e-01],
        [-1.4553e-01,  7.1840e-02,  1.8761e-01,  4.4093e-02,  1.6552e-01,
         -1.5505e-01,  1.7571e-01, -8.2927e-03, -2.2430e-01, -6.4806e-02,
          2.2096e-01, -8.7336e-02, -4.3299e-02, -1.0001e-01, -1.3593e-01,
          4.3312e-02],
        [ 1.5166e-01,  2.9561e-02, -1.5419e-02,  1.4462e-02, -1.8747e-01,
         -1.3172e-01,  1.2510e-02, -1.9982e-01,  1.2383e-01,  3.8105e-02,
          2.6324e-03, -1.6043e-02,  2.1115e-01,  2.2816e-01,  1.2207e-01,
          1.2417e-01],
        [-1.2122e-01,  1.0220e-01, -1.6909e-01,  1.0804e-01, -1.7752e-01,
         -1.3674e-03,  1.8120e-01,  1.6601e-01,  2.2105e-01,  8.5281e-02,
          9.7044e-02,  6.7042e-02,  1.8255e-01,  1.3119e-01,  7.3767e-02,
         -8.7229e-02],
        [-1.2099e-01, -6.1809e-02,  1.1931e-01, -1.3609e-01,  6.8302e-02,
          2.1873e-01,  2.1169e-01, -1.8406e-01,  7.1259e-02,  1.6347e-01,
         -2.2708e-01,  1.5978e-01, -1.5577e-01, -1.8076e-01, -1.0597e-01,
         -9.4034e-02],
        [-1.0336e-01,  7.1975e-02,  9.6850e-02,  9.7162e-02,  1.7261e-01,
         -1.5818e-01, -2.3738e-01, -2.0056e-01, -1.3741e-01, -1.1435e-01,
          1.0985e-01, -1.8092e-01, -1.8279e-01,  1.3388e-01, -1.5907e-01,
          4.6891e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1906,  0.0954,  0.1562, -0.2103,  0.0850, -0.1311,  0.1587,  0.2249,
        -0.2109,  0.0935,  0.1688,  0.2273,  0.1888,  0.0492,  0.0146,  0.0515,
        -0.1490, -0.0490, -0.0039, -0.1582, -0.0111, -0.0332, -0.0875, -0.0768,
        -0.2490,  0.2382,  0.1232,  0.1807, -0.2128, -0.2448,  0.1859, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0276,  0.0886,  0.0113, -0.0059,  0.1050,  0.1412, -0.0493, -0.1509,
         -0.0969,  0.1263,  0.0154,  0.1514, -0.0618, -0.1675,  0.0549, -0.0753,
         -0.1057,  0.1102,  0.0123, -0.0151,  0.1722,  0.1540, -0.1444, -0.1625,
         -0.0874, -0.1373, -0.0929,  0.1193, -0.1176,  0.1621,  0.0552,  0.0077]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0274,  0.0338,  0.0515,  ...,  0.0370, -0.1580, -0.1137],
        [-0.0412, -0.1228,  0.0849,  ..., -0.0255, -0.1542,  0.0871],
        [-0.0916,  0.0727,  0.1131,  ...,  0.1516,  0.0694,  0.0345],
        ...,
        [ 0.0835, -0.0818,  0.0083,  ..., -0.1147, -0.0697, -0.1180],
        [ 0.0086, -0.1214, -0.0074,  ..., -0.1376, -0.0348,  0.1557],
        [-0.1369,  0.0661,  0.0410,  ..., -0.0287, -0.1442, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0587,  0.0692, -0.1074, -0.1128, -0.0456,  0.0102, -0.1318,  0.0737,
        -0.0301,  0.0931,  0.0477, -0.0256, -0.0145,  0.0492, -0.0832, -0.0415,
         0.0733, -0.1429, -0.0319,  0.0333, -0.0826,  0.0758,  0.0793, -0.0232,
        -0.0515,  0.0775,  0.0090, -0.1238,  0.0923,  0.1576,  0.1370, -0.0883],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1641, -0.0737, -0.1340,  ..., -0.0192, -0.1329,  0.1699],
        [-0.0956,  0.0925,  0.0408,  ...,  0.0663, -0.1323,  0.1671],
        [ 0.0220, -0.1643, -0.1021,  ..., -0.0583,  0.1139,  0.0584],
        ...,
        [ 0.0230, -0.0144,  0.1370,  ...,  0.1392, -0.1018,  0.1490],
        [ 0.0984, -0.0202, -0.0055,  ...,  0.1521,  0.1041, -0.0493],
        [ 0.1011, -0.0131,  0.1673,  ...,  0.1591,  0.0347,  0.0616]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0691,  0.1030,  0.0027, -0.0455, -0.0609, -0.1135, -0.0068, -0.0992,
         0.1055, -0.1266,  0.1537, -0.1561,  0.1472,  0.0200, -0.1666,  0.0530,
        -0.1138, -0.1400,  0.0093, -0.0503,  0.0436,  0.1398, -0.1621,  0.1758,
        -0.0980, -0.0349,  0.1146, -0.0738, -0.0891, -0.0414,  0.0691, -0.0077],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1610,  0.0763, -0.1613, -0.1273,  0.0139, -0.0068, -0.0537,  0.0581,
          0.0742, -0.1026, -0.0353,  0.0633,  0.0641, -0.0159,  0.0889,  0.0632,
         -0.1659, -0.1689,  0.0059,  0.0605, -0.1260, -0.0910, -0.1689,  0.0335,
          0.1281,  0.1566, -0.1439,  0.1365, -0.0708, -0.1557,  0.1134,  0.1485]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0091], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.4959e-01,  2.3544e-01,  1.6261e-01, -1.7926e-01,  1.1951e-04,
         -5.4087e-03,  1.1917e-01, -2.1412e-01,  3.7155e-03,  8.3298e-02,
          1.2723e-01,  2.6141e-02, -1.2392e-01, -2.4000e-01,  1.3513e-01,
          2.2824e-01],
        [-7.5480e-02, -2.2341e-01,  7.3146e-02, -1.7527e-01, -1.6334e-01,
          6.8146e-02, -2.3741e-02, -1.7005e-02,  2.2424e-01, -4.3851e-02,
          1.5218e-01, -7.7806e-02,  1.8603e-01,  7.6268e-02,  2.2277e-01,
          8.7195e-02],
        [-8.8554e-02,  1.0896e-01,  2.1299e-01,  4.7383e-02,  1.1526e-01,
         -1.7588e-01,  1.3546e-01, -2.3632e-01,  2.2101e-01,  1.0326e-01,
          1.6452e-02, -2.3399e-01,  2.2734e-01,  1.5941e-01,  2.3047e-01,
          9.8278e-02],
        [ 8.4194e-02, -6.4758e-02, -1.0245e-01,  9.9101e-02,  8.6701e-02,
         -8.1050e-03,  3.9765e-02,  8.5878e-02, -2.4159e-01, -2.2109e-01,
         -6.6551e-02,  1.7026e-01,  1.2197e-01, -2.3862e-01, -7.5062e-02,
         -2.6426e-02],
        [ 8.2110e-02,  2.0453e-01,  5.4679e-03, -1.9460e-01,  1.5340e-02,
         -9.6540e-02, -1.5279e-01,  1.3847e-01, -3.3588e-02,  1.1813e-01,
          1.9466e-01,  2.4570e-02,  1.4081e-01, -1.1807e-01,  1.3955e-01,
          9.9876e-03],
        [ 1.6613e-01,  2.3901e-01, -1.8911e-01,  2.3733e-01,  1.9084e-01,
         -2.0139e-01,  7.3285e-02, -2.0353e-01,  8.1097e-02,  3.8660e-02,
         -2.3865e-01,  9.0755e-02, -6.8670e-02,  2.4919e-01,  2.4400e-01,
          8.6303e-02],
        [ 1.9706e-01,  9.0295e-02,  2.3652e-01, -2.3082e-02,  6.1788e-02,
         -4.1296e-02, -4.3721e-03, -7.5417e-02, -9.8939e-02,  1.4462e-01,
          1.0728e-01, -1.1036e-01, -2.2033e-01,  1.2224e-01, -2.2997e-01,
         -1.1063e-02],
        [-2.1511e-01,  2.0933e-01,  2.0357e-01, -2.0546e-01, -2.3243e-01,
         -1.4781e-01,  6.8985e-02, -1.2502e-01, -5.9537e-02, -6.3370e-02,
          4.5858e-02, -1.1825e-01,  1.1370e-01, -1.7890e-01, -2.2253e-02,
          2.0956e-01],
        [-1.3804e-01,  1.9180e-01,  1.3012e-01, -8.0755e-02,  8.6691e-02,
         -1.6889e-01,  2.0121e-02,  7.0815e-02,  2.1624e-01, -1.3989e-01,
         -1.4218e-01, -1.2478e-01, -2.4354e-01,  5.0557e-02, -2.0694e-01,
         -6.7111e-02],
        [-1.1155e-01,  1.3978e-02,  7.5837e-02, -1.8167e-01, -7.3804e-02,
         -2.4035e-02, -1.4452e-01,  5.7753e-02,  9.2549e-02, -1.7817e-01,
          1.9658e-01,  1.7765e-01, -7.5106e-02,  3.7198e-02,  3.0439e-02,
         -3.4493e-02],
        [-1.6778e-01,  2.0601e-01,  1.2303e-01, -2.0892e-01, -1.9375e-01,
          2.3774e-01,  3.9901e-02, -5.7436e-02,  1.6943e-01,  7.1820e-02,
          8.9743e-02,  1.9833e-01, -1.9512e-02,  2.3822e-01, -1.7561e-01,
         -1.5213e-01],
        [ 4.2360e-02, -3.0351e-02,  1.4266e-01, -6.7982e-02,  3.9312e-02,
         -5.1947e-02,  1.8769e-01, -1.6398e-02,  3.8373e-03,  1.8315e-01,
          2.4304e-01,  2.3921e-01, -2.4443e-01, -1.4127e-01, -5.4287e-02,
         -5.1611e-02],
        [ 1.4461e-01,  1.1291e-01, -2.0563e-02,  5.9224e-03,  5.3564e-02,
          2.1551e-01,  1.2955e-01, -1.2610e-01, -1.2807e-01,  7.9062e-02,
         -2.5286e-02, -1.6039e-01, -2.4197e-01,  3.5810e-02, -7.3006e-02,
         -1.4546e-01],
        [ 4.7027e-02,  2.4345e-01,  2.0765e-01,  1.4254e-01, -1.8855e-01,
          1.4268e-01,  1.2930e-01,  8.3411e-02, -6.2276e-02, -4.3533e-03,
         -1.3560e-01, -5.6314e-02, -4.1154e-02, -3.5414e-02, -2.4880e-01,
          8.8197e-02],
        [-2.0455e-01, -1.8696e-01,  1.0159e-01, -2.0464e-01,  2.3850e-01,
          2.3939e-01, -7.9446e-02, -4.3085e-02, -1.9126e-01,  1.5456e-02,
          4.5709e-02, -1.3714e-01,  7.8396e-02, -9.6213e-03, -7.3695e-02,
         -8.6492e-04],
        [-2.4233e-01, -1.7611e-01,  3.3092e-02,  2.4143e-01, -1.4818e-01,
          1.6027e-01,  2.2880e-02, -1.0756e-01,  2.7391e-04,  1.1986e-01,
          2.9743e-02,  2.2130e-01, -4.7314e-02, -1.6695e-01,  2.2591e-01,
         -7.1400e-02],
        [ 1.5863e-01,  1.6490e-01,  4.4276e-02, -2.0519e-01, -2.4544e-01,
          1.1868e-01,  6.1123e-02,  1.4547e-01, -2.2035e-01, -3.4443e-02,
          2.1600e-01,  1.3135e-01,  2.0776e-01,  1.9628e-01, -6.1342e-02,
         -1.7025e-01],
        [-1.4907e-01,  8.4907e-02, -9.9234e-02,  9.9149e-04,  3.9896e-02,
          1.5519e-01,  1.3943e-01,  1.4269e-01,  1.0161e-02,  1.4114e-01,
         -1.1704e-01, -1.0006e-01, -3.9583e-02, -1.4518e-01,  2.2300e-01,
         -3.8309e-02],
        [ 7.2681e-02, -7.7727e-03, -3.4193e-03, -1.3325e-01, -1.8354e-02,
         -2.2362e-01, -1.1955e-01,  1.9239e-01, -2.3449e-01,  4.1140e-02,
          3.9828e-02, -2.3928e-01,  4.8829e-02,  1.1608e-01,  1.8107e-01,
          4.6794e-02],
        [ 1.9542e-01,  9.4101e-03,  9.5256e-02,  7.3802e-02, -1.8433e-01,
         -5.4879e-02, -1.7605e-01,  1.9425e-01,  1.1926e-01, -1.0603e-01,
         -4.5749e-02,  6.6739e-02, -2.1798e-01,  7.0592e-03,  1.1925e-01,
          3.1325e-02],
        [-2.3003e-02,  1.6073e-01,  1.0875e-01, -2.2225e-01,  1.4713e-01,
         -1.9718e-01,  1.4043e-01,  2.1051e-01,  2.3040e-02, -8.4493e-02,
         -1.2914e-01, -1.1101e-01, -4.6083e-02, -1.0365e-01,  2.4818e-01,
         -1.0784e-01],
        [ 1.0380e-01, -2.3183e-01,  1.2671e-01,  2.1273e-01, -1.7922e-01,
         -6.3786e-02,  5.9585e-02, -2.3931e-01, -1.5818e-01,  8.6946e-02,
          2.3541e-01, -7.4686e-02, -2.2768e-03, -2.4133e-01, -2.3996e-01,
          2.1742e-01],
        [ 2.1215e-01, -7.6192e-02, -9.8855e-02, -1.6184e-02,  1.1600e-01,
         -2.4160e-01, -1.3848e-01, -8.2418e-02, -1.0881e-01, -6.6043e-03,
          1.8235e-01,  5.4585e-02, -2.2625e-01,  2.3122e-01,  2.0130e-01,
          7.8714e-02],
        [ 1.2237e-01,  9.3457e-02,  2.0492e-01, -2.4045e-01, -1.5563e-01,
         -3.1748e-02, -4.7555e-02, -1.6603e-01, -2.3975e-01, -1.9093e-01,
         -3.8828e-02,  2.1222e-01,  1.6574e-01,  7.2061e-02, -1.5355e-01,
         -1.0057e-01],
        [ 2.4084e-02, -2.3173e-01, -1.1413e-02,  5.0838e-02,  2.2602e-01,
         -6.5625e-02,  2.4539e-01,  1.8861e-02, -1.7345e-01,  2.3628e-01,
          2.1674e-01, -1.9754e-01, -1.4502e-01,  1.1954e-01, -1.5383e-01,
          1.6999e-01],
        [-1.1928e-01, -7.7591e-02, -7.1767e-02,  2.3851e-01, -8.4540e-02,
         -4.8611e-02,  1.5127e-01, -1.7105e-01, -1.2042e-03, -1.9311e-01,
         -2.3074e-01, -5.7078e-02,  2.7636e-02,  2.1319e-01, -2.3975e-01,
         -7.1936e-02],
        [ 6.5789e-02,  9.4403e-02,  1.4606e-01, -2.0102e-01, -6.1118e-02,
          5.7808e-02, -2.0040e-01,  1.2598e-01, -2.3854e-01,  1.5600e-01,
          8.1279e-02, -7.1012e-02,  8.1105e-02,  2.1174e-01,  1.8391e-01,
          1.5164e-01],
        [-1.4553e-01,  7.1840e-02,  1.8761e-01,  4.4093e-02,  1.6552e-01,
         -1.5505e-01,  1.7571e-01, -8.2927e-03, -2.2430e-01, -6.4806e-02,
          2.2096e-01, -8.7336e-02, -4.3299e-02, -1.0001e-01, -1.3593e-01,
          4.3312e-02],
        [ 1.5166e-01,  2.9561e-02, -1.5419e-02,  1.4462e-02, -1.8747e-01,
         -1.3172e-01,  1.2510e-02, -1.9982e-01,  1.2383e-01,  3.8105e-02,
          2.6324e-03, -1.6043e-02,  2.1115e-01,  2.2816e-01,  1.2207e-01,
          1.2417e-01],
        [-1.2122e-01,  1.0220e-01, -1.6909e-01,  1.0804e-01, -1.7752e-01,
         -1.3674e-03,  1.8120e-01,  1.6601e-01,  2.2105e-01,  8.5281e-02,
          9.7044e-02,  6.7042e-02,  1.8255e-01,  1.3119e-01,  7.3767e-02,
         -8.7229e-02],
        [-1.2099e-01, -6.1809e-02,  1.1931e-01, -1.3609e-01,  6.8302e-02,
          2.1873e-01,  2.1169e-01, -1.8406e-01,  7.1259e-02,  1.6347e-01,
         -2.2708e-01,  1.5978e-01, -1.5577e-01, -1.8076e-01, -1.0597e-01,
         -9.4034e-02],
        [-1.0336e-01,  7.1975e-02,  9.6850e-02,  9.7162e-02,  1.7261e-01,
         -1.5818e-01, -2.3738e-01, -2.0056e-01, -1.3741e-01, -1.1435e-01,
          1.0985e-01, -1.8092e-01, -1.8279e-01,  1.3388e-01, -1.5907e-01,
          4.6891e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1906,  0.0954,  0.1562, -0.2103,  0.0850, -0.1311,  0.1587,  0.2249,
        -0.2109,  0.0935,  0.1688,  0.2273,  0.1888,  0.0492,  0.0146,  0.0515,
        -0.1490, -0.0490, -0.0039, -0.1582, -0.0111, -0.0332, -0.0875, -0.0768,
        -0.2490,  0.2382,  0.1232,  0.1807, -0.2128, -0.2448,  0.1859, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0276,  0.0886,  0.0113, -0.0059,  0.1050,  0.1412, -0.0493, -0.1509,
         -0.0969,  0.1263,  0.0154,  0.1514, -0.0618, -0.1675,  0.0549, -0.0753,
         -0.1057,  0.1102,  0.0123, -0.0151,  0.1722,  0.1540, -0.1444, -0.1625,
         -0.0874, -0.1373, -0.0929,  0.1193, -0.1176,  0.1621,  0.0552,  0.0077]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0274,  0.0338,  0.0515,  ...,  0.0370, -0.1580, -0.1137],
        [-0.0412, -0.1228,  0.0849,  ..., -0.0255, -0.1542,  0.0871],
        [-0.0916,  0.0727,  0.1131,  ...,  0.1516,  0.0694,  0.0345],
        ...,
        [ 0.0835, -0.0818,  0.0083,  ..., -0.1147, -0.0697, -0.1180],
        [ 0.0086, -0.1214, -0.0074,  ..., -0.1376, -0.0348,  0.1557],
        [-0.1369,  0.0661,  0.0410,  ..., -0.0287, -0.1442, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0587,  0.0692, -0.1074, -0.1128, -0.0456,  0.0102, -0.1318,  0.0737,
        -0.0301,  0.0931,  0.0477, -0.0256, -0.0145,  0.0492, -0.0832, -0.0415,
         0.0733, -0.1429, -0.0319,  0.0333, -0.0826,  0.0758,  0.0793, -0.0232,
        -0.0515,  0.0775,  0.0090, -0.1238,  0.0923,  0.1576,  0.1370, -0.0883],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1641, -0.0737, -0.1340,  ..., -0.0192, -0.1329,  0.1699],
        [-0.0956,  0.0925,  0.0408,  ...,  0.0663, -0.1323,  0.1671],
        [ 0.0220, -0.1643, -0.1021,  ..., -0.0583,  0.1139,  0.0584],
        ...,
        [ 0.0230, -0.0144,  0.1370,  ...,  0.1392, -0.1018,  0.1490],
        [ 0.0984, -0.0202, -0.0055,  ...,  0.1521,  0.1041, -0.0493],
        [ 0.1011, -0.0131,  0.1673,  ...,  0.1591,  0.0347,  0.0616]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0691,  0.1030,  0.0027, -0.0455, -0.0609, -0.1135, -0.0068, -0.0992,
         0.1055, -0.1266,  0.1537, -0.1561,  0.1472,  0.0200, -0.1666,  0.0530,
        -0.1138, -0.1400,  0.0093, -0.0503,  0.0436,  0.1398, -0.1621,  0.1758,
        -0.0980, -0.0349,  0.1146, -0.0738, -0.0891, -0.0414,  0.0691, -0.0077],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1610,  0.0763, -0.1613, -0.1273,  0.0139, -0.0068, -0.0537,  0.0581,
          0.0742, -0.1026, -0.0353,  0.0633,  0.0641, -0.0159,  0.0889,  0.0632,
         -0.1659, -0.1689,  0.0059,  0.0605, -0.1260, -0.0910, -0.1689,  0.0335,
          0.1281,  0.1566, -0.1439,  0.1365, -0.0708, -0.1557,  0.1134,  0.1485]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0091], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.4959e-01,  2.3544e-01,  1.6261e-01, -1.7926e-01,  1.1951e-04,
         -5.4087e-03,  1.1917e-01, -2.1412e-01,  3.7155e-03,  8.3298e-02,
          1.2723e-01,  2.6141e-02, -1.2392e-01, -2.4000e-01,  1.3513e-01,
          2.2824e-01],
        [-7.5480e-02, -2.2341e-01,  7.3146e-02, -1.7527e-01, -1.6334e-01,
          6.8146e-02, -2.3741e-02, -1.7005e-02,  2.2424e-01, -4.3851e-02,
          1.5218e-01, -7.7806e-02,  1.8603e-01,  7.6268e-02,  2.2277e-01,
          8.7195e-02],
        [-8.8554e-02,  1.0896e-01,  2.1299e-01,  4.7383e-02,  1.1526e-01,
         -1.7588e-01,  1.3546e-01, -2.3632e-01,  2.2101e-01,  1.0326e-01,
          1.6452e-02, -2.3399e-01,  2.2734e-01,  1.5941e-01,  2.3047e-01,
          9.8278e-02],
        [ 8.4194e-02, -6.4758e-02, -1.0245e-01,  9.9101e-02,  8.6701e-02,
         -8.1050e-03,  3.9765e-02,  8.5878e-02, -2.4159e-01, -2.2109e-01,
         -6.6551e-02,  1.7026e-01,  1.2197e-01, -2.3862e-01, -7.5062e-02,
         -2.6426e-02],
        [ 8.2110e-02,  2.0453e-01,  5.4679e-03, -1.9460e-01,  1.5340e-02,
         -9.6540e-02, -1.5279e-01,  1.3847e-01, -3.3588e-02,  1.1813e-01,
          1.9466e-01,  2.4570e-02,  1.4081e-01, -1.1807e-01,  1.3955e-01,
          9.9876e-03],
        [ 1.6613e-01,  2.3901e-01, -1.8911e-01,  2.3733e-01,  1.9084e-01,
         -2.0139e-01,  7.3285e-02, -2.0353e-01,  8.1097e-02,  3.8660e-02,
         -2.3865e-01,  9.0755e-02, -6.8670e-02,  2.4919e-01,  2.4400e-01,
          8.6303e-02],
        [ 1.9706e-01,  9.0295e-02,  2.3652e-01, -2.3082e-02,  6.1788e-02,
         -4.1296e-02, -4.3721e-03, -7.5417e-02, -9.8939e-02,  1.4462e-01,
          1.0728e-01, -1.1036e-01, -2.2033e-01,  1.2224e-01, -2.2997e-01,
         -1.1063e-02],
        [-2.1511e-01,  2.0933e-01,  2.0357e-01, -2.0546e-01, -2.3243e-01,
         -1.4781e-01,  6.8985e-02, -1.2502e-01, -5.9537e-02, -6.3370e-02,
          4.5858e-02, -1.1825e-01,  1.1370e-01, -1.7890e-01, -2.2253e-02,
          2.0956e-01],
        [-1.3804e-01,  1.9180e-01,  1.3012e-01, -8.0755e-02,  8.6691e-02,
         -1.6889e-01,  2.0121e-02,  7.0815e-02,  2.1624e-01, -1.3989e-01,
         -1.4218e-01, -1.2478e-01, -2.4354e-01,  5.0557e-02, -2.0694e-01,
         -6.7111e-02],
        [-1.1155e-01,  1.3978e-02,  7.5837e-02, -1.8167e-01, -7.3804e-02,
         -2.4035e-02, -1.4452e-01,  5.7753e-02,  9.2549e-02, -1.7817e-01,
          1.9658e-01,  1.7765e-01, -7.5106e-02,  3.7198e-02,  3.0439e-02,
         -3.4493e-02],
        [-1.6778e-01,  2.0601e-01,  1.2303e-01, -2.0892e-01, -1.9375e-01,
          2.3774e-01,  3.9901e-02, -5.7436e-02,  1.6943e-01,  7.1820e-02,
          8.9743e-02,  1.9833e-01, -1.9512e-02,  2.3822e-01, -1.7561e-01,
         -1.5213e-01],
        [ 4.2360e-02, -3.0351e-02,  1.4266e-01, -6.7982e-02,  3.9312e-02,
         -5.1947e-02,  1.8769e-01, -1.6398e-02,  3.8373e-03,  1.8315e-01,
          2.4304e-01,  2.3921e-01, -2.4443e-01, -1.4127e-01, -5.4287e-02,
         -5.1611e-02],
        [ 1.4461e-01,  1.1291e-01, -2.0563e-02,  5.9224e-03,  5.3564e-02,
          2.1551e-01,  1.2955e-01, -1.2610e-01, -1.2807e-01,  7.9062e-02,
         -2.5286e-02, -1.6039e-01, -2.4197e-01,  3.5810e-02, -7.3006e-02,
         -1.4546e-01],
        [ 4.7027e-02,  2.4345e-01,  2.0765e-01,  1.4254e-01, -1.8855e-01,
          1.4268e-01,  1.2930e-01,  8.3411e-02, -6.2276e-02, -4.3533e-03,
         -1.3560e-01, -5.6314e-02, -4.1154e-02, -3.5414e-02, -2.4880e-01,
          8.8197e-02],
        [-2.0455e-01, -1.8696e-01,  1.0159e-01, -2.0464e-01,  2.3850e-01,
          2.3939e-01, -7.9446e-02, -4.3085e-02, -1.9126e-01,  1.5456e-02,
          4.5709e-02, -1.3714e-01,  7.8396e-02, -9.6213e-03, -7.3695e-02,
         -8.6492e-04],
        [-2.4233e-01, -1.7611e-01,  3.3092e-02,  2.4143e-01, -1.4818e-01,
          1.6027e-01,  2.2880e-02, -1.0756e-01,  2.7391e-04,  1.1986e-01,
          2.9743e-02,  2.2130e-01, -4.7314e-02, -1.6695e-01,  2.2591e-01,
         -7.1400e-02],
        [ 1.5863e-01,  1.6490e-01,  4.4276e-02, -2.0519e-01, -2.4544e-01,
          1.1868e-01,  6.1123e-02,  1.4547e-01, -2.2035e-01, -3.4443e-02,
          2.1600e-01,  1.3135e-01,  2.0776e-01,  1.9628e-01, -6.1342e-02,
         -1.7025e-01],
        [-1.4907e-01,  8.4907e-02, -9.9234e-02,  9.9149e-04,  3.9896e-02,
          1.5519e-01,  1.3943e-01,  1.4269e-01,  1.0161e-02,  1.4114e-01,
         -1.1704e-01, -1.0006e-01, -3.9583e-02, -1.4518e-01,  2.2300e-01,
         -3.8309e-02],
        [ 7.2681e-02, -7.7727e-03, -3.4193e-03, -1.3325e-01, -1.8354e-02,
         -2.2362e-01, -1.1955e-01,  1.9239e-01, -2.3449e-01,  4.1140e-02,
          3.9828e-02, -2.3928e-01,  4.8829e-02,  1.1608e-01,  1.8107e-01,
          4.6794e-02],
        [ 1.9542e-01,  9.4101e-03,  9.5256e-02,  7.3802e-02, -1.8433e-01,
         -5.4879e-02, -1.7605e-01,  1.9425e-01,  1.1926e-01, -1.0603e-01,
         -4.5749e-02,  6.6739e-02, -2.1798e-01,  7.0592e-03,  1.1925e-01,
          3.1325e-02],
        [-2.3003e-02,  1.6073e-01,  1.0875e-01, -2.2225e-01,  1.4713e-01,
         -1.9718e-01,  1.4043e-01,  2.1051e-01,  2.3040e-02, -8.4493e-02,
         -1.2914e-01, -1.1101e-01, -4.6083e-02, -1.0365e-01,  2.4818e-01,
         -1.0784e-01],
        [ 1.0380e-01, -2.3183e-01,  1.2671e-01,  2.1273e-01, -1.7922e-01,
         -6.3786e-02,  5.9585e-02, -2.3931e-01, -1.5818e-01,  8.6946e-02,
          2.3541e-01, -7.4686e-02, -2.2768e-03, -2.4133e-01, -2.3996e-01,
          2.1742e-01],
        [ 2.1215e-01, -7.6192e-02, -9.8855e-02, -1.6184e-02,  1.1600e-01,
         -2.4160e-01, -1.3848e-01, -8.2418e-02, -1.0881e-01, -6.6043e-03,
          1.8235e-01,  5.4585e-02, -2.2625e-01,  2.3122e-01,  2.0130e-01,
          7.8714e-02],
        [ 1.2237e-01,  9.3457e-02,  2.0492e-01, -2.4045e-01, -1.5563e-01,
         -3.1748e-02, -4.7555e-02, -1.6603e-01, -2.3975e-01, -1.9093e-01,
         -3.8828e-02,  2.1222e-01,  1.6574e-01,  7.2061e-02, -1.5355e-01,
         -1.0057e-01],
        [ 2.4084e-02, -2.3173e-01, -1.1413e-02,  5.0838e-02,  2.2602e-01,
         -6.5625e-02,  2.4539e-01,  1.8861e-02, -1.7345e-01,  2.3628e-01,
          2.1674e-01, -1.9754e-01, -1.4502e-01,  1.1954e-01, -1.5383e-01,
          1.6999e-01],
        [-1.1928e-01, -7.7591e-02, -7.1767e-02,  2.3851e-01, -8.4540e-02,
         -4.8611e-02,  1.5127e-01, -1.7105e-01, -1.2042e-03, -1.9311e-01,
         -2.3074e-01, -5.7078e-02,  2.7636e-02,  2.1319e-01, -2.3975e-01,
         -7.1936e-02],
        [ 6.5789e-02,  9.4403e-02,  1.4606e-01, -2.0102e-01, -6.1118e-02,
          5.7808e-02, -2.0040e-01,  1.2598e-01, -2.3854e-01,  1.5600e-01,
          8.1279e-02, -7.1012e-02,  8.1105e-02,  2.1174e-01,  1.8391e-01,
          1.5164e-01],
        [-1.4553e-01,  7.1840e-02,  1.8761e-01,  4.4093e-02,  1.6552e-01,
         -1.5505e-01,  1.7571e-01, -8.2927e-03, -2.2430e-01, -6.4806e-02,
          2.2096e-01, -8.7336e-02, -4.3299e-02, -1.0001e-01, -1.3593e-01,
          4.3312e-02],
        [ 1.5166e-01,  2.9561e-02, -1.5419e-02,  1.4462e-02, -1.8747e-01,
         -1.3172e-01,  1.2510e-02, -1.9982e-01,  1.2383e-01,  3.8105e-02,
          2.6324e-03, -1.6043e-02,  2.1115e-01,  2.2816e-01,  1.2207e-01,
          1.2417e-01],
        [-1.2122e-01,  1.0220e-01, -1.6909e-01,  1.0804e-01, -1.7752e-01,
         -1.3674e-03,  1.8120e-01,  1.6601e-01,  2.2105e-01,  8.5281e-02,
          9.7044e-02,  6.7042e-02,  1.8255e-01,  1.3119e-01,  7.3767e-02,
         -8.7229e-02],
        [-1.2099e-01, -6.1809e-02,  1.1931e-01, -1.3609e-01,  6.8302e-02,
          2.1873e-01,  2.1169e-01, -1.8406e-01,  7.1259e-02,  1.6347e-01,
         -2.2708e-01,  1.5978e-01, -1.5577e-01, -1.8076e-01, -1.0597e-01,
         -9.4034e-02],
        [-1.0336e-01,  7.1975e-02,  9.6850e-02,  9.7162e-02,  1.7261e-01,
         -1.5818e-01, -2.3738e-01, -2.0056e-01, -1.3741e-01, -1.1435e-01,
          1.0985e-01, -1.8092e-01, -1.8279e-01,  1.3388e-01, -1.5907e-01,
          4.6891e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1906,  0.0954,  0.1562, -0.2103,  0.0850, -0.1311,  0.1587,  0.2249,
        -0.2109,  0.0935,  0.1688,  0.2273,  0.1888,  0.0492,  0.0146,  0.0515,
        -0.1490, -0.0490, -0.0039, -0.1582, -0.0111, -0.0332, -0.0875, -0.0768,
        -0.2490,  0.2382,  0.1232,  0.1807, -0.2128, -0.2448,  0.1859, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0276,  0.0886,  0.0113, -0.0059,  0.1050,  0.1412, -0.0493, -0.1509,
         -0.0969,  0.1263,  0.0154,  0.1514, -0.0618, -0.1675,  0.0549, -0.0753,
         -0.1057,  0.1102,  0.0123, -0.0151,  0.1722,  0.1540, -0.1444, -0.1625,
         -0.0874, -0.1373, -0.0929,  0.1193, -0.1176,  0.1621,  0.0552,  0.0077]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0274,  0.0338,  0.0515,  ...,  0.0370, -0.1580, -0.1137],
        [-0.0412, -0.1228,  0.0849,  ..., -0.0255, -0.1542,  0.0871],
        [-0.0916,  0.0727,  0.1131,  ...,  0.1516,  0.0694,  0.0345],
        ...,
        [ 0.0835, -0.0818,  0.0083,  ..., -0.1147, -0.0697, -0.1180],
        [ 0.0086, -0.1214, -0.0074,  ..., -0.1376, -0.0348,  0.1557],
        [-0.1369,  0.0661,  0.0410,  ..., -0.0287, -0.1442, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0587,  0.0692, -0.1074, -0.1128, -0.0456,  0.0102, -0.1318,  0.0737,
        -0.0301,  0.0931,  0.0477, -0.0256, -0.0145,  0.0492, -0.0832, -0.0415,
         0.0733, -0.1429, -0.0319,  0.0333, -0.0826,  0.0758,  0.0793, -0.0232,
        -0.0515,  0.0775,  0.0090, -0.1238,  0.0923,  0.1576,  0.1370, -0.0883],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1641, -0.0737, -0.1340,  ..., -0.0192, -0.1329,  0.1699],
        [-0.0956,  0.0925,  0.0408,  ...,  0.0663, -0.1323,  0.1671],
        [ 0.0220, -0.1643, -0.1021,  ..., -0.0583,  0.1139,  0.0584],
        ...,
        [ 0.0230, -0.0144,  0.1370,  ...,  0.1392, -0.1018,  0.1490],
        [ 0.0984, -0.0202, -0.0055,  ...,  0.1521,  0.1041, -0.0493],
        [ 0.1011, -0.0131,  0.1673,  ...,  0.1591,  0.0347,  0.0616]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0691,  0.1030,  0.0027, -0.0455, -0.0609, -0.1135, -0.0068, -0.0992,
         0.1055, -0.1266,  0.1537, -0.1561,  0.1472,  0.0200, -0.1666,  0.0530,
        -0.1138, -0.1400,  0.0093, -0.0503,  0.0436,  0.1398, -0.1621,  0.1758,
        -0.0980, -0.0349,  0.1146, -0.0738, -0.0891, -0.0414,  0.0691, -0.0077],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1610,  0.0763, -0.1613, -0.1273,  0.0139, -0.0068, -0.0537,  0.0581,
          0.0742, -0.1026, -0.0353,  0.0633,  0.0641, -0.0159,  0.0889,  0.0632,
         -0.1659, -0.1689,  0.0059,  0.0605, -0.1260, -0.0910, -0.1689,  0.0335,
          0.1281,  0.1566, -0.1439,  0.1365, -0.0708, -0.1557,  0.1134,  0.1485]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0091], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5810e-01,  3.2222e-01,  5.1338e-02, -8.0751e-02,  6.0026e-02,
          1.0471e-01,  2.3054e-01, -1.1197e-01,  1.1021e-01,  1.9137e-01,
          1.0580e-01, -8.0379e-02, -2.2323e-01, -3.0886e-01,  1.9425e-01,
          1.2407e-01],
        [-1.8454e-01, -1.3238e-01, -3.9662e-02, -7.6975e-02, -1.0760e-01,
          1.8191e-01,  8.5168e-02,  8.5265e-02,  3.2404e-01,  6.4237e-02,
          1.0665e-01, -1.8834e-01,  8.2363e-02,  8.0350e-03,  2.7806e-01,
         -1.8633e-02],
        [ 1.0216e-02,  2.3827e-02,  3.1615e-01, -5.4984e-02,  1.7241e-02,
         -2.7532e-01,  3.7001e-02, -3.3692e-01,  1.2288e-01, -2.1007e-03,
          9.1470e-03, -1.3752e-01,  3.2414e-01,  2.6315e-01,  1.3711e-01,
          1.9668e-01],
        [ 2.0430e-01, -1.6729e-01,  2.0856e-02, -5.5629e-03,  2.2755e-02,
         -1.3323e-01, -7.6594e-02, -2.4852e-02, -3.4615e-01, -3.3575e-01,
          1.9207e-02,  2.9251e-01,  2.3613e-01, -1.6299e-01, -1.4292e-01,
          9.3201e-02],
        [-2.3543e-02,  2.9220e-01, -1.0346e-01, -1.0044e-01,  6.6791e-02,
          1.4859e-02, -4.7495e-02,  2.3918e-01,  6.1942e-02,  2.2316e-01,
          1.4377e-01, -8.4018e-02,  3.6458e-02, -1.8309e-01,  1.8975e-01,
         -9.1037e-02],
        [ 5.9840e-02,  3.3096e-01, -2.9848e-01,  3.3284e-01,  2.4822e-01,
         -8.9963e-02,  1.7965e-01, -1.0180e-01,  1.8036e-01,  1.4504e-01,
         -2.4104e-01, -1.7769e-02, -1.7076e-01,  1.8170e-01,  3.0201e-01,
         -1.6368e-02],
        [ 3.1024e-01, -9.4790e-03,  3.5205e-01, -1.2112e-01,  7.6157e-03,
         -1.5760e-01, -1.1375e-01, -1.8165e-01, -1.9744e-01,  3.8555e-02,
          4.9999e-02,  2.3981e-03, -1.1134e-01,  1.8633e-01, -2.5773e-01,
          9.9195e-02],
        [-1.1162e-01,  1.1933e-01,  3.1041e-01, -2.9681e-01, -2.8122e-01,
         -2.5500e-01, -3.2957e-02, -2.2314e-01, -1.5128e-01, -1.6323e-01,
          2.6958e-04, -1.3455e-02,  2.1490e-01, -1.1944e-01, -5.8669e-02,
          3.0959e-01],
        [-3.2866e-02,  1.0599e-01,  2.3928e-01, -1.7562e-01,  3.5888e-02,
         -2.8013e-01, -8.4488e-02, -2.8658e-02,  1.2054e-01, -2.4504e-01,
         -9.8847e-02, -1.6770e-02, -1.4316e-01,  1.1580e-01, -2.5745e-01,
          3.3907e-02],
        [-2.1904e-01,  1.0449e-01, -3.5245e-02, -8.5019e-02, -1.9166e-02,
          8.8175e-02, -3.7224e-02,  1.6032e-01,  1.8988e-01, -7.0956e-02,
          1.4541e-01,  6.7846e-02, -1.8173e-01, -3.0118e-02,  8.5126e-02,
         -1.3822e-01],
        [-2.8607e-01,  2.9225e-01,  5.5396e-04, -1.0216e-01, -1.2741e-01,
          3.6045e-01,  1.5345e-01,  4.8974e-02,  2.7875e-01,  1.8954e-01,
          2.5032e-03,  7.9204e-02, -1.2183e-01,  1.5924e-01, -8.8663e-02,
         -2.7037e-01],
        [-6.6503e-02,  5.4610e-02,  3.0640e-02,  2.6896e-02,  9.1156e-02,
          6.4199e-02,  2.9385e-01,  8.5938e-02,  9.7030e-02,  2.8988e-01,
          1.6319e-01,  1.2732e-01, -3.5227e-01, -2.0865e-01,  4.9198e-03,
         -1.5737e-01],
        [ 2.4301e-01,  3.3505e-02,  8.3516e-02, -8.6238e-02,  2.4764e-03,
          1.0968e-01,  2.4045e-02, -2.1965e-01, -2.2694e-01, -2.5175e-02,
          1.0793e-02, -5.8156e-02, -1.4390e-01,  1.0336e-01, -1.3866e-01,
         -5.0602e-02],
        [ 1.5291e-01,  1.5192e-01,  3.1711e-01,  4.8142e-02, -2.4094e-01,
          3.1461e-02,  2.3653e-02, -1.5243e-02, -1.5827e-01, -1.0907e-01,
         -1.0630e-01,  5.1279e-02,  6.1186e-02,  2.9297e-02, -2.9883e-01,
          1.9108e-01],
        [-3.1669e-01, -9.0835e-02, -1.4441e-02, -1.0372e-01,  2.9907e-01,
          3.5484e-01,  3.1647e-02,  6.3585e-02, -8.9705e-02,  1.2469e-01,
          1.4652e-02, -2.5007e-01, -2.8156e-02, -8.0191e-02, -1.5843e-02,
         -1.1099e-01],
        [-1.4201e-01, -2.6203e-01,  1.3658e-01,  1.5143e-01, -1.9681e-01,
          5.5609e-02, -7.8356e-02, -2.0421e-01, -9.2538e-02,  1.8140e-02,
          3.3014e-02,  3.2496e-01,  5.3311e-02, -1.0531e-01,  1.8252e-01,
          2.3163e-02],
        [ 2.6289e-01,  7.3464e-02,  1.5079e-01, -2.9619e-01, -2.9623e-01,
          6.4554e-03, -4.2071e-02,  4.6921e-02, -3.1481e-01, -1.3847e-01,
          2.5802e-01,  2.3863e-01,  3.1020e-01,  2.6029e-01, -1.1325e-01,
         -6.9981e-02],
        [-2.4932e-01,  1.7557e-01, -2.0077e-01,  8.6447e-02,  9.0664e-02,
          2.6221e-01,  2.3828e-01,  2.3869e-01,  9.9440e-02,  2.3793e-01,
         -1.2286e-01, -2.0460e-01, -1.4057e-01, -2.0417e-01,  2.6614e-01,
         -1.3408e-01],
        [ 1.6267e-01, -8.7807e-02,  8.9614e-02, -2.2979e-01, -1.1406e-01,
         -3.1642e-01, -2.0785e-01,  1.0027e-01, -3.2512e-01, -5.7281e-02,
          8.0621e-02, -1.4935e-01,  1.3962e-01,  2.1871e-01,  8.6434e-02,
          1.3565e-01],
        [ 3.1107e-01, -8.8564e-02,  2.1469e-01, -2.8039e-02, -2.4196e-01,
         -1.7608e-01, -2.8774e-01,  8.9261e-02,  1.8132e-02, -2.1725e-01,
          2.6566e-02,  1.8373e-01, -1.0922e-01,  7.8101e-02,  5.9014e-02,
          1.4612e-01],
        [-1.2525e-01,  2.5350e-01,  4.5544e-03, -1.3278e-01,  2.0533e-01,
         -8.7538e-02,  2.4356e-01,  3.0854e-01,  1.1798e-01,  1.6842e-02,
         -1.8481e-01, -2.1866e-01, -1.4697e-01, -1.6953e-01,  3.0706e-01,
         -2.0616e-01],
        [ 7.6444e-03, -1.5113e-01,  2.6951e-02,  2.9900e-01, -1.3289e-01,
          3.7353e-02,  1.5532e-01, -1.4711e-01, -6.9288e-02,  1.8255e-01,
          2.3886e-01, -1.7456e-01, -9.6809e-02, -2.9832e-01, -2.0147e-01,
          1.2642e-01],
        [ 3.1342e-01, -1.6402e-01,  5.4739e-03, -1.0500e-01,  6.6792e-02,
         -3.4955e-01, -2.3911e-01, -1.7847e-01, -1.9927e-01, -1.0612e-01,
          2.2900e-01,  1.5931e-01, -1.2777e-01,  2.9207e-01,  1.5261e-01,
          1.7655e-01],
        [ 2.1788e-01,  1.0623e-02,  3.0163e-01, -3.2019e-01, -1.9956e-01,
         -1.3773e-01, -1.4223e-01, -2.5653e-01, -3.2304e-01, -2.8460e-01,
          3.5503e-02,  3.1377e-01,  2.6187e-01,  1.2823e-01, -2.0224e-01,
         -9.6840e-03],
        [ 1.3274e-01, -3.2462e-01,  1.0070e-01, -4.5723e-02,  1.7146e-01,
         -1.7971e-01,  1.3799e-01, -8.4065e-02, -2.7084e-01,  1.2988e-01,
          2.6665e-01, -8.6347e-02, -4.0362e-02,  1.8676e-01, -2.0694e-01,
          2.7551e-01],
        [-1.5085e-02, -1.6886e-01,  3.6054e-02,  1.4369e-01, -1.4548e-01,
         -1.5708e-01,  4.4302e-02, -2.6976e-01, -1.0451e-01, -2.9774e-01,
         -2.1022e-01,  5.0232e-02,  1.2736e-01,  2.8128e-01, -3.0104e-01,
          2.9294e-02],
        [ 1.6910e-01,  4.9499e-03,  2.5240e-01, -2.9129e-01, -1.0919e-01,
         -5.2092e-02, -3.0167e-01,  2.8832e-02, -3.2903e-01,  5.5321e-02,
          9.7315e-02,  3.4930e-02,  1.8342e-01,  2.7273e-01,  1.3799e-01,
          2.5160e-01],
        [-2.5601e-01,  1.6364e-01,  7.4245e-02,  1.4046e-01,  2.1804e-01,
         -3.8766e-02,  2.8441e-01,  9.5962e-02, -1.2764e-01,  4.3201e-02,
          1.5386e-01, -1.9989e-01, -1.5265e-01, -1.6750e-01, -8.0604e-02,
         -6.3475e-02],
        [ 2.5433e-01, -4.5782e-02,  9.0727e-02, -7.5854e-02, -2.4124e-01,
         -2.4338e-01, -9.1010e-02, -2.9460e-01,  3.1634e-02, -6.4955e-02,
          9.0995e-02,  9.1570e-02,  3.0709e-01,  2.9476e-01,  5.4933e-02,
          2.2481e-01],
        [-2.2199e-01,  1.8917e-01, -2.7267e-01,  1.9588e-01, -1.3137e-01,
          1.0460e-01,  2.7967e-01,  2.6115e-01,  3.0892e-01,  1.8218e-01,
          1.0951e-01, -3.6124e-02,  8.3326e-02,  7.3950e-02,  1.1126e-01,
         -1.8399e-01],
        [-2.2854e-01,  3.1831e-02,  8.6400e-03, -4.1053e-02,  1.2527e-01,
          3.3250e-01,  3.1815e-01, -8.3788e-02,  1.6763e-01,  2.6884e-01,
         -2.8687e-01,  4.8987e-02, -2.5912e-01, -2.4844e-01, -4.6566e-02,
         -1.9926e-01],
        [-2.4407e-03, -2.0177e-02,  2.0146e-01,  1.2193e-03,  8.8941e-02,
         -2.6585e-01, -3.3422e-01, -2.9930e-01, -2.3220e-01, -2.1799e-01,
          1.3538e-01, -7.9110e-02, -8.0624e-02,  2.2796e-01, -2.3946e-01,
          1.4720e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1540,  0.0110,  0.0768, -0.0898,  0.0286, -0.1138,  0.0999,  0.1463,
        -0.1223,  0.0248,  0.0656,  0.1300,  0.2108,  0.0733,  0.0516,  0.0342,
        -0.1078, -0.0274,  0.0284, -0.0395, -0.0521,  0.0066, -0.0666,  0.0109,
        -0.1777,  0.2031,  0.0983,  0.0974, -0.1036, -0.2136,  0.1060, -0.0338],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0790,  0.1638, -0.1021, -0.1233,  0.1595,  0.2167, -0.1654, -0.2671,
         -0.1498,  0.2035,  0.1273,  0.2516, -0.0687, -0.2611,  0.1662, -0.0805,
         -0.1848,  0.2227, -0.0999, -0.1306,  0.2718,  0.1195, -0.2561, -0.2739,
         -0.1860, -0.1969, -0.2038,  0.2051, -0.2339,  0.2725,  0.1707, -0.1122]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0095,  0.0653,  0.0879,  ...,  0.0112, -0.1698, -0.1137],
        [-0.1075, -0.0712,  0.1196,  ..., -0.0194, -0.2282,  0.0871],
        [-0.0427,  0.0354,  0.0872,  ...,  0.1369,  0.1286,  0.0345],
        ...,
        [ 0.1035, -0.1123, -0.0123,  ..., -0.0910, -0.0725, -0.1180],
        [ 0.0746, -0.1720, -0.0426,  ..., -0.1452,  0.0377,  0.1557],
        [-0.1736,  0.1104,  0.0604,  ..., -0.0566, -0.1531, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0306,  0.0366, -0.0928, -0.1453, -0.0785,  0.0518, -0.0950,  0.0500,
        -0.0086,  0.0633,  0.0212,  0.0096, -0.0433,  0.0641, -0.0462, -0.0128,
         0.0441, -0.1764, -0.0631,  0.0634, -0.0463,  0.0496,  0.1177,  0.0049,
        -0.0754,  0.1118,  0.0488, -0.0922,  0.0303,  0.1876,  0.1678, -0.1281],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1287, -0.1131, -0.1479,  ...,  0.0179, -0.1109,  0.1127],
        [-0.1340,  0.0480,  0.0273,  ...,  0.1060, -0.1047,  0.1061],
        [ 0.0578, -0.1218, -0.0909,  ..., -0.0956,  0.0887,  0.1175],
        ...,
        [ 0.0609,  0.0247,  0.1541,  ...,  0.0988, -0.1229,  0.2070],
        [ 0.0611, -0.0633, -0.0170,  ...,  0.1906,  0.1298, -0.1097],
        [ 0.0640, -0.0528,  0.1517,  ...,  0.1982,  0.0561,  0.0034]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0963,  0.1334, -0.0247, -0.0752, -0.0387, -0.0632, -0.0369, -0.0827,
         0.1326, -0.1513,  0.1268, -0.1248,  0.1766,  0.0793, -0.1390,  0.0853,
        -0.1388, -0.1684,  0.0426, -0.0219,  0.0144,  0.1113, -0.1913,  0.2056,
        -0.0674, -0.0110,  0.0866, -0.0448, -0.1199, -0.0716,  0.0979,  0.0211],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2059,  0.1243, -0.1737, -0.1538,  0.0170,  0.0225, -0.0849,  0.0117,
          0.1162, -0.1469, -0.0539,  0.0790,  0.0811,  0.0730,  0.1151,  0.0941,
         -0.2058, -0.2092,  0.0478,  0.0422, -0.1128, -0.0955, -0.1895,  0.0687,
          0.1327,  0.2138, -0.1806,  0.1456, -0.0916, -0.1952,  0.1505,  0.1879]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0205], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5810e-01,  3.2222e-01,  5.1338e-02, -8.0751e-02,  6.0026e-02,
          1.0471e-01,  2.3054e-01, -1.1197e-01,  1.1021e-01,  1.9137e-01,
          1.0580e-01, -8.0379e-02, -2.2323e-01, -3.0886e-01,  1.9425e-01,
          1.2407e-01],
        [-1.8454e-01, -1.3238e-01, -3.9662e-02, -7.6975e-02, -1.0760e-01,
          1.8191e-01,  8.5168e-02,  8.5265e-02,  3.2404e-01,  6.4237e-02,
          1.0665e-01, -1.8834e-01,  8.2363e-02,  8.0350e-03,  2.7806e-01,
         -1.8633e-02],
        [ 1.0216e-02,  2.3827e-02,  3.1615e-01, -5.4984e-02,  1.7241e-02,
         -2.7532e-01,  3.7001e-02, -3.3692e-01,  1.2288e-01, -2.1007e-03,
          9.1470e-03, -1.3752e-01,  3.2414e-01,  2.6315e-01,  1.3711e-01,
          1.9668e-01],
        [ 2.0430e-01, -1.6729e-01,  2.0856e-02, -5.5629e-03,  2.2755e-02,
         -1.3323e-01, -7.6594e-02, -2.4852e-02, -3.4615e-01, -3.3575e-01,
          1.9207e-02,  2.9251e-01,  2.3613e-01, -1.6299e-01, -1.4292e-01,
          9.3201e-02],
        [-2.3543e-02,  2.9220e-01, -1.0346e-01, -1.0044e-01,  6.6791e-02,
          1.4859e-02, -4.7495e-02,  2.3918e-01,  6.1942e-02,  2.2316e-01,
          1.4377e-01, -8.4018e-02,  3.6458e-02, -1.8309e-01,  1.8975e-01,
         -9.1037e-02],
        [ 5.9840e-02,  3.3096e-01, -2.9848e-01,  3.3284e-01,  2.4822e-01,
         -8.9963e-02,  1.7965e-01, -1.0180e-01,  1.8036e-01,  1.4504e-01,
         -2.4104e-01, -1.7769e-02, -1.7076e-01,  1.8170e-01,  3.0201e-01,
         -1.6368e-02],
        [ 3.1024e-01, -9.4790e-03,  3.5205e-01, -1.2112e-01,  7.6157e-03,
         -1.5760e-01, -1.1375e-01, -1.8165e-01, -1.9744e-01,  3.8555e-02,
          4.9999e-02,  2.3981e-03, -1.1134e-01,  1.8633e-01, -2.5773e-01,
          9.9195e-02],
        [-1.1162e-01,  1.1933e-01,  3.1041e-01, -2.9681e-01, -2.8122e-01,
         -2.5500e-01, -3.2957e-02, -2.2314e-01, -1.5128e-01, -1.6323e-01,
          2.6958e-04, -1.3455e-02,  2.1490e-01, -1.1944e-01, -5.8669e-02,
          3.0959e-01],
        [-3.2866e-02,  1.0599e-01,  2.3928e-01, -1.7562e-01,  3.5888e-02,
         -2.8013e-01, -8.4488e-02, -2.8658e-02,  1.2054e-01, -2.4504e-01,
         -9.8847e-02, -1.6770e-02, -1.4316e-01,  1.1580e-01, -2.5745e-01,
          3.3907e-02],
        [-2.1904e-01,  1.0449e-01, -3.5245e-02, -8.5019e-02, -1.9166e-02,
          8.8175e-02, -3.7224e-02,  1.6032e-01,  1.8988e-01, -7.0956e-02,
          1.4541e-01,  6.7846e-02, -1.8173e-01, -3.0118e-02,  8.5126e-02,
         -1.3822e-01],
        [-2.8607e-01,  2.9225e-01,  5.5396e-04, -1.0216e-01, -1.2741e-01,
          3.6045e-01,  1.5345e-01,  4.8974e-02,  2.7875e-01,  1.8954e-01,
          2.5032e-03,  7.9204e-02, -1.2183e-01,  1.5924e-01, -8.8663e-02,
         -2.7037e-01],
        [-6.6503e-02,  5.4610e-02,  3.0640e-02,  2.6896e-02,  9.1156e-02,
          6.4199e-02,  2.9385e-01,  8.5938e-02,  9.7030e-02,  2.8988e-01,
          1.6319e-01,  1.2732e-01, -3.5227e-01, -2.0865e-01,  4.9198e-03,
         -1.5737e-01],
        [ 2.4301e-01,  3.3505e-02,  8.3516e-02, -8.6238e-02,  2.4764e-03,
          1.0968e-01,  2.4045e-02, -2.1965e-01, -2.2694e-01, -2.5175e-02,
          1.0793e-02, -5.8156e-02, -1.4390e-01,  1.0336e-01, -1.3866e-01,
         -5.0602e-02],
        [ 1.5291e-01,  1.5192e-01,  3.1711e-01,  4.8142e-02, -2.4094e-01,
          3.1461e-02,  2.3653e-02, -1.5243e-02, -1.5827e-01, -1.0907e-01,
         -1.0630e-01,  5.1279e-02,  6.1186e-02,  2.9297e-02, -2.9883e-01,
          1.9108e-01],
        [-3.1669e-01, -9.0835e-02, -1.4441e-02, -1.0372e-01,  2.9907e-01,
          3.5484e-01,  3.1647e-02,  6.3585e-02, -8.9705e-02,  1.2469e-01,
          1.4652e-02, -2.5007e-01, -2.8156e-02, -8.0191e-02, -1.5843e-02,
         -1.1099e-01],
        [-1.4201e-01, -2.6203e-01,  1.3658e-01,  1.5143e-01, -1.9681e-01,
          5.5609e-02, -7.8356e-02, -2.0421e-01, -9.2538e-02,  1.8140e-02,
          3.3014e-02,  3.2496e-01,  5.3311e-02, -1.0531e-01,  1.8252e-01,
          2.3163e-02],
        [ 2.6289e-01,  7.3464e-02,  1.5079e-01, -2.9619e-01, -2.9623e-01,
          6.4554e-03, -4.2071e-02,  4.6921e-02, -3.1481e-01, -1.3847e-01,
          2.5802e-01,  2.3863e-01,  3.1020e-01,  2.6029e-01, -1.1325e-01,
         -6.9981e-02],
        [-2.4932e-01,  1.7557e-01, -2.0077e-01,  8.6447e-02,  9.0664e-02,
          2.6221e-01,  2.3828e-01,  2.3869e-01,  9.9440e-02,  2.3793e-01,
         -1.2286e-01, -2.0460e-01, -1.4057e-01, -2.0417e-01,  2.6614e-01,
         -1.3408e-01],
        [ 1.6267e-01, -8.7807e-02,  8.9614e-02, -2.2979e-01, -1.1406e-01,
         -3.1642e-01, -2.0785e-01,  1.0027e-01, -3.2512e-01, -5.7281e-02,
          8.0621e-02, -1.4935e-01,  1.3962e-01,  2.1871e-01,  8.6434e-02,
          1.3565e-01],
        [ 3.1107e-01, -8.8564e-02,  2.1469e-01, -2.8039e-02, -2.4196e-01,
         -1.7608e-01, -2.8774e-01,  8.9261e-02,  1.8132e-02, -2.1725e-01,
          2.6566e-02,  1.8373e-01, -1.0922e-01,  7.8101e-02,  5.9014e-02,
          1.4612e-01],
        [-1.2525e-01,  2.5350e-01,  4.5544e-03, -1.3278e-01,  2.0533e-01,
         -8.7538e-02,  2.4356e-01,  3.0854e-01,  1.1798e-01,  1.6842e-02,
         -1.8481e-01, -2.1866e-01, -1.4697e-01, -1.6953e-01,  3.0706e-01,
         -2.0616e-01],
        [ 7.6444e-03, -1.5113e-01,  2.6951e-02,  2.9900e-01, -1.3289e-01,
          3.7353e-02,  1.5532e-01, -1.4711e-01, -6.9288e-02,  1.8255e-01,
          2.3886e-01, -1.7456e-01, -9.6809e-02, -2.9832e-01, -2.0147e-01,
          1.2642e-01],
        [ 3.1342e-01, -1.6402e-01,  5.4739e-03, -1.0500e-01,  6.6792e-02,
         -3.4955e-01, -2.3911e-01, -1.7847e-01, -1.9927e-01, -1.0612e-01,
          2.2900e-01,  1.5931e-01, -1.2777e-01,  2.9207e-01,  1.5261e-01,
          1.7655e-01],
        [ 2.1788e-01,  1.0623e-02,  3.0163e-01, -3.2019e-01, -1.9956e-01,
         -1.3773e-01, -1.4223e-01, -2.5653e-01, -3.2304e-01, -2.8460e-01,
          3.5503e-02,  3.1377e-01,  2.6187e-01,  1.2823e-01, -2.0224e-01,
         -9.6840e-03],
        [ 1.3274e-01, -3.2462e-01,  1.0070e-01, -4.5723e-02,  1.7146e-01,
         -1.7971e-01,  1.3799e-01, -8.4065e-02, -2.7084e-01,  1.2988e-01,
          2.6665e-01, -8.6347e-02, -4.0362e-02,  1.8676e-01, -2.0694e-01,
          2.7551e-01],
        [-1.5085e-02, -1.6886e-01,  3.6054e-02,  1.4369e-01, -1.4548e-01,
         -1.5708e-01,  4.4302e-02, -2.6976e-01, -1.0451e-01, -2.9774e-01,
         -2.1022e-01,  5.0232e-02,  1.2736e-01,  2.8128e-01, -3.0104e-01,
          2.9294e-02],
        [ 1.6910e-01,  4.9499e-03,  2.5240e-01, -2.9129e-01, -1.0919e-01,
         -5.2092e-02, -3.0167e-01,  2.8832e-02, -3.2903e-01,  5.5321e-02,
          9.7315e-02,  3.4930e-02,  1.8342e-01,  2.7273e-01,  1.3799e-01,
          2.5160e-01],
        [-2.5601e-01,  1.6364e-01,  7.4245e-02,  1.4046e-01,  2.1804e-01,
         -3.8766e-02,  2.8441e-01,  9.5962e-02, -1.2764e-01,  4.3201e-02,
          1.5386e-01, -1.9989e-01, -1.5265e-01, -1.6750e-01, -8.0604e-02,
         -6.3475e-02],
        [ 2.5433e-01, -4.5782e-02,  9.0727e-02, -7.5854e-02, -2.4124e-01,
         -2.4338e-01, -9.1010e-02, -2.9460e-01,  3.1634e-02, -6.4955e-02,
          9.0995e-02,  9.1570e-02,  3.0709e-01,  2.9476e-01,  5.4933e-02,
          2.2481e-01],
        [-2.2199e-01,  1.8917e-01, -2.7267e-01,  1.9588e-01, -1.3137e-01,
          1.0460e-01,  2.7967e-01,  2.6115e-01,  3.0892e-01,  1.8218e-01,
          1.0951e-01, -3.6124e-02,  8.3326e-02,  7.3950e-02,  1.1126e-01,
         -1.8399e-01],
        [-2.2854e-01,  3.1831e-02,  8.6400e-03, -4.1053e-02,  1.2527e-01,
          3.3250e-01,  3.1815e-01, -8.3788e-02,  1.6763e-01,  2.6884e-01,
         -2.8687e-01,  4.8987e-02, -2.5912e-01, -2.4844e-01, -4.6566e-02,
         -1.9926e-01],
        [-2.4407e-03, -2.0177e-02,  2.0146e-01,  1.2193e-03,  8.8941e-02,
         -2.6585e-01, -3.3422e-01, -2.9930e-01, -2.3220e-01, -2.1799e-01,
          1.3538e-01, -7.9110e-02, -8.0624e-02,  2.2796e-01, -2.3946e-01,
          1.4720e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1540,  0.0110,  0.0768, -0.0898,  0.0286, -0.1138,  0.0999,  0.1463,
        -0.1223,  0.0248,  0.0656,  0.1300,  0.2108,  0.0733,  0.0516,  0.0342,
        -0.1078, -0.0274,  0.0284, -0.0395, -0.0521,  0.0066, -0.0666,  0.0109,
        -0.1777,  0.2031,  0.0983,  0.0974, -0.1036, -0.2136,  0.1060, -0.0338],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0790,  0.1638, -0.1021, -0.1233,  0.1595,  0.2167, -0.1654, -0.2671,
         -0.1498,  0.2035,  0.1273,  0.2516, -0.0687, -0.2611,  0.1662, -0.0805,
         -0.1848,  0.2227, -0.0999, -0.1306,  0.2718,  0.1195, -0.2561, -0.2739,
         -0.1860, -0.1969, -0.2038,  0.2051, -0.2339,  0.2725,  0.1707, -0.1122]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0095,  0.0653,  0.0879,  ...,  0.0112, -0.1698, -0.1137],
        [-0.1075, -0.0712,  0.1196,  ..., -0.0194, -0.2282,  0.0871],
        [-0.0427,  0.0354,  0.0872,  ...,  0.1369,  0.1286,  0.0345],
        ...,
        [ 0.1035, -0.1123, -0.0123,  ..., -0.0910, -0.0725, -0.1180],
        [ 0.0746, -0.1720, -0.0426,  ..., -0.1452,  0.0377,  0.1557],
        [-0.1736,  0.1104,  0.0604,  ..., -0.0566, -0.1531, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0306,  0.0366, -0.0928, -0.1453, -0.0785,  0.0518, -0.0950,  0.0500,
        -0.0086,  0.0633,  0.0212,  0.0096, -0.0433,  0.0641, -0.0462, -0.0128,
         0.0441, -0.1764, -0.0631,  0.0634, -0.0463,  0.0496,  0.1177,  0.0049,
        -0.0754,  0.1118,  0.0488, -0.0922,  0.0303,  0.1876,  0.1678, -0.1281],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1287, -0.1131, -0.1479,  ...,  0.0179, -0.1109,  0.1127],
        [-0.1340,  0.0480,  0.0273,  ...,  0.1060, -0.1047,  0.1061],
        [ 0.0578, -0.1218, -0.0909,  ..., -0.0956,  0.0887,  0.1175],
        ...,
        [ 0.0609,  0.0247,  0.1541,  ...,  0.0988, -0.1229,  0.2070],
        [ 0.0611, -0.0633, -0.0170,  ...,  0.1906,  0.1298, -0.1097],
        [ 0.0640, -0.0528,  0.1517,  ...,  0.1982,  0.0561,  0.0034]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0963,  0.1334, -0.0247, -0.0752, -0.0387, -0.0632, -0.0369, -0.0827,
         0.1326, -0.1513,  0.1268, -0.1248,  0.1766,  0.0793, -0.1390,  0.0853,
        -0.1388, -0.1684,  0.0426, -0.0219,  0.0144,  0.1113, -0.1913,  0.2056,
        -0.0674, -0.0110,  0.0866, -0.0448, -0.1199, -0.0716,  0.0979,  0.0211],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2059,  0.1243, -0.1737, -0.1538,  0.0170,  0.0225, -0.0849,  0.0117,
          0.1162, -0.1469, -0.0539,  0.0790,  0.0811,  0.0730,  0.1151,  0.0941,
         -0.2058, -0.2092,  0.0478,  0.0422, -0.1128, -0.0955, -0.1895,  0.0687,
          0.1327,  0.2138, -0.1806,  0.1456, -0.0916, -0.1952,  0.1505,  0.1879]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0205], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5810e-01,  3.2222e-01,  5.1338e-02, -8.0751e-02,  6.0026e-02,
          1.0471e-01,  2.3054e-01, -1.1197e-01,  1.1021e-01,  1.9137e-01,
          1.0580e-01, -8.0379e-02, -2.2323e-01, -3.0886e-01,  1.9425e-01,
          1.2407e-01],
        [-1.8454e-01, -1.3238e-01, -3.9662e-02, -7.6975e-02, -1.0760e-01,
          1.8191e-01,  8.5168e-02,  8.5265e-02,  3.2404e-01,  6.4237e-02,
          1.0665e-01, -1.8834e-01,  8.2363e-02,  8.0350e-03,  2.7806e-01,
         -1.8633e-02],
        [ 1.0216e-02,  2.3827e-02,  3.1615e-01, -5.4984e-02,  1.7241e-02,
         -2.7532e-01,  3.7001e-02, -3.3692e-01,  1.2288e-01, -2.1007e-03,
          9.1470e-03, -1.3752e-01,  3.2414e-01,  2.6315e-01,  1.3711e-01,
          1.9668e-01],
        [ 2.0430e-01, -1.6729e-01,  2.0856e-02, -5.5629e-03,  2.2755e-02,
         -1.3323e-01, -7.6594e-02, -2.4852e-02, -3.4615e-01, -3.3575e-01,
          1.9207e-02,  2.9251e-01,  2.3613e-01, -1.6299e-01, -1.4292e-01,
          9.3201e-02],
        [-2.3543e-02,  2.9220e-01, -1.0346e-01, -1.0044e-01,  6.6791e-02,
          1.4859e-02, -4.7495e-02,  2.3918e-01,  6.1942e-02,  2.2316e-01,
          1.4377e-01, -8.4018e-02,  3.6458e-02, -1.8309e-01,  1.8975e-01,
         -9.1037e-02],
        [ 5.9840e-02,  3.3096e-01, -2.9848e-01,  3.3284e-01,  2.4822e-01,
         -8.9963e-02,  1.7965e-01, -1.0180e-01,  1.8036e-01,  1.4504e-01,
         -2.4104e-01, -1.7769e-02, -1.7076e-01,  1.8170e-01,  3.0201e-01,
         -1.6368e-02],
        [ 3.1024e-01, -9.4790e-03,  3.5205e-01, -1.2112e-01,  7.6157e-03,
         -1.5760e-01, -1.1375e-01, -1.8165e-01, -1.9744e-01,  3.8555e-02,
          4.9999e-02,  2.3981e-03, -1.1134e-01,  1.8633e-01, -2.5773e-01,
          9.9195e-02],
        [-1.1162e-01,  1.1933e-01,  3.1041e-01, -2.9681e-01, -2.8122e-01,
         -2.5500e-01, -3.2957e-02, -2.2314e-01, -1.5128e-01, -1.6323e-01,
          2.6958e-04, -1.3455e-02,  2.1490e-01, -1.1944e-01, -5.8669e-02,
          3.0959e-01],
        [-3.2866e-02,  1.0599e-01,  2.3928e-01, -1.7562e-01,  3.5888e-02,
         -2.8013e-01, -8.4488e-02, -2.8658e-02,  1.2054e-01, -2.4504e-01,
         -9.8847e-02, -1.6770e-02, -1.4316e-01,  1.1580e-01, -2.5745e-01,
          3.3907e-02],
        [-2.1904e-01,  1.0449e-01, -3.5245e-02, -8.5019e-02, -1.9166e-02,
          8.8175e-02, -3.7224e-02,  1.6032e-01,  1.8988e-01, -7.0956e-02,
          1.4541e-01,  6.7846e-02, -1.8173e-01, -3.0118e-02,  8.5126e-02,
         -1.3822e-01],
        [-2.8607e-01,  2.9225e-01,  5.5396e-04, -1.0216e-01, -1.2741e-01,
          3.6045e-01,  1.5345e-01,  4.8974e-02,  2.7875e-01,  1.8954e-01,
          2.5032e-03,  7.9204e-02, -1.2183e-01,  1.5924e-01, -8.8663e-02,
         -2.7037e-01],
        [-6.6503e-02,  5.4610e-02,  3.0640e-02,  2.6896e-02,  9.1156e-02,
          6.4199e-02,  2.9385e-01,  8.5938e-02,  9.7030e-02,  2.8988e-01,
          1.6319e-01,  1.2732e-01, -3.5227e-01, -2.0865e-01,  4.9198e-03,
         -1.5737e-01],
        [ 2.4301e-01,  3.3505e-02,  8.3516e-02, -8.6238e-02,  2.4764e-03,
          1.0968e-01,  2.4045e-02, -2.1965e-01, -2.2694e-01, -2.5175e-02,
          1.0793e-02, -5.8156e-02, -1.4390e-01,  1.0336e-01, -1.3866e-01,
         -5.0602e-02],
        [ 1.5291e-01,  1.5192e-01,  3.1711e-01,  4.8142e-02, -2.4094e-01,
          3.1461e-02,  2.3653e-02, -1.5243e-02, -1.5827e-01, -1.0907e-01,
         -1.0630e-01,  5.1279e-02,  6.1186e-02,  2.9297e-02, -2.9883e-01,
          1.9108e-01],
        [-3.1669e-01, -9.0835e-02, -1.4441e-02, -1.0372e-01,  2.9907e-01,
          3.5484e-01,  3.1647e-02,  6.3585e-02, -8.9705e-02,  1.2469e-01,
          1.4652e-02, -2.5007e-01, -2.8156e-02, -8.0191e-02, -1.5843e-02,
         -1.1099e-01],
        [-1.4201e-01, -2.6203e-01,  1.3658e-01,  1.5143e-01, -1.9681e-01,
          5.5609e-02, -7.8356e-02, -2.0421e-01, -9.2538e-02,  1.8140e-02,
          3.3014e-02,  3.2496e-01,  5.3311e-02, -1.0531e-01,  1.8252e-01,
          2.3163e-02],
        [ 2.6289e-01,  7.3464e-02,  1.5079e-01, -2.9619e-01, -2.9623e-01,
          6.4554e-03, -4.2071e-02,  4.6921e-02, -3.1481e-01, -1.3847e-01,
          2.5802e-01,  2.3863e-01,  3.1020e-01,  2.6029e-01, -1.1325e-01,
         -6.9981e-02],
        [-2.4932e-01,  1.7557e-01, -2.0077e-01,  8.6447e-02,  9.0664e-02,
          2.6221e-01,  2.3828e-01,  2.3869e-01,  9.9440e-02,  2.3793e-01,
         -1.2286e-01, -2.0460e-01, -1.4057e-01, -2.0417e-01,  2.6614e-01,
         -1.3408e-01],
        [ 1.6267e-01, -8.7807e-02,  8.9614e-02, -2.2979e-01, -1.1406e-01,
         -3.1642e-01, -2.0785e-01,  1.0027e-01, -3.2512e-01, -5.7281e-02,
          8.0621e-02, -1.4935e-01,  1.3962e-01,  2.1871e-01,  8.6434e-02,
          1.3565e-01],
        [ 3.1107e-01, -8.8564e-02,  2.1469e-01, -2.8039e-02, -2.4196e-01,
         -1.7608e-01, -2.8774e-01,  8.9261e-02,  1.8132e-02, -2.1725e-01,
          2.6566e-02,  1.8373e-01, -1.0922e-01,  7.8101e-02,  5.9014e-02,
          1.4612e-01],
        [-1.2525e-01,  2.5350e-01,  4.5544e-03, -1.3278e-01,  2.0533e-01,
         -8.7538e-02,  2.4356e-01,  3.0854e-01,  1.1798e-01,  1.6842e-02,
         -1.8481e-01, -2.1866e-01, -1.4697e-01, -1.6953e-01,  3.0706e-01,
         -2.0616e-01],
        [ 7.6444e-03, -1.5113e-01,  2.6951e-02,  2.9900e-01, -1.3289e-01,
          3.7353e-02,  1.5532e-01, -1.4711e-01, -6.9288e-02,  1.8255e-01,
          2.3886e-01, -1.7456e-01, -9.6809e-02, -2.9832e-01, -2.0147e-01,
          1.2642e-01],
        [ 3.1342e-01, -1.6402e-01,  5.4739e-03, -1.0500e-01,  6.6792e-02,
         -3.4955e-01, -2.3911e-01, -1.7847e-01, -1.9927e-01, -1.0612e-01,
          2.2900e-01,  1.5931e-01, -1.2777e-01,  2.9207e-01,  1.5261e-01,
          1.7655e-01],
        [ 2.1788e-01,  1.0623e-02,  3.0163e-01, -3.2019e-01, -1.9956e-01,
         -1.3773e-01, -1.4223e-01, -2.5653e-01, -3.2304e-01, -2.8460e-01,
          3.5503e-02,  3.1377e-01,  2.6187e-01,  1.2823e-01, -2.0224e-01,
         -9.6840e-03],
        [ 1.3274e-01, -3.2462e-01,  1.0070e-01, -4.5723e-02,  1.7146e-01,
         -1.7971e-01,  1.3799e-01, -8.4065e-02, -2.7084e-01,  1.2988e-01,
          2.6665e-01, -8.6347e-02, -4.0362e-02,  1.8676e-01, -2.0694e-01,
          2.7551e-01],
        [-1.5085e-02, -1.6886e-01,  3.6054e-02,  1.4369e-01, -1.4548e-01,
         -1.5708e-01,  4.4302e-02, -2.6976e-01, -1.0451e-01, -2.9774e-01,
         -2.1022e-01,  5.0232e-02,  1.2736e-01,  2.8128e-01, -3.0104e-01,
          2.9294e-02],
        [ 1.6910e-01,  4.9499e-03,  2.5240e-01, -2.9129e-01, -1.0919e-01,
         -5.2092e-02, -3.0167e-01,  2.8832e-02, -3.2903e-01,  5.5321e-02,
          9.7315e-02,  3.4930e-02,  1.8342e-01,  2.7273e-01,  1.3799e-01,
          2.5160e-01],
        [-2.5601e-01,  1.6364e-01,  7.4245e-02,  1.4046e-01,  2.1804e-01,
         -3.8766e-02,  2.8441e-01,  9.5962e-02, -1.2764e-01,  4.3201e-02,
          1.5386e-01, -1.9989e-01, -1.5265e-01, -1.6750e-01, -8.0604e-02,
         -6.3475e-02],
        [ 2.5433e-01, -4.5782e-02,  9.0727e-02, -7.5854e-02, -2.4124e-01,
         -2.4338e-01, -9.1010e-02, -2.9460e-01,  3.1634e-02, -6.4955e-02,
          9.0995e-02,  9.1570e-02,  3.0709e-01,  2.9476e-01,  5.4933e-02,
          2.2481e-01],
        [-2.2199e-01,  1.8917e-01, -2.7267e-01,  1.9588e-01, -1.3137e-01,
          1.0460e-01,  2.7967e-01,  2.6115e-01,  3.0892e-01,  1.8218e-01,
          1.0951e-01, -3.6124e-02,  8.3326e-02,  7.3950e-02,  1.1126e-01,
         -1.8399e-01],
        [-2.2854e-01,  3.1831e-02,  8.6400e-03, -4.1053e-02,  1.2527e-01,
          3.3250e-01,  3.1815e-01, -8.3788e-02,  1.6763e-01,  2.6884e-01,
         -2.8687e-01,  4.8987e-02, -2.5912e-01, -2.4844e-01, -4.6566e-02,
         -1.9926e-01],
        [-2.4407e-03, -2.0177e-02,  2.0146e-01,  1.2193e-03,  8.8941e-02,
         -2.6585e-01, -3.3422e-01, -2.9930e-01, -2.3220e-01, -2.1799e-01,
          1.3538e-01, -7.9110e-02, -8.0624e-02,  2.2796e-01, -2.3946e-01,
          1.4720e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1540,  0.0110,  0.0768, -0.0898,  0.0286, -0.1138,  0.0999,  0.1463,
        -0.1223,  0.0248,  0.0656,  0.1300,  0.2108,  0.0733,  0.0516,  0.0342,
        -0.1078, -0.0274,  0.0284, -0.0395, -0.0521,  0.0066, -0.0666,  0.0109,
        -0.1777,  0.2031,  0.0983,  0.0974, -0.1036, -0.2136,  0.1060, -0.0338],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0790,  0.1638, -0.1021, -0.1233,  0.1595,  0.2167, -0.1654, -0.2671,
         -0.1498,  0.2035,  0.1273,  0.2516, -0.0687, -0.2611,  0.1662, -0.0805,
         -0.1848,  0.2227, -0.0999, -0.1306,  0.2718,  0.1195, -0.2561, -0.2739,
         -0.1860, -0.1969, -0.2038,  0.2051, -0.2339,  0.2725,  0.1707, -0.1122]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0095,  0.0653,  0.0879,  ...,  0.0112, -0.1698, -0.1137],
        [-0.1075, -0.0712,  0.1196,  ..., -0.0194, -0.2282,  0.0871],
        [-0.0427,  0.0354,  0.0872,  ...,  0.1369,  0.1286,  0.0345],
        ...,
        [ 0.1035, -0.1123, -0.0123,  ..., -0.0910, -0.0725, -0.1180],
        [ 0.0746, -0.1720, -0.0426,  ..., -0.1452,  0.0377,  0.1557],
        [-0.1736,  0.1104,  0.0604,  ..., -0.0566, -0.1531, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0306,  0.0366, -0.0928, -0.1453, -0.0785,  0.0518, -0.0950,  0.0500,
        -0.0086,  0.0633,  0.0212,  0.0096, -0.0433,  0.0641, -0.0462, -0.0128,
         0.0441, -0.1764, -0.0631,  0.0634, -0.0463,  0.0496,  0.1177,  0.0049,
        -0.0754,  0.1118,  0.0488, -0.0922,  0.0303,  0.1876,  0.1678, -0.1281],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1287, -0.1131, -0.1479,  ...,  0.0179, -0.1109,  0.1127],
        [-0.1340,  0.0480,  0.0273,  ...,  0.1060, -0.1047,  0.1061],
        [ 0.0578, -0.1218, -0.0909,  ..., -0.0956,  0.0887,  0.1175],
        ...,
        [ 0.0609,  0.0247,  0.1541,  ...,  0.0988, -0.1229,  0.2070],
        [ 0.0611, -0.0633, -0.0170,  ...,  0.1906,  0.1298, -0.1097],
        [ 0.0640, -0.0528,  0.1517,  ...,  0.1982,  0.0561,  0.0034]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0963,  0.1334, -0.0247, -0.0752, -0.0387, -0.0632, -0.0369, -0.0827,
         0.1326, -0.1513,  0.1268, -0.1248,  0.1766,  0.0793, -0.1390,  0.0853,
        -0.1388, -0.1684,  0.0426, -0.0219,  0.0144,  0.1113, -0.1913,  0.2056,
        -0.0674, -0.0110,  0.0866, -0.0448, -0.1199, -0.0716,  0.0979,  0.0211],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2059,  0.1243, -0.1737, -0.1538,  0.0170,  0.0225, -0.0849,  0.0117,
          0.1162, -0.1469, -0.0539,  0.0790,  0.0811,  0.0730,  0.1151,  0.0941,
         -0.2058, -0.2092,  0.0478,  0.0422, -0.1128, -0.0955, -0.1895,  0.0687,
          0.1327,  0.2138, -0.1806,  0.1456, -0.0916, -0.1952,  0.1505,  0.1879]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0205], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5810e-01,  3.2222e-01,  5.1338e-02, -8.0751e-02,  6.0026e-02,
          1.0471e-01,  2.3054e-01, -1.1197e-01,  1.1021e-01,  1.9137e-01,
          1.0580e-01, -8.0379e-02, -2.2323e-01, -3.0886e-01,  1.9425e-01,
          1.2407e-01],
        [-1.8454e-01, -1.3238e-01, -3.9662e-02, -7.6975e-02, -1.0760e-01,
          1.8191e-01,  8.5168e-02,  8.5265e-02,  3.2404e-01,  6.4237e-02,
          1.0665e-01, -1.8834e-01,  8.2363e-02,  8.0350e-03,  2.7806e-01,
         -1.8633e-02],
        [ 1.0216e-02,  2.3827e-02,  3.1615e-01, -5.4984e-02,  1.7241e-02,
         -2.7532e-01,  3.7001e-02, -3.3692e-01,  1.2288e-01, -2.1007e-03,
          9.1470e-03, -1.3752e-01,  3.2414e-01,  2.6315e-01,  1.3711e-01,
          1.9668e-01],
        [ 2.0430e-01, -1.6729e-01,  2.0856e-02, -5.5629e-03,  2.2755e-02,
         -1.3323e-01, -7.6594e-02, -2.4852e-02, -3.4615e-01, -3.3575e-01,
          1.9207e-02,  2.9251e-01,  2.3613e-01, -1.6299e-01, -1.4292e-01,
          9.3201e-02],
        [-2.3543e-02,  2.9220e-01, -1.0346e-01, -1.0044e-01,  6.6791e-02,
          1.4859e-02, -4.7495e-02,  2.3918e-01,  6.1942e-02,  2.2316e-01,
          1.4377e-01, -8.4018e-02,  3.6458e-02, -1.8309e-01,  1.8975e-01,
         -9.1037e-02],
        [ 5.9840e-02,  3.3096e-01, -2.9848e-01,  3.3284e-01,  2.4822e-01,
         -8.9963e-02,  1.7965e-01, -1.0180e-01,  1.8036e-01,  1.4504e-01,
         -2.4104e-01, -1.7769e-02, -1.7076e-01,  1.8170e-01,  3.0201e-01,
         -1.6368e-02],
        [ 3.1024e-01, -9.4790e-03,  3.5205e-01, -1.2112e-01,  7.6157e-03,
         -1.5760e-01, -1.1375e-01, -1.8165e-01, -1.9744e-01,  3.8555e-02,
          4.9999e-02,  2.3981e-03, -1.1134e-01,  1.8633e-01, -2.5773e-01,
          9.9195e-02],
        [-1.1162e-01,  1.1933e-01,  3.1041e-01, -2.9681e-01, -2.8122e-01,
         -2.5500e-01, -3.2957e-02, -2.2314e-01, -1.5128e-01, -1.6323e-01,
          2.6958e-04, -1.3455e-02,  2.1490e-01, -1.1944e-01, -5.8669e-02,
          3.0959e-01],
        [-3.2866e-02,  1.0599e-01,  2.3928e-01, -1.7562e-01,  3.5888e-02,
         -2.8013e-01, -8.4488e-02, -2.8658e-02,  1.2054e-01, -2.4504e-01,
         -9.8847e-02, -1.6770e-02, -1.4316e-01,  1.1580e-01, -2.5745e-01,
          3.3907e-02],
        [-2.1904e-01,  1.0449e-01, -3.5245e-02, -8.5019e-02, -1.9166e-02,
          8.8175e-02, -3.7224e-02,  1.6032e-01,  1.8988e-01, -7.0956e-02,
          1.4541e-01,  6.7846e-02, -1.8173e-01, -3.0118e-02,  8.5126e-02,
         -1.3822e-01],
        [-2.8607e-01,  2.9225e-01,  5.5396e-04, -1.0216e-01, -1.2741e-01,
          3.6045e-01,  1.5345e-01,  4.8974e-02,  2.7875e-01,  1.8954e-01,
          2.5032e-03,  7.9204e-02, -1.2183e-01,  1.5924e-01, -8.8663e-02,
         -2.7037e-01],
        [-6.6503e-02,  5.4610e-02,  3.0640e-02,  2.6896e-02,  9.1156e-02,
          6.4199e-02,  2.9385e-01,  8.5938e-02,  9.7030e-02,  2.8988e-01,
          1.6319e-01,  1.2732e-01, -3.5227e-01, -2.0865e-01,  4.9198e-03,
         -1.5737e-01],
        [ 2.4301e-01,  3.3505e-02,  8.3516e-02, -8.6238e-02,  2.4764e-03,
          1.0968e-01,  2.4045e-02, -2.1965e-01, -2.2694e-01, -2.5175e-02,
          1.0793e-02, -5.8156e-02, -1.4390e-01,  1.0336e-01, -1.3866e-01,
         -5.0602e-02],
        [ 1.5291e-01,  1.5192e-01,  3.1711e-01,  4.8142e-02, -2.4094e-01,
          3.1461e-02,  2.3653e-02, -1.5243e-02, -1.5827e-01, -1.0907e-01,
         -1.0630e-01,  5.1279e-02,  6.1186e-02,  2.9297e-02, -2.9883e-01,
          1.9108e-01],
        [-3.1669e-01, -9.0835e-02, -1.4441e-02, -1.0372e-01,  2.9907e-01,
          3.5484e-01,  3.1647e-02,  6.3585e-02, -8.9705e-02,  1.2469e-01,
          1.4652e-02, -2.5007e-01, -2.8156e-02, -8.0191e-02, -1.5843e-02,
         -1.1099e-01],
        [-1.4201e-01, -2.6203e-01,  1.3658e-01,  1.5143e-01, -1.9681e-01,
          5.5609e-02, -7.8356e-02, -2.0421e-01, -9.2538e-02,  1.8140e-02,
          3.3014e-02,  3.2496e-01,  5.3311e-02, -1.0531e-01,  1.8252e-01,
          2.3163e-02],
        [ 2.6289e-01,  7.3464e-02,  1.5079e-01, -2.9619e-01, -2.9623e-01,
          6.4554e-03, -4.2071e-02,  4.6921e-02, -3.1481e-01, -1.3847e-01,
          2.5802e-01,  2.3863e-01,  3.1020e-01,  2.6029e-01, -1.1325e-01,
         -6.9981e-02],
        [-2.4932e-01,  1.7557e-01, -2.0077e-01,  8.6447e-02,  9.0664e-02,
          2.6221e-01,  2.3828e-01,  2.3869e-01,  9.9440e-02,  2.3793e-01,
         -1.2286e-01, -2.0460e-01, -1.4057e-01, -2.0417e-01,  2.6614e-01,
         -1.3408e-01],
        [ 1.6267e-01, -8.7807e-02,  8.9614e-02, -2.2979e-01, -1.1406e-01,
         -3.1642e-01, -2.0785e-01,  1.0027e-01, -3.2512e-01, -5.7281e-02,
          8.0621e-02, -1.4935e-01,  1.3962e-01,  2.1871e-01,  8.6434e-02,
          1.3565e-01],
        [ 3.1107e-01, -8.8564e-02,  2.1469e-01, -2.8039e-02, -2.4196e-01,
         -1.7608e-01, -2.8774e-01,  8.9261e-02,  1.8132e-02, -2.1725e-01,
          2.6566e-02,  1.8373e-01, -1.0922e-01,  7.8101e-02,  5.9014e-02,
          1.4612e-01],
        [-1.2525e-01,  2.5350e-01,  4.5544e-03, -1.3278e-01,  2.0533e-01,
         -8.7538e-02,  2.4356e-01,  3.0854e-01,  1.1798e-01,  1.6842e-02,
         -1.8481e-01, -2.1866e-01, -1.4697e-01, -1.6953e-01,  3.0706e-01,
         -2.0616e-01],
        [ 7.6444e-03, -1.5113e-01,  2.6951e-02,  2.9900e-01, -1.3289e-01,
          3.7353e-02,  1.5532e-01, -1.4711e-01, -6.9288e-02,  1.8255e-01,
          2.3886e-01, -1.7456e-01, -9.6809e-02, -2.9832e-01, -2.0147e-01,
          1.2642e-01],
        [ 3.1342e-01, -1.6402e-01,  5.4739e-03, -1.0500e-01,  6.6792e-02,
         -3.4955e-01, -2.3911e-01, -1.7847e-01, -1.9927e-01, -1.0612e-01,
          2.2900e-01,  1.5931e-01, -1.2777e-01,  2.9207e-01,  1.5261e-01,
          1.7655e-01],
        [ 2.1788e-01,  1.0623e-02,  3.0163e-01, -3.2019e-01, -1.9956e-01,
         -1.3773e-01, -1.4223e-01, -2.5653e-01, -3.2304e-01, -2.8460e-01,
          3.5503e-02,  3.1377e-01,  2.6187e-01,  1.2823e-01, -2.0224e-01,
         -9.6840e-03],
        [ 1.3274e-01, -3.2462e-01,  1.0070e-01, -4.5723e-02,  1.7146e-01,
         -1.7971e-01,  1.3799e-01, -8.4065e-02, -2.7084e-01,  1.2988e-01,
          2.6665e-01, -8.6347e-02, -4.0362e-02,  1.8676e-01, -2.0694e-01,
          2.7551e-01],
        [-1.5085e-02, -1.6886e-01,  3.6054e-02,  1.4369e-01, -1.4548e-01,
         -1.5708e-01,  4.4302e-02, -2.6976e-01, -1.0451e-01, -2.9774e-01,
         -2.1022e-01,  5.0232e-02,  1.2736e-01,  2.8128e-01, -3.0104e-01,
          2.9294e-02],
        [ 1.6910e-01,  4.9499e-03,  2.5240e-01, -2.9129e-01, -1.0919e-01,
         -5.2092e-02, -3.0167e-01,  2.8832e-02, -3.2903e-01,  5.5321e-02,
          9.7315e-02,  3.4930e-02,  1.8342e-01,  2.7273e-01,  1.3799e-01,
          2.5160e-01],
        [-2.5601e-01,  1.6364e-01,  7.4245e-02,  1.4046e-01,  2.1804e-01,
         -3.8766e-02,  2.8441e-01,  9.5962e-02, -1.2764e-01,  4.3201e-02,
          1.5386e-01, -1.9989e-01, -1.5265e-01, -1.6750e-01, -8.0604e-02,
         -6.3475e-02],
        [ 2.5433e-01, -4.5782e-02,  9.0727e-02, -7.5854e-02, -2.4124e-01,
         -2.4338e-01, -9.1010e-02, -2.9460e-01,  3.1634e-02, -6.4955e-02,
          9.0995e-02,  9.1570e-02,  3.0709e-01,  2.9476e-01,  5.4933e-02,
          2.2481e-01],
        [-2.2199e-01,  1.8917e-01, -2.7267e-01,  1.9588e-01, -1.3137e-01,
          1.0460e-01,  2.7967e-01,  2.6115e-01,  3.0892e-01,  1.8218e-01,
          1.0951e-01, -3.6124e-02,  8.3326e-02,  7.3950e-02,  1.1126e-01,
         -1.8399e-01],
        [-2.2854e-01,  3.1831e-02,  8.6400e-03, -4.1053e-02,  1.2527e-01,
          3.3250e-01,  3.1815e-01, -8.3788e-02,  1.6763e-01,  2.6884e-01,
         -2.8687e-01,  4.8987e-02, -2.5912e-01, -2.4844e-01, -4.6566e-02,
         -1.9926e-01],
        [-2.4407e-03, -2.0177e-02,  2.0146e-01,  1.2193e-03,  8.8941e-02,
         -2.6585e-01, -3.3422e-01, -2.9930e-01, -2.3220e-01, -2.1799e-01,
          1.3538e-01, -7.9110e-02, -8.0624e-02,  2.2796e-01, -2.3946e-01,
          1.4720e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1540,  0.0110,  0.0768, -0.0898,  0.0286, -0.1138,  0.0999,  0.1463,
        -0.1223,  0.0248,  0.0656,  0.1300,  0.2108,  0.0733,  0.0516,  0.0342,
        -0.1078, -0.0274,  0.0284, -0.0395, -0.0521,  0.0066, -0.0666,  0.0109,
        -0.1777,  0.2031,  0.0983,  0.0974, -0.1036, -0.2136,  0.1060, -0.0338],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0790,  0.1638, -0.1021, -0.1233,  0.1595,  0.2167, -0.1654, -0.2671,
         -0.1498,  0.2035,  0.1273,  0.2516, -0.0687, -0.2611,  0.1662, -0.0805,
         -0.1848,  0.2227, -0.0999, -0.1306,  0.2718,  0.1195, -0.2561, -0.2739,
         -0.1860, -0.1969, -0.2038,  0.2051, -0.2339,  0.2725,  0.1707, -0.1122]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0095,  0.0653,  0.0879,  ...,  0.0112, -0.1698, -0.1137],
        [-0.1075, -0.0712,  0.1196,  ..., -0.0194, -0.2282,  0.0871],
        [-0.0427,  0.0354,  0.0872,  ...,  0.1369,  0.1286,  0.0345],
        ...,
        [ 0.1035, -0.1123, -0.0123,  ..., -0.0910, -0.0725, -0.1180],
        [ 0.0746, -0.1720, -0.0426,  ..., -0.1452,  0.0377,  0.1557],
        [-0.1736,  0.1104,  0.0604,  ..., -0.0566, -0.1531, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0306,  0.0366, -0.0928, -0.1453, -0.0785,  0.0518, -0.0950,  0.0500,
        -0.0086,  0.0633,  0.0212,  0.0096, -0.0433,  0.0641, -0.0462, -0.0128,
         0.0441, -0.1764, -0.0631,  0.0634, -0.0463,  0.0496,  0.1177,  0.0049,
        -0.0754,  0.1118,  0.0488, -0.0922,  0.0303,  0.1876,  0.1678, -0.1281],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1287, -0.1131, -0.1479,  ...,  0.0179, -0.1109,  0.1127],
        [-0.1340,  0.0480,  0.0273,  ...,  0.1060, -0.1047,  0.1061],
        [ 0.0578, -0.1218, -0.0909,  ..., -0.0956,  0.0887,  0.1175],
        ...,
        [ 0.0609,  0.0247,  0.1541,  ...,  0.0988, -0.1229,  0.2070],
        [ 0.0611, -0.0633, -0.0170,  ...,  0.1906,  0.1298, -0.1097],
        [ 0.0640, -0.0528,  0.1517,  ...,  0.1982,  0.0561,  0.0034]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0963,  0.1334, -0.0247, -0.0752, -0.0387, -0.0632, -0.0369, -0.0827,
         0.1326, -0.1513,  0.1268, -0.1248,  0.1766,  0.0793, -0.1390,  0.0853,
        -0.1388, -0.1684,  0.0426, -0.0219,  0.0144,  0.1113, -0.1913,  0.2056,
        -0.0674, -0.0110,  0.0866, -0.0448, -0.1199, -0.0716,  0.0979,  0.0211],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2059,  0.1243, -0.1737, -0.1538,  0.0170,  0.0225, -0.0849,  0.0117,
          0.1162, -0.1469, -0.0539,  0.0790,  0.0811,  0.0730,  0.1151,  0.0941,
         -0.2058, -0.2092,  0.0478,  0.0422, -0.1128, -0.0955, -0.1895,  0.0687,
          0.1327,  0.2138, -0.1806,  0.1456, -0.0916, -0.1952,  0.1505,  0.1879]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0205], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5810e-01,  3.2222e-01,  5.1338e-02, -8.0751e-02,  6.0026e-02,
          1.0471e-01,  2.3054e-01, -1.1197e-01,  1.1021e-01,  1.9137e-01,
          1.0580e-01, -8.0379e-02, -2.2323e-01, -3.0886e-01,  1.9425e-01,
          1.2407e-01],
        [-1.8454e-01, -1.3238e-01, -3.9662e-02, -7.6975e-02, -1.0760e-01,
          1.8191e-01,  8.5168e-02,  8.5265e-02,  3.2404e-01,  6.4237e-02,
          1.0665e-01, -1.8834e-01,  8.2363e-02,  8.0350e-03,  2.7806e-01,
         -1.8633e-02],
        [ 1.0216e-02,  2.3827e-02,  3.1615e-01, -5.4984e-02,  1.7241e-02,
         -2.7532e-01,  3.7001e-02, -3.3692e-01,  1.2288e-01, -2.1007e-03,
          9.1470e-03, -1.3752e-01,  3.2414e-01,  2.6315e-01,  1.3711e-01,
          1.9668e-01],
        [ 2.0430e-01, -1.6729e-01,  2.0856e-02, -5.5629e-03,  2.2755e-02,
         -1.3323e-01, -7.6594e-02, -2.4852e-02, -3.4615e-01, -3.3575e-01,
          1.9207e-02,  2.9251e-01,  2.3613e-01, -1.6299e-01, -1.4292e-01,
          9.3201e-02],
        [-2.3543e-02,  2.9220e-01, -1.0346e-01, -1.0044e-01,  6.6791e-02,
          1.4859e-02, -4.7495e-02,  2.3918e-01,  6.1942e-02,  2.2316e-01,
          1.4377e-01, -8.4018e-02,  3.6458e-02, -1.8309e-01,  1.8975e-01,
         -9.1037e-02],
        [ 5.9840e-02,  3.3096e-01, -2.9848e-01,  3.3284e-01,  2.4822e-01,
         -8.9963e-02,  1.7965e-01, -1.0180e-01,  1.8036e-01,  1.4504e-01,
         -2.4104e-01, -1.7769e-02, -1.7076e-01,  1.8170e-01,  3.0201e-01,
         -1.6368e-02],
        [ 3.1024e-01, -9.4790e-03,  3.5205e-01, -1.2112e-01,  7.6157e-03,
         -1.5760e-01, -1.1375e-01, -1.8165e-01, -1.9744e-01,  3.8555e-02,
          4.9999e-02,  2.3981e-03, -1.1134e-01,  1.8633e-01, -2.5773e-01,
          9.9195e-02],
        [-1.1162e-01,  1.1933e-01,  3.1041e-01, -2.9681e-01, -2.8122e-01,
         -2.5500e-01, -3.2957e-02, -2.2314e-01, -1.5128e-01, -1.6323e-01,
          2.6958e-04, -1.3455e-02,  2.1490e-01, -1.1944e-01, -5.8669e-02,
          3.0959e-01],
        [-3.2866e-02,  1.0599e-01,  2.3928e-01, -1.7562e-01,  3.5888e-02,
         -2.8013e-01, -8.4488e-02, -2.8658e-02,  1.2054e-01, -2.4504e-01,
         -9.8847e-02, -1.6770e-02, -1.4316e-01,  1.1580e-01, -2.5745e-01,
          3.3907e-02],
        [-2.1904e-01,  1.0449e-01, -3.5245e-02, -8.5019e-02, -1.9166e-02,
          8.8175e-02, -3.7224e-02,  1.6032e-01,  1.8988e-01, -7.0956e-02,
          1.4541e-01,  6.7846e-02, -1.8173e-01, -3.0118e-02,  8.5126e-02,
         -1.3822e-01],
        [-2.8607e-01,  2.9225e-01,  5.5396e-04, -1.0216e-01, -1.2741e-01,
          3.6045e-01,  1.5345e-01,  4.8974e-02,  2.7875e-01,  1.8954e-01,
          2.5032e-03,  7.9204e-02, -1.2183e-01,  1.5924e-01, -8.8663e-02,
         -2.7037e-01],
        [-6.6503e-02,  5.4610e-02,  3.0640e-02,  2.6896e-02,  9.1156e-02,
          6.4199e-02,  2.9385e-01,  8.5938e-02,  9.7030e-02,  2.8988e-01,
          1.6319e-01,  1.2732e-01, -3.5227e-01, -2.0865e-01,  4.9198e-03,
         -1.5737e-01],
        [ 2.4301e-01,  3.3505e-02,  8.3516e-02, -8.6238e-02,  2.4764e-03,
          1.0968e-01,  2.4045e-02, -2.1965e-01, -2.2694e-01, -2.5175e-02,
          1.0793e-02, -5.8156e-02, -1.4390e-01,  1.0336e-01, -1.3866e-01,
         -5.0602e-02],
        [ 1.5291e-01,  1.5192e-01,  3.1711e-01,  4.8142e-02, -2.4094e-01,
          3.1461e-02,  2.3653e-02, -1.5243e-02, -1.5827e-01, -1.0907e-01,
         -1.0630e-01,  5.1279e-02,  6.1186e-02,  2.9297e-02, -2.9883e-01,
          1.9108e-01],
        [-3.1669e-01, -9.0835e-02, -1.4441e-02, -1.0372e-01,  2.9907e-01,
          3.5484e-01,  3.1647e-02,  6.3585e-02, -8.9705e-02,  1.2469e-01,
          1.4652e-02, -2.5007e-01, -2.8156e-02, -8.0191e-02, -1.5843e-02,
         -1.1099e-01],
        [-1.4201e-01, -2.6203e-01,  1.3658e-01,  1.5143e-01, -1.9681e-01,
          5.5609e-02, -7.8356e-02, -2.0421e-01, -9.2538e-02,  1.8140e-02,
          3.3014e-02,  3.2496e-01,  5.3311e-02, -1.0531e-01,  1.8252e-01,
          2.3163e-02],
        [ 2.6289e-01,  7.3464e-02,  1.5079e-01, -2.9619e-01, -2.9623e-01,
          6.4554e-03, -4.2071e-02,  4.6921e-02, -3.1481e-01, -1.3847e-01,
          2.5802e-01,  2.3863e-01,  3.1020e-01,  2.6029e-01, -1.1325e-01,
         -6.9981e-02],
        [-2.4932e-01,  1.7557e-01, -2.0077e-01,  8.6447e-02,  9.0664e-02,
          2.6221e-01,  2.3828e-01,  2.3869e-01,  9.9440e-02,  2.3793e-01,
         -1.2286e-01, -2.0460e-01, -1.4057e-01, -2.0417e-01,  2.6614e-01,
         -1.3408e-01],
        [ 1.6267e-01, -8.7807e-02,  8.9614e-02, -2.2979e-01, -1.1406e-01,
         -3.1642e-01, -2.0785e-01,  1.0027e-01, -3.2512e-01, -5.7281e-02,
          8.0621e-02, -1.4935e-01,  1.3962e-01,  2.1871e-01,  8.6434e-02,
          1.3565e-01],
        [ 3.1107e-01, -8.8564e-02,  2.1469e-01, -2.8039e-02, -2.4196e-01,
         -1.7608e-01, -2.8774e-01,  8.9261e-02,  1.8132e-02, -2.1725e-01,
          2.6566e-02,  1.8373e-01, -1.0922e-01,  7.8101e-02,  5.9014e-02,
          1.4612e-01],
        [-1.2525e-01,  2.5350e-01,  4.5544e-03, -1.3278e-01,  2.0533e-01,
         -8.7538e-02,  2.4356e-01,  3.0854e-01,  1.1798e-01,  1.6842e-02,
         -1.8481e-01, -2.1866e-01, -1.4697e-01, -1.6953e-01,  3.0706e-01,
         -2.0616e-01],
        [ 7.6444e-03, -1.5113e-01,  2.6951e-02,  2.9900e-01, -1.3289e-01,
          3.7353e-02,  1.5532e-01, -1.4711e-01, -6.9288e-02,  1.8255e-01,
          2.3886e-01, -1.7456e-01, -9.6809e-02, -2.9832e-01, -2.0147e-01,
          1.2642e-01],
        [ 3.1342e-01, -1.6402e-01,  5.4739e-03, -1.0500e-01,  6.6792e-02,
         -3.4955e-01, -2.3911e-01, -1.7847e-01, -1.9927e-01, -1.0612e-01,
          2.2900e-01,  1.5931e-01, -1.2777e-01,  2.9207e-01,  1.5261e-01,
          1.7655e-01],
        [ 2.1788e-01,  1.0623e-02,  3.0163e-01, -3.2019e-01, -1.9956e-01,
         -1.3773e-01, -1.4223e-01, -2.5653e-01, -3.2304e-01, -2.8460e-01,
          3.5503e-02,  3.1377e-01,  2.6187e-01,  1.2823e-01, -2.0224e-01,
         -9.6840e-03],
        [ 1.3274e-01, -3.2462e-01,  1.0070e-01, -4.5723e-02,  1.7146e-01,
         -1.7971e-01,  1.3799e-01, -8.4065e-02, -2.7084e-01,  1.2988e-01,
          2.6665e-01, -8.6347e-02, -4.0362e-02,  1.8676e-01, -2.0694e-01,
          2.7551e-01],
        [-1.5085e-02, -1.6886e-01,  3.6054e-02,  1.4369e-01, -1.4548e-01,
         -1.5708e-01,  4.4302e-02, -2.6976e-01, -1.0451e-01, -2.9774e-01,
         -2.1022e-01,  5.0232e-02,  1.2736e-01,  2.8128e-01, -3.0104e-01,
          2.9294e-02],
        [ 1.6910e-01,  4.9499e-03,  2.5240e-01, -2.9129e-01, -1.0919e-01,
         -5.2092e-02, -3.0167e-01,  2.8832e-02, -3.2903e-01,  5.5321e-02,
          9.7315e-02,  3.4930e-02,  1.8342e-01,  2.7273e-01,  1.3799e-01,
          2.5160e-01],
        [-2.5601e-01,  1.6364e-01,  7.4245e-02,  1.4046e-01,  2.1804e-01,
         -3.8766e-02,  2.8441e-01,  9.5962e-02, -1.2764e-01,  4.3201e-02,
          1.5386e-01, -1.9989e-01, -1.5265e-01, -1.6750e-01, -8.0604e-02,
         -6.3475e-02],
        [ 2.5433e-01, -4.5782e-02,  9.0727e-02, -7.5854e-02, -2.4124e-01,
         -2.4338e-01, -9.1010e-02, -2.9460e-01,  3.1634e-02, -6.4955e-02,
          9.0995e-02,  9.1570e-02,  3.0709e-01,  2.9476e-01,  5.4933e-02,
          2.2481e-01],
        [-2.2199e-01,  1.8917e-01, -2.7267e-01,  1.9588e-01, -1.3137e-01,
          1.0460e-01,  2.7967e-01,  2.6115e-01,  3.0892e-01,  1.8218e-01,
          1.0951e-01, -3.6124e-02,  8.3326e-02,  7.3950e-02,  1.1126e-01,
         -1.8399e-01],
        [-2.2854e-01,  3.1831e-02,  8.6400e-03, -4.1053e-02,  1.2527e-01,
          3.3250e-01,  3.1815e-01, -8.3788e-02,  1.6763e-01,  2.6884e-01,
         -2.8687e-01,  4.8987e-02, -2.5912e-01, -2.4844e-01, -4.6566e-02,
         -1.9926e-01],
        [-2.4407e-03, -2.0177e-02,  2.0146e-01,  1.2193e-03,  8.8941e-02,
         -2.6585e-01, -3.3422e-01, -2.9930e-01, -2.3220e-01, -2.1799e-01,
          1.3538e-01, -7.9110e-02, -8.0624e-02,  2.2796e-01, -2.3946e-01,
          1.4720e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1540,  0.0110,  0.0768, -0.0898,  0.0286, -0.1138,  0.0999,  0.1463,
        -0.1223,  0.0248,  0.0656,  0.1300,  0.2108,  0.0733,  0.0516,  0.0342,
        -0.1078, -0.0274,  0.0284, -0.0395, -0.0521,  0.0066, -0.0666,  0.0109,
        -0.1777,  0.2031,  0.0983,  0.0974, -0.1036, -0.2136,  0.1060, -0.0338],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0790,  0.1638, -0.1021, -0.1233,  0.1595,  0.2167, -0.1654, -0.2671,
         -0.1498,  0.2035,  0.1273,  0.2516, -0.0687, -0.2611,  0.1662, -0.0805,
         -0.1848,  0.2227, -0.0999, -0.1306,  0.2718,  0.1195, -0.2561, -0.2739,
         -0.1860, -0.1969, -0.2038,  0.2051, -0.2339,  0.2725,  0.1707, -0.1122]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0095,  0.0653,  0.0879,  ...,  0.0112, -0.1698, -0.1137],
        [-0.1075, -0.0712,  0.1196,  ..., -0.0194, -0.2282,  0.0871],
        [-0.0427,  0.0354,  0.0872,  ...,  0.1369,  0.1286,  0.0345],
        ...,
        [ 0.1035, -0.1123, -0.0123,  ..., -0.0910, -0.0725, -0.1180],
        [ 0.0746, -0.1720, -0.0426,  ..., -0.1452,  0.0377,  0.1557],
        [-0.1736,  0.1104,  0.0604,  ..., -0.0566, -0.1531, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0306,  0.0366, -0.0928, -0.1453, -0.0785,  0.0518, -0.0950,  0.0500,
        -0.0086,  0.0633,  0.0212,  0.0096, -0.0433,  0.0641, -0.0462, -0.0128,
         0.0441, -0.1764, -0.0631,  0.0634, -0.0463,  0.0496,  0.1177,  0.0049,
        -0.0754,  0.1118,  0.0488, -0.0922,  0.0303,  0.1876,  0.1678, -0.1281],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1287, -0.1131, -0.1479,  ...,  0.0179, -0.1109,  0.1127],
        [-0.1340,  0.0480,  0.0273,  ...,  0.1060, -0.1047,  0.1061],
        [ 0.0578, -0.1218, -0.0909,  ..., -0.0956,  0.0887,  0.1175],
        ...,
        [ 0.0609,  0.0247,  0.1541,  ...,  0.0988, -0.1229,  0.2070],
        [ 0.0611, -0.0633, -0.0170,  ...,  0.1906,  0.1298, -0.1097],
        [ 0.0640, -0.0528,  0.1517,  ...,  0.1982,  0.0561,  0.0034]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0963,  0.1334, -0.0247, -0.0752, -0.0387, -0.0632, -0.0369, -0.0827,
         0.1326, -0.1513,  0.1268, -0.1248,  0.1766,  0.0793, -0.1390,  0.0853,
        -0.1388, -0.1684,  0.0426, -0.0219,  0.0144,  0.1113, -0.1913,  0.2056,
        -0.0674, -0.0110,  0.0866, -0.0448, -0.1199, -0.0716,  0.0979,  0.0211],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2059,  0.1243, -0.1737, -0.1538,  0.0170,  0.0225, -0.0849,  0.0117,
          0.1162, -0.1469, -0.0539,  0.0790,  0.0811,  0.0730,  0.1151,  0.0941,
         -0.2058, -0.2092,  0.0478,  0.0422, -0.1128, -0.0955, -0.1895,  0.0687,
          0.1327,  0.2138, -0.1806,  0.1456, -0.0916, -0.1952,  0.1505,  0.1879]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0205], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5810e-01,  3.2222e-01,  5.1338e-02, -8.0751e-02,  6.0026e-02,
          1.0471e-01,  2.3054e-01, -1.1197e-01,  1.1021e-01,  1.9137e-01,
          1.0580e-01, -8.0379e-02, -2.2323e-01, -3.0886e-01,  1.9425e-01,
          1.2407e-01],
        [-1.8454e-01, -1.3238e-01, -3.9662e-02, -7.6975e-02, -1.0760e-01,
          1.8191e-01,  8.5168e-02,  8.5265e-02,  3.2404e-01,  6.4237e-02,
          1.0665e-01, -1.8834e-01,  8.2363e-02,  8.0350e-03,  2.7806e-01,
         -1.8633e-02],
        [ 1.0216e-02,  2.3827e-02,  3.1615e-01, -5.4984e-02,  1.7241e-02,
         -2.7532e-01,  3.7001e-02, -3.3692e-01,  1.2288e-01, -2.1007e-03,
          9.1470e-03, -1.3752e-01,  3.2414e-01,  2.6315e-01,  1.3711e-01,
          1.9668e-01],
        [ 2.0430e-01, -1.6729e-01,  2.0856e-02, -5.5629e-03,  2.2755e-02,
         -1.3323e-01, -7.6594e-02, -2.4852e-02, -3.4615e-01, -3.3575e-01,
          1.9207e-02,  2.9251e-01,  2.3613e-01, -1.6299e-01, -1.4292e-01,
          9.3201e-02],
        [-2.3543e-02,  2.9220e-01, -1.0346e-01, -1.0044e-01,  6.6791e-02,
          1.4859e-02, -4.7495e-02,  2.3918e-01,  6.1942e-02,  2.2316e-01,
          1.4377e-01, -8.4018e-02,  3.6458e-02, -1.8309e-01,  1.8975e-01,
         -9.1037e-02],
        [ 5.9840e-02,  3.3096e-01, -2.9848e-01,  3.3284e-01,  2.4822e-01,
         -8.9963e-02,  1.7965e-01, -1.0180e-01,  1.8036e-01,  1.4504e-01,
         -2.4104e-01, -1.7769e-02, -1.7076e-01,  1.8170e-01,  3.0201e-01,
         -1.6368e-02],
        [ 3.1024e-01, -9.4790e-03,  3.5205e-01, -1.2112e-01,  7.6157e-03,
         -1.5760e-01, -1.1375e-01, -1.8165e-01, -1.9744e-01,  3.8555e-02,
          4.9999e-02,  2.3981e-03, -1.1134e-01,  1.8633e-01, -2.5773e-01,
          9.9195e-02],
        [-1.1162e-01,  1.1933e-01,  3.1041e-01, -2.9681e-01, -2.8122e-01,
         -2.5500e-01, -3.2957e-02, -2.2314e-01, -1.5128e-01, -1.6323e-01,
          2.6958e-04, -1.3455e-02,  2.1490e-01, -1.1944e-01, -5.8669e-02,
          3.0959e-01],
        [-3.2866e-02,  1.0599e-01,  2.3928e-01, -1.7562e-01,  3.5888e-02,
         -2.8013e-01, -8.4488e-02, -2.8658e-02,  1.2054e-01, -2.4504e-01,
         -9.8847e-02, -1.6770e-02, -1.4316e-01,  1.1580e-01, -2.5745e-01,
          3.3907e-02],
        [-2.1904e-01,  1.0449e-01, -3.5245e-02, -8.5019e-02, -1.9166e-02,
          8.8175e-02, -3.7224e-02,  1.6032e-01,  1.8988e-01, -7.0956e-02,
          1.4541e-01,  6.7846e-02, -1.8173e-01, -3.0118e-02,  8.5126e-02,
         -1.3822e-01],
        [-2.8607e-01,  2.9225e-01,  5.5396e-04, -1.0216e-01, -1.2741e-01,
          3.6045e-01,  1.5345e-01,  4.8974e-02,  2.7875e-01,  1.8954e-01,
          2.5032e-03,  7.9204e-02, -1.2183e-01,  1.5924e-01, -8.8663e-02,
         -2.7037e-01],
        [-6.6503e-02,  5.4610e-02,  3.0640e-02,  2.6896e-02,  9.1156e-02,
          6.4199e-02,  2.9385e-01,  8.5938e-02,  9.7030e-02,  2.8988e-01,
          1.6319e-01,  1.2732e-01, -3.5227e-01, -2.0865e-01,  4.9198e-03,
         -1.5737e-01],
        [ 2.4301e-01,  3.3505e-02,  8.3516e-02, -8.6238e-02,  2.4764e-03,
          1.0968e-01,  2.4045e-02, -2.1965e-01, -2.2694e-01, -2.5175e-02,
          1.0793e-02, -5.8156e-02, -1.4390e-01,  1.0336e-01, -1.3866e-01,
         -5.0602e-02],
        [ 1.5291e-01,  1.5192e-01,  3.1711e-01,  4.8142e-02, -2.4094e-01,
          3.1461e-02,  2.3653e-02, -1.5243e-02, -1.5827e-01, -1.0907e-01,
         -1.0630e-01,  5.1279e-02,  6.1186e-02,  2.9297e-02, -2.9883e-01,
          1.9108e-01],
        [-3.1669e-01, -9.0835e-02, -1.4441e-02, -1.0372e-01,  2.9907e-01,
          3.5484e-01,  3.1647e-02,  6.3585e-02, -8.9705e-02,  1.2469e-01,
          1.4652e-02, -2.5007e-01, -2.8156e-02, -8.0191e-02, -1.5843e-02,
         -1.1099e-01],
        [-1.4201e-01, -2.6203e-01,  1.3658e-01,  1.5143e-01, -1.9681e-01,
          5.5609e-02, -7.8356e-02, -2.0421e-01, -9.2538e-02,  1.8140e-02,
          3.3014e-02,  3.2496e-01,  5.3311e-02, -1.0531e-01,  1.8252e-01,
          2.3163e-02],
        [ 2.6289e-01,  7.3464e-02,  1.5079e-01, -2.9619e-01, -2.9623e-01,
          6.4554e-03, -4.2071e-02,  4.6921e-02, -3.1481e-01, -1.3847e-01,
          2.5802e-01,  2.3863e-01,  3.1020e-01,  2.6029e-01, -1.1325e-01,
         -6.9981e-02],
        [-2.4932e-01,  1.7557e-01, -2.0077e-01,  8.6447e-02,  9.0664e-02,
          2.6221e-01,  2.3828e-01,  2.3869e-01,  9.9440e-02,  2.3793e-01,
         -1.2286e-01, -2.0460e-01, -1.4057e-01, -2.0417e-01,  2.6614e-01,
         -1.3408e-01],
        [ 1.6267e-01, -8.7807e-02,  8.9614e-02, -2.2979e-01, -1.1406e-01,
         -3.1642e-01, -2.0785e-01,  1.0027e-01, -3.2512e-01, -5.7281e-02,
          8.0621e-02, -1.4935e-01,  1.3962e-01,  2.1871e-01,  8.6434e-02,
          1.3565e-01],
        [ 3.1107e-01, -8.8564e-02,  2.1469e-01, -2.8039e-02, -2.4196e-01,
         -1.7608e-01, -2.8774e-01,  8.9261e-02,  1.8132e-02, -2.1725e-01,
          2.6566e-02,  1.8373e-01, -1.0922e-01,  7.8101e-02,  5.9014e-02,
          1.4612e-01],
        [-1.2525e-01,  2.5350e-01,  4.5544e-03, -1.3278e-01,  2.0533e-01,
         -8.7538e-02,  2.4356e-01,  3.0854e-01,  1.1798e-01,  1.6842e-02,
         -1.8481e-01, -2.1866e-01, -1.4697e-01, -1.6953e-01,  3.0706e-01,
         -2.0616e-01],
        [ 7.6444e-03, -1.5113e-01,  2.6951e-02,  2.9900e-01, -1.3289e-01,
          3.7353e-02,  1.5532e-01, -1.4711e-01, -6.9288e-02,  1.8255e-01,
          2.3886e-01, -1.7456e-01, -9.6809e-02, -2.9832e-01, -2.0147e-01,
          1.2642e-01],
        [ 3.1342e-01, -1.6402e-01,  5.4739e-03, -1.0500e-01,  6.6792e-02,
         -3.4955e-01, -2.3911e-01, -1.7847e-01, -1.9927e-01, -1.0612e-01,
          2.2900e-01,  1.5931e-01, -1.2777e-01,  2.9207e-01,  1.5261e-01,
          1.7655e-01],
        [ 2.1788e-01,  1.0623e-02,  3.0163e-01, -3.2019e-01, -1.9956e-01,
         -1.3773e-01, -1.4223e-01, -2.5653e-01, -3.2304e-01, -2.8460e-01,
          3.5503e-02,  3.1377e-01,  2.6187e-01,  1.2823e-01, -2.0224e-01,
         -9.6840e-03],
        [ 1.3274e-01, -3.2462e-01,  1.0070e-01, -4.5723e-02,  1.7146e-01,
         -1.7971e-01,  1.3799e-01, -8.4065e-02, -2.7084e-01,  1.2988e-01,
          2.6665e-01, -8.6347e-02, -4.0362e-02,  1.8676e-01, -2.0694e-01,
          2.7551e-01],
        [-1.5085e-02, -1.6886e-01,  3.6054e-02,  1.4369e-01, -1.4548e-01,
         -1.5708e-01,  4.4302e-02, -2.6976e-01, -1.0451e-01, -2.9774e-01,
         -2.1022e-01,  5.0232e-02,  1.2736e-01,  2.8128e-01, -3.0104e-01,
          2.9294e-02],
        [ 1.6910e-01,  4.9499e-03,  2.5240e-01, -2.9129e-01, -1.0919e-01,
         -5.2092e-02, -3.0167e-01,  2.8832e-02, -3.2903e-01,  5.5321e-02,
          9.7315e-02,  3.4930e-02,  1.8342e-01,  2.7273e-01,  1.3799e-01,
          2.5160e-01],
        [-2.5601e-01,  1.6364e-01,  7.4245e-02,  1.4046e-01,  2.1804e-01,
         -3.8766e-02,  2.8441e-01,  9.5962e-02, -1.2764e-01,  4.3201e-02,
          1.5386e-01, -1.9989e-01, -1.5265e-01, -1.6750e-01, -8.0604e-02,
         -6.3475e-02],
        [ 2.5433e-01, -4.5782e-02,  9.0727e-02, -7.5854e-02, -2.4124e-01,
         -2.4338e-01, -9.1010e-02, -2.9460e-01,  3.1634e-02, -6.4955e-02,
          9.0995e-02,  9.1570e-02,  3.0709e-01,  2.9476e-01,  5.4933e-02,
          2.2481e-01],
        [-2.2199e-01,  1.8917e-01, -2.7267e-01,  1.9588e-01, -1.3137e-01,
          1.0460e-01,  2.7967e-01,  2.6115e-01,  3.0892e-01,  1.8218e-01,
          1.0951e-01, -3.6124e-02,  8.3326e-02,  7.3950e-02,  1.1126e-01,
         -1.8399e-01],
        [-2.2854e-01,  3.1831e-02,  8.6400e-03, -4.1053e-02,  1.2527e-01,
          3.3250e-01,  3.1815e-01, -8.3788e-02,  1.6763e-01,  2.6884e-01,
         -2.8687e-01,  4.8987e-02, -2.5912e-01, -2.4844e-01, -4.6566e-02,
         -1.9926e-01],
        [-2.4407e-03, -2.0177e-02,  2.0146e-01,  1.2193e-03,  8.8941e-02,
         -2.6585e-01, -3.3422e-01, -2.9930e-01, -2.3220e-01, -2.1799e-01,
          1.3538e-01, -7.9110e-02, -8.0624e-02,  2.2796e-01, -2.3946e-01,
          1.4720e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1540,  0.0110,  0.0768, -0.0898,  0.0286, -0.1138,  0.0999,  0.1463,
        -0.1223,  0.0248,  0.0656,  0.1300,  0.2108,  0.0733,  0.0516,  0.0342,
        -0.1078, -0.0274,  0.0284, -0.0395, -0.0521,  0.0066, -0.0666,  0.0109,
        -0.1777,  0.2031,  0.0983,  0.0974, -0.1036, -0.2136,  0.1060, -0.0338],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0790,  0.1638, -0.1021, -0.1233,  0.1595,  0.2167, -0.1654, -0.2671,
         -0.1498,  0.2035,  0.1273,  0.2516, -0.0687, -0.2611,  0.1662, -0.0805,
         -0.1848,  0.2227, -0.0999, -0.1306,  0.2718,  0.1195, -0.2561, -0.2739,
         -0.1860, -0.1969, -0.2038,  0.2051, -0.2339,  0.2725,  0.1707, -0.1122]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0095,  0.0653,  0.0879,  ...,  0.0112, -0.1698, -0.1137],
        [-0.1075, -0.0712,  0.1196,  ..., -0.0194, -0.2282,  0.0871],
        [-0.0427,  0.0354,  0.0872,  ...,  0.1369,  0.1286,  0.0345],
        ...,
        [ 0.1035, -0.1123, -0.0123,  ..., -0.0910, -0.0725, -0.1180],
        [ 0.0746, -0.1720, -0.0426,  ..., -0.1452,  0.0377,  0.1557],
        [-0.1736,  0.1104,  0.0604,  ..., -0.0566, -0.1531, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0306,  0.0366, -0.0928, -0.1453, -0.0785,  0.0518, -0.0950,  0.0500,
        -0.0086,  0.0633,  0.0212,  0.0096, -0.0433,  0.0641, -0.0462, -0.0128,
         0.0441, -0.1764, -0.0631,  0.0634, -0.0463,  0.0496,  0.1177,  0.0049,
        -0.0754,  0.1118,  0.0488, -0.0922,  0.0303,  0.1876,  0.1678, -0.1281],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1287, -0.1131, -0.1479,  ...,  0.0179, -0.1109,  0.1127],
        [-0.1340,  0.0480,  0.0273,  ...,  0.1060, -0.1047,  0.1061],
        [ 0.0578, -0.1218, -0.0909,  ..., -0.0956,  0.0887,  0.1175],
        ...,
        [ 0.0609,  0.0247,  0.1541,  ...,  0.0988, -0.1229,  0.2070],
        [ 0.0611, -0.0633, -0.0170,  ...,  0.1906,  0.1298, -0.1097],
        [ 0.0640, -0.0528,  0.1517,  ...,  0.1982,  0.0561,  0.0034]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0963,  0.1334, -0.0247, -0.0752, -0.0387, -0.0632, -0.0369, -0.0827,
         0.1326, -0.1513,  0.1268, -0.1248,  0.1766,  0.0793, -0.1390,  0.0853,
        -0.1388, -0.1684,  0.0426, -0.0219,  0.0144,  0.1113, -0.1913,  0.2056,
        -0.0674, -0.0110,  0.0866, -0.0448, -0.1199, -0.0716,  0.0979,  0.0211],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2059,  0.1243, -0.1737, -0.1538,  0.0170,  0.0225, -0.0849,  0.0117,
          0.1162, -0.1469, -0.0539,  0.0790,  0.0811,  0.0730,  0.1151,  0.0941,
         -0.2058, -0.2092,  0.0478,  0.0422, -0.1128, -0.0955, -0.1895,  0.0687,
          0.1327,  0.2138, -0.1806,  0.1456, -0.0916, -0.1952,  0.1505,  0.1879]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0205], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5810e-01,  3.2222e-01,  5.1338e-02, -8.0751e-02,  6.0026e-02,
          1.0471e-01,  2.3054e-01, -1.1197e-01,  1.1021e-01,  1.9137e-01,
          1.0580e-01, -8.0379e-02, -2.2323e-01, -3.0886e-01,  1.9425e-01,
          1.2407e-01],
        [-1.8454e-01, -1.3238e-01, -3.9662e-02, -7.6975e-02, -1.0760e-01,
          1.8191e-01,  8.5168e-02,  8.5265e-02,  3.2404e-01,  6.4237e-02,
          1.0665e-01, -1.8834e-01,  8.2363e-02,  8.0350e-03,  2.7806e-01,
         -1.8633e-02],
        [ 1.0216e-02,  2.3827e-02,  3.1615e-01, -5.4984e-02,  1.7241e-02,
         -2.7532e-01,  3.7001e-02, -3.3692e-01,  1.2288e-01, -2.1007e-03,
          9.1470e-03, -1.3752e-01,  3.2414e-01,  2.6315e-01,  1.3711e-01,
          1.9668e-01],
        [ 2.0430e-01, -1.6729e-01,  2.0856e-02, -5.5629e-03,  2.2755e-02,
         -1.3323e-01, -7.6594e-02, -2.4852e-02, -3.4615e-01, -3.3575e-01,
          1.9207e-02,  2.9251e-01,  2.3613e-01, -1.6299e-01, -1.4292e-01,
          9.3201e-02],
        [-2.3543e-02,  2.9220e-01, -1.0346e-01, -1.0044e-01,  6.6791e-02,
          1.4859e-02, -4.7495e-02,  2.3918e-01,  6.1942e-02,  2.2316e-01,
          1.4377e-01, -8.4018e-02,  3.6458e-02, -1.8309e-01,  1.8975e-01,
         -9.1037e-02],
        [ 5.9840e-02,  3.3096e-01, -2.9848e-01,  3.3284e-01,  2.4822e-01,
         -8.9963e-02,  1.7965e-01, -1.0180e-01,  1.8036e-01,  1.4504e-01,
         -2.4104e-01, -1.7769e-02, -1.7076e-01,  1.8170e-01,  3.0201e-01,
         -1.6368e-02],
        [ 3.1024e-01, -9.4790e-03,  3.5205e-01, -1.2112e-01,  7.6157e-03,
         -1.5760e-01, -1.1375e-01, -1.8165e-01, -1.9744e-01,  3.8555e-02,
          4.9999e-02,  2.3981e-03, -1.1134e-01,  1.8633e-01, -2.5773e-01,
          9.9195e-02],
        [-1.1162e-01,  1.1933e-01,  3.1041e-01, -2.9681e-01, -2.8122e-01,
         -2.5500e-01, -3.2957e-02, -2.2314e-01, -1.5128e-01, -1.6323e-01,
          2.6958e-04, -1.3455e-02,  2.1490e-01, -1.1944e-01, -5.8669e-02,
          3.0959e-01],
        [-3.2866e-02,  1.0599e-01,  2.3928e-01, -1.7562e-01,  3.5888e-02,
         -2.8013e-01, -8.4488e-02, -2.8658e-02,  1.2054e-01, -2.4504e-01,
         -9.8847e-02, -1.6770e-02, -1.4316e-01,  1.1580e-01, -2.5745e-01,
          3.3907e-02],
        [-2.1904e-01,  1.0449e-01, -3.5245e-02, -8.5019e-02, -1.9166e-02,
          8.8175e-02, -3.7224e-02,  1.6032e-01,  1.8988e-01, -7.0956e-02,
          1.4541e-01,  6.7846e-02, -1.8173e-01, -3.0118e-02,  8.5126e-02,
         -1.3822e-01],
        [-2.8607e-01,  2.9225e-01,  5.5396e-04, -1.0216e-01, -1.2741e-01,
          3.6045e-01,  1.5345e-01,  4.8974e-02,  2.7875e-01,  1.8954e-01,
          2.5032e-03,  7.9204e-02, -1.2183e-01,  1.5924e-01, -8.8663e-02,
         -2.7037e-01],
        [-6.6503e-02,  5.4610e-02,  3.0640e-02,  2.6896e-02,  9.1156e-02,
          6.4199e-02,  2.9385e-01,  8.5938e-02,  9.7030e-02,  2.8988e-01,
          1.6319e-01,  1.2732e-01, -3.5227e-01, -2.0865e-01,  4.9198e-03,
         -1.5737e-01],
        [ 2.4301e-01,  3.3505e-02,  8.3516e-02, -8.6238e-02,  2.4764e-03,
          1.0968e-01,  2.4045e-02, -2.1965e-01, -2.2694e-01, -2.5175e-02,
          1.0793e-02, -5.8156e-02, -1.4390e-01,  1.0336e-01, -1.3866e-01,
         -5.0602e-02],
        [ 1.5291e-01,  1.5192e-01,  3.1711e-01,  4.8142e-02, -2.4094e-01,
          3.1461e-02,  2.3653e-02, -1.5243e-02, -1.5827e-01, -1.0907e-01,
         -1.0630e-01,  5.1279e-02,  6.1186e-02,  2.9297e-02, -2.9883e-01,
          1.9108e-01],
        [-3.1669e-01, -9.0835e-02, -1.4441e-02, -1.0372e-01,  2.9907e-01,
          3.5484e-01,  3.1647e-02,  6.3585e-02, -8.9705e-02,  1.2469e-01,
          1.4652e-02, -2.5007e-01, -2.8156e-02, -8.0191e-02, -1.5843e-02,
         -1.1099e-01],
        [-1.4201e-01, -2.6203e-01,  1.3658e-01,  1.5143e-01, -1.9681e-01,
          5.5609e-02, -7.8356e-02, -2.0421e-01, -9.2538e-02,  1.8140e-02,
          3.3014e-02,  3.2496e-01,  5.3311e-02, -1.0531e-01,  1.8252e-01,
          2.3163e-02],
        [ 2.6289e-01,  7.3464e-02,  1.5079e-01, -2.9619e-01, -2.9623e-01,
          6.4554e-03, -4.2071e-02,  4.6921e-02, -3.1481e-01, -1.3847e-01,
          2.5802e-01,  2.3863e-01,  3.1020e-01,  2.6029e-01, -1.1325e-01,
         -6.9981e-02],
        [-2.4932e-01,  1.7557e-01, -2.0077e-01,  8.6447e-02,  9.0664e-02,
          2.6221e-01,  2.3828e-01,  2.3869e-01,  9.9440e-02,  2.3793e-01,
         -1.2286e-01, -2.0460e-01, -1.4057e-01, -2.0417e-01,  2.6614e-01,
         -1.3408e-01],
        [ 1.6267e-01, -8.7807e-02,  8.9614e-02, -2.2979e-01, -1.1406e-01,
         -3.1642e-01, -2.0785e-01,  1.0027e-01, -3.2512e-01, -5.7281e-02,
          8.0621e-02, -1.4935e-01,  1.3962e-01,  2.1871e-01,  8.6434e-02,
          1.3565e-01],
        [ 3.1107e-01, -8.8564e-02,  2.1469e-01, -2.8039e-02, -2.4196e-01,
         -1.7608e-01, -2.8774e-01,  8.9261e-02,  1.8132e-02, -2.1725e-01,
          2.6566e-02,  1.8373e-01, -1.0922e-01,  7.8101e-02,  5.9014e-02,
          1.4612e-01],
        [-1.2525e-01,  2.5350e-01,  4.5544e-03, -1.3278e-01,  2.0533e-01,
         -8.7538e-02,  2.4356e-01,  3.0854e-01,  1.1798e-01,  1.6842e-02,
         -1.8481e-01, -2.1866e-01, -1.4697e-01, -1.6953e-01,  3.0706e-01,
         -2.0616e-01],
        [ 7.6444e-03, -1.5113e-01,  2.6951e-02,  2.9900e-01, -1.3289e-01,
          3.7353e-02,  1.5532e-01, -1.4711e-01, -6.9288e-02,  1.8255e-01,
          2.3886e-01, -1.7456e-01, -9.6809e-02, -2.9832e-01, -2.0147e-01,
          1.2642e-01],
        [ 3.1342e-01, -1.6402e-01,  5.4739e-03, -1.0500e-01,  6.6792e-02,
         -3.4955e-01, -2.3911e-01, -1.7847e-01, -1.9927e-01, -1.0612e-01,
          2.2900e-01,  1.5931e-01, -1.2777e-01,  2.9207e-01,  1.5261e-01,
          1.7655e-01],
        [ 2.1788e-01,  1.0623e-02,  3.0163e-01, -3.2019e-01, -1.9956e-01,
         -1.3773e-01, -1.4223e-01, -2.5653e-01, -3.2304e-01, -2.8460e-01,
          3.5503e-02,  3.1377e-01,  2.6187e-01,  1.2823e-01, -2.0224e-01,
         -9.6840e-03],
        [ 1.3274e-01, -3.2462e-01,  1.0070e-01, -4.5723e-02,  1.7146e-01,
         -1.7971e-01,  1.3799e-01, -8.4065e-02, -2.7084e-01,  1.2988e-01,
          2.6665e-01, -8.6347e-02, -4.0362e-02,  1.8676e-01, -2.0694e-01,
          2.7551e-01],
        [-1.5085e-02, -1.6886e-01,  3.6054e-02,  1.4369e-01, -1.4548e-01,
         -1.5708e-01,  4.4302e-02, -2.6976e-01, -1.0451e-01, -2.9774e-01,
         -2.1022e-01,  5.0232e-02,  1.2736e-01,  2.8128e-01, -3.0104e-01,
          2.9294e-02],
        [ 1.6910e-01,  4.9499e-03,  2.5240e-01, -2.9129e-01, -1.0919e-01,
         -5.2092e-02, -3.0167e-01,  2.8832e-02, -3.2903e-01,  5.5321e-02,
          9.7315e-02,  3.4930e-02,  1.8342e-01,  2.7273e-01,  1.3799e-01,
          2.5160e-01],
        [-2.5601e-01,  1.6364e-01,  7.4245e-02,  1.4046e-01,  2.1804e-01,
         -3.8766e-02,  2.8441e-01,  9.5962e-02, -1.2764e-01,  4.3201e-02,
          1.5386e-01, -1.9989e-01, -1.5265e-01, -1.6750e-01, -8.0604e-02,
         -6.3475e-02],
        [ 2.5433e-01, -4.5782e-02,  9.0727e-02, -7.5854e-02, -2.4124e-01,
         -2.4338e-01, -9.1010e-02, -2.9460e-01,  3.1634e-02, -6.4955e-02,
          9.0995e-02,  9.1570e-02,  3.0709e-01,  2.9476e-01,  5.4933e-02,
          2.2481e-01],
        [-2.2199e-01,  1.8917e-01, -2.7267e-01,  1.9588e-01, -1.3137e-01,
          1.0460e-01,  2.7967e-01,  2.6115e-01,  3.0892e-01,  1.8218e-01,
          1.0951e-01, -3.6124e-02,  8.3326e-02,  7.3950e-02,  1.1126e-01,
         -1.8399e-01],
        [-2.2854e-01,  3.1831e-02,  8.6400e-03, -4.1053e-02,  1.2527e-01,
          3.3250e-01,  3.1815e-01, -8.3788e-02,  1.6763e-01,  2.6884e-01,
         -2.8687e-01,  4.8987e-02, -2.5912e-01, -2.4844e-01, -4.6566e-02,
         -1.9926e-01],
        [-2.4407e-03, -2.0177e-02,  2.0146e-01,  1.2193e-03,  8.8941e-02,
         -2.6585e-01, -3.3422e-01, -2.9930e-01, -2.3220e-01, -2.1799e-01,
          1.3538e-01, -7.9110e-02, -8.0624e-02,  2.2796e-01, -2.3946e-01,
          1.4720e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1540,  0.0110,  0.0768, -0.0898,  0.0286, -0.1138,  0.0999,  0.1463,
        -0.1223,  0.0248,  0.0656,  0.1300,  0.2108,  0.0733,  0.0516,  0.0342,
        -0.1078, -0.0274,  0.0284, -0.0395, -0.0521,  0.0066, -0.0666,  0.0109,
        -0.1777,  0.2031,  0.0983,  0.0974, -0.1036, -0.2136,  0.1060, -0.0338],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0790,  0.1638, -0.1021, -0.1233,  0.1595,  0.2167, -0.1654, -0.2671,
         -0.1498,  0.2035,  0.1273,  0.2516, -0.0687, -0.2611,  0.1662, -0.0805,
         -0.1848,  0.2227, -0.0999, -0.1306,  0.2718,  0.1195, -0.2561, -0.2739,
         -0.1860, -0.1969, -0.2038,  0.2051, -0.2339,  0.2725,  0.1707, -0.1122]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0095,  0.0653,  0.0879,  ...,  0.0112, -0.1698, -0.1137],
        [-0.1075, -0.0712,  0.1196,  ..., -0.0194, -0.2282,  0.0871],
        [-0.0427,  0.0354,  0.0872,  ...,  0.1369,  0.1286,  0.0345],
        ...,
        [ 0.1035, -0.1123, -0.0123,  ..., -0.0910, -0.0725, -0.1180],
        [ 0.0746, -0.1720, -0.0426,  ..., -0.1452,  0.0377,  0.1557],
        [-0.1736,  0.1104,  0.0604,  ..., -0.0566, -0.1531, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0306,  0.0366, -0.0928, -0.1453, -0.0785,  0.0518, -0.0950,  0.0500,
        -0.0086,  0.0633,  0.0212,  0.0096, -0.0433,  0.0641, -0.0462, -0.0128,
         0.0441, -0.1764, -0.0631,  0.0634, -0.0463,  0.0496,  0.1177,  0.0049,
        -0.0754,  0.1118,  0.0488, -0.0922,  0.0303,  0.1876,  0.1678, -0.1281],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1287, -0.1131, -0.1479,  ...,  0.0179, -0.1109,  0.1127],
        [-0.1340,  0.0480,  0.0273,  ...,  0.1060, -0.1047,  0.1061],
        [ 0.0578, -0.1218, -0.0909,  ..., -0.0956,  0.0887,  0.1175],
        ...,
        [ 0.0609,  0.0247,  0.1541,  ...,  0.0988, -0.1229,  0.2070],
        [ 0.0611, -0.0633, -0.0170,  ...,  0.1906,  0.1298, -0.1097],
        [ 0.0640, -0.0528,  0.1517,  ...,  0.1982,  0.0561,  0.0034]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0963,  0.1334, -0.0247, -0.0752, -0.0387, -0.0632, -0.0369, -0.0827,
         0.1326, -0.1513,  0.1268, -0.1248,  0.1766,  0.0793, -0.1390,  0.0853,
        -0.1388, -0.1684,  0.0426, -0.0219,  0.0144,  0.1113, -0.1913,  0.2056,
        -0.0674, -0.0110,  0.0866, -0.0448, -0.1199, -0.0716,  0.0979,  0.0211],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2059,  0.1243, -0.1737, -0.1538,  0.0170,  0.0225, -0.0849,  0.0117,
          0.1162, -0.1469, -0.0539,  0.0790,  0.0811,  0.0730,  0.1151,  0.0941,
         -0.2058, -0.2092,  0.0478,  0.0422, -0.1128, -0.0955, -0.1895,  0.0687,
          0.1327,  0.2138, -0.1806,  0.1456, -0.0916, -0.1952,  0.1505,  0.1879]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0205], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5810e-01,  3.2222e-01,  5.1338e-02, -8.0751e-02,  6.0026e-02,
          1.0471e-01,  2.3054e-01, -1.1197e-01,  1.1021e-01,  1.9137e-01,
          1.0580e-01, -8.0379e-02, -2.2323e-01, -3.0886e-01,  1.9425e-01,
          1.2407e-01],
        [-1.8454e-01, -1.3238e-01, -3.9662e-02, -7.6975e-02, -1.0760e-01,
          1.8191e-01,  8.5168e-02,  8.5265e-02,  3.2404e-01,  6.4237e-02,
          1.0665e-01, -1.8834e-01,  8.2363e-02,  8.0350e-03,  2.7806e-01,
         -1.8633e-02],
        [ 1.0216e-02,  2.3827e-02,  3.1615e-01, -5.4984e-02,  1.7241e-02,
         -2.7532e-01,  3.7001e-02, -3.3692e-01,  1.2288e-01, -2.1007e-03,
          9.1470e-03, -1.3752e-01,  3.2414e-01,  2.6315e-01,  1.3711e-01,
          1.9668e-01],
        [ 2.0430e-01, -1.6729e-01,  2.0856e-02, -5.5629e-03,  2.2755e-02,
         -1.3323e-01, -7.6594e-02, -2.4852e-02, -3.4615e-01, -3.3575e-01,
          1.9207e-02,  2.9251e-01,  2.3613e-01, -1.6299e-01, -1.4292e-01,
          9.3201e-02],
        [-2.3543e-02,  2.9220e-01, -1.0346e-01, -1.0044e-01,  6.6791e-02,
          1.4859e-02, -4.7495e-02,  2.3918e-01,  6.1942e-02,  2.2316e-01,
          1.4377e-01, -8.4018e-02,  3.6458e-02, -1.8309e-01,  1.8975e-01,
         -9.1037e-02],
        [ 5.9840e-02,  3.3096e-01, -2.9848e-01,  3.3284e-01,  2.4822e-01,
         -8.9963e-02,  1.7965e-01, -1.0180e-01,  1.8036e-01,  1.4504e-01,
         -2.4104e-01, -1.7769e-02, -1.7076e-01,  1.8170e-01,  3.0201e-01,
         -1.6368e-02],
        [ 3.1024e-01, -9.4790e-03,  3.5205e-01, -1.2112e-01,  7.6157e-03,
         -1.5760e-01, -1.1375e-01, -1.8165e-01, -1.9744e-01,  3.8555e-02,
          4.9999e-02,  2.3981e-03, -1.1134e-01,  1.8633e-01, -2.5773e-01,
          9.9195e-02],
        [-1.1162e-01,  1.1933e-01,  3.1041e-01, -2.9681e-01, -2.8122e-01,
         -2.5500e-01, -3.2957e-02, -2.2314e-01, -1.5128e-01, -1.6323e-01,
          2.6958e-04, -1.3455e-02,  2.1490e-01, -1.1944e-01, -5.8669e-02,
          3.0959e-01],
        [-3.2866e-02,  1.0599e-01,  2.3928e-01, -1.7562e-01,  3.5888e-02,
         -2.8013e-01, -8.4488e-02, -2.8658e-02,  1.2054e-01, -2.4504e-01,
         -9.8847e-02, -1.6770e-02, -1.4316e-01,  1.1580e-01, -2.5745e-01,
          3.3907e-02],
        [-2.1904e-01,  1.0449e-01, -3.5245e-02, -8.5019e-02, -1.9166e-02,
          8.8175e-02, -3.7224e-02,  1.6032e-01,  1.8988e-01, -7.0956e-02,
          1.4541e-01,  6.7846e-02, -1.8173e-01, -3.0118e-02,  8.5126e-02,
         -1.3822e-01],
        [-2.8607e-01,  2.9225e-01,  5.5396e-04, -1.0216e-01, -1.2741e-01,
          3.6045e-01,  1.5345e-01,  4.8974e-02,  2.7875e-01,  1.8954e-01,
          2.5032e-03,  7.9204e-02, -1.2183e-01,  1.5924e-01, -8.8663e-02,
         -2.7037e-01],
        [-6.6503e-02,  5.4610e-02,  3.0640e-02,  2.6896e-02,  9.1156e-02,
          6.4199e-02,  2.9385e-01,  8.5938e-02,  9.7030e-02,  2.8988e-01,
          1.6319e-01,  1.2732e-01, -3.5227e-01, -2.0865e-01,  4.9198e-03,
         -1.5737e-01],
        [ 2.4301e-01,  3.3505e-02,  8.3516e-02, -8.6238e-02,  2.4764e-03,
          1.0968e-01,  2.4045e-02, -2.1965e-01, -2.2694e-01, -2.5175e-02,
          1.0793e-02, -5.8156e-02, -1.4390e-01,  1.0336e-01, -1.3866e-01,
         -5.0602e-02],
        [ 1.5291e-01,  1.5192e-01,  3.1711e-01,  4.8142e-02, -2.4094e-01,
          3.1461e-02,  2.3653e-02, -1.5243e-02, -1.5827e-01, -1.0907e-01,
         -1.0630e-01,  5.1279e-02,  6.1186e-02,  2.9297e-02, -2.9883e-01,
          1.9108e-01],
        [-3.1669e-01, -9.0835e-02, -1.4441e-02, -1.0372e-01,  2.9907e-01,
          3.5484e-01,  3.1647e-02,  6.3585e-02, -8.9705e-02,  1.2469e-01,
          1.4652e-02, -2.5007e-01, -2.8156e-02, -8.0191e-02, -1.5843e-02,
         -1.1099e-01],
        [-1.4201e-01, -2.6203e-01,  1.3658e-01,  1.5143e-01, -1.9681e-01,
          5.5609e-02, -7.8356e-02, -2.0421e-01, -9.2538e-02,  1.8140e-02,
          3.3014e-02,  3.2496e-01,  5.3311e-02, -1.0531e-01,  1.8252e-01,
          2.3163e-02],
        [ 2.6289e-01,  7.3464e-02,  1.5079e-01, -2.9619e-01, -2.9623e-01,
          6.4554e-03, -4.2071e-02,  4.6921e-02, -3.1481e-01, -1.3847e-01,
          2.5802e-01,  2.3863e-01,  3.1020e-01,  2.6029e-01, -1.1325e-01,
         -6.9981e-02],
        [-2.4932e-01,  1.7557e-01, -2.0077e-01,  8.6447e-02,  9.0664e-02,
          2.6221e-01,  2.3828e-01,  2.3869e-01,  9.9440e-02,  2.3793e-01,
         -1.2286e-01, -2.0460e-01, -1.4057e-01, -2.0417e-01,  2.6614e-01,
         -1.3408e-01],
        [ 1.6267e-01, -8.7807e-02,  8.9614e-02, -2.2979e-01, -1.1406e-01,
         -3.1642e-01, -2.0785e-01,  1.0027e-01, -3.2512e-01, -5.7281e-02,
          8.0621e-02, -1.4935e-01,  1.3962e-01,  2.1871e-01,  8.6434e-02,
          1.3565e-01],
        [ 3.1107e-01, -8.8564e-02,  2.1469e-01, -2.8039e-02, -2.4196e-01,
         -1.7608e-01, -2.8774e-01,  8.9261e-02,  1.8132e-02, -2.1725e-01,
          2.6566e-02,  1.8373e-01, -1.0922e-01,  7.8101e-02,  5.9014e-02,
          1.4612e-01],
        [-1.2525e-01,  2.5350e-01,  4.5544e-03, -1.3278e-01,  2.0533e-01,
         -8.7538e-02,  2.4356e-01,  3.0854e-01,  1.1798e-01,  1.6842e-02,
         -1.8481e-01, -2.1866e-01, -1.4697e-01, -1.6953e-01,  3.0706e-01,
         -2.0616e-01],
        [ 7.6444e-03, -1.5113e-01,  2.6951e-02,  2.9900e-01, -1.3289e-01,
          3.7353e-02,  1.5532e-01, -1.4711e-01, -6.9288e-02,  1.8255e-01,
          2.3886e-01, -1.7456e-01, -9.6809e-02, -2.9832e-01, -2.0147e-01,
          1.2642e-01],
        [ 3.1342e-01, -1.6402e-01,  5.4739e-03, -1.0500e-01,  6.6792e-02,
         -3.4955e-01, -2.3911e-01, -1.7847e-01, -1.9927e-01, -1.0612e-01,
          2.2900e-01,  1.5931e-01, -1.2777e-01,  2.9207e-01,  1.5261e-01,
          1.7655e-01],
        [ 2.1788e-01,  1.0623e-02,  3.0163e-01, -3.2019e-01, -1.9956e-01,
         -1.3773e-01, -1.4223e-01, -2.5653e-01, -3.2304e-01, -2.8460e-01,
          3.5503e-02,  3.1377e-01,  2.6187e-01,  1.2823e-01, -2.0224e-01,
         -9.6840e-03],
        [ 1.3274e-01, -3.2462e-01,  1.0070e-01, -4.5723e-02,  1.7146e-01,
         -1.7971e-01,  1.3799e-01, -8.4065e-02, -2.7084e-01,  1.2988e-01,
          2.6665e-01, -8.6347e-02, -4.0362e-02,  1.8676e-01, -2.0694e-01,
          2.7551e-01],
        [-1.5085e-02, -1.6886e-01,  3.6054e-02,  1.4369e-01, -1.4548e-01,
         -1.5708e-01,  4.4302e-02, -2.6976e-01, -1.0451e-01, -2.9774e-01,
         -2.1022e-01,  5.0232e-02,  1.2736e-01,  2.8128e-01, -3.0104e-01,
          2.9294e-02],
        [ 1.6910e-01,  4.9499e-03,  2.5240e-01, -2.9129e-01, -1.0919e-01,
         -5.2092e-02, -3.0167e-01,  2.8832e-02, -3.2903e-01,  5.5321e-02,
          9.7315e-02,  3.4930e-02,  1.8342e-01,  2.7273e-01,  1.3799e-01,
          2.5160e-01],
        [-2.5601e-01,  1.6364e-01,  7.4245e-02,  1.4046e-01,  2.1804e-01,
         -3.8766e-02,  2.8441e-01,  9.5962e-02, -1.2764e-01,  4.3201e-02,
          1.5386e-01, -1.9989e-01, -1.5265e-01, -1.6750e-01, -8.0604e-02,
         -6.3475e-02],
        [ 2.5433e-01, -4.5782e-02,  9.0727e-02, -7.5854e-02, -2.4124e-01,
         -2.4338e-01, -9.1010e-02, -2.9460e-01,  3.1634e-02, -6.4955e-02,
          9.0995e-02,  9.1570e-02,  3.0709e-01,  2.9476e-01,  5.4933e-02,
          2.2481e-01],
        [-2.2199e-01,  1.8917e-01, -2.7267e-01,  1.9588e-01, -1.3137e-01,
          1.0460e-01,  2.7967e-01,  2.6115e-01,  3.0892e-01,  1.8218e-01,
          1.0951e-01, -3.6124e-02,  8.3326e-02,  7.3950e-02,  1.1126e-01,
         -1.8399e-01],
        [-2.2854e-01,  3.1831e-02,  8.6400e-03, -4.1053e-02,  1.2527e-01,
          3.3250e-01,  3.1815e-01, -8.3788e-02,  1.6763e-01,  2.6884e-01,
         -2.8687e-01,  4.8987e-02, -2.5912e-01, -2.4844e-01, -4.6566e-02,
         -1.9926e-01],
        [-2.4407e-03, -2.0177e-02,  2.0146e-01,  1.2193e-03,  8.8941e-02,
         -2.6585e-01, -3.3422e-01, -2.9930e-01, -2.3220e-01, -2.1799e-01,
          1.3538e-01, -7.9110e-02, -8.0624e-02,  2.2796e-01, -2.3946e-01,
          1.4720e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1540,  0.0110,  0.0768, -0.0898,  0.0286, -0.1138,  0.0999,  0.1463,
        -0.1223,  0.0248,  0.0656,  0.1300,  0.2108,  0.0733,  0.0516,  0.0342,
        -0.1078, -0.0274,  0.0284, -0.0395, -0.0521,  0.0066, -0.0666,  0.0109,
        -0.1777,  0.2031,  0.0983,  0.0974, -0.1036, -0.2136,  0.1060, -0.0338],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0790,  0.1638, -0.1021, -0.1233,  0.1595,  0.2167, -0.1654, -0.2671,
         -0.1498,  0.2035,  0.1273,  0.2516, -0.0687, -0.2611,  0.1662, -0.0805,
         -0.1848,  0.2227, -0.0999, -0.1306,  0.2718,  0.1195, -0.2561, -0.2739,
         -0.1860, -0.1969, -0.2038,  0.2051, -0.2339,  0.2725,  0.1707, -0.1122]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0095,  0.0653,  0.0879,  ...,  0.0112, -0.1698, -0.1137],
        [-0.1075, -0.0712,  0.1196,  ..., -0.0194, -0.2282,  0.0871],
        [-0.0427,  0.0354,  0.0872,  ...,  0.1369,  0.1286,  0.0345],
        ...,
        [ 0.1035, -0.1123, -0.0123,  ..., -0.0910, -0.0725, -0.1180],
        [ 0.0746, -0.1720, -0.0426,  ..., -0.1452,  0.0377,  0.1557],
        [-0.1736,  0.1104,  0.0604,  ..., -0.0566, -0.1531, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0306,  0.0366, -0.0928, -0.1453, -0.0785,  0.0518, -0.0950,  0.0500,
        -0.0086,  0.0633,  0.0212,  0.0096, -0.0433,  0.0641, -0.0462, -0.0128,
         0.0441, -0.1764, -0.0631,  0.0634, -0.0463,  0.0496,  0.1177,  0.0049,
        -0.0754,  0.1118,  0.0488, -0.0922,  0.0303,  0.1876,  0.1678, -0.1281],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1287, -0.1131, -0.1479,  ...,  0.0179, -0.1109,  0.1127],
        [-0.1340,  0.0480,  0.0273,  ...,  0.1060, -0.1047,  0.1061],
        [ 0.0578, -0.1218, -0.0909,  ..., -0.0956,  0.0887,  0.1175],
        ...,
        [ 0.0609,  0.0247,  0.1541,  ...,  0.0988, -0.1229,  0.2070],
        [ 0.0611, -0.0633, -0.0170,  ...,  0.1906,  0.1298, -0.1097],
        [ 0.0640, -0.0528,  0.1517,  ...,  0.1982,  0.0561,  0.0034]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0963,  0.1334, -0.0247, -0.0752, -0.0387, -0.0632, -0.0369, -0.0827,
         0.1326, -0.1513,  0.1268, -0.1248,  0.1766,  0.0793, -0.1390,  0.0853,
        -0.1388, -0.1684,  0.0426, -0.0219,  0.0144,  0.1113, -0.1913,  0.2056,
        -0.0674, -0.0110,  0.0866, -0.0448, -0.1199, -0.0716,  0.0979,  0.0211],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2059,  0.1243, -0.1737, -0.1538,  0.0170,  0.0225, -0.0849,  0.0117,
          0.1162, -0.1469, -0.0539,  0.0790,  0.0811,  0.0730,  0.1151,  0.0941,
         -0.2058, -0.2092,  0.0478,  0.0422, -0.1128, -0.0955, -0.1895,  0.0687,
          0.1327,  0.2138, -0.1806,  0.1456, -0.0916, -0.1952,  0.1505,  0.1879]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0205], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5810e-01,  3.2222e-01,  5.1338e-02, -8.0751e-02,  6.0026e-02,
          1.0471e-01,  2.3054e-01, -1.1197e-01,  1.1021e-01,  1.9137e-01,
          1.0580e-01, -8.0379e-02, -2.2323e-01, -3.0886e-01,  1.9425e-01,
          1.2407e-01],
        [-1.8454e-01, -1.3238e-01, -3.9662e-02, -7.6975e-02, -1.0760e-01,
          1.8191e-01,  8.5168e-02,  8.5265e-02,  3.2404e-01,  6.4237e-02,
          1.0665e-01, -1.8834e-01,  8.2363e-02,  8.0350e-03,  2.7806e-01,
         -1.8633e-02],
        [ 1.0216e-02,  2.3827e-02,  3.1615e-01, -5.4984e-02,  1.7241e-02,
         -2.7532e-01,  3.7001e-02, -3.3692e-01,  1.2288e-01, -2.1007e-03,
          9.1470e-03, -1.3752e-01,  3.2414e-01,  2.6315e-01,  1.3711e-01,
          1.9668e-01],
        [ 2.0430e-01, -1.6729e-01,  2.0856e-02, -5.5629e-03,  2.2755e-02,
         -1.3323e-01, -7.6594e-02, -2.4852e-02, -3.4615e-01, -3.3575e-01,
          1.9207e-02,  2.9251e-01,  2.3613e-01, -1.6299e-01, -1.4292e-01,
          9.3201e-02],
        [-2.3543e-02,  2.9220e-01, -1.0346e-01, -1.0044e-01,  6.6791e-02,
          1.4859e-02, -4.7495e-02,  2.3918e-01,  6.1942e-02,  2.2316e-01,
          1.4377e-01, -8.4018e-02,  3.6458e-02, -1.8309e-01,  1.8975e-01,
         -9.1037e-02],
        [ 5.9840e-02,  3.3096e-01, -2.9848e-01,  3.3284e-01,  2.4822e-01,
         -8.9963e-02,  1.7965e-01, -1.0180e-01,  1.8036e-01,  1.4504e-01,
         -2.4104e-01, -1.7769e-02, -1.7076e-01,  1.8170e-01,  3.0201e-01,
         -1.6368e-02],
        [ 3.1024e-01, -9.4790e-03,  3.5205e-01, -1.2112e-01,  7.6157e-03,
         -1.5760e-01, -1.1375e-01, -1.8165e-01, -1.9744e-01,  3.8555e-02,
          4.9999e-02,  2.3981e-03, -1.1134e-01,  1.8633e-01, -2.5773e-01,
          9.9195e-02],
        [-1.1162e-01,  1.1933e-01,  3.1041e-01, -2.9681e-01, -2.8122e-01,
         -2.5500e-01, -3.2957e-02, -2.2314e-01, -1.5128e-01, -1.6323e-01,
          2.6958e-04, -1.3455e-02,  2.1490e-01, -1.1944e-01, -5.8669e-02,
          3.0959e-01],
        [-3.2866e-02,  1.0599e-01,  2.3928e-01, -1.7562e-01,  3.5888e-02,
         -2.8013e-01, -8.4488e-02, -2.8658e-02,  1.2054e-01, -2.4504e-01,
         -9.8847e-02, -1.6770e-02, -1.4316e-01,  1.1580e-01, -2.5745e-01,
          3.3907e-02],
        [-2.1904e-01,  1.0449e-01, -3.5245e-02, -8.5019e-02, -1.9166e-02,
          8.8175e-02, -3.7224e-02,  1.6032e-01,  1.8988e-01, -7.0956e-02,
          1.4541e-01,  6.7846e-02, -1.8173e-01, -3.0118e-02,  8.5126e-02,
         -1.3822e-01],
        [-2.8607e-01,  2.9225e-01,  5.5396e-04, -1.0216e-01, -1.2741e-01,
          3.6045e-01,  1.5345e-01,  4.8974e-02,  2.7875e-01,  1.8954e-01,
          2.5032e-03,  7.9204e-02, -1.2183e-01,  1.5924e-01, -8.8663e-02,
         -2.7037e-01],
        [-6.6503e-02,  5.4610e-02,  3.0640e-02,  2.6896e-02,  9.1156e-02,
          6.4199e-02,  2.9385e-01,  8.5938e-02,  9.7030e-02,  2.8988e-01,
          1.6319e-01,  1.2732e-01, -3.5227e-01, -2.0865e-01,  4.9198e-03,
         -1.5737e-01],
        [ 2.4301e-01,  3.3505e-02,  8.3516e-02, -8.6238e-02,  2.4764e-03,
          1.0968e-01,  2.4045e-02, -2.1965e-01, -2.2694e-01, -2.5175e-02,
          1.0793e-02, -5.8156e-02, -1.4390e-01,  1.0336e-01, -1.3866e-01,
         -5.0602e-02],
        [ 1.5291e-01,  1.5192e-01,  3.1711e-01,  4.8142e-02, -2.4094e-01,
          3.1461e-02,  2.3653e-02, -1.5243e-02, -1.5827e-01, -1.0907e-01,
         -1.0630e-01,  5.1279e-02,  6.1186e-02,  2.9297e-02, -2.9883e-01,
          1.9108e-01],
        [-3.1669e-01, -9.0835e-02, -1.4441e-02, -1.0372e-01,  2.9907e-01,
          3.5484e-01,  3.1647e-02,  6.3585e-02, -8.9705e-02,  1.2469e-01,
          1.4652e-02, -2.5007e-01, -2.8156e-02, -8.0191e-02, -1.5843e-02,
         -1.1099e-01],
        [-1.4201e-01, -2.6203e-01,  1.3658e-01,  1.5143e-01, -1.9681e-01,
          5.5609e-02, -7.8356e-02, -2.0421e-01, -9.2538e-02,  1.8140e-02,
          3.3014e-02,  3.2496e-01,  5.3311e-02, -1.0531e-01,  1.8252e-01,
          2.3163e-02],
        [ 2.6289e-01,  7.3464e-02,  1.5079e-01, -2.9619e-01, -2.9623e-01,
          6.4554e-03, -4.2071e-02,  4.6921e-02, -3.1481e-01, -1.3847e-01,
          2.5802e-01,  2.3863e-01,  3.1020e-01,  2.6029e-01, -1.1325e-01,
         -6.9981e-02],
        [-2.4932e-01,  1.7557e-01, -2.0077e-01,  8.6447e-02,  9.0664e-02,
          2.6221e-01,  2.3828e-01,  2.3869e-01,  9.9440e-02,  2.3793e-01,
         -1.2286e-01, -2.0460e-01, -1.4057e-01, -2.0417e-01,  2.6614e-01,
         -1.3408e-01],
        [ 1.6267e-01, -8.7807e-02,  8.9614e-02, -2.2979e-01, -1.1406e-01,
         -3.1642e-01, -2.0785e-01,  1.0027e-01, -3.2512e-01, -5.7281e-02,
          8.0621e-02, -1.4935e-01,  1.3962e-01,  2.1871e-01,  8.6434e-02,
          1.3565e-01],
        [ 3.1107e-01, -8.8564e-02,  2.1469e-01, -2.8039e-02, -2.4196e-01,
         -1.7608e-01, -2.8774e-01,  8.9261e-02,  1.8132e-02, -2.1725e-01,
          2.6566e-02,  1.8373e-01, -1.0922e-01,  7.8101e-02,  5.9014e-02,
          1.4612e-01],
        [-1.2525e-01,  2.5350e-01,  4.5544e-03, -1.3278e-01,  2.0533e-01,
         -8.7538e-02,  2.4356e-01,  3.0854e-01,  1.1798e-01,  1.6842e-02,
         -1.8481e-01, -2.1866e-01, -1.4697e-01, -1.6953e-01,  3.0706e-01,
         -2.0616e-01],
        [ 7.6444e-03, -1.5113e-01,  2.6951e-02,  2.9900e-01, -1.3289e-01,
          3.7353e-02,  1.5532e-01, -1.4711e-01, -6.9288e-02,  1.8255e-01,
          2.3886e-01, -1.7456e-01, -9.6809e-02, -2.9832e-01, -2.0147e-01,
          1.2642e-01],
        [ 3.1342e-01, -1.6402e-01,  5.4739e-03, -1.0500e-01,  6.6792e-02,
         -3.4955e-01, -2.3911e-01, -1.7847e-01, -1.9927e-01, -1.0612e-01,
          2.2900e-01,  1.5931e-01, -1.2777e-01,  2.9207e-01,  1.5261e-01,
          1.7655e-01],
        [ 2.1788e-01,  1.0623e-02,  3.0163e-01, -3.2019e-01, -1.9956e-01,
         -1.3773e-01, -1.4223e-01, -2.5653e-01, -3.2304e-01, -2.8460e-01,
          3.5503e-02,  3.1377e-01,  2.6187e-01,  1.2823e-01, -2.0224e-01,
         -9.6840e-03],
        [ 1.3274e-01, -3.2462e-01,  1.0070e-01, -4.5723e-02,  1.7146e-01,
         -1.7971e-01,  1.3799e-01, -8.4065e-02, -2.7084e-01,  1.2988e-01,
          2.6665e-01, -8.6347e-02, -4.0362e-02,  1.8676e-01, -2.0694e-01,
          2.7551e-01],
        [-1.5085e-02, -1.6886e-01,  3.6054e-02,  1.4369e-01, -1.4548e-01,
         -1.5708e-01,  4.4302e-02, -2.6976e-01, -1.0451e-01, -2.9774e-01,
         -2.1022e-01,  5.0232e-02,  1.2736e-01,  2.8128e-01, -3.0104e-01,
          2.9294e-02],
        [ 1.6910e-01,  4.9499e-03,  2.5240e-01, -2.9129e-01, -1.0919e-01,
         -5.2092e-02, -3.0167e-01,  2.8832e-02, -3.2903e-01,  5.5321e-02,
          9.7315e-02,  3.4930e-02,  1.8342e-01,  2.7273e-01,  1.3799e-01,
          2.5160e-01],
        [-2.5601e-01,  1.6364e-01,  7.4245e-02,  1.4046e-01,  2.1804e-01,
         -3.8766e-02,  2.8441e-01,  9.5962e-02, -1.2764e-01,  4.3201e-02,
          1.5386e-01, -1.9989e-01, -1.5265e-01, -1.6750e-01, -8.0604e-02,
         -6.3475e-02],
        [ 2.5433e-01, -4.5782e-02,  9.0727e-02, -7.5854e-02, -2.4124e-01,
         -2.4338e-01, -9.1010e-02, -2.9460e-01,  3.1634e-02, -6.4955e-02,
          9.0995e-02,  9.1570e-02,  3.0709e-01,  2.9476e-01,  5.4933e-02,
          2.2481e-01],
        [-2.2199e-01,  1.8917e-01, -2.7267e-01,  1.9588e-01, -1.3137e-01,
          1.0460e-01,  2.7967e-01,  2.6115e-01,  3.0892e-01,  1.8218e-01,
          1.0951e-01, -3.6124e-02,  8.3326e-02,  7.3950e-02,  1.1126e-01,
         -1.8399e-01],
        [-2.2854e-01,  3.1831e-02,  8.6400e-03, -4.1053e-02,  1.2527e-01,
          3.3250e-01,  3.1815e-01, -8.3788e-02,  1.6763e-01,  2.6884e-01,
         -2.8687e-01,  4.8987e-02, -2.5912e-01, -2.4844e-01, -4.6566e-02,
         -1.9926e-01],
        [-2.4407e-03, -2.0177e-02,  2.0146e-01,  1.2193e-03,  8.8941e-02,
         -2.6585e-01, -3.3422e-01, -2.9930e-01, -2.3220e-01, -2.1799e-01,
          1.3538e-01, -7.9110e-02, -8.0624e-02,  2.2796e-01, -2.3946e-01,
          1.4720e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1540,  0.0110,  0.0768, -0.0898,  0.0286, -0.1138,  0.0999,  0.1463,
        -0.1223,  0.0248,  0.0656,  0.1300,  0.2108,  0.0733,  0.0516,  0.0342,
        -0.1078, -0.0274,  0.0284, -0.0395, -0.0521,  0.0066, -0.0666,  0.0109,
        -0.1777,  0.2031,  0.0983,  0.0974, -0.1036, -0.2136,  0.1060, -0.0338],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0790,  0.1638, -0.1021, -0.1233,  0.1595,  0.2167, -0.1654, -0.2671,
         -0.1498,  0.2035,  0.1273,  0.2516, -0.0687, -0.2611,  0.1662, -0.0805,
         -0.1848,  0.2227, -0.0999, -0.1306,  0.2718,  0.1195, -0.2561, -0.2739,
         -0.1860, -0.1969, -0.2038,  0.2051, -0.2339,  0.2725,  0.1707, -0.1122]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0095,  0.0653,  0.0879,  ...,  0.0112, -0.1698, -0.1137],
        [-0.1075, -0.0712,  0.1196,  ..., -0.0194, -0.2282,  0.0871],
        [-0.0427,  0.0354,  0.0872,  ...,  0.1369,  0.1286,  0.0345],
        ...,
        [ 0.1035, -0.1123, -0.0123,  ..., -0.0910, -0.0725, -0.1180],
        [ 0.0746, -0.1720, -0.0426,  ..., -0.1452,  0.0377,  0.1557],
        [-0.1736,  0.1104,  0.0604,  ..., -0.0566, -0.1531, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0306,  0.0366, -0.0928, -0.1453, -0.0785,  0.0518, -0.0950,  0.0500,
        -0.0086,  0.0633,  0.0212,  0.0096, -0.0433,  0.0641, -0.0462, -0.0128,
         0.0441, -0.1764, -0.0631,  0.0634, -0.0463,  0.0496,  0.1177,  0.0049,
        -0.0754,  0.1118,  0.0488, -0.0922,  0.0303,  0.1876,  0.1678, -0.1281],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1287, -0.1131, -0.1479,  ...,  0.0179, -0.1109,  0.1127],
        [-0.1340,  0.0480,  0.0273,  ...,  0.1060, -0.1047,  0.1061],
        [ 0.0578, -0.1218, -0.0909,  ..., -0.0956,  0.0887,  0.1175],
        ...,
        [ 0.0609,  0.0247,  0.1541,  ...,  0.0988, -0.1229,  0.2070],
        [ 0.0611, -0.0633, -0.0170,  ...,  0.1906,  0.1298, -0.1097],
        [ 0.0640, -0.0528,  0.1517,  ...,  0.1982,  0.0561,  0.0034]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0963,  0.1334, -0.0247, -0.0752, -0.0387, -0.0632, -0.0369, -0.0827,
         0.1326, -0.1513,  0.1268, -0.1248,  0.1766,  0.0793, -0.1390,  0.0853,
        -0.1388, -0.1684,  0.0426, -0.0219,  0.0144,  0.1113, -0.1913,  0.2056,
        -0.0674, -0.0110,  0.0866, -0.0448, -0.1199, -0.0716,  0.0979,  0.0211],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2059,  0.1243, -0.1737, -0.1538,  0.0170,  0.0225, -0.0849,  0.0117,
          0.1162, -0.1469, -0.0539,  0.0790,  0.0811,  0.0730,  0.1151,  0.0941,
         -0.2058, -0.2092,  0.0478,  0.0422, -0.1128, -0.0955, -0.1895,  0.0687,
          0.1327,  0.2138, -0.1806,  0.1456, -0.0916, -0.1952,  0.1505,  0.1879]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0205], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5810e-01,  3.2222e-01,  5.1338e-02, -8.0751e-02,  6.0026e-02,
          1.0471e-01,  2.3054e-01, -1.1197e-01,  1.1021e-01,  1.9137e-01,
          1.0580e-01, -8.0379e-02, -2.2323e-01, -3.0886e-01,  1.9425e-01,
          1.2407e-01],
        [-1.8454e-01, -1.3238e-01, -3.9662e-02, -7.6975e-02, -1.0760e-01,
          1.8191e-01,  8.5168e-02,  8.5265e-02,  3.2404e-01,  6.4237e-02,
          1.0665e-01, -1.8834e-01,  8.2363e-02,  8.0350e-03,  2.7806e-01,
         -1.8633e-02],
        [ 1.0216e-02,  2.3827e-02,  3.1615e-01, -5.4984e-02,  1.7241e-02,
         -2.7532e-01,  3.7001e-02, -3.3692e-01,  1.2288e-01, -2.1007e-03,
          9.1470e-03, -1.3752e-01,  3.2414e-01,  2.6315e-01,  1.3711e-01,
          1.9668e-01],
        [ 2.0430e-01, -1.6729e-01,  2.0856e-02, -5.5629e-03,  2.2755e-02,
         -1.3323e-01, -7.6594e-02, -2.4852e-02, -3.4615e-01, -3.3575e-01,
          1.9207e-02,  2.9251e-01,  2.3613e-01, -1.6299e-01, -1.4292e-01,
          9.3201e-02],
        [-2.3543e-02,  2.9220e-01, -1.0346e-01, -1.0044e-01,  6.6791e-02,
          1.4859e-02, -4.7495e-02,  2.3918e-01,  6.1942e-02,  2.2316e-01,
          1.4377e-01, -8.4018e-02,  3.6458e-02, -1.8309e-01,  1.8975e-01,
         -9.1037e-02],
        [ 5.9840e-02,  3.3096e-01, -2.9848e-01,  3.3284e-01,  2.4822e-01,
         -8.9963e-02,  1.7965e-01, -1.0180e-01,  1.8036e-01,  1.4504e-01,
         -2.4104e-01, -1.7769e-02, -1.7076e-01,  1.8170e-01,  3.0201e-01,
         -1.6368e-02],
        [ 3.1024e-01, -9.4790e-03,  3.5205e-01, -1.2112e-01,  7.6157e-03,
         -1.5760e-01, -1.1375e-01, -1.8165e-01, -1.9744e-01,  3.8555e-02,
          4.9999e-02,  2.3981e-03, -1.1134e-01,  1.8633e-01, -2.5773e-01,
          9.9195e-02],
        [-1.1162e-01,  1.1933e-01,  3.1041e-01, -2.9681e-01, -2.8122e-01,
         -2.5500e-01, -3.2957e-02, -2.2314e-01, -1.5128e-01, -1.6323e-01,
          2.6958e-04, -1.3455e-02,  2.1490e-01, -1.1944e-01, -5.8669e-02,
          3.0959e-01],
        [-3.2866e-02,  1.0599e-01,  2.3928e-01, -1.7562e-01,  3.5888e-02,
         -2.8013e-01, -8.4488e-02, -2.8658e-02,  1.2054e-01, -2.4504e-01,
         -9.8847e-02, -1.6770e-02, -1.4316e-01,  1.1580e-01, -2.5745e-01,
          3.3907e-02],
        [-2.1904e-01,  1.0449e-01, -3.5245e-02, -8.5019e-02, -1.9166e-02,
          8.8175e-02, -3.7224e-02,  1.6032e-01,  1.8988e-01, -7.0956e-02,
          1.4541e-01,  6.7846e-02, -1.8173e-01, -3.0118e-02,  8.5126e-02,
         -1.3822e-01],
        [-2.8607e-01,  2.9225e-01,  5.5396e-04, -1.0216e-01, -1.2741e-01,
          3.6045e-01,  1.5345e-01,  4.8974e-02,  2.7875e-01,  1.8954e-01,
          2.5032e-03,  7.9204e-02, -1.2183e-01,  1.5924e-01, -8.8663e-02,
         -2.7037e-01],
        [-6.6503e-02,  5.4610e-02,  3.0640e-02,  2.6896e-02,  9.1156e-02,
          6.4199e-02,  2.9385e-01,  8.5938e-02,  9.7030e-02,  2.8988e-01,
          1.6319e-01,  1.2732e-01, -3.5227e-01, -2.0865e-01,  4.9198e-03,
         -1.5737e-01],
        [ 2.4301e-01,  3.3505e-02,  8.3516e-02, -8.6238e-02,  2.4764e-03,
          1.0968e-01,  2.4045e-02, -2.1965e-01, -2.2694e-01, -2.5175e-02,
          1.0793e-02, -5.8156e-02, -1.4390e-01,  1.0336e-01, -1.3866e-01,
         -5.0602e-02],
        [ 1.5291e-01,  1.5192e-01,  3.1711e-01,  4.8142e-02, -2.4094e-01,
          3.1461e-02,  2.3653e-02, -1.5243e-02, -1.5827e-01, -1.0907e-01,
         -1.0630e-01,  5.1279e-02,  6.1186e-02,  2.9297e-02, -2.9883e-01,
          1.9108e-01],
        [-3.1669e-01, -9.0835e-02, -1.4441e-02, -1.0372e-01,  2.9907e-01,
          3.5484e-01,  3.1647e-02,  6.3585e-02, -8.9705e-02,  1.2469e-01,
          1.4652e-02, -2.5007e-01, -2.8156e-02, -8.0191e-02, -1.5843e-02,
         -1.1099e-01],
        [-1.4201e-01, -2.6203e-01,  1.3658e-01,  1.5143e-01, -1.9681e-01,
          5.5609e-02, -7.8356e-02, -2.0421e-01, -9.2538e-02,  1.8140e-02,
          3.3014e-02,  3.2496e-01,  5.3311e-02, -1.0531e-01,  1.8252e-01,
          2.3163e-02],
        [ 2.6289e-01,  7.3464e-02,  1.5079e-01, -2.9619e-01, -2.9623e-01,
          6.4554e-03, -4.2071e-02,  4.6921e-02, -3.1481e-01, -1.3847e-01,
          2.5802e-01,  2.3863e-01,  3.1020e-01,  2.6029e-01, -1.1325e-01,
         -6.9981e-02],
        [-2.4932e-01,  1.7557e-01, -2.0077e-01,  8.6447e-02,  9.0664e-02,
          2.6221e-01,  2.3828e-01,  2.3869e-01,  9.9440e-02,  2.3793e-01,
         -1.2286e-01, -2.0460e-01, -1.4057e-01, -2.0417e-01,  2.6614e-01,
         -1.3408e-01],
        [ 1.6267e-01, -8.7807e-02,  8.9614e-02, -2.2979e-01, -1.1406e-01,
         -3.1642e-01, -2.0785e-01,  1.0027e-01, -3.2512e-01, -5.7281e-02,
          8.0621e-02, -1.4935e-01,  1.3962e-01,  2.1871e-01,  8.6434e-02,
          1.3565e-01],
        [ 3.1107e-01, -8.8564e-02,  2.1469e-01, -2.8039e-02, -2.4196e-01,
         -1.7608e-01, -2.8774e-01,  8.9261e-02,  1.8132e-02, -2.1725e-01,
          2.6566e-02,  1.8373e-01, -1.0922e-01,  7.8101e-02,  5.9014e-02,
          1.4612e-01],
        [-1.2525e-01,  2.5350e-01,  4.5544e-03, -1.3278e-01,  2.0533e-01,
         -8.7538e-02,  2.4356e-01,  3.0854e-01,  1.1798e-01,  1.6842e-02,
         -1.8481e-01, -2.1866e-01, -1.4697e-01, -1.6953e-01,  3.0706e-01,
         -2.0616e-01],
        [ 7.6444e-03, -1.5113e-01,  2.6951e-02,  2.9900e-01, -1.3289e-01,
          3.7353e-02,  1.5532e-01, -1.4711e-01, -6.9288e-02,  1.8255e-01,
          2.3886e-01, -1.7456e-01, -9.6809e-02, -2.9832e-01, -2.0147e-01,
          1.2642e-01],
        [ 3.1342e-01, -1.6402e-01,  5.4739e-03, -1.0500e-01,  6.6792e-02,
         -3.4955e-01, -2.3911e-01, -1.7847e-01, -1.9927e-01, -1.0612e-01,
          2.2900e-01,  1.5931e-01, -1.2777e-01,  2.9207e-01,  1.5261e-01,
          1.7655e-01],
        [ 2.1788e-01,  1.0623e-02,  3.0163e-01, -3.2019e-01, -1.9956e-01,
         -1.3773e-01, -1.4223e-01, -2.5653e-01, -3.2304e-01, -2.8460e-01,
          3.5503e-02,  3.1377e-01,  2.6187e-01,  1.2823e-01, -2.0224e-01,
         -9.6840e-03],
        [ 1.3274e-01, -3.2462e-01,  1.0070e-01, -4.5723e-02,  1.7146e-01,
         -1.7971e-01,  1.3799e-01, -8.4065e-02, -2.7084e-01,  1.2988e-01,
          2.6665e-01, -8.6347e-02, -4.0362e-02,  1.8676e-01, -2.0694e-01,
          2.7551e-01],
        [-1.5085e-02, -1.6886e-01,  3.6054e-02,  1.4369e-01, -1.4548e-01,
         -1.5708e-01,  4.4302e-02, -2.6976e-01, -1.0451e-01, -2.9774e-01,
         -2.1022e-01,  5.0232e-02,  1.2736e-01,  2.8128e-01, -3.0104e-01,
          2.9294e-02],
        [ 1.6910e-01,  4.9499e-03,  2.5240e-01, -2.9129e-01, -1.0919e-01,
         -5.2092e-02, -3.0167e-01,  2.8832e-02, -3.2903e-01,  5.5321e-02,
          9.7315e-02,  3.4930e-02,  1.8342e-01,  2.7273e-01,  1.3799e-01,
          2.5160e-01],
        [-2.5601e-01,  1.6364e-01,  7.4245e-02,  1.4046e-01,  2.1804e-01,
         -3.8766e-02,  2.8441e-01,  9.5962e-02, -1.2764e-01,  4.3201e-02,
          1.5386e-01, -1.9989e-01, -1.5265e-01, -1.6750e-01, -8.0604e-02,
         -6.3475e-02],
        [ 2.5433e-01, -4.5782e-02,  9.0727e-02, -7.5854e-02, -2.4124e-01,
         -2.4338e-01, -9.1010e-02, -2.9460e-01,  3.1634e-02, -6.4955e-02,
          9.0995e-02,  9.1570e-02,  3.0709e-01,  2.9476e-01,  5.4933e-02,
          2.2481e-01],
        [-2.2199e-01,  1.8917e-01, -2.7267e-01,  1.9588e-01, -1.3137e-01,
          1.0460e-01,  2.7967e-01,  2.6115e-01,  3.0892e-01,  1.8218e-01,
          1.0951e-01, -3.6124e-02,  8.3326e-02,  7.3950e-02,  1.1126e-01,
         -1.8399e-01],
        [-2.2854e-01,  3.1831e-02,  8.6400e-03, -4.1053e-02,  1.2527e-01,
          3.3250e-01,  3.1815e-01, -8.3788e-02,  1.6763e-01,  2.6884e-01,
         -2.8687e-01,  4.8987e-02, -2.5912e-01, -2.4844e-01, -4.6566e-02,
         -1.9926e-01],
        [-2.4407e-03, -2.0177e-02,  2.0146e-01,  1.2193e-03,  8.8941e-02,
         -2.6585e-01, -3.3422e-01, -2.9930e-01, -2.3220e-01, -2.1799e-01,
          1.3538e-01, -7.9110e-02, -8.0624e-02,  2.2796e-01, -2.3946e-01,
          1.4720e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1540,  0.0110,  0.0768, -0.0898,  0.0286, -0.1138,  0.0999,  0.1463,
        -0.1223,  0.0248,  0.0656,  0.1300,  0.2108,  0.0733,  0.0516,  0.0342,
        -0.1078, -0.0274,  0.0284, -0.0395, -0.0521,  0.0066, -0.0666,  0.0109,
        -0.1777,  0.2031,  0.0983,  0.0974, -0.1036, -0.2136,  0.1060, -0.0338],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0790,  0.1638, -0.1021, -0.1233,  0.1595,  0.2167, -0.1654, -0.2671,
         -0.1498,  0.2035,  0.1273,  0.2516, -0.0687, -0.2611,  0.1662, -0.0805,
         -0.1848,  0.2227, -0.0999, -0.1306,  0.2718,  0.1195, -0.2561, -0.2739,
         -0.1860, -0.1969, -0.2038,  0.2051, -0.2339,  0.2725,  0.1707, -0.1122]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0095,  0.0653,  0.0879,  ...,  0.0112, -0.1698, -0.1137],
        [-0.1075, -0.0712,  0.1196,  ..., -0.0194, -0.2282,  0.0871],
        [-0.0427,  0.0354,  0.0872,  ...,  0.1369,  0.1286,  0.0345],
        ...,
        [ 0.1035, -0.1123, -0.0123,  ..., -0.0910, -0.0725, -0.1180],
        [ 0.0746, -0.1720, -0.0426,  ..., -0.1452,  0.0377,  0.1557],
        [-0.1736,  0.1104,  0.0604,  ..., -0.0566, -0.1531, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0306,  0.0366, -0.0928, -0.1453, -0.0785,  0.0518, -0.0950,  0.0500,
        -0.0086,  0.0633,  0.0212,  0.0096, -0.0433,  0.0641, -0.0462, -0.0128,
         0.0441, -0.1764, -0.0631,  0.0634, -0.0463,  0.0496,  0.1177,  0.0049,
        -0.0754,  0.1118,  0.0488, -0.0922,  0.0303,  0.1876,  0.1678, -0.1281],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1287, -0.1131, -0.1479,  ...,  0.0179, -0.1109,  0.1127],
        [-0.1340,  0.0480,  0.0273,  ...,  0.1060, -0.1047,  0.1061],
        [ 0.0578, -0.1218, -0.0909,  ..., -0.0956,  0.0887,  0.1175],
        ...,
        [ 0.0609,  0.0247,  0.1541,  ...,  0.0988, -0.1229,  0.2070],
        [ 0.0611, -0.0633, -0.0170,  ...,  0.1906,  0.1298, -0.1097],
        [ 0.0640, -0.0528,  0.1517,  ...,  0.1982,  0.0561,  0.0034]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0963,  0.1334, -0.0247, -0.0752, -0.0387, -0.0632, -0.0369, -0.0827,
         0.1326, -0.1513,  0.1268, -0.1248,  0.1766,  0.0793, -0.1390,  0.0853,
        -0.1388, -0.1684,  0.0426, -0.0219,  0.0144,  0.1113, -0.1913,  0.2056,
        -0.0674, -0.0110,  0.0866, -0.0448, -0.1199, -0.0716,  0.0979,  0.0211],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2059,  0.1243, -0.1737, -0.1538,  0.0170,  0.0225, -0.0849,  0.0117,
          0.1162, -0.1469, -0.0539,  0.0790,  0.0811,  0.0730,  0.1151,  0.0941,
         -0.2058, -0.2092,  0.0478,  0.0422, -0.1128, -0.0955, -0.1895,  0.0687,
          0.1327,  0.2138, -0.1806,  0.1456, -0.0916, -0.1952,  0.1505,  0.1879]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0205], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5810e-01,  3.2222e-01,  5.1338e-02, -8.0751e-02,  6.0026e-02,
          1.0471e-01,  2.3054e-01, -1.1197e-01,  1.1021e-01,  1.9137e-01,
          1.0580e-01, -8.0379e-02, -2.2323e-01, -3.0886e-01,  1.9425e-01,
          1.2407e-01],
        [-1.8454e-01, -1.3238e-01, -3.9662e-02, -7.6975e-02, -1.0760e-01,
          1.8191e-01,  8.5168e-02,  8.5265e-02,  3.2404e-01,  6.4237e-02,
          1.0665e-01, -1.8834e-01,  8.2363e-02,  8.0350e-03,  2.7806e-01,
         -1.8633e-02],
        [ 1.0216e-02,  2.3827e-02,  3.1615e-01, -5.4984e-02,  1.7241e-02,
         -2.7532e-01,  3.7001e-02, -3.3692e-01,  1.2288e-01, -2.1007e-03,
          9.1470e-03, -1.3752e-01,  3.2414e-01,  2.6315e-01,  1.3711e-01,
          1.9668e-01],
        [ 2.0430e-01, -1.6729e-01,  2.0856e-02, -5.5629e-03,  2.2755e-02,
         -1.3323e-01, -7.6594e-02, -2.4852e-02, -3.4615e-01, -3.3575e-01,
          1.9207e-02,  2.9251e-01,  2.3613e-01, -1.6299e-01, -1.4292e-01,
          9.3201e-02],
        [-2.3543e-02,  2.9220e-01, -1.0346e-01, -1.0044e-01,  6.6791e-02,
          1.4859e-02, -4.7495e-02,  2.3918e-01,  6.1942e-02,  2.2316e-01,
          1.4377e-01, -8.4018e-02,  3.6458e-02, -1.8309e-01,  1.8975e-01,
         -9.1037e-02],
        [ 5.9840e-02,  3.3096e-01, -2.9848e-01,  3.3284e-01,  2.4822e-01,
         -8.9963e-02,  1.7965e-01, -1.0180e-01,  1.8036e-01,  1.4504e-01,
         -2.4104e-01, -1.7769e-02, -1.7076e-01,  1.8170e-01,  3.0201e-01,
         -1.6368e-02],
        [ 3.1024e-01, -9.4790e-03,  3.5205e-01, -1.2112e-01,  7.6157e-03,
         -1.5760e-01, -1.1375e-01, -1.8165e-01, -1.9744e-01,  3.8555e-02,
          4.9999e-02,  2.3981e-03, -1.1134e-01,  1.8633e-01, -2.5773e-01,
          9.9195e-02],
        [-1.1162e-01,  1.1933e-01,  3.1041e-01, -2.9681e-01, -2.8122e-01,
         -2.5500e-01, -3.2957e-02, -2.2314e-01, -1.5128e-01, -1.6323e-01,
          2.6958e-04, -1.3455e-02,  2.1490e-01, -1.1944e-01, -5.8669e-02,
          3.0959e-01],
        [-3.2866e-02,  1.0599e-01,  2.3928e-01, -1.7562e-01,  3.5888e-02,
         -2.8013e-01, -8.4488e-02, -2.8658e-02,  1.2054e-01, -2.4504e-01,
         -9.8847e-02, -1.6770e-02, -1.4316e-01,  1.1580e-01, -2.5745e-01,
          3.3907e-02],
        [-2.1904e-01,  1.0449e-01, -3.5245e-02, -8.5019e-02, -1.9166e-02,
          8.8175e-02, -3.7224e-02,  1.6032e-01,  1.8988e-01, -7.0956e-02,
          1.4541e-01,  6.7846e-02, -1.8173e-01, -3.0118e-02,  8.5126e-02,
         -1.3822e-01],
        [-2.8607e-01,  2.9225e-01,  5.5396e-04, -1.0216e-01, -1.2741e-01,
          3.6045e-01,  1.5345e-01,  4.8974e-02,  2.7875e-01,  1.8954e-01,
          2.5032e-03,  7.9204e-02, -1.2183e-01,  1.5924e-01, -8.8663e-02,
         -2.7037e-01],
        [-6.6503e-02,  5.4610e-02,  3.0640e-02,  2.6896e-02,  9.1156e-02,
          6.4199e-02,  2.9385e-01,  8.5938e-02,  9.7030e-02,  2.8988e-01,
          1.6319e-01,  1.2732e-01, -3.5227e-01, -2.0865e-01,  4.9198e-03,
         -1.5737e-01],
        [ 2.4301e-01,  3.3505e-02,  8.3516e-02, -8.6238e-02,  2.4764e-03,
          1.0968e-01,  2.4045e-02, -2.1965e-01, -2.2694e-01, -2.5175e-02,
          1.0793e-02, -5.8156e-02, -1.4390e-01,  1.0336e-01, -1.3866e-01,
         -5.0602e-02],
        [ 1.5291e-01,  1.5192e-01,  3.1711e-01,  4.8142e-02, -2.4094e-01,
          3.1461e-02,  2.3653e-02, -1.5243e-02, -1.5827e-01, -1.0907e-01,
         -1.0630e-01,  5.1279e-02,  6.1186e-02,  2.9297e-02, -2.9883e-01,
          1.9108e-01],
        [-3.1669e-01, -9.0835e-02, -1.4441e-02, -1.0372e-01,  2.9907e-01,
          3.5484e-01,  3.1647e-02,  6.3585e-02, -8.9705e-02,  1.2469e-01,
          1.4652e-02, -2.5007e-01, -2.8156e-02, -8.0191e-02, -1.5843e-02,
         -1.1099e-01],
        [-1.4201e-01, -2.6203e-01,  1.3658e-01,  1.5143e-01, -1.9681e-01,
          5.5609e-02, -7.8356e-02, -2.0421e-01, -9.2538e-02,  1.8140e-02,
          3.3014e-02,  3.2496e-01,  5.3311e-02, -1.0531e-01,  1.8252e-01,
          2.3163e-02],
        [ 2.6289e-01,  7.3464e-02,  1.5079e-01, -2.9619e-01, -2.9623e-01,
          6.4554e-03, -4.2071e-02,  4.6921e-02, -3.1481e-01, -1.3847e-01,
          2.5802e-01,  2.3863e-01,  3.1020e-01,  2.6029e-01, -1.1325e-01,
         -6.9981e-02],
        [-2.4932e-01,  1.7557e-01, -2.0077e-01,  8.6447e-02,  9.0664e-02,
          2.6221e-01,  2.3828e-01,  2.3869e-01,  9.9440e-02,  2.3793e-01,
         -1.2286e-01, -2.0460e-01, -1.4057e-01, -2.0417e-01,  2.6614e-01,
         -1.3408e-01],
        [ 1.6267e-01, -8.7807e-02,  8.9614e-02, -2.2979e-01, -1.1406e-01,
         -3.1642e-01, -2.0785e-01,  1.0027e-01, -3.2512e-01, -5.7281e-02,
          8.0621e-02, -1.4935e-01,  1.3962e-01,  2.1871e-01,  8.6434e-02,
          1.3565e-01],
        [ 3.1107e-01, -8.8564e-02,  2.1469e-01, -2.8039e-02, -2.4196e-01,
         -1.7608e-01, -2.8774e-01,  8.9261e-02,  1.8132e-02, -2.1725e-01,
          2.6566e-02,  1.8373e-01, -1.0922e-01,  7.8101e-02,  5.9014e-02,
          1.4612e-01],
        [-1.2525e-01,  2.5350e-01,  4.5544e-03, -1.3278e-01,  2.0533e-01,
         -8.7538e-02,  2.4356e-01,  3.0854e-01,  1.1798e-01,  1.6842e-02,
         -1.8481e-01, -2.1866e-01, -1.4697e-01, -1.6953e-01,  3.0706e-01,
         -2.0616e-01],
        [ 7.6444e-03, -1.5113e-01,  2.6951e-02,  2.9900e-01, -1.3289e-01,
          3.7353e-02,  1.5532e-01, -1.4711e-01, -6.9288e-02,  1.8255e-01,
          2.3886e-01, -1.7456e-01, -9.6809e-02, -2.9832e-01, -2.0147e-01,
          1.2642e-01],
        [ 3.1342e-01, -1.6402e-01,  5.4739e-03, -1.0500e-01,  6.6792e-02,
         -3.4955e-01, -2.3911e-01, -1.7847e-01, -1.9927e-01, -1.0612e-01,
          2.2900e-01,  1.5931e-01, -1.2777e-01,  2.9207e-01,  1.5261e-01,
          1.7655e-01],
        [ 2.1788e-01,  1.0623e-02,  3.0163e-01, -3.2019e-01, -1.9956e-01,
         -1.3773e-01, -1.4223e-01, -2.5653e-01, -3.2304e-01, -2.8460e-01,
          3.5503e-02,  3.1377e-01,  2.6187e-01,  1.2823e-01, -2.0224e-01,
         -9.6840e-03],
        [ 1.3274e-01, -3.2462e-01,  1.0070e-01, -4.5723e-02,  1.7146e-01,
         -1.7971e-01,  1.3799e-01, -8.4065e-02, -2.7084e-01,  1.2988e-01,
          2.6665e-01, -8.6347e-02, -4.0362e-02,  1.8676e-01, -2.0694e-01,
          2.7551e-01],
        [-1.5085e-02, -1.6886e-01,  3.6054e-02,  1.4369e-01, -1.4548e-01,
         -1.5708e-01,  4.4302e-02, -2.6976e-01, -1.0451e-01, -2.9774e-01,
         -2.1022e-01,  5.0232e-02,  1.2736e-01,  2.8128e-01, -3.0104e-01,
          2.9294e-02],
        [ 1.6910e-01,  4.9499e-03,  2.5240e-01, -2.9129e-01, -1.0919e-01,
         -5.2092e-02, -3.0167e-01,  2.8832e-02, -3.2903e-01,  5.5321e-02,
          9.7315e-02,  3.4930e-02,  1.8342e-01,  2.7273e-01,  1.3799e-01,
          2.5160e-01],
        [-2.5601e-01,  1.6364e-01,  7.4245e-02,  1.4046e-01,  2.1804e-01,
         -3.8766e-02,  2.8441e-01,  9.5962e-02, -1.2764e-01,  4.3201e-02,
          1.5386e-01, -1.9989e-01, -1.5265e-01, -1.6750e-01, -8.0604e-02,
         -6.3475e-02],
        [ 2.5433e-01, -4.5782e-02,  9.0727e-02, -7.5854e-02, -2.4124e-01,
         -2.4338e-01, -9.1010e-02, -2.9460e-01,  3.1634e-02, -6.4955e-02,
          9.0995e-02,  9.1570e-02,  3.0709e-01,  2.9476e-01,  5.4933e-02,
          2.2481e-01],
        [-2.2199e-01,  1.8917e-01, -2.7267e-01,  1.9588e-01, -1.3137e-01,
          1.0460e-01,  2.7967e-01,  2.6115e-01,  3.0892e-01,  1.8218e-01,
          1.0951e-01, -3.6124e-02,  8.3326e-02,  7.3950e-02,  1.1126e-01,
         -1.8399e-01],
        [-2.2854e-01,  3.1831e-02,  8.6400e-03, -4.1053e-02,  1.2527e-01,
          3.3250e-01,  3.1815e-01, -8.3788e-02,  1.6763e-01,  2.6884e-01,
         -2.8687e-01,  4.8987e-02, -2.5912e-01, -2.4844e-01, -4.6566e-02,
         -1.9926e-01],
        [-2.4407e-03, -2.0177e-02,  2.0146e-01,  1.2193e-03,  8.8941e-02,
         -2.6585e-01, -3.3422e-01, -2.9930e-01, -2.3220e-01, -2.1799e-01,
          1.3538e-01, -7.9110e-02, -8.0624e-02,  2.2796e-01, -2.3946e-01,
          1.4720e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1540,  0.0110,  0.0768, -0.0898,  0.0286, -0.1138,  0.0999,  0.1463,
        -0.1223,  0.0248,  0.0656,  0.1300,  0.2108,  0.0733,  0.0516,  0.0342,
        -0.1078, -0.0274,  0.0284, -0.0395, -0.0521,  0.0066, -0.0666,  0.0109,
        -0.1777,  0.2031,  0.0983,  0.0974, -0.1036, -0.2136,  0.1060, -0.0338],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0790,  0.1638, -0.1021, -0.1233,  0.1595,  0.2167, -0.1654, -0.2671,
         -0.1498,  0.2035,  0.1273,  0.2516, -0.0687, -0.2611,  0.1662, -0.0805,
         -0.1848,  0.2227, -0.0999, -0.1306,  0.2718,  0.1195, -0.2561, -0.2739,
         -0.1860, -0.1969, -0.2038,  0.2051, -0.2339,  0.2725,  0.1707, -0.1122]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0095,  0.0653,  0.0879,  ...,  0.0112, -0.1698, -0.1137],
        [-0.1075, -0.0712,  0.1196,  ..., -0.0194, -0.2282,  0.0871],
        [-0.0427,  0.0354,  0.0872,  ...,  0.1369,  0.1286,  0.0345],
        ...,
        [ 0.1035, -0.1123, -0.0123,  ..., -0.0910, -0.0725, -0.1180],
        [ 0.0746, -0.1720, -0.0426,  ..., -0.1452,  0.0377,  0.1557],
        [-0.1736,  0.1104,  0.0604,  ..., -0.0566, -0.1531, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0306,  0.0366, -0.0928, -0.1453, -0.0785,  0.0518, -0.0950,  0.0500,
        -0.0086,  0.0633,  0.0212,  0.0096, -0.0433,  0.0641, -0.0462, -0.0128,
         0.0441, -0.1764, -0.0631,  0.0634, -0.0463,  0.0496,  0.1177,  0.0049,
        -0.0754,  0.1118,  0.0488, -0.0922,  0.0303,  0.1876,  0.1678, -0.1281],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1287, -0.1131, -0.1479,  ...,  0.0179, -0.1109,  0.1127],
        [-0.1340,  0.0480,  0.0273,  ...,  0.1060, -0.1047,  0.1061],
        [ 0.0578, -0.1218, -0.0909,  ..., -0.0956,  0.0887,  0.1175],
        ...,
        [ 0.0609,  0.0247,  0.1541,  ...,  0.0988, -0.1229,  0.2070],
        [ 0.0611, -0.0633, -0.0170,  ...,  0.1906,  0.1298, -0.1097],
        [ 0.0640, -0.0528,  0.1517,  ...,  0.1982,  0.0561,  0.0034]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0963,  0.1334, -0.0247, -0.0752, -0.0387, -0.0632, -0.0369, -0.0827,
         0.1326, -0.1513,  0.1268, -0.1248,  0.1766,  0.0793, -0.1390,  0.0853,
        -0.1388, -0.1684,  0.0426, -0.0219,  0.0144,  0.1113, -0.1913,  0.2056,
        -0.0674, -0.0110,  0.0866, -0.0448, -0.1199, -0.0716,  0.0979,  0.0211],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2059,  0.1243, -0.1737, -0.1538,  0.0170,  0.0225, -0.0849,  0.0117,
          0.1162, -0.1469, -0.0539,  0.0790,  0.0811,  0.0730,  0.1151,  0.0941,
         -0.2058, -0.2092,  0.0478,  0.0422, -0.1128, -0.0955, -0.1895,  0.0687,
          0.1327,  0.2138, -0.1806,  0.1456, -0.0916, -0.1952,  0.1505,  0.1879]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0205], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.4959e-01,  2.3544e-01,  1.6261e-01, -1.7926e-01,  1.1951e-04,
         -5.4087e-03,  1.1917e-01, -2.1412e-01,  3.7155e-03,  8.3298e-02,
          1.2723e-01,  2.6141e-02, -1.2392e-01, -2.4000e-01,  1.3513e-01,
          2.2824e-01],
        [-7.5480e-02, -2.2341e-01,  7.3146e-02, -1.7527e-01, -1.6334e-01,
          6.8146e-02, -2.3741e-02, -1.7005e-02,  2.2424e-01, -4.3851e-02,
          1.5218e-01, -7.7806e-02,  1.8603e-01,  7.6268e-02,  2.2277e-01,
          8.7195e-02],
        [-8.8554e-02,  1.0896e-01,  2.1299e-01,  4.7383e-02,  1.1526e-01,
         -1.7588e-01,  1.3546e-01, -2.3632e-01,  2.2101e-01,  1.0326e-01,
          1.6452e-02, -2.3399e-01,  2.2734e-01,  1.5941e-01,  2.3047e-01,
          9.8278e-02],
        [ 8.4194e-02, -6.4758e-02, -1.0245e-01,  9.9101e-02,  8.6701e-02,
         -8.1050e-03,  3.9765e-02,  8.5878e-02, -2.4159e-01, -2.2109e-01,
         -6.6551e-02,  1.7026e-01,  1.2197e-01, -2.3862e-01, -7.5062e-02,
         -2.6426e-02],
        [ 8.2110e-02,  2.0453e-01,  5.4679e-03, -1.9460e-01,  1.5340e-02,
         -9.6540e-02, -1.5279e-01,  1.3847e-01, -3.3588e-02,  1.1813e-01,
          1.9466e-01,  2.4570e-02,  1.4081e-01, -1.1807e-01,  1.3955e-01,
          9.9876e-03],
        [ 1.6613e-01,  2.3901e-01, -1.8911e-01,  2.3733e-01,  1.9084e-01,
         -2.0139e-01,  7.3285e-02, -2.0353e-01,  8.1097e-02,  3.8660e-02,
         -2.3865e-01,  9.0755e-02, -6.8670e-02,  2.4919e-01,  2.4400e-01,
          8.6303e-02],
        [ 1.9706e-01,  9.0295e-02,  2.3652e-01, -2.3082e-02,  6.1788e-02,
         -4.1296e-02, -4.3721e-03, -7.5417e-02, -9.8939e-02,  1.4462e-01,
          1.0728e-01, -1.1036e-01, -2.2033e-01,  1.2224e-01, -2.2997e-01,
         -1.1063e-02],
        [-2.1511e-01,  2.0933e-01,  2.0357e-01, -2.0546e-01, -2.3243e-01,
         -1.4781e-01,  6.8985e-02, -1.2502e-01, -5.9537e-02, -6.3370e-02,
          4.5858e-02, -1.1825e-01,  1.1370e-01, -1.7890e-01, -2.2253e-02,
          2.0956e-01],
        [-1.3804e-01,  1.9180e-01,  1.3012e-01, -8.0755e-02,  8.6691e-02,
         -1.6889e-01,  2.0121e-02,  7.0815e-02,  2.1624e-01, -1.3989e-01,
         -1.4218e-01, -1.2478e-01, -2.4354e-01,  5.0557e-02, -2.0694e-01,
         -6.7111e-02],
        [-1.1155e-01,  1.3978e-02,  7.5837e-02, -1.8167e-01, -7.3804e-02,
         -2.4035e-02, -1.4452e-01,  5.7753e-02,  9.2549e-02, -1.7817e-01,
          1.9658e-01,  1.7765e-01, -7.5106e-02,  3.7198e-02,  3.0439e-02,
         -3.4493e-02],
        [-1.6778e-01,  2.0601e-01,  1.2303e-01, -2.0892e-01, -1.9375e-01,
          2.3774e-01,  3.9901e-02, -5.7436e-02,  1.6943e-01,  7.1820e-02,
          8.9743e-02,  1.9833e-01, -1.9512e-02,  2.3822e-01, -1.7561e-01,
         -1.5213e-01],
        [ 4.2360e-02, -3.0351e-02,  1.4266e-01, -6.7982e-02,  3.9312e-02,
         -5.1947e-02,  1.8769e-01, -1.6398e-02,  3.8373e-03,  1.8315e-01,
          2.4304e-01,  2.3921e-01, -2.4443e-01, -1.4127e-01, -5.4287e-02,
         -5.1611e-02],
        [ 1.4461e-01,  1.1291e-01, -2.0563e-02,  5.9224e-03,  5.3564e-02,
          2.1551e-01,  1.2955e-01, -1.2610e-01, -1.2807e-01,  7.9062e-02,
         -2.5286e-02, -1.6039e-01, -2.4197e-01,  3.5810e-02, -7.3006e-02,
         -1.4546e-01],
        [ 4.7027e-02,  2.4345e-01,  2.0765e-01,  1.4254e-01, -1.8855e-01,
          1.4268e-01,  1.2930e-01,  8.3411e-02, -6.2276e-02, -4.3533e-03,
         -1.3560e-01, -5.6314e-02, -4.1154e-02, -3.5414e-02, -2.4880e-01,
          8.8197e-02],
        [-2.0455e-01, -1.8696e-01,  1.0159e-01, -2.0464e-01,  2.3850e-01,
          2.3939e-01, -7.9446e-02, -4.3085e-02, -1.9126e-01,  1.5456e-02,
          4.5709e-02, -1.3714e-01,  7.8396e-02, -9.6213e-03, -7.3695e-02,
         -8.6492e-04],
        [-2.4233e-01, -1.7611e-01,  3.3092e-02,  2.4143e-01, -1.4818e-01,
          1.6027e-01,  2.2880e-02, -1.0756e-01,  2.7391e-04,  1.1986e-01,
          2.9743e-02,  2.2130e-01, -4.7314e-02, -1.6695e-01,  2.2591e-01,
         -7.1400e-02],
        [ 1.5863e-01,  1.6490e-01,  4.4276e-02, -2.0519e-01, -2.4544e-01,
          1.1868e-01,  6.1123e-02,  1.4547e-01, -2.2035e-01, -3.4443e-02,
          2.1600e-01,  1.3135e-01,  2.0776e-01,  1.9628e-01, -6.1342e-02,
         -1.7025e-01],
        [-1.4907e-01,  8.4907e-02, -9.9234e-02,  9.9149e-04,  3.9896e-02,
          1.5519e-01,  1.3943e-01,  1.4269e-01,  1.0161e-02,  1.4114e-01,
         -1.1704e-01, -1.0006e-01, -3.9583e-02, -1.4518e-01,  2.2300e-01,
         -3.8309e-02],
        [ 7.2681e-02, -7.7727e-03, -3.4193e-03, -1.3325e-01, -1.8354e-02,
         -2.2362e-01, -1.1955e-01,  1.9239e-01, -2.3449e-01,  4.1140e-02,
          3.9828e-02, -2.3928e-01,  4.8829e-02,  1.1608e-01,  1.8107e-01,
          4.6794e-02],
        [ 1.9542e-01,  9.4101e-03,  9.5256e-02,  7.3802e-02, -1.8433e-01,
         -5.4879e-02, -1.7605e-01,  1.9425e-01,  1.1926e-01, -1.0603e-01,
         -4.5749e-02,  6.6739e-02, -2.1798e-01,  7.0592e-03,  1.1925e-01,
          3.1325e-02],
        [-2.3003e-02,  1.6073e-01,  1.0875e-01, -2.2225e-01,  1.4713e-01,
         -1.9718e-01,  1.4043e-01,  2.1051e-01,  2.3040e-02, -8.4493e-02,
         -1.2914e-01, -1.1101e-01, -4.6083e-02, -1.0365e-01,  2.4818e-01,
         -1.0784e-01],
        [ 1.0380e-01, -2.3183e-01,  1.2671e-01,  2.1273e-01, -1.7922e-01,
         -6.3786e-02,  5.9585e-02, -2.3931e-01, -1.5818e-01,  8.6946e-02,
          2.3541e-01, -7.4686e-02, -2.2768e-03, -2.4133e-01, -2.3996e-01,
          2.1742e-01],
        [ 2.1215e-01, -7.6192e-02, -9.8855e-02, -1.6184e-02,  1.1600e-01,
         -2.4160e-01, -1.3848e-01, -8.2418e-02, -1.0881e-01, -6.6043e-03,
          1.8235e-01,  5.4585e-02, -2.2625e-01,  2.3122e-01,  2.0130e-01,
          7.8714e-02],
        [ 1.2237e-01,  9.3457e-02,  2.0492e-01, -2.4045e-01, -1.5563e-01,
         -3.1748e-02, -4.7555e-02, -1.6603e-01, -2.3975e-01, -1.9093e-01,
         -3.8828e-02,  2.1222e-01,  1.6574e-01,  7.2061e-02, -1.5355e-01,
         -1.0057e-01],
        [ 2.4084e-02, -2.3173e-01, -1.1413e-02,  5.0838e-02,  2.2602e-01,
         -6.5625e-02,  2.4539e-01,  1.8861e-02, -1.7345e-01,  2.3628e-01,
          2.1674e-01, -1.9754e-01, -1.4502e-01,  1.1954e-01, -1.5383e-01,
          1.6999e-01],
        [-1.1928e-01, -7.7591e-02, -7.1767e-02,  2.3851e-01, -8.4540e-02,
         -4.8611e-02,  1.5127e-01, -1.7105e-01, -1.2042e-03, -1.9311e-01,
         -2.3074e-01, -5.7078e-02,  2.7636e-02,  2.1319e-01, -2.3975e-01,
         -7.1936e-02],
        [ 6.5789e-02,  9.4403e-02,  1.4606e-01, -2.0102e-01, -6.1118e-02,
          5.7808e-02, -2.0040e-01,  1.2598e-01, -2.3854e-01,  1.5600e-01,
          8.1279e-02, -7.1012e-02,  8.1105e-02,  2.1174e-01,  1.8391e-01,
          1.5164e-01],
        [-1.4553e-01,  7.1840e-02,  1.8761e-01,  4.4093e-02,  1.6552e-01,
         -1.5505e-01,  1.7571e-01, -8.2927e-03, -2.2430e-01, -6.4806e-02,
          2.2096e-01, -8.7336e-02, -4.3299e-02, -1.0001e-01, -1.3593e-01,
          4.3312e-02],
        [ 1.5166e-01,  2.9561e-02, -1.5419e-02,  1.4462e-02, -1.8747e-01,
         -1.3172e-01,  1.2510e-02, -1.9982e-01,  1.2383e-01,  3.8105e-02,
          2.6324e-03, -1.6043e-02,  2.1115e-01,  2.2816e-01,  1.2207e-01,
          1.2417e-01],
        [-1.2122e-01,  1.0220e-01, -1.6909e-01,  1.0804e-01, -1.7752e-01,
         -1.3674e-03,  1.8120e-01,  1.6601e-01,  2.2105e-01,  8.5281e-02,
          9.7044e-02,  6.7042e-02,  1.8255e-01,  1.3119e-01,  7.3767e-02,
         -8.7229e-02],
        [-1.2099e-01, -6.1809e-02,  1.1931e-01, -1.3609e-01,  6.8302e-02,
          2.1873e-01,  2.1169e-01, -1.8406e-01,  7.1259e-02,  1.6347e-01,
         -2.2708e-01,  1.5978e-01, -1.5577e-01, -1.8076e-01, -1.0597e-01,
         -9.4034e-02],
        [-1.0336e-01,  7.1975e-02,  9.6850e-02,  9.7162e-02,  1.7261e-01,
         -1.5818e-01, -2.3738e-01, -2.0056e-01, -1.3741e-01, -1.1435e-01,
          1.0985e-01, -1.8092e-01, -1.8279e-01,  1.3388e-01, -1.5907e-01,
          4.6891e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1906,  0.0954,  0.1562, -0.2103,  0.0850, -0.1311,  0.1587,  0.2249,
        -0.2109,  0.0935,  0.1688,  0.2273,  0.1888,  0.0492,  0.0146,  0.0515,
        -0.1490, -0.0490, -0.0039, -0.1582, -0.0111, -0.0332, -0.0875, -0.0768,
        -0.2490,  0.2382,  0.1232,  0.1807, -0.2128, -0.2448,  0.1859, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0276,  0.0886,  0.0113, -0.0059,  0.1050,  0.1412, -0.0493, -0.1509,
         -0.0969,  0.1263,  0.0154,  0.1514, -0.0618, -0.1675,  0.0549, -0.0753,
         -0.1057,  0.1102,  0.0123, -0.0151,  0.1722,  0.1540, -0.1444, -0.1625,
         -0.0874, -0.1373, -0.0929,  0.1193, -0.1176,  0.1621,  0.0552,  0.0077]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0274,  0.0338,  0.0515,  ...,  0.0370, -0.1580, -0.1137],
        [-0.0412, -0.1228,  0.0849,  ..., -0.0255, -0.1542,  0.0871],
        [-0.0916,  0.0727,  0.1131,  ...,  0.1516,  0.0694,  0.0345],
        ...,
        [ 0.0835, -0.0818,  0.0083,  ..., -0.1147, -0.0697, -0.1180],
        [ 0.0086, -0.1214, -0.0074,  ..., -0.1376, -0.0348,  0.1557],
        [-0.1369,  0.0661,  0.0410,  ..., -0.0287, -0.1442, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0587,  0.0692, -0.1074, -0.1128, -0.0456,  0.0102, -0.1318,  0.0737,
        -0.0301,  0.0931,  0.0477, -0.0256, -0.0145,  0.0492, -0.0832, -0.0415,
         0.0733, -0.1429, -0.0319,  0.0333, -0.0826,  0.0758,  0.0793, -0.0232,
        -0.0515,  0.0775,  0.0090, -0.1238,  0.0923,  0.1576,  0.1370, -0.0883],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1641, -0.0737, -0.1340,  ..., -0.0192, -0.1329,  0.1699],
        [-0.0956,  0.0925,  0.0408,  ...,  0.0663, -0.1323,  0.1671],
        [ 0.0220, -0.1643, -0.1021,  ..., -0.0583,  0.1139,  0.0584],
        ...,
        [ 0.0230, -0.0144,  0.1370,  ...,  0.1392, -0.1018,  0.1490],
        [ 0.0984, -0.0202, -0.0055,  ...,  0.1521,  0.1041, -0.0493],
        [ 0.1011, -0.0131,  0.1673,  ...,  0.1591,  0.0347,  0.0616]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0691,  0.1030,  0.0027, -0.0455, -0.0609, -0.1135, -0.0068, -0.0992,
         0.1055, -0.1266,  0.1537, -0.1561,  0.1472,  0.0200, -0.1666,  0.0530,
        -0.1138, -0.1400,  0.0093, -0.0503,  0.0436,  0.1398, -0.1621,  0.1758,
        -0.0980, -0.0349,  0.1146, -0.0738, -0.0891, -0.0414,  0.0691, -0.0077],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1610,  0.0763, -0.1613, -0.1273,  0.0139, -0.0068, -0.0537,  0.0581,
          0.0742, -0.1026, -0.0353,  0.0633,  0.0641, -0.0159,  0.0889,  0.0632,
         -0.1659, -0.1689,  0.0059,  0.0605, -0.1260, -0.0910, -0.1689,  0.0335,
          0.1281,  0.1566, -0.1439,  0.1365, -0.0708, -0.1557,  0.1134,  0.1485]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0091], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-0.3332,  0.3940, -0.0239,  0.0021,  0.1312,  0.1884,  0.2961, -0.0526,
          0.1737,  0.2738,  0.0086, -0.1586, -0.2939, -0.3737,  0.2078,  0.0482],
        [-0.2509, -0.0649, -0.1052, -0.0010, -0.0396,  0.2526,  0.1416,  0.1405,
          0.3826,  0.1383,  0.0202, -0.2568,  0.0212, -0.0507,  0.3203, -0.0832],
        [ 0.0832, -0.0417,  0.3865, -0.1327, -0.0497, -0.3567, -0.0253, -0.3954,
          0.0631, -0.0820,  0.1003, -0.0605,  0.3893,  0.3240,  0.1129,  0.2678],
        [ 0.2693, -0.2186,  0.0861, -0.0818, -0.0271, -0.1990, -0.1273, -0.0694,
         -0.3961, -0.4086,  0.0851,  0.3544,  0.2874, -0.1145, -0.1575,  0.1573],
        [-0.0881,  0.3567, -0.1681, -0.0244,  0.1314,  0.0822,  0.0067,  0.2911,
          0.1185,  0.2958,  0.0617, -0.1495, -0.0218, -0.2390,  0.2268, -0.1543],
        [ 0.0041,  0.3731, -0.3549,  0.4005,  0.2943, -0.0328,  0.2217, -0.0651,
          0.2225,  0.2091, -0.3155, -0.0713, -0.2139,  0.1400,  0.3133, -0.0711],
        [ 0.3700, -0.0470,  0.4123, -0.1923, -0.0364, -0.2168, -0.1593, -0.2170,
         -0.2417, -0.0299,  0.1194,  0.0570, -0.0683,  0.2277, -0.2610,  0.1586],
        [-0.0581,  0.0869,  0.3645, -0.3628, -0.3188, -0.3089, -0.0711, -0.2535,
         -0.1892, -0.2260,  0.0656,  0.0354,  0.2520, -0.0827, -0.0615,  0.3616],
        [ 0.0372,  0.0325,  0.3080, -0.2550, -0.0373, -0.3548, -0.1446, -0.0902,
          0.0572, -0.3222, -0.0120,  0.0563, -0.0774,  0.1784, -0.3129,  0.1015],
        [-0.2832,  0.1721, -0.0986, -0.0110,  0.0478,  0.1568,  0.0167,  0.2148,
          0.2473,  0.0011,  0.0617,  0.0007, -0.2418, -0.0874,  0.1316, -0.2001],
        [-0.3525,  0.3556, -0.0646, -0.0269, -0.0703,  0.4312,  0.2064,  0.1008,
          0.3321,  0.2634, -0.0699,  0.0119, -0.1792,  0.1051, -0.0519, -0.3345],
        [-0.1249,  0.1146, -0.0279,  0.0975,  0.1417,  0.1243,  0.3367,  0.1324,
          0.1440,  0.3570,  0.1081,  0.0682, -0.4021, -0.2558,  0.0439, -0.2128],
        [ 0.3346, -0.0638,  0.1733, -0.1839, -0.0936,  0.0089, -0.0629, -0.3061,
         -0.3142, -0.1225,  0.1149,  0.0404, -0.0526,  0.1873, -0.2007,  0.0405],
        [ 0.2107,  0.0994,  0.3750, -0.0210, -0.2963, -0.0280, -0.0222, -0.0587,
         -0.2065, -0.1754, -0.0256,  0.1090,  0.1101,  0.0770, -0.3255,  0.2473],
        [-0.3802, -0.0314, -0.0768, -0.0310,  0.3583,  0.4231,  0.0823,  0.1118,
         -0.0379,  0.1960, -0.0671, -0.3141, -0.0839, -0.1333,  0.0162, -0.1722],
        [-0.0625, -0.3478,  0.2152,  0.0613, -0.2819, -0.0309, -0.1478, -0.2751,
         -0.1657, -0.0697,  0.1429,  0.4094,  0.1310, -0.0314,  0.1150,  0.1001],
        [ 0.3185,  0.0345,  0.2077, -0.3661, -0.3326, -0.0492, -0.0795,  0.0131,
         -0.3520, -0.2036,  0.3230,  0.2905,  0.3501,  0.2987, -0.1275, -0.0167],
        [-0.2969,  0.1832, -0.2539,  0.1537,  0.1063,  0.3010,  0.2702,  0.2519,
          0.1261,  0.2962, -0.1718, -0.2366, -0.1626, -0.2263,  0.2352, -0.1840],
        [ 0.2330, -0.1449,  0.1589, -0.3064, -0.1702, -0.3917, -0.2646,  0.0462,
         -0.3776, -0.1346,  0.1651, -0.0779,  0.1970,  0.2717,  0.0639,  0.2042],
        [ 0.3767, -0.1454,  0.2789, -0.1033, -0.2954, -0.2446, -0.3370,  0.0390,
         -0.0333, -0.2907,  0.0985,  0.2494, -0.0553,  0.1292,  0.0243,  0.2088],
        [-0.1726,  0.2894, -0.0457, -0.0692,  0.2436, -0.0410,  0.2769,  0.3379,
          0.1530,  0.0739, -0.2544, -0.2619, -0.1821, -0.2053,  0.3181, -0.2528],
        [-0.0615, -0.0741, -0.0412,  0.3799, -0.0532,  0.1127,  0.2133, -0.0848,
         -0.0047,  0.2613,  0.1419, -0.2496, -0.1641, -0.3650, -0.1333,  0.0613],
        [ 0.3666, -0.2019,  0.0594, -0.1718,  0.0312, -0.4042, -0.2743, -0.2105,
         -0.2353, -0.1690,  0.2899,  0.2092, -0.0893,  0.3299,  0.1368,  0.2267],
        [ 0.2638,  0.0089,  0.3545, -0.3880, -0.2073, -0.1736, -0.1718, -0.2666,
         -0.3461, -0.3418,  0.0679,  0.3436,  0.2807,  0.1461, -0.1730,  0.0390],
        [ 0.1951, -0.3869,  0.1621, -0.1183,  0.1109, -0.2462,  0.0887, -0.1344,
         -0.3232,  0.0595,  0.3467, -0.0223,  0.0154,  0.2400, -0.2504,  0.3349],
        [ 0.0390, -0.2193,  0.0917,  0.0768, -0.2012, -0.2111, -0.0013, -0.3099,
         -0.1514, -0.3609, -0.1251,  0.1028,  0.1749,  0.3284, -0.3161,  0.0842],
        [ 0.2248, -0.0348,  0.3081, -0.3593, -0.1464, -0.1105, -0.3366, -0.0071,
         -0.3667, -0.0104,  0.1651,  0.0900,  0.2235,  0.3121,  0.1165,  0.3033],
        [-0.3177,  0.2256,  0.0130,  0.2133,  0.2758,  0.0254,  0.3322,  0.1459,
         -0.0760,  0.1131,  0.0877, -0.2625, -0.2067, -0.2189, -0.0386, -0.1225],
        [ 0.3072, -0.0858,  0.1461, -0.1441, -0.2732, -0.2956, -0.1267, -0.3249,
         -0.0033, -0.1274,  0.1376,  0.1398,  0.3446,  0.3309,  0.0443,  0.2765],
        [-0.2737,  0.2124, -0.3269,  0.2626, -0.1014,  0.1526,  0.3163,  0.2854,
          0.3437,  0.2437,  0.0484, -0.0796,  0.0512,  0.0423,  0.0999, -0.2359],
        [-0.2860,  0.0762, -0.0487,  0.0284,  0.1650,  0.3933,  0.3563, -0.0461,
          0.2070,  0.3354, -0.3572, -0.0069, -0.3024, -0.2904, -0.0233, -0.2531],
        [ 0.0635, -0.0646,  0.2679, -0.0761,  0.0442, -0.3308, -0.3845, -0.3412,
         -0.2805, -0.2921,  0.2141, -0.0177, -0.0320,  0.2734, -0.2446,  0.2128]],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0939,  0.0300,  0.0561, -0.0827,  0.0384, -0.0834,  0.0636,  0.1236,
        -0.0660,  0.0051,  0.0222,  0.0873,  0.1212,  0.0552,  0.0535,  0.0704,
        -0.0871,  0.0122,  0.0596,  0.0100, -0.0375, -0.0557, -0.0409, -0.0150,
        -0.1190,  0.1434,  0.1319,  0.0480, -0.0883, -0.1741,  0.0678, -0.0293],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1638,  0.2496, -0.1819, -0.1966,  0.2452,  0.2967, -0.2339, -0.3355,
         -0.2387,  0.2915,  0.2018,  0.3252, -0.1778, -0.3385,  0.2483, -0.1878,
         -0.2548,  0.2812, -0.1753, -0.2039,  0.3358,  0.2164, -0.3224, -0.3324,
         -0.2732, -0.2717, -0.2690,  0.2874, -0.2987,  0.3345,  0.2387, -0.1796]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0306,  0.0883,  0.1017,  ...,  0.0343, -0.1923, -0.1137],
        [-0.1183, -0.0617,  0.1357,  ..., -0.0026, -0.2494,  0.0871],
        [-0.0119,  0.0053,  0.0494,  ...,  0.1119,  0.1714,  0.0345],
        ...,
        [ 0.1191, -0.1344, -0.0345,  ..., -0.1021, -0.0579, -0.1180],
        [ 0.0923, -0.1890, -0.0671,  ..., -0.1648,  0.0665,  0.1557],
        [-0.1941,  0.1335,  0.0866,  ..., -0.0339, -0.1769, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0195,  0.0264, -0.0759, -0.1564, -0.0877,  0.0764, -0.0863,  0.0455,
        -0.0071,  0.0524,  0.0141,  0.0179, -0.0570,  0.0990, -0.0365, -0.0132,
         0.0374, -0.1824, -0.0713,  0.0744, -0.0399, -0.0002,  0.1269,  0.0148,
        -0.1164,  0.1317,  0.0526, -0.1114,  0.0218,  0.1996,  0.1831, -0.1421],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1080, -0.1372, -0.1364,  ...,  0.0366, -0.0803,  0.0919],
        [-0.1628,  0.0165,  0.0534,  ...,  0.1323, -0.0660,  0.0779],
        [ 0.0837, -0.0922, -0.1123,  ..., -0.1196,  0.0519,  0.1439],
        ...,
        [ 0.0798,  0.0467,  0.1436,  ...,  0.0824, -0.1520,  0.2252],
        [ 0.0342, -0.0936,  0.0062,  ...,  0.2155,  0.1674, -0.1368],
        [ 0.0456, -0.0736,  0.1608,  ...,  0.2141,  0.0839, -0.0139]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 1.0905e-01,  1.5385e-01, -4.2207e-02, -9.7003e-02, -1.8080e-04,
        -2.1297e-02, -6.1240e-02, -3.7610e-02,  1.4904e-01, -1.6738e-01,
         1.0621e-01, -1.1067e-01,  1.9381e-01,  9.1509e-02, -1.2501e-01,
         1.1533e-01, -1.5026e-01, -1.7682e-01,  6.1874e-02,  7.9521e-03,
        -1.2919e-02,  8.9608e-02, -2.0925e-01,  2.1861e-01, -4.0905e-02,
        -1.3628e-03,  7.2471e-02, -2.3320e-02, -1.4507e-01, -8.3179e-02,
         1.1634e-01,  3.2390e-02], device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2617,  0.1793, -0.2337, -0.2350,  0.0740,  0.0962, -0.1489,  0.1099,
          0.1727, -0.1963, -0.1250,  0.1417,  0.1434,  0.1263,  0.1778,  0.1592,
         -0.2594, -0.2642,  0.1116,  0.1127, -0.1820, -0.1601, -0.2521,  0.1218,
          0.1998,  0.2652, -0.2360,  0.2231, -0.1605, -0.2517,  0.2115,  0.2454]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0664], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-0.3465,  0.4239, -0.0364,  0.0172,  0.1557,  0.1957,  0.3124, -0.0379,
          0.1831,  0.2881, -0.0225, -0.1719, -0.3086, -0.3873,  0.2228,  0.0339],
        [-0.2644, -0.0385, -0.1183,  0.0156, -0.0127,  0.2605,  0.1596,  0.1546,
          0.3946,  0.1521, -0.0108, -0.2711,  0.0048, -0.0655,  0.3417, -0.0986],
        [ 0.0961, -0.0693,  0.3986, -0.1473, -0.0761, -0.3645, -0.0424, -0.4105,
          0.0519, -0.0956,  0.1291, -0.0468,  0.4046,  0.3380,  0.0970,  0.2821],
        [ 0.2801, -0.2415,  0.0967, -0.0954, -0.0495, -0.2035, -0.1417, -0.0799,
         -0.4038, -0.4198,  0.1099,  0.3646,  0.2991, -0.1034, -0.1675,  0.1698],
        [-0.1008,  0.3823, -0.1806, -0.0082,  0.1570,  0.0888,  0.0239,  0.3040,
          0.1288,  0.3087,  0.0318, -0.1622, -0.0369, -0.2524,  0.2456, -0.1690],
        [-0.0029,  0.3902, -0.3615,  0.4092,  0.3103, -0.0286,  0.2305, -0.0569,
          0.2279,  0.2176, -0.3372, -0.0784, -0.2215,  0.1328,  0.3211, -0.0790],
        [ 0.3787, -0.0664,  0.4205, -0.2024, -0.0551, -0.2222, -0.1695, -0.2268,
         -0.2486, -0.0402,  0.1417,  0.0664, -0.0592,  0.2372, -0.2686,  0.1678],
        [-0.0510,  0.0709,  0.3712, -0.3713, -0.3346, -0.3135, -0.0792, -0.2613,
         -0.1947, -0.2348,  0.0857,  0.0431,  0.2592, -0.0750, -0.0676,  0.3692],
        [ 0.0506,  0.0069,  0.3211, -0.2718, -0.0642, -0.3622, -0.1634, -0.1046,
          0.0449, -0.3358,  0.0173,  0.0699, -0.0615,  0.1928, -0.3321,  0.1172],
        [-0.2963,  0.1980, -0.1113,  0.0053,  0.0744,  0.1652,  0.0344,  0.2292,
          0.2596,  0.0148,  0.0315, -0.0134, -0.2579, -0.1019,  0.1528, -0.2152],
        [-0.3640,  0.3796, -0.0759, -0.0125, -0.0460,  0.4365,  0.2227,  0.1128,
          0.3414,  0.2753, -0.0965,  0.0009, -0.1923,  0.0931, -0.0391, -0.3482],
        [-0.1342,  0.1341, -0.0373,  0.1100,  0.1614,  0.1286,  0.3498,  0.1419,
          0.1516,  0.3669,  0.0890,  0.0597, -0.4123, -0.2653,  0.0533, -0.2240],
        [ 0.3523, -0.0986,  0.1900, -0.2035, -0.1258, -0.0033, -0.0865, -0.3275,
         -0.3307, -0.1407,  0.1484,  0.0592, -0.0311,  0.2064, -0.2289,  0.0600],
        [ 0.2202,  0.0788,  0.3841, -0.0327, -0.3170, -0.0346, -0.0343, -0.0696,
         -0.2153, -0.1862, -0.0012,  0.1197,  0.1215,  0.0878, -0.3394,  0.2579],
        [-0.3922, -0.0074, -0.0883, -0.0162,  0.3831,  0.4294,  0.0980,  0.1238,
         -0.0281,  0.2082, -0.0966, -0.3264, -0.0981, -0.1462,  0.0329, -0.1859],
        [-0.0445, -0.3807,  0.2327,  0.0397, -0.3151, -0.0420, -0.1721, -0.2948,
         -0.1819, -0.0881,  0.1786,  0.4276,  0.1523, -0.0125,  0.0883,  0.1207],
        [ 0.3257,  0.0190,  0.2150, -0.3755, -0.3473, -0.0529, -0.0879,  0.0061,
         -0.3569, -0.2124,  0.3424,  0.2974,  0.3567,  0.3063, -0.1312, -0.0087],
        [-0.3027,  0.1961, -0.2597,  0.1609,  0.1174,  0.3039,  0.2756,  0.2571,
          0.1290,  0.3042, -0.1889, -0.2422, -0.1668, -0.2322,  0.2353, -0.1899],
        [ 0.2430, -0.1666,  0.1686, -0.3181, -0.1908, -0.3971, -0.2778,  0.0347,
         -0.3855, -0.1458,  0.1889, -0.0682,  0.2072,  0.2818,  0.0569,  0.2156],
        [ 0.3859, -0.1649,  0.2880, -0.1146, -0.3145, -0.2493, -0.3492,  0.0290,
         -0.0404, -0.3011,  0.1203,  0.2580, -0.0461,  0.1384,  0.0177,  0.2195],
        [-0.1791,  0.3046, -0.0522, -0.0602,  0.2570, -0.0380,  0.2844,  0.3441,
          0.1569,  0.0819, -0.2761, -0.2677, -0.1884, -0.2117,  0.3238, -0.2602],
        [-0.0790, -0.0433, -0.0583,  0.4012, -0.0199,  0.1261,  0.2356, -0.0650,
          0.0136,  0.2801,  0.1073, -0.2694, -0.1858, -0.3852, -0.1045,  0.0418],
        [ 0.3746, -0.2186,  0.0674, -0.1825,  0.0139, -0.4078, -0.2843, -0.2180,
         -0.2410, -0.1780,  0.3121,  0.2169, -0.0811,  0.3384,  0.1300,  0.2358],
        [ 0.2691, -0.0028,  0.3600, -0.3945, -0.2164, -0.1766, -0.1764, -0.2713,
         -0.3489, -0.3495,  0.0799,  0.3489,  0.2843,  0.1516, -0.1723,  0.0442],
        [ 0.2064, -0.4094,  0.1733, -0.1330,  0.0874, -0.2520,  0.0731, -0.1459,
         -0.3327,  0.0478,  0.3746, -0.0111,  0.0286,  0.2520, -0.2658,  0.3483],
        [ 0.0504, -0.2424,  0.1027,  0.0624, -0.2224, -0.2182, -0.0143, -0.3209,
         -0.1598, -0.3735, -0.0927,  0.1150,  0.1879,  0.3404, -0.3335,  0.0965],
        [ 0.2309, -0.0489,  0.3140, -0.3671, -0.1597, -0.1139, -0.3439, -0.0140,
         -0.3712, -0.0182,  0.1823,  0.0956,  0.2290,  0.3181,  0.1135,  0.3104],
        [-0.3276,  0.2467,  0.0031,  0.2261,  0.2971,  0.0308,  0.3461,  0.1568,
         -0.0675,  0.1239,  0.0651, -0.2723, -0.2179, -0.2293, -0.0271, -0.1344],
        [ 0.3146, -0.1029,  0.1537, -0.1540, -0.2888, -0.2989, -0.1359, -0.3320,
         -0.0083, -0.1361,  0.1550,  0.1469,  0.3521,  0.3387,  0.0396,  0.2850],
        [-0.2804,  0.2285, -0.3332,  0.2706, -0.0863,  0.1570,  0.3239,  0.2932,
          0.3489,  0.2524,  0.0294, -0.0870,  0.0445,  0.0350,  0.1048, -0.2430],
        [-0.2940,  0.0930, -0.0567,  0.0388,  0.1816,  0.3969,  0.3662, -0.0385,
          0.2124,  0.3445, -0.3796, -0.0142, -0.3101, -0.2986, -0.0182, -0.2623],
        [ 0.0733, -0.0861,  0.2775, -0.0880,  0.0238, -0.3351, -0.3970, -0.3513,
         -0.2873, -0.3029,  0.2377, -0.0086, -0.0223,  0.2835, -0.2511,  0.2238]],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1090, -0.0115,  0.0735, -0.0586,  0.0018, -0.0909,  0.0733,  0.1308,
        -0.0324, -0.0321, -0.0036,  0.0703,  0.1359,  0.0703,  0.0203,  0.1006,
        -0.0758,  0.0050,  0.0697,  0.0215, -0.0515, -0.0764, -0.0241, -0.0104,
        -0.0852,  0.1597,  0.1351,  0.0297, -0.0742, -0.1792,  0.0534, -0.0124],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1928,  0.2779, -0.2059, -0.2180,  0.2743,  0.3221, -0.2542, -0.3550,
         -0.2654,  0.3231,  0.2239,  0.3490, -0.2147, -0.3634,  0.2725, -0.2284,
         -0.2748,  0.2980, -0.1971, -0.2249,  0.3589,  0.2505, -0.3411, -0.3482,
         -0.3005, -0.2996, -0.2876,  0.3143, -0.3175,  0.3526,  0.2584, -0.1998]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0390,  0.1086,  0.0867,  ...,  0.1249, -0.2484, -0.1137],
        [-0.1267, -0.0442,  0.1266,  ...,  0.0636, -0.2806,  0.0871],
        [ 0.0157, -0.0315,  0.0340,  ...,  0.0615,  0.2230,  0.0345],
        ...,
        [ 0.1292, -0.1556, -0.0226,  ..., -0.1880, -0.0102, -0.1180],
        [ 0.1069, -0.2126, -0.0666,  ..., -0.2317,  0.1037,  0.1557],
        [-0.2055,  0.1570,  0.0762,  ...,  0.0523, -0.2321, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0466,  0.0422, -0.0730, -0.1427, -0.0756,  0.0632, -0.1024,  0.0390,
        -0.0370,  0.0593,  0.0040,  0.0107, -0.0294,  0.0855, -0.0468,  0.0003,
         0.0481, -0.1615, -0.0392,  0.0666, -0.0579,  0.0237,  0.1174,  0.0144,
        -0.0958,  0.1116,  0.0595, -0.1119,  0.0394,  0.1753,  0.1724, -0.1177],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0905, -0.1416, -0.1096,  ...,  0.0392, -0.0678,  0.0744],
        [-0.1809,  0.0087,  0.0832,  ...,  0.1383, -0.0530,  0.0610],
        [ 0.1017, -0.0821, -0.1423,  ..., -0.1281,  0.0369,  0.1632],
        ...,
        [ 0.0990,  0.0532,  0.1133,  ...,  0.0775, -0.1674,  0.2452],
        [ 0.0189, -0.1018,  0.0329,  ...,  0.2226,  0.1798, -0.1534],
        [ 0.0265, -0.0814,  0.1913,  ...,  0.2206,  0.1003, -0.0359]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1045,  0.1535, -0.0437, -0.0990,  0.0079, -0.0257, -0.0637, -0.0308,
         0.1446, -0.1620,  0.1077, -0.1089,  0.1888,  0.0764, -0.1284,  0.1200,
        -0.1464, -0.1699,  0.0500,  0.0144, -0.0158,  0.0873, -0.2094,  0.2022,
        -0.0349, -0.0094,  0.0724, -0.0202, -0.1461, -0.0802,  0.1172,  0.0297],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2768,  0.1953, -0.2487, -0.2503,  0.0926,  0.1130, -0.1653,  0.1248,
          0.1864, -0.2112, -0.1417,  0.1592,  0.1584,  0.1413,  0.1920,  0.1734,
         -0.2767, -0.2792,  0.1273,  0.1298, -0.1986, -0.1763, -0.2693,  0.1361,
          0.2167,  0.2809, -0.2518,  0.2383, -0.1768, -0.2676,  0.2254,  0.2602]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0775], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-0.3007,  0.4656,  0.0466, -0.0357,  0.2492,  0.1566,  0.3651,  0.0502,
          0.2754,  0.2115,  0.0274, -0.2130, -0.3800, -0.3288,  0.3333,  0.0869],
        [-0.2043, -0.0420, -0.0444, -0.0358,  0.0743,  0.2320,  0.1674,  0.2111,
          0.4731,  0.0694,  0.0900, -0.2947, -0.0242, -0.0005,  0.4772, -0.0349],
        [ 0.0497, -0.1114,  0.3224, -0.1014, -0.1727, -0.3200, -0.0922, -0.4924,
         -0.0636, -0.0202,  0.0868,  0.0043,  0.4796,  0.2786, -0.0206,  0.2289],
        [ 0.1912, -0.2504, -0.0036, -0.0214, -0.1146, -0.1594, -0.1359, -0.1294,
         -0.4636, -0.3194,  0.0232,  0.3745,  0.3237, -0.1963, -0.2666,  0.0805],
        [-0.0597,  0.4183, -0.1106, -0.0516,  0.2649,  0.0567,  0.0789,  0.3935,
          0.2329,  0.2368,  0.0935, -0.2093, -0.1042, -0.2032,  0.3706, -0.1228],
        [ 0.0101,  0.4423, -0.2996,  0.3703,  0.4127, -0.0592,  0.3028,  0.0361,
          0.3265,  0.1617, -0.3044, -0.1314, -0.3015,  0.1638,  0.4260, -0.0492],
        [ 0.3122, -0.0955,  0.3308, -0.1413, -0.1337, -0.1796, -0.1978, -0.2942,
         -0.3323,  0.0466,  0.0826,  0.0967, -0.0052,  0.1625, -0.3717,  0.0970],
        [-0.1185,  0.0389,  0.2816, -0.3095, -0.4158, -0.2692, -0.1066, -0.3274,
         -0.2781, -0.1465,  0.0297,  0.0734,  0.3104, -0.1504, -0.1712,  0.2965],
        [ 0.0011, -0.0165,  0.2549, -0.2273, -0.1744, -0.3288, -0.1878, -0.1740,
         -0.0521, -0.2586, -0.0664,  0.1138, -0.0150,  0.1348, -0.4731,  0.0606],
        [-0.2568,  0.2230, -0.0500, -0.0321,  0.1828,  0.1394,  0.0786,  0.3136,
          0.3663, -0.0532,  0.1095, -0.0627, -0.3219, -0.0554,  0.2927, -0.1707],
        [-0.3104,  0.4223,  0.0020, -0.0628,  0.0547,  0.3912,  0.2675,  0.1920,
          0.4510,  0.1957, -0.0449, -0.0429, -0.2575,  0.1564,  0.0811, -0.2882],
        [-0.0665,  0.1554,  0.0487,  0.0482,  0.2536,  0.0864,  0.3636,  0.2083,
          0.2420,  0.2776,  0.1701,  0.0285, -0.4567, -0.1868,  0.1730, -0.1494],
        [ 0.3265, -0.1412,  0.1260, -0.1685, -0.2312,  0.0248, -0.1551, -0.4227,
         -0.4468, -0.0795,  0.0992,  0.1174,  0.0533,  0.1692, -0.3475,  0.0273],
        [ 0.1628,  0.0614,  0.3065,  0.0194, -0.4079, -0.0033, -0.0610, -0.1377,
         -0.3148, -0.1047, -0.0835,  0.1545,  0.1729,  0.0234, -0.4592,  0.1969],
        [-0.3273,  0.0029, -0.0098, -0.0706,  0.4753,  0.3921,  0.1053,  0.1858,
          0.0580,  0.1221, -0.0070, -0.3574, -0.1342, -0.0743,  0.1615, -0.1181],
        [-0.0554, -0.4287,  0.1805,  0.0635, -0.4358, -0.0202, -0.2568, -0.4066,
         -0.3031, -0.0362,  0.1344,  0.5000,  0.2457, -0.0363, -0.0418,  0.1029],
        [ 0.2249,  0.0143,  0.1045, -0.2892, -0.3950, -0.0069, -0.0721, -0.0326,
         -0.3957, -0.1049,  0.2571,  0.2996,  0.3706,  0.1969, -0.2168, -0.1119],
        [-0.2084,  0.2211, -0.1505,  0.0789,  0.1739,  0.2511,  0.2855,  0.3100,
          0.1652,  0.2032, -0.1385, -0.2484, -0.1907, -0.1374,  0.3194, -0.0951],
        [ 0.1763, -0.2047,  0.0755, -0.2528, -0.2708, -0.3468, -0.3068, -0.0315,
         -0.4681, -0.0561,  0.1407, -0.0363,  0.2589,  0.1997, -0.0464,  0.1387],
        [ 0.3242, -0.2057,  0.1995, -0.0541, -0.4028, -0.2014, -0.3855, -0.0431,
         -0.1271, -0.2130,  0.0746,  0.2960,  0.0084,  0.0655, -0.0894,  0.1500],
        [-0.1410,  0.3383,  0.0202, -0.1088,  0.3461, -0.0664,  0.3409,  0.4374,
          0.2367,  0.0181, -0.2234, -0.3063, -0.2579, -0.1654,  0.4272, -0.2139],
        [-0.0636,  0.0059, -0.0186,  0.3827,  0.1151,  0.1059,  0.2959,  0.0306,
          0.1357,  0.2283,  0.1685, -0.3458, -0.2630, -0.3579,  0.0526,  0.0676],
        [ 0.3135, -0.2552, -0.0184, -0.1236, -0.0695, -0.3602, -0.3161, -0.2867,
         -0.3293, -0.0934,  0.2658,  0.2551, -0.0272,  0.2648,  0.0246,  0.1659],
        [ 0.1508, -0.0068,  0.2372, -0.2969, -0.2508, -0.1257, -0.1524, -0.3008,
         -0.3572, -0.2339,  0.0071,  0.3351,  0.2814,  0.0336, -0.2434, -0.0706],
        [ 0.1637, -0.4474,  0.1054, -0.0894, -0.0142, -0.2160,  0.0251, -0.2233,
         -0.4499,  0.1187,  0.3128,  0.0347,  0.0962,  0.1988, -0.3903,  0.2967],
        [ 0.0131, -0.2754,  0.0332,  0.1030, -0.3221, -0.1901, -0.0700, -0.4137,
         -0.2630, -0.3061, -0.1520,  0.1622,  0.2606,  0.2948, -0.4535,  0.0562],
        [ 0.1805, -0.0957,  0.2255, -0.3050, -0.2388, -0.0635, -0.3870, -0.0851,
         -0.4431,  0.0638,  0.1543,  0.1281,  0.2845,  0.2510,  0.0159,  0.2439],
        [-0.2738,  0.2781,  0.0829,  0.1721,  0.4002, -0.0074,  0.3849,  0.2376,
          0.0307,  0.0416,  0.1318, -0.3145, -0.2784, -0.1650,  0.0946, -0.0738],
        [ 0.2256, -0.1179,  0.0531, -0.0803, -0.3506, -0.2508, -0.1331, -0.3840,
         -0.0661, -0.0380,  0.0830,  0.1635,  0.3815,  0.2426, -0.0561,  0.1956],
        [-0.2484,  0.2809, -0.2583,  0.2247,  0.0089,  0.1151,  0.3860,  0.3799,
          0.4422,  0.1838,  0.0558, -0.1321, -0.0281,  0.0798,  0.2102, -0.1991],
        [-0.2167,  0.1229,  0.0391, -0.0299,  0.2550,  0.3457,  0.3818,  0.0221,
          0.2879,  0.2515, -0.3229, -0.0414, -0.3530, -0.2087,  0.0832, -0.1783],
        [-0.0108, -0.1129,  0.1767, -0.0156, -0.0462, -0.2846, -0.4103, -0.4128,
         -0.3515, -0.2063,  0.1766,  0.0095,  0.0161,  0.1940, -0.3496,  0.1382]],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1219,  0.0057,  0.0967, -0.0517, -0.0041, -0.1026,  0.0869,  0.1478,
        -0.0289, -0.0263, -0.0273,  0.0590,  0.1395,  0.0658,  0.0192,  0.1007,
        -0.0696, -0.0191,  0.0941,  0.0460, -0.0530, -0.0775,  0.0007,  0.0016,
        -0.0719,  0.1589,  0.1637,  0.0196, -0.0586, -0.2027,  0.0292,  0.0086],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2969,  0.3823, -0.2694, -0.3047,  0.3795,  0.4255, -0.3356, -0.4310,
         -0.3376,  0.4287,  0.2957,  0.4355, -0.3188, -0.4624,  0.3472, -0.3402,
         -0.3529,  0.3768, -0.2615, -0.2907,  0.4831,  0.3205, -0.3985, -0.4247,
         -0.3834, -0.4137, -0.3589,  0.4109, -0.3870,  0.4402,  0.3176, -0.2781]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0571,  0.1339,  0.0830,  ...,  0.1373, -0.2274, -0.1137],
        [-0.1518, -0.0138,  0.1368,  ...,  0.0627, -0.2707,  0.0871],
        [ 0.0428, -0.0643,  0.0233,  ...,  0.0606,  0.2113,  0.0345],
        ...,
        [ 0.1505, -0.1820, -0.0316,  ..., -0.1872, -0.0168, -0.1180],
        [ 0.1323, -0.2434, -0.0772,  ..., -0.2326,  0.1006,  0.1557],
        [-0.2327,  0.1908,  0.0833,  ...,  0.0577, -0.2203, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0604,  0.0381, -0.0695, -0.1407, -0.0761,  0.0561, -0.0963,  0.0519,
        -0.0401,  0.0527,  0.0170,  0.0147, -0.0200,  0.0955, -0.0374, -0.0059,
         0.0487, -0.1597, -0.0242,  0.0748, -0.0734,  0.0192,  0.1134,  0.0249,
        -0.0991,  0.1067,  0.0537, -0.1247,  0.0401,  0.1804,  0.1768, -0.1150],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0805, -0.1891, -0.0800,  ...,  0.0842, -0.0198,  0.0505],
        [-0.2041, -0.0359,  0.1273,  ...,  0.1818, -0.0035,  0.0224],
        [ 0.1332, -0.0384, -0.1957,  ..., -0.1724, -0.0135,  0.2101],
        ...,
        [ 0.1417,  0.0825,  0.0529,  ...,  0.0461, -0.2120,  0.3070],
        [ 0.0252, -0.1711,  0.0455,  ...,  0.2862,  0.2337, -0.1572],
        [ 0.0041, -0.1186,  0.2318,  ...,  0.2569,  0.1455, -0.0747]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1276,  0.1706, -0.0594, -0.1331,  0.0249, -0.0223, -0.0824,  0.0163,
         0.1792, -0.1660,  0.1265, -0.1300,  0.2136,  0.0590, -0.0995,  0.1717,
        -0.1167, -0.1761,  0.0542,  0.0467, -0.0556,  0.0764, -0.2257,  0.2097,
        -0.0080, -0.0383,  0.0803,  0.0065, -0.1735, -0.0798,  0.1613,  0.0410],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5013,  0.4193, -0.4738, -0.4763,  0.3177,  0.3356, -0.3901,  0.3496,
          0.4099, -0.4341, -0.3617,  0.3804,  0.3815,  0.3615,  0.4154,  0.3986,
         -0.4978, -0.5014,  0.3500,  0.3558, -0.4255, -0.4005, -0.4949,  0.3587,
          0.4431,  0.5010, -0.4736,  0.4637, -0.4019, -0.4899,  0.4494,  0.4836]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2892], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.4700e-01,  4.4873e-01,  1.0657e-01, -8.6320e-02,  3.0054e-01,
          1.5455e-01,  3.3673e-01,  9.9189e-02,  3.3308e-01,  1.5813e-01,
          1.2105e-01, -2.6263e-01, -3.5652e-01, -2.5179e-01,  3.8036e-01,
          1.4579e-01],
        [-1.2026e-01, -1.3156e-01,  3.6565e-02, -1.0472e-01,  7.9749e-02,
          2.1076e-01,  8.7887e-02,  2.5573e-01,  5.6079e-01, -9.4208e-03,
          2.1481e-01, -3.4610e-01,  5.5244e-02,  8.8611e-02,  5.7715e-01,
          4.8455e-02],
        [ 3.7999e-02, -1.4083e-01,  2.8233e-01, -6.2895e-02, -2.5089e-01,
         -3.0377e-01, -1.0268e-01, -5.5719e-01, -1.4226e-01,  5.9930e-03,
          5.4935e-02,  7.5956e-02,  5.1479e-01,  2.2510e-01, -8.3074e-02,
          1.9512e-01],
        [ 8.8076e-02, -1.6905e-01, -9.6721e-02,  5.6639e-02, -1.1341e-01,
         -1.3253e-01, -4.6573e-02, -1.6573e-01, -5.4251e-01, -2.2751e-01,
         -1.2337e-01,  4.0864e-01,  2.2293e-01, -3.0308e-01, -3.3958e-01,
         -1.6060e-02],
        [ 3.9622e-02,  3.3700e-01, -1.8235e-02, -1.3033e-01,  2.6344e-01,
          3.5880e-02, -4.0939e-03,  4.2717e-01,  2.9172e-01,  1.4654e-01,
          2.3627e-01, -2.3344e-01, -1.3802e-02, -9.6964e-02,  4.3236e-01,
         -2.8089e-02],
        [ 1.4140e-02,  4.5248e-01, -2.6755e-01,  3.3881e-01,  4.7955e-01,
         -5.2163e-02,  3.1674e-01,  9.0868e-02,  3.7986e-01,  1.3989e-01,
         -2.5336e-01, -1.8962e-01, -3.1363e-01,  2.1270e-01,  4.6806e-01,
         -1.9446e-02],
        [ 2.2360e-01, -6.9443e-02,  2.5020e-01, -7.4482e-02, -1.7268e-01,
         -1.5686e-01, -1.3317e-01, -3.4102e-01, -4.0626e-01,  1.2252e-01,
         -3.2254e-02,  1.4578e-01, -5.5462e-02,  6.4504e-02, -4.3277e-01,
          1.5882e-02],
        [-2.0108e-01,  4.7871e-02,  2.0519e-01, -2.4554e-01, -4.6539e-01,
         -2.4396e-01, -4.9451e-02, -3.7919e-01, -3.5248e-01, -7.4762e-02,
         -6.8590e-02,  1.2856e-01,  2.7827e-01, -2.4346e-01, -2.3353e-01,
          2.2116e-01],
        [-8.7587e-02,  3.8390e-02,  1.7346e-01, -1.5811e-01, -2.2320e-01,
         -3.0161e-01, -1.0709e-01, -2.3492e-01, -1.6839e-01, -1.7910e-01,
         -2.0496e-01,  1.8776e-01, -9.1133e-02,  3.9629e-02, -5.5904e-01,
         -2.2754e-02],
        [-1.6433e-01,  1.3711e-01,  3.6772e-02, -1.0623e-01,  1.9205e-01,
          1.1724e-01, -3.2264e-03,  3.5817e-01,  4.5497e-01, -1.3727e-01,
          2.4940e-01, -1.0808e-01, -2.3455e-01,  4.2813e-02,  3.7539e-01,
         -8.0198e-02],
        [-2.4036e-01,  4.2060e-01,  7.0241e-02, -1.2194e-01,  1.1506e-01,
          3.6740e-01,  2.2065e-01,  2.4932e-01,  5.3211e-01,  1.3253e-01,
          4.7769e-02, -1.0679e-01, -2.3830e-01,  2.4189e-01,  1.4659e-01,
         -2.2067e-01],
        [ 1.7193e-02,  1.2345e-01,  1.2722e-01, -1.8715e-02,  3.1326e-01,
          6.1266e-02,  2.9102e-01,  2.6985e-01,  3.4950e-01,  2.0192e-01,
          3.0076e-01, -4.4020e-02, -4.0191e-01, -9.3136e-02,  2.5211e-01,
         -6.9294e-02],
        [ 2.3588e-01, -9.0067e-02,  4.1556e-02, -9.6784e-02, -2.5187e-01,
          3.9339e-02, -9.0747e-02, -4.6069e-01, -5.0128e-01,  4.2049e-05,
         -2.7223e-02,  1.4915e-01, -1.3265e-02,  6.7942e-02, -3.9813e-01,
         -5.9484e-02],
        [ 6.4418e-02,  1.4726e-01,  2.1652e-01,  9.5448e-02, -4.1353e-01,
          1.9376e-02,  2.5902e-02, -1.7844e-01, -4.0319e-01, -1.6605e-02,
         -2.2909e-01,  1.9417e-01,  7.8673e-02, -7.9914e-02, -5.3718e-01,
          1.0317e-01],
        [-2.3739e-01, -5.8662e-02,  7.2617e-02, -1.4013e-01,  5.0642e-01,
          3.6431e-01,  2.5430e-02,  2.3905e-01,  1.5741e-01,  4.2339e-02,
          1.2780e-01, -4.2018e-01, -5.2289e-02,  2.0945e-02,  2.4232e-01,
         -3.4443e-02],
        [-1.3305e-01, -3.7858e-01,  1.0383e-01,  1.2929e-01, -4.6226e-01,
         -1.5880e-02, -2.0508e-01, -4.4627e-01, -3.5122e-01,  3.5233e-02,
          1.4985e-02,  5.3310e-01,  1.8981e-01, -1.2839e-01, -8.6403e-02,
          2.5248e-02],
        [ 1.2266e-01,  5.7105e-02,  1.8212e-02, -2.1451e-01, -4.2528e-01,
          1.9076e-02,  9.4118e-03, -7.9793e-02, -4.8671e-01, -1.6955e-02,
          1.1969e-01,  3.4853e-01,  2.9482e-01,  8.9182e-02, -2.8678e-01,
         -1.9973e-01],
        [-1.5008e-01,  2.2256e-01, -8.8800e-02,  2.6539e-02,  2.2522e-01,
          2.3210e-01,  2.5416e-01,  3.5965e-01,  2.1905e-01,  1.4731e-01,
         -6.3949e-02, -3.0125e-01, -1.7591e-01, -6.0199e-02,  3.7019e-01,
         -3.7761e-02],
        [ 1.5037e-01, -2.3472e-01,  2.4277e-02, -2.0404e-01, -3.4511e-01,
         -3.2443e-01, -3.0278e-01, -9.7920e-02, -5.4757e-01, -1.7496e-02,
          1.0762e-01,  3.5025e-02,  2.9108e-01,  1.3197e-01, -1.1351e-01,
          9.3203e-02],
        [ 3.0765e-01, -2.3486e-01,  1.5133e-01, -1.0664e-02, -4.8126e-01,
         -1.8442e-01, -3.8792e-01, -1.1008e-01, -1.9840e-01, -1.7915e-01,
          3.9357e-02,  3.6786e-01,  3.5888e-02,  5.6176e-03, -1.5249e-01,
          1.0940e-01],
        [-6.3649e-02,  2.8252e-01,  9.4000e-02, -1.7562e-01,  3.5594e-01,
         -7.1018e-02,  2.9072e-01,  4.6565e-01,  2.6804e-01, -5.3091e-02,
         -1.0374e-01, -3.2229e-01, -1.9378e-01, -7.6075e-02,  4.5795e-01,
         -1.3738e-01],
        [ 2.7578e-03,  5.1271e-03,  4.8701e-02,  3.2240e-01,  2.0355e-01,
          8.6261e-02,  2.4387e-01,  1.0425e-01,  2.4941e-01,  1.6533e-01,
          2.7783e-01, -4.2759e-01, -2.5491e-01, -2.7300e-01,  1.3334e-01,
          1.3537e-01],
        [ 2.9201e-01, -2.8457e-01, -6.5778e-02, -7.8851e-02, -1.4330e-01,
         -3.3949e-01, -3.1637e-01, -3.5118e-01, -4.0132e-01, -5.8645e-02,
          2.3261e-01,  3.2515e-01,  1.6193e-03,  2.0363e-01, -3.8425e-02,
          1.2485e-01],
        [ 4.8149e-02,  2.8662e-02,  1.4971e-01, -2.2280e-01, -2.7000e-01,
         -9.5045e-02, -7.2590e-02, -3.3993e-01, -4.1616e-01, -1.4474e-01,
         -1.1450e-01,  3.7367e-01,  2.1082e-01, -7.2864e-02, -3.0204e-01,
         -1.5759e-01],
        [ 6.9452e-02, -3.9735e-01,  2.1340e-02, -1.8705e-02, -4.1237e-02,
         -1.9443e-01,  9.8783e-02, -2.6680e-01, -5.3902e-01,  1.9970e-01,
          1.7569e-01,  7.9756e-02,  2.1263e-02,  9.7728e-02, -4.5750e-01,
          2.0906e-01],
        [-9.0628e-02, -1.8707e-01, -6.3566e-02,  1.8731e-01, -3.0163e-01,
         -1.6734e-01,  1.5104e-02, -4.3358e-01, -3.0027e-01, -2.1240e-01,
         -2.9461e-01,  1.6213e-01,  1.6310e-01,  1.8500e-01, -5.0454e-01,
         -4.2710e-02],
        [ 2.3185e-01, -1.3625e-01,  2.0925e-01, -2.7975e-01, -3.1875e-01,
         -5.5673e-02, -4.4008e-01, -1.5400e-01, -5.1335e-01,  5.8384e-02,
          1.5424e-01,  2.0045e-01,  3.3606e-01,  2.2666e-01, -4.4957e-02,
          2.3937e-01],
        [-1.9735e-01,  2.5171e-01,  1.5823e-01,  1.0864e-01,  4.5892e-01,
         -2.3594e-02,  3.2519e-01,  2.9523e-01,  1.1354e-01, -2.9758e-02,
          2.4932e-01, -3.7749e-01, -2.3824e-01, -7.4641e-02,  1.6219e-01,
          2.7740e-03],
        [ 1.5149e-01, -1.1621e-01, -1.6081e-02, -2.0036e-02, -4.0957e-01,
         -2.2435e-01, -7.9939e-02, -4.4096e-01, -1.4728e-01,  2.7490e-02,
         -1.1504e-02,  2.2714e-01,  3.5885e-01,  1.5495e-01, -1.2217e-01,
          1.2767e-01],
        [-2.4195e-01,  2.9977e-01, -2.2046e-01,  1.9057e-01,  7.9253e-02,
          1.1092e-01,  3.9867e-01,  4.3720e-01,  5.0010e-01,  1.6033e-01,
          9.6474e-02, -1.9398e-01, -4.7489e-02,  1.3010e-01,  2.5974e-01,
         -1.6604e-01],
        [-1.8306e-01,  1.5176e-01,  9.1437e-02, -7.9140e-02,  3.2962e-01,
          3.2090e-01,  3.6952e-01,  8.8634e-02,  3.6995e-01,  2.0989e-01,
         -2.8364e-01, -1.1351e-01, -3.8202e-01, -1.3924e-01,  1.5072e-01,
         -1.3090e-01],
        [-9.9544e-02, -8.9599e-02,  9.7158e-02,  5.2007e-02, -8.4648e-02,
         -2.5672e-01, -3.4173e-01, -4.6132e-01, -4.2518e-01, -1.2861e-01,
          6.3616e-02,  6.2375e-02, -3.5099e-02,  9.5573e-02, -4.1364e-01,
          5.9134e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0867,  0.1064,  0.1096, -0.1275,  0.0786, -0.0893,  0.0569,  0.1341,
        -0.0731,  0.0628, -0.0179,  0.0877,  0.0797, -0.0170,  0.0723,  0.0353,
        -0.1088, -0.0102,  0.1120,  0.0599,  0.0144, -0.0683,  0.0166, -0.0298,
        -0.1222,  0.0662,  0.1864,  0.0525, -0.0653, -0.2002,  0.0111, -0.0150],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3640,  0.5164, -0.2972, -0.4050,  0.4819,  0.4783, -0.3918, -0.4760,
         -0.3973,  0.5380,  0.3408,  0.4945, -0.3960, -0.5649,  0.4239, -0.4232,
         -0.4145,  0.4308, -0.2801, -0.3214,  0.5652,  0.3520, -0.4251, -0.4908,
         -0.4486, -0.5178, -0.3822,  0.4798, -0.4302,  0.4895,  0.3376, -0.3335]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0313,  0.1062,  0.0633,  ...,  0.1548, -0.2423, -0.1137],
        [-0.1404, -0.0305,  0.1365,  ...,  0.0556, -0.2590,  0.0871],
        [ 0.0285, -0.0450,  0.0267,  ...,  0.0643,  0.2071,  0.0345],
        ...,
        [ 0.1418, -0.1670, -0.0356,  ..., -0.1753, -0.0354, -0.1180],
        [ 0.1192, -0.2249, -0.0756,  ..., -0.2271,  0.0947,  0.1557],
        [-0.2138,  0.1697,  0.0704,  ...,  0.0664, -0.2236, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0756,  0.0322, -0.0667, -0.1406, -0.0808,  0.0452, -0.0898,  0.0694,
        -0.0373,  0.0483,  0.0432,  0.0190, -0.0226,  0.1016, -0.0294, -0.0148,
         0.0470, -0.1625, -0.0087,  0.0835, -0.0864,  0.0087,  0.1147,  0.0377,
        -0.1074,  0.1076,  0.0535, -0.1365,  0.0429,  0.1907,  0.1815, -0.1065],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0900, -0.1993, -0.0713,  ...,  0.0931, -0.0146,  0.0623],
        [-0.1934, -0.0448,  0.1361,  ...,  0.1902,  0.0011,  0.0356],
        [ 0.1224, -0.0327, -0.1997,  ..., -0.1782, -0.0156,  0.1963],
        ...,
        [ 0.1300,  0.0783,  0.0720,  ...,  0.0482, -0.2074,  0.2914],
        [ 0.0334, -0.1885,  0.0561,  ...,  0.3001,  0.2455, -0.1475],
        [ 0.0141, -0.1256,  0.2349,  ...,  0.2633,  0.1478, -0.0616]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1386,  0.1813, -0.0680, -0.1435,  0.0332, -0.0137, -0.0915,  0.0311,
         0.1920, -0.1738,  0.1530, -0.1797,  0.2256,  0.0670, -0.0868,  0.1867,
        -0.0522, -0.1858,  0.0637,  0.0574, -0.0672,  0.0670, -0.2314,  0.2204,
         0.0022, -0.0867,  0.0877,  0.0149, -0.1846, -0.0811,  0.1754,  0.0505],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.7176,  0.6425, -0.6990, -0.6845,  0.5456,  0.5626, -0.6151,  0.5410,
          0.6059, -0.6617, -0.5774,  0.5925,  0.5862,  0.5876,  0.6127,  0.5882,
         -0.7068, -0.7238,  0.5753,  0.5702, -0.6322, -0.6246, -0.7243,  0.5824,
          0.6686,  0.7136, -0.6961,  0.6798, -0.6216, -0.7151,  0.6374,  0.7027]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.4668], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-3.0729e-01,  5.0725e-01,  6.8698e-02, -6.7732e-02,  4.0396e-01,
          2.0869e-01,  4.1013e-01,  1.9353e-01,  3.6427e-01,  1.9031e-01,
          1.3911e-01, -3.4332e-01, -3.9878e-01, -2.6517e-01,  3.8109e-01,
          1.1395e-01],
        [-9.0019e-02, -1.5371e-01,  8.3860e-02, -1.4767e-01,  1.5423e-01,
          2.1267e-01,  3.2174e-02,  3.7754e-01,  7.3026e-01, -5.2154e-02,
          3.0549e-01, -4.7124e-01,  8.5137e-02,  1.3788e-01,  7.1329e-01,
          9.2770e-02],
        [ 1.6466e-01, -2.4624e-01,  3.6630e-01, -1.0727e-01, -4.1278e-01,
         -3.7885e-01, -2.5891e-01, -6.7599e-01, -1.8959e-01, -6.3281e-02,
          9.5091e-02,  1.8815e-01,  6.5068e-01,  2.8782e-01, -1.1864e-01,
          2.7110e-01],
        [ 3.8778e-02, -1.1569e-01, -1.5645e-01,  1.0868e-01, -1.5670e-01,
         -1.2408e-01,  2.2848e-02, -2.7386e-01, -7.1030e-01, -1.7250e-01,
         -2.2893e-01,  5.0621e-01,  1.6548e-01, -3.6699e-01, -4.6649e-01,
         -7.1691e-02],
        [ 9.5120e-02,  2.6918e-01,  4.1669e-02, -1.8019e-01,  2.9577e-01,
          3.2052e-02, -7.3405e-02,  5.2251e-01,  4.5192e-01,  8.7060e-02,
          3.4459e-01, -3.0796e-01,  5.1400e-02, -2.9963e-02,  5.4420e-01,
          2.8218e-02],
        [-9.9144e-02,  5.4279e-01, -3.4841e-01,  3.8453e-01,  6.1262e-01,
          1.2564e-02,  4.5150e-01,  1.9519e-01,  3.9233e-01,  2.0509e-01,
         -2.7510e-01, -2.8048e-01, -4.0505e-01,  1.6295e-01,  4.6586e-01,
         -8.8246e-02],
        [ 1.8231e-01, -3.4490e-02,  1.9614e-01, -2.7061e-02, -2.1988e-01,
         -1.4169e-01, -7.8075e-02, -4.3460e-01, -5.4889e-01,  1.6832e-01,
         -1.3452e-01,  2.3023e-01, -1.0577e-01,  4.9579e-03, -5.2388e-01,
         -3.2039e-02],
        [-2.2319e-01,  5.0808e-02,  1.6002e-01, -2.0284e-01, -5.1956e-01,
         -2.2305e-01, -8.7840e-03, -4.7158e-01, -4.7041e-01, -4.1610e-02,
         -1.5398e-01,  2.1999e-01,  2.4711e-01, -2.9067e-01, -3.1489e-01,
          1.8466e-01],
        [-1.3401e-01,  7.0910e-02,  1.0997e-01, -1.0107e-01, -2.8700e-01,
         -2.8520e-01, -3.6793e-02, -3.5541e-01, -3.4269e-01, -1.2399e-01,
         -3.1168e-01,  3.0891e-01, -1.3717e-01, -2.5148e-02, -6.9296e-01,
         -7.9760e-02],
        [-1.2078e-01,  9.2301e-02,  9.2379e-02, -1.5493e-01,  2.4101e-01,
          1.1108e-01, -6.7267e-02,  4.6819e-01,  6.1827e-01, -1.8731e-01,
          3.4845e-01, -2.0950e-01, -1.8441e-01,  1.0155e-01,  5.0200e-01,
         -2.8884e-02],
        [-2.5873e-01,  4.5492e-01,  8.1362e-02, -1.4089e-01,  1.9165e-01,
          3.7536e-01,  2.3125e-01,  3.4345e-01,  6.0788e-01,  1.2933e-01,
          9.7433e-02, -1.9651e-01, -2.4761e-01,  2.6048e-01,  1.9616e-01,
         -2.1553e-01],
        [ 5.0629e-02,  1.0451e-01,  1.8153e-01, -6.8932e-02,  3.6805e-01,
          4.2787e-02,  2.3627e-01,  3.7712e-01,  4.9268e-01,  1.5713e-01,
          3.9397e-01, -1.4792e-01, -3.6301e-01, -3.7220e-02,  3.5990e-01,
         -2.3637e-02],
        [ 1.8149e-01, -2.6881e-02, -1.7399e-02, -4.7968e-02, -2.8405e-01,
          5.0443e-02, -2.5418e-02, -5.4533e-01, -6.4582e-01,  5.3920e-02,
         -1.3869e-01,  2.1485e-01, -7.9835e-02,  7.8336e-04, -4.8850e-01,
         -1.1415e-01],
        [ 2.0671e-02,  1.8977e-01,  1.5987e-01,  1.4550e-01, -4.7101e-01,
          2.3045e-02,  9.0798e-02, -2.9478e-01, -5.7419e-01,  3.4189e-02,
         -3.3017e-01,  3.0652e-01,  3.1293e-02, -1.3984e-01, -6.7013e-01,
          5.0703e-02],
        [-1.9035e-01, -1.0166e-01,  1.3242e-01, -1.9242e-01,  5.5430e-01,
          3.4793e-01, -4.2077e-02,  3.4556e-01,  3.1869e-01, -1.0775e-02,
          2.3137e-01, -5.2003e-01,  2.3207e-05,  8.3559e-02,  3.6117e-01,
          1.9615e-02],
        [-1.5612e-01, -3.4625e-01,  7.1405e-02,  1.5691e-01, -4.9550e-01,
         -1.3967e-02, -1.7338e-01, -5.1515e-01, -4.4131e-01,  6.2628e-02,
         -6.7850e-02,  5.8765e-01,  1.4410e-01, -1.7041e-01, -1.2973e-01,
         -2.7944e-03],
        [ 7.1726e-02,  1.0231e-01, -4.7911e-02, -1.5540e-01, -4.7417e-01,
          3.7626e-02,  8.1471e-02, -1.9278e-01, -6.6175e-01,  4.1251e-02,
          7.5040e-03,  4.5735e-01,  2.3752e-01,  2.0236e-02, -4.1267e-01,
         -2.5875e-01],
        [-2.1273e-01,  2.9093e-01, -1.1794e-01,  3.5766e-02,  3.1983e-01,
          2.6044e-01,  3.2208e-01,  4.4611e-01,  2.4363e-01,  1.7793e-01,
         -5.1278e-02, -3.8322e-01, -2.2256e-01, -7.4080e-02,  3.8072e-01,
         -6.5758e-02],
        [ 2.7125e-01, -3.4229e-01,  9.2655e-02, -2.3356e-01, -5.0234e-01,
         -3.8709e-01, -4.4112e-01, -2.2404e-01, -6.0211e-01, -7.7088e-02,
          1.4037e-01,  1.5485e-01,  4.2662e-01,  1.8597e-01, -1.6158e-01,
          1.6055e-01],
        [ 4.1986e-01, -3.2855e-01,  2.1904e-01, -4.4205e-02, -6.5436e-01,
         -2.5202e-01, -5.2481e-01, -2.4155e-01, -2.5771e-01, -2.3642e-01,
          6.0345e-02,  4.8336e-01,  1.4954e-01,  4.6412e-02, -2.0842e-01,
          1.7069e-01],
        [-3.8777e-02,  2.4532e-01,  1.2391e-01, -2.0118e-01,  3.7912e-01,
         -7.3658e-02,  2.6178e-01,  5.2236e-01,  3.4082e-01, -7.9393e-02,
         -2.0599e-02, -3.5860e-01, -1.4095e-01, -3.3792e-02,  4.7583e-01,
         -1.0945e-01],
        [-2.6144e-03,  3.7915e-02,  7.5274e-02,  2.9044e-01,  3.1382e-01,
          1.0440e-01,  2.3880e-01,  2.2740e-01,  3.7321e-01,  1.4718e-01,
          3.4328e-01, -5.4491e-01, -2.7160e-01, -2.3947e-01,  2.2739e-01,
          1.5407e-01],
        [ 4.0041e-01, -3.8017e-01, -3.0719e-03, -1.0797e-01, -2.9677e-01,
         -3.9575e-01, -4.4506e-01, -4.6848e-01, -4.4925e-01, -1.1357e-01,
          2.5671e-01,  4.3351e-01,  1.1509e-01,  2.4696e-01, -8.1132e-02,
          1.8411e-01],
        [-5.4778e-03,  7.8168e-02,  8.4273e-02, -1.6601e-01, -3.0461e-01,
         -6.8698e-02, -9.4820e-05, -4.3643e-01, -5.7183e-01, -8.7085e-02,
         -2.2595e-01,  4.6130e-01,  1.4639e-01, -1.4194e-01, -4.1188e-01,
         -2.1644e-01],
        [ 1.7963e-02, -3.4381e-01, -4.0715e-02,  3.5472e-02, -8.1331e-02,
         -1.8048e-01,  1.6824e-01, -3.6905e-01, -7.0501e-01,  2.5519e-01,
          6.5435e-02,  1.7178e-01, -4.0212e-02,  3.0804e-02, -5.7206e-01,
          1.5224e-01],
        [-1.5553e-01, -1.0650e-01, -1.2876e-01,  2.4032e-01, -3.1537e-01,
         -1.5861e-01,  9.1342e-02, -5.1298e-01, -4.5468e-01, -1.4589e-01,
         -4.0725e-01,  2.0863e-01,  8.5828e-02,  1.1206e-01, -6.0782e-01,
         -1.0445e-01],
        [ 3.8078e-01, -2.2385e-01,  3.3154e-01, -3.5534e-01, -5.2160e-01,
         -1.6283e-01, -6.4251e-01, -3.0610e-01, -6.1409e-01, -2.1957e-02,
          2.0830e-01,  3.2247e-01,  5.0820e-01,  3.1521e-01, -1.0626e-01,
          3.4698e-01],
        [-1.9706e-01,  2.6269e-01,  1.8229e-01,  8.2474e-02,  5.3083e-01,
         -1.7178e-02,  3.1253e-01,  3.9249e-01,  2.0940e-01, -4.5988e-02,
          3.1416e-01, -4.6947e-01, -2.3034e-01, -4.3457e-02,  2.2943e-01,
          2.0242e-02],
        [ 1.7220e-01, -1.5848e-01, -3.0547e-02,  2.5702e-03, -4.8668e-01,
         -2.2323e-01, -8.6741e-02, -5.3683e-01, -2.2464e-01,  3.0967e-02,
         -5.8868e-02,  3.2342e-01,  3.7240e-01,  1.3698e-01, -1.7988e-01,
          1.2144e-01],
        [-3.4302e-01,  3.8577e-01, -2.8954e-01,  2.2945e-01,  2.1708e-01,
          1.7355e-01,  5.2337e-01,  5.3757e-01,  5.2742e-01,  2.1727e-01,
          7.8282e-02, -2.8479e-01, -1.3936e-01,  8.8323e-02,  2.7140e-01,
         -2.2502e-01],
        [-3.0145e-01,  2.5656e-01,  2.2897e-02, -4.8707e-02,  4.9222e-01,
          3.8763e-01,  5.0709e-01,  2.1857e-01,  4.2951e-01,  2.6810e-01,
         -3.1559e-01, -2.3418e-01, -5.1733e-01, -1.9173e-01,  2.0170e-01,
         -1.9763e-01],
        [-1.3749e-01, -6.1760e-02,  4.1832e-02,  1.0159e-01, -1.2546e-01,
         -2.3137e-01, -2.8512e-01, -5.5575e-01, -5.6588e-01, -8.3181e-02,
         -3.5223e-02,  1.5076e-01, -8.4682e-02,  3.7649e-02, -5.0800e-01,
          1.1686e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1041,  0.1660,  0.1888, -0.2359,  0.2089, -0.1548, -0.0395,  0.1228,
        -0.1514,  0.1567, -0.0518,  0.1197, -0.0662, -0.1163,  0.1740, -0.0428,
        -0.1925, -0.0749,  0.2019,  0.1266,  0.1037, -0.0928,  0.0952, -0.1251,
        -0.2370, -0.0682,  0.2242,  0.0585, -0.0051, -0.2525, -0.0760, -0.0706],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5404,  0.7101, -0.4641, -0.6201,  0.6945,  0.6265, -0.6222, -0.6860,
         -0.6403,  0.7456,  0.5382,  0.7205, -0.6318, -0.7926,  0.6497, -0.6198,
         -0.6470,  0.6050, -0.4316, -0.4739,  0.7683,  0.5357, -0.5835, -0.7212,
         -0.6758, -0.7201, -0.5351,  0.6754, -0.6213,  0.6548,  0.4870, -0.5499]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0257,  0.1067,  0.0539,  ...,  0.1982, -0.5890, -0.1137],
        [-0.1400, -0.0348,  0.1412,  ...,  0.0528, -0.5172,  0.0871],
        [ 0.0282, -0.0403,  0.0214,  ...,  0.0647,  0.5371,  0.0345],
        ...,
        [ 0.1386, -0.1548, -0.0413,  ..., -0.1692,  0.2329, -0.1180],
        [ 0.1117, -0.2133, -0.0737,  ..., -0.2314,  0.3921,  0.1557],
        [-0.2234,  0.1923,  0.0707,  ...,  0.0836, -0.5128, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0861,  0.0267, -0.0607, -0.1338, -0.0858,  0.0443, -0.0832,  0.0701,
        -0.0403,  0.0482,  0.0515,  0.0141, -0.0243,  0.1067, -0.0211, -0.0179,
         0.0554, -0.1662, -0.0009,  0.0936, -0.0962, -0.0051,  0.1196,  0.0590,
        -0.1084,  0.1135,  0.0613, -0.1566,  0.0460,  0.1982,  0.1808, -0.1032],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0965, -0.2211,  0.0091,  ...,  0.1126, -0.0027,  0.0695],
        [-0.1877, -0.0636,  0.2101,  ...,  0.2072,  0.0107,  0.0407],
        [ 0.1372, -0.0339, -0.2406,  ..., -0.1746, -0.0122,  0.2187],
        ...,
        [ 0.1454,  0.0882,  0.0209,  ...,  0.0451, -0.2324,  0.3502],
        [ 0.0543, -0.2311,  0.1609,  ...,  0.3389,  0.2751, -0.1229],
        [ 0.0171, -0.1377,  0.2917,  ...,  0.2744,  0.1486, -0.0538]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1572,  0.1973, -0.0641, -0.1637,  0.0403, -0.0021, -0.1010,  0.0698,
         0.2231, -0.1738,  0.1353, -0.1472,  0.2502,  0.0708, -0.0562,  0.2235,
         0.0353, -0.1957,  0.0632,  0.0757, -0.0924,  0.0628, -0.2337,  0.2324,
         0.0159, -0.0323,  0.0837,  0.0033, -0.2033, -0.0777,  0.2130,  0.0627],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 1.1464,  1.0739, -1.1345, -1.1115,  0.9817,  0.9982, -1.0491,  0.9625,
          1.0292, -1.1003, -1.0144,  1.0126,  1.0134,  1.0249,  1.0358,  1.0089,
         -1.1279, -1.1562,  1.0106,  0.9990, -1.0585, -1.0584, -1.1645,  1.0148,
          1.1015,  1.1359, -1.1362,  1.1133, -1.0520, -1.1562,  1.0578,  1.1328]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.8845], device='cuda:0', requires_grad=True)

