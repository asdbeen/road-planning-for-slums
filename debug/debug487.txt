Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 7.9827e-03,  3.8357e-01,  2.9912e-01, -2.9979e-01, -1.9652e-01,
         -1.5476e-01, -1.0288e-01, -4.1913e-01, -3.4425e-01, -8.0150e-02,
         -1.0939e-02,  2.2825e-01, -3.5441e-01, -8.9058e-02, -7.5173e-02,
          3.9118e-01],
        [-2.5044e-01, -3.7253e-01, -8.9621e-02, -3.7850e-02, -2.4319e-02,
          2.5179e-01,  1.7763e-01,  1.8501e-01,  5.0222e-01,  1.3716e-01,
          2.8146e-01, -2.8855e-01,  3.9837e-01, -4.7180e-03,  3.7413e-01,
         -8.9512e-02],
        [ 1.1262e-01,  2.9074e-01,  3.9020e-01, -1.1430e-01, -1.2284e-01,
         -3.5144e-01, -1.3076e-01, -4.9025e-01, -1.6123e-01, -1.0309e-01,
         -1.5002e-01,  1.0753e-02, -4.2589e-02,  3.3955e-01, -7.4576e-02,
          3.0165e-01],
        [ 2.8634e-01,  1.0034e-01,  8.3706e-02, -5.5854e-02, -6.9683e-02,
         -2.2078e-01, -1.9265e-01, -1.5015e-01, -5.5276e-01, -4.2841e-01,
         -1.9776e-01,  4.1808e-01, -1.1847e-01, -1.4138e-01, -2.4724e-01,
          1.7837e-01],
        [-1.0412e-01,  4.7650e-02, -1.6536e-01, -4.7513e-02,  1.7722e-01,
          9.9643e-02,  6.9004e-02,  3.6438e-01,  2.6327e-01,  3.1044e-01,
          3.3548e-01, -2.0559e-01,  3.7126e-01, -2.1397e-01,  3.3490e-01,
         -1.7693e-01],
        [-3.7198e-02,  6.6628e-02, -3.7496e-01,  3.9979e-01,  3.8071e-01,
          4.6728e-03,  3.2336e-01,  3.9885e-02,  4.0852e-01,  2.4848e-01,
         -7.9778e-02, -1.5692e-01,  1.8377e-01,  1.2532e-01,  4.9333e-01,
         -1.1702e-01],
        [ 3.6821e-01,  2.3252e-01,  3.9619e-01, -1.5953e-01, -5.7485e-02,
         -2.0718e-01, -2.0228e-01, -2.5912e-01, -3.6892e-01, -3.1099e-02,
         -2.8730e-02,  8.6465e-02, -3.9342e-01,  1.7997e-01, -3.3377e-01,
          1.6230e-01],
        [-5.1622e-02,  3.5603e-01,  3.5825e-01, -3.4590e-01, -3.5661e-01,
         -3.0062e-01, -1.2542e-01, -2.9724e-01, -3.1468e-01, -2.3367e-01,
         -8.5780e-02,  6.6450e-02, -7.8167e-02, -1.1051e-01, -1.6443e-01,
          3.7619e-01],
        [ 4.2273e-02,  3.5351e-01,  3.0174e-01, -2.3135e-01, -5.9756e-02,
         -3.4778e-01, -1.8363e-01, -1.2091e-01, -6.2108e-02, -3.2485e-01,
         -2.7548e-01,  7.8625e-02, -4.5453e-01,  1.5046e-01, -3.3628e-01,
          1.1660e-01],
        [-3.1640e-01, -1.6157e-01, -1.1306e-01, -1.4578e-02,  1.1214e-01,
          1.8397e-01,  1.0660e-01,  2.9733e-01,  4.0760e-01,  3.1384e-02,
          3.6075e-01, -6.6368e-02,  1.6994e-01, -8.7956e-02,  2.5602e-01,
         -2.3950e-01],
        [-3.7820e-01,  2.7605e-02, -7.1240e-02, -4.3824e-02, -1.8490e-02,
          4.5395e-01,  2.8665e-01,  1.8617e-01,  4.9263e-01,  2.8695e-01,
          2.1563e-01, -5.5459e-02,  2.4401e-01,  1.1980e-01,  6.4280e-02,
         -3.6608e-01],
        [-1.5544e-01, -2.0527e-01, -4.3718e-02,  9.2948e-02,  2.0575e-01,
          1.4655e-01,  4.2103e-01,  1.9698e-01,  2.9176e-01,  3.8154e-01,
          4.0682e-01,  1.5844e-02, -1.8295e-02, -2.6467e-01,  8.8772e-02,
         -2.4974e-01],
        [ 3.4111e-01,  2.7527e-01,  1.5731e-01, -1.4462e-01, -1.1144e-01,
          1.6250e-02, -1.0905e-01, -3.6292e-01, -4.4669e-01, -1.2012e-01,
         -1.6131e-01,  7.5933e-02, -4.8500e-01,  1.3164e-01, -2.8619e-01,
          5.4182e-02],
        [ 2.1609e-01,  3.9636e-01,  3.6849e-01,  1.2985e-03, -3.2027e-01,
         -2.4994e-02, -6.0127e-02, -9.4919e-02, -3.1680e-01, -1.7818e-01,
         -2.7219e-01,  1.3472e-01, -2.3454e-01,  4.8154e-02, -3.6996e-01,
          2.5884e-01],
        [-3.8314e-01, -3.4392e-01, -6.5913e-02, -5.2782e-02,  3.7785e-01,
          4.0743e-01,  1.3122e-01,  1.5187e-01,  8.4617e-02,  1.9955e-01,
          1.7976e-01, -3.4499e-01,  2.9433e-01, -9.4158e-02,  1.0408e-01,
         -1.8439e-01],
        [-3.7096e-02, -2.7560e-02,  1.9104e-01,  1.2036e-01, -3.8825e-01,
         -7.4160e-02, -2.6559e-01, -4.2785e-01, -4.4204e-01, -1.1119e-01,
         -1.2171e-01,  5.3552e-01, -4.1246e-01, -5.7020e-02, -4.1792e-02,
          1.2805e-01],
        [ 3.3945e-01,  3.2668e-01,  2.1477e-01, -3.5420e-01, -3.9106e-01,
         -6.0318e-02, -1.4371e-01, -4.7785e-02, -4.9976e-01, -2.1787e-01,
          7.9044e-02,  3.3765e-01, -3.2423e-04,  2.9587e-01, -1.9488e-01,
          1.2221e-02],
        [-3.0000e-01, -4.6695e-02, -2.4159e-01,  1.2339e-01,  1.4309e-01,
          3.0817e-01,  3.1355e-01,  3.0776e-01,  2.5424e-01,  2.9978e-01,
         -5.2941e-03, -2.7848e-01,  1.4423e-01, -1.9058e-01,  3.2821e-01,
         -1.9172e-01],
        [ 2.3802e-01,  1.4004e-01,  1.3555e-01, -2.5351e-01, -2.2752e-01,
         -3.7671e-01, -3.5586e-01, -3.0209e-02, -6.0391e-01, -1.3021e-01,
         -1.0009e-01, -2.2870e-02, -2.0239e-01,  2.7278e-01, -1.0278e-01,
          2.1702e-01],
        [ 3.7636e-01,  1.6913e-01,  2.6646e-01, -7.3026e-02, -3.1098e-01,
         -2.2912e-01, -3.8107e-01,  6.5647e-03, -1.6028e-01, -2.9059e-01,
         -1.5582e-01,  2.6926e-01, -4.3656e-01,  8.5453e-02,  4.1158e-03,
          2.1870e-01],
        [-1.9651e-01,  1.3931e-02, -5.2962e-02, -8.2399e-02,  2.9948e-01,
         -1.1615e-02,  3.4100e-01,  4.1726e-01,  3.0611e-01,  9.8140e-02,
         -1.3479e-04, -3.2579e-01,  1.6875e-01, -1.9261e-01,  4.4271e-01,
         -2.8145e-01],
        [-9.7936e-02, -4.1197e-01, -6.2636e-02,  3.8931e-01,  5.3106e-03,
          1.2535e-01,  3.0479e-01, -1.8080e-02,  1.5321e-01,  2.9331e-01,
          4.0125e-01, -3.0289e-01,  2.3416e-01, -3.7204e-01, -1.4274e-02,
          1.2606e-02],
        [ 3.7072e-01,  6.8064e-02,  5.1937e-02, -1.5082e-01, -2.3374e-03,
         -4.0047e-01, -3.1951e-01, -2.5336e-01, -3.5888e-01, -1.7228e-01,
          6.7541e-02,  2.3848e-01, -4.2348e-01,  2.9738e-01,  5.9835e-02,
          2.4128e-01],
        [ 2.5969e-01,  2.2113e-01,  3.3755e-01, -3.5212e-01, -2.3658e-01,
         -1.7066e-01, -1.9696e-01, -3.0533e-01, -4.5572e-01, -3.3606e-01,
         -1.1931e-01,  3.6569e-01, -9.6500e-03,  1.0560e-01, -2.1370e-01,
          4.0930e-02],
        [ 2.4306e-01, -5.3145e-02,  1.8295e-01, -1.1325e-01,  1.7921e-02,
         -2.9985e-01, -2.0671e-02, -2.5483e-01, -5.3995e-01,  1.1067e-02,
          5.2798e-02,  8.0338e-02, -4.2448e-01,  2.5281e-01, -3.9840e-01,
          3.8700e-01],
        [ 5.7867e-02,  7.2352e-02,  9.0601e-02,  9.3631e-02, -2.4219e-01,
         -2.2591e-01, -6.1387e-02, -3.8710e-01, -2.9536e-01, -3.7964e-01,
         -3.5509e-01,  1.6372e-01, -2.0473e-01,  2.9813e-01, -4.4253e-01,
          1.0903e-01],
        [ 2.3840e-01,  2.4975e-01,  3.0943e-01, -3.4494e-01, -1.9412e-01,
         -1.0632e-01, -3.9775e-01, -5.3940e-02, -5.1147e-01, -2.0936e-02,
         -5.0078e-02,  1.2071e-01, -1.2170e-01,  2.9474e-01,  5.2603e-02,
          3.2784e-01],
        [-3.3886e-01, -9.9718e-02,  5.6450e-03,  2.0362e-01,  3.2706e-01,
          3.6100e-02,  4.0875e-01,  2.0160e-01,  6.2015e-02,  1.3013e-01,
          3.7440e-01, -3.0595e-01,  1.8033e-01, -2.1507e-01,  3.8238e-02,
         -1.5190e-01],
        [ 3.2511e-01,  1.9046e-01,  1.5028e-01, -1.3326e-01, -3.2253e-01,
         -3.0051e-01, -1.9012e-01, -3.8111e-01, -1.4152e-01, -1.3945e-01,
         -9.7034e-02,  1.7994e-01, -2.4251e-03,  3.2081e-01, -4.8184e-02,
          3.0274e-01],
        [-2.6965e-01, -2.6993e-02, -3.0935e-01,  2.2916e-01, -7.4458e-02,
          1.4875e-01,  3.5277e-01,  3.2837e-01,  4.5890e-01,  2.4263e-01,
          2.1344e-01, -1.0607e-01,  3.6004e-01,  8.9174e-02,  1.6886e-01,
         -2.3758e-01],
        [-3.1293e-01, -2.2987e-01, -6.0837e-02,  2.1678e-02,  2.2471e-01,
          4.1007e-01,  4.3241e-01,  2.5616e-02,  3.6636e-01,  3.5883e-01,
         -9.2908e-02, -6.3006e-02,  7.2588e-02, -2.8873e-01,  8.0223e-02,
         -2.8899e-01],
        [ 4.6284e-02,  2.0927e-01,  2.3079e-01, -1.0284e-02,  1.1127e-02,
         -3.1695e-01, -4.2546e-01, -3.9825e-01, -4.5535e-01, -2.7484e-01,
         -1.5381e-02,  1.6444e-02, -3.9427e-01,  2.3604e-01, -2.8586e-01,
          1.9793e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0834, -0.0245, -0.0457, -0.0266,  0.0028, -0.2254,  0.0857,  0.1043,
        -0.0749, -0.0010,  0.0386,  0.0874,  0.1318,  0.0579,  0.0747,  0.0079,
        -0.0435, -0.0361,  0.0652, -0.0453, -0.1148, -0.0357, -0.0350,  0.0276,
        -0.0397,  0.1349,  0.1332,  0.0593, -0.1201, -0.1842,  0.0398,  0.0284],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2765,  0.3717, -0.2884, -0.3215,  0.3727,  0.4472, -0.3279, -0.4152,
         -0.3678,  0.4218,  0.3297,  0.4367, -0.3302, -0.4453,  0.3332, -0.3841,
         -0.3770,  0.3773, -0.2971, -0.2793,  0.4831,  0.3757, -0.4217, -0.4142,
         -0.3922, -0.3991, -0.3654,  0.4026, -0.3977,  0.4252,  0.3593, -0.2892]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0108,  0.1706,  0.0592,  ...,  0.2078, -0.3352, -0.1137],
        [-0.0546, -0.0696,  0.1186,  ...,  0.1023, -0.3050,  0.0871],
        [-0.1276,  0.2476,  0.0798,  ...,  0.2153, -0.0365,  0.0345],
        ...,
        [ 0.0863, -0.1266, -0.0383,  ..., -0.1674, -0.0034, -0.1180],
        [ 0.0238, -0.1943, -0.0379,  ..., -0.2630,  0.1097,  0.1557],
        [-0.1643,  0.1400,  0.0450,  ...,  0.0756, -0.2728, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0608,  0.0278, -0.0849, -0.1564, -0.0827, -0.0101, -0.0997,  0.0460,
        -0.0363,  0.0578,  0.0343, -0.0114,  0.0220,  0.1035, -0.0407, -0.0217,
         0.0542, -0.1681,  0.0093,  0.0841, -0.0654,  0.0146,  0.1113,  0.0263,
        -0.1083,  0.0989,  0.0453, -0.1085,  0.0518,  0.2093,  0.1701, -0.1266],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0435, -0.1662, -0.1940,  ...,  0.0364, -0.0415,  0.0689],
        [-0.2212, -0.0216, -0.0184,  ...,  0.1433, -0.0220,  0.0518],
        [ 0.1565, -0.0441, -0.0336,  ..., -0.1451, -0.0038,  0.1870],
        ...,
        [ 0.1779,  0.0469,  0.2478,  ...,  0.1167, -0.1719,  0.2478],
        [-0.0126, -0.1530, -0.0375,  ...,  0.2537,  0.2288, -0.1783],
        [-0.0012, -0.1208,  0.1333,  ...,  0.2320,  0.1370, -0.0447]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1005,  0.1512, -0.0487, -0.1096, -0.0971, -0.1821, -0.0758, -0.0161,
         0.1522, -0.1823,  0.1419, -0.1350,  0.2093,  0.1062, -0.0980,  0.1370,
        -0.1288, -0.1890,  0.0847,  0.0151, -0.0242,  0.0693, -0.2057,  0.2292,
        -0.0386, -0.0180,  0.0753, -0.0498, -0.1636, -0.0470,  0.1347,  0.0382],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4563,  0.3812, -0.4248, -0.4523, -0.3164, -0.3056, -0.3623,  0.3403,
          0.3487, -0.3659, -0.3321,  0.3452,  0.3479,  0.3009,  0.3671,  0.3462,
         -0.4477, -0.4482,  0.3040,  0.3567, -0.4113, -0.3572, -0.4631,  0.2954,
          0.4251,  0.4738, -0.4282,  0.4536, -0.3624, -0.4555,  0.4151,  0.4550]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1897], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 4.3333e-02,  2.9831e-01,  3.2387e-01, -3.5848e-01, -7.7671e-02,
         -2.1459e-01, -1.3292e-01, -4.5222e-01, -1.9638e-01, -6.8264e-02,
          3.5292e-02,  2.0635e-01,  1.0187e-01, -5.6705e-02,  4.3391e-01,
          3.3097e-01],
        [-3.1300e-01, -2.8990e-01, -1.3970e-01,  3.6264e-02, -1.0673e-01,
          3.2813e-01,  2.5640e-01,  2.3434e-01,  4.3206e-01,  1.3263e-01,
          2.1516e-01, -3.1180e-01, -5.0857e-02, -5.3540e-02, -1.1599e-01,
         -6.3120e-02],
        [ 1.1340e-01,  1.8676e-01,  3.8944e-01, -1.3701e-01,  8.8518e-02,
         -3.9488e-01, -1.1804e-01, -4.6959e-01,  4.0155e-02, -5.2436e-02,
         -7.9255e-02, -3.2468e-02,  4.3319e-01,  2.9172e-01,  5.3422e-01,
          2.2372e-01],
        [ 3.1732e-01,  1.8549e-02,  1.0770e-01, -1.0285e-01,  5.1360e-02,
         -2.6079e-01, -2.2797e-01, -1.5020e-01, -4.2304e-01, -3.9014e-01,
         -9.9107e-02,  3.9132e-01,  3.2362e-01, -1.2825e-01,  2.4293e-01,
          1.3050e-01],
        [-1.7682e-01,  1.7067e-01, -2.1495e-01,  3.6643e-02,  1.1174e-01,
          1.9081e-01,  1.5366e-01,  4.2286e-01,  2.0479e-01,  2.9993e-01,
          2.2416e-01, -2.3963e-01, -1.1455e-01, -2.5480e-01, -2.3400e-01,
         -1.2036e-01],
        [-6.3904e-02,  1.9176e-01, -3.9424e-01,  4.4598e-01,  2.1567e-01,
          5.4777e-02,  3.3801e-01,  4.1097e-02,  2.9644e-01,  2.1299e-01,
         -1.5339e-01, -1.4554e-01, -3.0926e-01,  1.0332e-01, -8.4345e-02,
         -5.6274e-02],
        [ 4.1227e-01,  1.4569e-01,  4.2890e-01, -2.0843e-01,  7.3404e-02,
         -2.7597e-01, -2.6298e-01, -3.0146e-01, -2.7366e-01, -8.2758e-03,
         -3.3039e-03,  1.0176e-01,  9.6917e-03,  2.1481e-01,  8.3378e-02,
          1.2941e-01],
        [-3.0538e-02,  2.6690e-01,  3.7176e-01, -3.6663e-01, -1.9308e-01,
         -3.5062e-01, -1.5141e-01, -2.9818e-01, -1.9540e-01, -1.9898e-01,
         -5.9776e-02,  4.8338e-02,  2.8977e-01, -9.3403e-02,  2.3998e-01,
          3.3969e-01],
        [ 8.8262e-02,  2.4255e-01,  3.2934e-01, -2.8675e-01, -4.1625e-02,
         -4.1983e-01, -2.4150e-01, -1.9577e-01, -1.7745e-03, -2.9581e-01,
         -9.3555e-02,  1.3518e-01, -2.0659e-02,  1.1620e-01,  1.2839e-01,
          6.1550e-02],
        [-3.5249e-01, -3.7600e-02, -1.3514e-01,  3.2923e-02,  1.2227e-02,
          2.4138e-01,  1.4273e-01,  3.1899e-01,  3.0721e-01, -3.2630e-03,
          2.3420e-01, -6.5015e-02, -3.1527e-01, -8.6769e-02, -3.1634e-01,
         -1.7173e-01],
        [-3.9038e-01,  1.2534e-01, -7.5606e-02, -2.1234e-02, -1.2740e-01,
          4.8072e-01,  3.0314e-01,  1.7284e-01,  3.5146e-01,  2.3013e-01,
          6.0458e-02, -1.8176e-02, -1.9975e-01,  1.4291e-01, -4.9317e-01,
         -2.9687e-01],
        [-1.7338e-01, -8.7048e-02, -4.4656e-02,  1.1603e-01,  1.7586e-01,
          1.8661e-01,  4.5573e-01,  2.3455e-01,  2.0045e-01,  3.2374e-01,
          1.3883e-01,  3.5734e-03, -4.5181e-01, -1.7752e-01, -3.7195e-01,
         -1.6329e-01],
        [ 4.1552e-01,  1.6516e-01,  2.1493e-01, -2.3003e-01,  1.9624e-02,
         -8.4132e-02, -1.9476e-01, -4.0727e-01, -3.7340e-01, -1.1604e-01,
         -1.1254e-01,  8.5496e-02,  2.8245e-02,  2.0962e-01,  3.1263e-01,
          6.7817e-03],
        [ 2.7051e-01,  3.0680e-01,  4.0939e-01, -5.6912e-02, -2.3737e-01,
         -1.0316e-01, -1.3445e-01, -1.5696e-01, -2.6117e-01, -1.7114e-01,
         -2.0435e-01,  1.7335e-01,  1.8839e-01,  7.6296e-02,  7.3024e-02,
          2.3243e-01],
        [-4.2069e-01, -2.5456e-01, -9.3504e-02, -1.5023e-02,  2.5324e-01,
          4.7555e-01,  1.7595e-01,  1.7732e-01, -1.6684e-02,  1.7426e-01,
          1.2077e-01, -3.4580e-01, -1.2742e-01, -1.1669e-01, -3.8362e-01,
         -1.4536e-01],
        [-1.4290e-02, -2.3771e-01,  1.9079e-01,  3.0311e-02, -2.8633e-01,
         -9.6223e-02, -2.3172e-01, -3.9261e-01, -2.4925e-01, -1.3284e-02,
          3.2850e-02,  5.2987e-01,  2.2456e-01, -3.9342e-02,  6.1020e-01,
         -9.1710e-05],
        [ 3.5104e-01,  2.2067e-01,  2.1813e-01, -3.7370e-01, -2.6515e-01,
         -9.6268e-02, -1.7106e-01, -6.3051e-02, -3.7735e-01, -1.6935e-01,
          1.5610e-01,  3.2092e-01,  3.8525e-01,  2.6932e-01,  2.1526e-01,
         -4.9061e-02],
        [-3.2971e-01,  2.7197e-02, -2.6320e-01,  1.5822e-01,  3.4890e-02,
          3.5575e-01,  3.5689e-01,  3.2572e-01,  1.4678e-01,  2.7012e-01,
         -4.8196e-02, -2.7178e-01, -2.0132e-01, -2.1367e-01, -3.9714e-02,
         -1.5927e-01],
        [ 2.5807e-01,  6.6674e-02,  1.5667e-01, -3.0263e-01, -6.3565e-02,
         -4.2602e-01, -3.5591e-01, -3.0124e-02, -4.0129e-01, -9.8728e-02,
         -2.4530e-02, -4.8235e-02,  2.3204e-01,  2.2850e-01,  4.6451e-01,
          1.6084e-01],
        [ 4.0538e-01,  7.7579e-02,  2.8072e-01, -1.0657e-01, -2.2661e-01,
         -2.8640e-01, -4.2450e-01, -2.9950e-02, -5.5823e-02, -2.4888e-01,
         -5.2326e-02,  2.8367e-01, -3.3718e-02,  8.2867e-02,  4.2951e-01,
          1.6593e-01],
        [-2.4466e-01,  1.2257e-01, -8.6051e-02, -1.5064e-02,  2.0393e-01,
          5.0269e-02,  3.8963e-01,  4.5386e-01,  2.3778e-01,  8.4319e-02,
         -7.9900e-02, -3.5291e-01, -2.6773e-01, -2.4059e-01, -7.7462e-02,
         -2.4239e-01],
        [-1.0384e-01, -2.8002e-01, -5.7633e-02,  3.9950e-01, -8.6934e-02,
          1.6771e-01,  3.0510e-01,  3.9619e-03,  3.8670e-02,  2.3110e-01,
          2.3249e-01, -3.0433e-01, -2.0097e-01, -3.1352e-01, -5.5192e-01,
          9.5878e-02],
        [ 3.8678e-01, -1.7318e-02,  5.9572e-02, -1.6771e-01,  1.1220e-01,
         -4.3600e-01, -3.4949e-01, -2.5957e-01, -2.4078e-01, -1.2980e-01,
          1.2967e-01,  2.2418e-01, -7.8952e-02,  2.9343e-01,  4.5885e-01,
          1.9624e-01],
        [ 2.8316e-01,  1.5561e-01,  3.5190e-01, -3.7924e-01, -1.2775e-01,
         -2.1168e-01, -2.3964e-01, -3.0981e-01, -3.4645e-01, -3.0558e-01,
         -9.6801e-02,  3.5164e-01,  2.8182e-01,  1.3553e-01,  7.7803e-02,
          1.5198e-02],
        [ 2.7806e-01, -1.9043e-01,  2.0980e-01, -1.7647e-01,  1.1989e-01,
         -3.4963e-01, -5.7854e-02, -2.7581e-01, -4.1131e-01,  5.8276e-02,
          1.8794e-01,  6.9824e-02,  1.1001e-01,  2.4227e-01,  2.1280e-01,
          3.0317e-01],
        [ 1.2341e-01, -2.8561e-02,  1.4437e-01,  1.7864e-02, -1.3071e-01,
         -3.2049e-01, -1.3161e-01, -4.2902e-01, -2.2578e-01, -3.7564e-01,
         -2.8912e-01,  1.8595e-01,  2.5621e-01,  3.6486e-01,  1.1265e-01,
          7.4287e-02],
        [ 2.3830e-01,  1.5142e-01,  3.0167e-01, -3.4912e-01, -5.4179e-02,
         -1.3453e-01, -4.1136e-01, -5.0381e-02, -3.6900e-01,  3.7177e-02,
          1.9460e-02,  9.8068e-02,  2.3164e-01,  2.7274e-01,  4.4202e-01,
          2.6816e-01],
        [-3.6748e-01,  7.6505e-03, -8.0113e-03,  2.3481e-01,  2.5015e-01,
          8.7130e-02,  4.4454e-01,  2.2725e-01, -3.6193e-02,  9.0524e-02,
          2.1328e-01, -3.0505e-01, -2.5270e-01, -1.9141e-01, -4.5507e-01,
         -8.6311e-02],
        [ 3.3799e-01,  9.9352e-02,  1.5448e-01, -1.4567e-01, -2.2759e-01,
         -3.3892e-01, -2.1042e-01, -3.8909e-01, -2.1821e-02, -9.5520e-02,
          8.8137e-03,  1.6298e-01,  3.4671e-01,  2.9921e-01,  3.8614e-01,
          2.4810e-01],
        [-2.9892e-01,  4.6925e-02, -3.3028e-01,  2.6362e-01, -1.9311e-01,
          1.9521e-01,  3.9403e-01,  3.3914e-01,  3.5447e-01,  2.1476e-01,
          1.7601e-01, -1.0028e-01,  1.6079e-02,  5.7347e-02, -1.8387e-01,
         -2.0880e-01],
        [-3.1438e-01, -1.2185e-01, -5.3624e-02,  3.0067e-02,  1.1120e-01,
          4.3454e-01,  4.4795e-01,  3.1967e-02,  2.3278e-01,  2.9408e-01,
         -2.1011e-01, -4.4253e-02, -3.2691e-01, -2.3916e-01, -3.9221e-01,
         -2.1577e-01],
        [ 1.0278e-01,  1.4617e-01,  2.7666e-01, -9.0324e-02,  1.2041e-01,
         -3.8467e-01, -4.9361e-01, -4.4422e-01, -3.2432e-01, -2.6646e-01,
          4.9105e-02,  3.7338e-02,  3.3310e-02,  2.4080e-01,  1.5430e-01,
          1.7103e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0791, -0.0783,  0.2096, -0.0125, -0.1043, -0.0582,  0.1028,  0.0860,
         0.0103, -0.0743, -0.0452,  0.0205,  0.1457,  0.1308, -0.0351, -0.0396,
        -0.1037,  0.0005,  0.1457,  0.0433, -0.0169, -0.2155,  0.0098, -0.0368,
         0.0131,  0.2399,  0.1515,  0.0009, -0.0324, -0.1665, -0.0208,  0.0633],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2557,  0.3544, -0.2707, -0.3081,  0.3941,  0.4159, -0.3126, -0.4111,
         -0.3378,  0.4155,  0.3178,  0.4422, -0.3176, -0.4192,  0.3525, -0.3238,
         -0.3436,  0.3765, -0.2707, -0.2843,  0.4650,  0.4104, -0.4178, -0.4099,
         -0.3670, -0.3998, -0.3557,  0.4280, -0.4142,  0.4201,  0.3434, -0.2763]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0125, -0.0010,  0.0252,  ...,  0.2106, -0.4040, -0.1137],
        [-0.0820, -0.1860,  0.0811,  ...,  0.1482, -0.3662,  0.0871],
        [-0.0540,  0.1536,  0.0939,  ...,  0.0057,  0.2847,  0.0345],
        ...,
        [ 0.0408, -0.1531,  0.0115,  ...,  0.0699, -0.3366, -0.1180],
        [ 0.0313, -0.0779,  0.0125,  ..., -0.3113,  0.1638,  0.1557],
        [-0.0840,  0.1585,  0.0134,  ..., -0.1752,  0.1242, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0499,  0.0544, -0.0944, -0.1215, -0.0567,  0.0472, -0.1305,  0.0612,
        -0.0447,  0.0922,  0.0361,  0.0049,  0.0109,  0.0644, -0.0772, -0.0185,
         0.0448, -0.1423, -0.0338, -0.0150, -0.1087,  0.0523,  0.0817, -0.0065,
        -0.0860,  0.0666,  0.0253, -0.0946,  0.0633,  0.1471,  0.1313, -0.0655],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0213, -0.2110, -0.0677,  ..., -0.1600, -0.0007,  0.2765],
        [-0.2558, -0.0580,  0.1145,  ..., -0.0901,  0.0075,  0.2839],
        [ 0.1808, -0.0040, -0.1910,  ...,  0.1013, -0.0402, -0.0816],
        ...,
        [ 0.1673,  0.1255,  0.0684,  ...,  0.2826, -0.2402,  0.0438],
        [-0.0722, -0.1907,  0.0916,  ..., -0.0182,  0.2642,  0.1017],
        [-0.0339, -0.1344,  0.2226,  ...,  0.0325,  0.1550,  0.1431]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0921,  0.1286, -0.0385, -0.0592, -0.0316, -0.0380, -0.0347, -0.0628,
         0.1122, -0.1812,  0.1243, -0.1329,  0.1673, -0.0226, -0.1438,  0.1107,
        -0.1302, -0.1561,  0.0160, -0.0295,  0.0069,  0.1059, -0.1949,  0.2077,
        -0.0654, -0.0271,  0.0881, -0.0321, -0.1144, -0.0624,  0.1170,  0.0044],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.6516,  0.5759, -0.6578, -0.6575,  0.5043,  0.5144, -0.5603,  0.5712,
          0.5670, -0.5932, -0.5831,  0.5421,  0.5636, -0.5056,  0.5862,  0.5352,
         -0.6625, -0.6530,  0.5295,  0.5487, -0.6183, -0.5906, -0.6529,  0.4865,
          0.6283,  0.6527, -0.6289,  0.6975, -0.5633, -0.6446,  0.6316,  0.6434]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.3600], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 3.9094e-02,  2.9102e-01,  3.1632e-01, -3.5257e-01, -8.1359e-02,
         -2.0975e-01, -1.2763e-01, -4.5617e-01, -1.9660e-01, -6.0144e-02,
          3.7860e-02,  2.0793e-01,  1.0763e-01, -5.9745e-02,  4.3433e-01,
          3.2452e-01],
        [-3.0948e-01, -2.8284e-01, -1.3325e-01,  3.1152e-02, -1.0300e-01,
          3.2407e-01,  2.5165e-01,  2.3814e-01,  4.3248e-01,  1.2510e-01,
          2.1221e-01, -3.1346e-01, -5.6487e-02, -5.0311e-02, -1.1608e-01,
         -5.7073e-02],
        [ 1.0986e-01,  1.8030e-01,  3.8268e-01, -1.3172e-01,  8.5818e-02,
         -3.9058e-01, -1.1293e-01, -4.7261e-01,  4.0361e-02, -4.5177e-02,
         -7.7604e-02, -3.1743e-02,  4.3872e-01,  2.8986e-01,  5.3501e-01,
          2.1824e-01],
        [ 3.1271e-01,  1.0391e-02,  1.0005e-01, -9.6744e-02,  4.6146e-02,
         -2.5589e-01, -2.2254e-01, -1.5559e-01, -4.2455e-01, -3.8139e-01,
         -9.4620e-02,  3.9441e-01,  3.3016e-01, -1.3302e-01,  2.4264e-01,
          1.2314e-01],
        [-1.7152e-01,  1.7956e-01, -2.0614e-01,  2.9848e-02,  1.1732e-01,
          1.8491e-01,  1.4741e-01,  4.2868e-01,  2.0647e-01,  2.9020e-01,
          2.1885e-01, -2.4318e-01, -1.2144e-01, -2.4967e-01, -2.3367e-01,
         -1.1222e-01],
        [-5.9517e-02,  2.0065e-01, -3.8684e-01,  4.4017e-01,  2.2228e-01,
          5.0198e-02,  3.3263e-01,  4.7651e-02,  2.9964e-01,  2.0392e-01,
         -1.6030e-01, -1.5053e-01, -3.1670e-01,  1.0923e-01, -8.3637e-02,
         -4.8444e-02],
        [ 4.0933e-01,  1.3961e-01,  4.2324e-01, -2.0385e-01,  7.0723e-02,
         -2.7246e-01, -2.5875e-01, -3.0431e-01, -2.7358e-01, -1.7023e-03,
         -1.4950e-03,  1.0255e-01,  1.4861e-02,  2.1289e-01,  8.3804e-02,
          1.2448e-01],
        [-3.3015e-02,  2.6087e-01,  3.6683e-01, -3.6266e-01, -1.9607e-01,
         -3.4764e-01, -1.4768e-01, -3.0139e-01, -1.9581e-01, -1.9289e-01,
         -5.7717e-02,  4.9641e-02,  2.9499e-01, -9.5670e-02,  2.4038e-01,
          3.3516e-01],
        [ 8.6634e-02,  2.3772e-01,  3.2505e-01, -2.8329e-01, -4.2457e-02,
         -4.1740e-01, -2.3832e-01, -1.9668e-01,  7.5917e-05, -2.9110e-01,
         -9.4329e-02,  1.3422e-01, -1.6445e-02,  1.1686e-01,  1.3006e-01,
          5.7864e-02],
        [-3.4797e-01, -2.9343e-02, -1.2744e-01,  2.6867e-02,  1.7235e-02,
          2.3633e-01,  1.3709e-01,  3.2411e-01,  3.0829e-01, -1.2126e-02,
          2.2973e-01, -6.7759e-02, -3.2168e-01, -8.2119e-02, -3.1604e-01,
         -1.6435e-01],
        [-3.8662e-01,  1.3229e-01, -6.8783e-02, -2.6602e-02, -1.2406e-01,
          4.7634e-01,  2.9796e-01,  1.7641e-01,  3.5152e-01,  2.2253e-01,
          5.8182e-02, -1.9407e-02, -2.0548e-01,  1.4563e-01, -4.9361e-01,
         -2.9081e-01],
        [-1.7041e-01, -8.0756e-02, -3.8735e-02,  1.1136e-01,  1.7846e-01,
          1.8296e-01,  4.5109e-01,  2.3728e-01,  1.9986e-01,  3.1708e-01,
          1.3751e-01,  3.1245e-03, -4.5713e-01, -1.7572e-01, -3.7277e-01,
         -1.5791e-01],
        [ 4.1014e-01,  1.5695e-01,  2.0611e-01, -2.2314e-01,  1.5011e-02,
         -7.8223e-02, -1.8873e-01, -4.1217e-01, -3.7451e-01, -1.0667e-01,
         -1.0850e-01,  8.8080e-02,  3.4643e-02,  2.0548e-01,  3.1253e-01,
         -7.3300e-04],
        [ 2.6802e-01,  3.0060e-01,  4.0440e-01, -5.2889e-02, -2.4042e-01,
         -1.0016e-01, -1.3064e-01, -1.6000e-01, -2.6133e-01, -1.6491e-01,
         -2.0207e-01,  1.7450e-01,  1.9352e-01,  7.3878e-02,  7.3278e-02,
          2.2753e-01],
        [-4.1757e-01, -2.4803e-01, -8.7555e-02, -1.9741e-02,  2.5629e-01,
          4.7172e-01,  1.7143e-01,  1.8056e-01, -1.6810e-02,  1.6738e-01,
          1.1880e-01, -3.4686e-01, -1.3280e-01, -1.1430e-01, -3.8409e-01,
         -1.3999e-01],
        [-1.9002e-02, -2.4857e-01,  1.8048e-01,  3.7264e-02, -2.9406e-01,
         -9.0602e-02, -2.2411e-01, -4.0119e-01, -2.5154e-01, -1.5857e-03,
          3.8094e-02,  5.3595e-01,  2.3356e-01, -4.5802e-02,  6.1257e-01,
         -1.0167e-02],
        [ 3.4708e-01,  2.1295e-01,  2.1140e-01, -3.6820e-01, -2.7003e-01,
         -9.1944e-02, -1.6616e-01, -6.8005e-02, -3.7868e-01, -1.6131e-01,
          1.6015e-01,  3.2369e-01,  3.9152e-01,  2.6490e-01,  2.1494e-01,
         -5.5656e-02],
        [-3.2663e-01,  3.3771e-02, -2.5754e-01,  1.5368e-01,  3.8397e-02,
          3.5214e-01,  3.5248e-01,  3.2941e-01,  1.4734e-01,  2.6326e-01,
         -5.0837e-02, -2.7342e-01, -2.0692e-01, -2.1069e-01, -3.9858e-02,
         -1.5397e-01],
        [ 2.5485e-01,  6.0695e-02,  1.5037e-01, -2.9761e-01, -6.5842e-02,
         -4.2207e-01, -3.5116e-01, -3.2645e-02, -4.0082e-01, -9.2061e-02,
         -2.3368e-02, -4.7923e-02,  2.3735e-01,  2.2722e-01,  4.6554e-01,
          1.5583e-01],
        [ 4.0305e-01,  7.2458e-02,  2.7550e-01, -1.0237e-01, -2.2796e-01,
         -2.8323e-01, -4.2050e-01, -3.1511e-02, -5.4469e-02, -2.4336e-01,
         -5.2332e-02,  2.8312e-01, -2.9003e-02,  8.2815e-02,  4.3104e-01,
          1.6183e-01],
        [-2.4060e-01,  1.3154e-01, -7.8734e-02, -2.0669e-02,  2.1059e-01,
          4.5861e-02,  3.8409e-01,  4.6063e-01,  2.4044e-01,  7.5230e-02,
         -8.6382e-02, -3.5777e-01, -2.7527e-01, -2.3475e-01, -7.7212e-02,
         -2.3456e-01],
        [-1.0161e-01, -2.7446e-01, -5.2722e-02,  3.9545e-01, -8.5097e-02,
          1.6482e-01,  3.0138e-01,  5.8763e-03,  3.7568e-02,  2.2542e-01,
          2.3203e-01, -3.0416e-01, -2.0579e-01, -3.1283e-01, -5.5296e-01,
          1.0033e-01],
        [ 3.8427e-01, -2.3032e-02,  5.4632e-02, -1.6365e-01,  1.0979e-01,
         -4.3289e-01, -3.4555e-01, -2.6213e-01, -2.4034e-01, -1.2393e-01,
          1.3095e-01,  2.2467e-01, -7.3965e-02,  2.9181e-01,  4.5948e-01,
          1.9176e-01],
        [ 2.8028e-01,  1.4926e-01,  3.4654e-01, -3.7486e-01, -1.3124e-01,
         -2.0833e-01, -2.3550e-01, -3.1350e-01, -3.4708e-01, -2.9906e-01,
         -9.4318e-02,  3.5333e-01,  2.8733e-01,  1.3263e-01,  7.8034e-02,
          1.0176e-02],
        [ 2.7268e-01, -1.9928e-01,  2.0125e-01, -1.6958e-01,  1.1415e-01,
         -3.4386e-01, -5.1829e-02, -2.8154e-01, -4.1299e-01,  6.7986e-02,
          1.9348e-01,  7.3275e-02,  1.1676e-01,  2.3685e-01,  2.1209e-01,
          2.9500e-01],
        [ 1.1898e-01, -3.6938e-02,  1.3668e-01,  2.3797e-02, -1.3596e-01,
         -3.1544e-01, -1.2596e-01, -4.3449e-01, -2.2766e-01, -3.6667e-01,
         -2.8400e-01,  1.8941e-01,  2.6292e-01,  3.6007e-01,  1.1223e-01,
          6.6906e-02],
        [ 2.3573e-01,  1.4570e-01,  2.9656e-01, -3.4490e-01, -5.6655e-02,
         -1.3145e-01, -4.0740e-01, -5.3023e-02, -3.6888e-01,  4.3181e-02,
          2.0942e-02,  9.8693e-02,  2.3679e-01,  2.7114e-01,  4.4269e-01,
          2.6363e-01],
        [-3.6345e-01,  1.5229e-02, -9.2271e-04,  2.2925e-01,  2.5436e-01,
          8.2526e-02,  4.3919e-01,  2.3167e-01, -3.5698e-02,  8.2409e-02,
          2.0996e-01, -3.0706e-01, -2.5875e-01, -1.8763e-01, -4.5507e-01,
         -7.9602e-02],
        [ 3.3484e-01,  9.2660e-02,  1.4868e-01, -1.4101e-01, -2.3118e-01,
         -3.3522e-01, -2.0583e-01, -3.9283e-01, -2.2146e-02, -8.8588e-02,
          1.1382e-02,  1.6451e-01,  3.5235e-01,  2.9613e-01,  3.8636e-01,
          2.4249e-01],
        [-2.9655e-01,  5.2613e-02, -3.2552e-01,  2.5974e-01, -1.9055e-01,
          1.9232e-01,  3.9028e-01,  3.4189e-01,  3.5449e-01,  2.0893e-01,
          1.7433e-01, -1.0111e-01,  1.1040e-02,  5.9127e-02, -1.8435e-01,
         -2.0445e-01],
        [-3.1171e-01, -1.1613e-01, -4.8236e-02,  2.5729e-02,  1.1337e-01,
          4.3113e-01,  4.4372e-01,  3.4316e-02,  2.3221e-01,  2.8800e-01,
         -2.1115e-01, -4.4479e-02, -3.3201e-01, -2.3792e-01, -3.9313e-01,
         -2.1113e-01],
        [ 9.9909e-02,  1.4042e-01,  2.7076e-01, -8.5683e-02,  1.1829e-01,
         -3.8104e-01, -4.8910e-01, -4.4660e-01, -3.2385e-01, -2.6007e-01,
          5.0231e-02,  3.7608e-02,  3.8462e-02,  2.3970e-01,  1.5532e-01,
          1.6627e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-7.9449e-02, -7.8723e-02,  2.0887e-01, -1.0325e-02, -1.0684e-01,
        -6.3213e-02,  1.0252e-01,  8.6141e-02,  6.5735e-03, -7.6087e-02,
        -4.4749e-02,  2.2008e-02,  1.4714e-01,  1.3068e-01, -3.4129e-02,
        -4.2505e-02, -1.0176e-01,  8.2862e-05,  1.4464e-01,  4.0809e-02,
        -1.9590e-02, -2.1317e-01,  8.7087e-03, -3.6254e-02,  1.6780e-02,
         2.4267e-01,  1.5118e-01,  6.5512e-04, -3.2356e-02, -1.6621e-01,
        -1.9496e-02,  6.2248e-02], device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2518,  0.3498, -0.2679, -0.3054,  0.3906,  0.4132, -0.3087, -0.4076,
         -0.3329,  0.4129,  0.3150,  0.4390, -0.3131, -0.4144,  0.3492, -0.3274,
         -0.3412,  0.3736, -0.2677, -0.2807,  0.4649,  0.4064, -0.4149, -0.4071,
         -0.3641, -0.3963, -0.3527,  0.4257, -0.4119,  0.4167,  0.3403, -0.2723]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0120, -0.0004,  0.0251,  ...,  0.2107, -0.4028, -0.1137],
        [-0.0814, -0.1855,  0.0810,  ...,  0.1482, -0.3653,  0.0871],
        [-0.0546,  0.1530,  0.0940,  ...,  0.0056,  0.2835,  0.0345],
        ...,
        [ 0.0414, -0.1526,  0.0114,  ...,  0.0700, -0.3353, -0.1180],
        [ 0.0307, -0.0785,  0.0126,  ..., -0.3114,  0.1630,  0.1557],
        [-0.0845,  0.1580,  0.0135,  ..., -0.1753,  0.1228, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0501,  0.0545, -0.0945, -0.1214, -0.0566,  0.0471, -0.1307,  0.0613,
        -0.0448,  0.0923,  0.0363,  0.0047,  0.0107,  0.0643, -0.0773, -0.0186,
         0.0449, -0.1422, -0.0337, -0.0148, -0.1086,  0.0524,  0.0816, -0.0066,
        -0.0859,  0.0667,  0.0252, -0.0947,  0.0634,  0.1472,  0.1311, -0.0656],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0219, -0.2101, -0.0684,  ..., -0.1591, -0.0011,  0.2760],
        [-0.2552, -0.0570,  0.1137,  ..., -0.0892,  0.0071,  0.2834],
        [ 0.1802, -0.0049, -0.1903,  ...,  0.1005, -0.0398, -0.0811],
        ...,
        [ 0.1667,  0.1246,  0.0691,  ...,  0.2818, -0.2398,  0.0443],
        [-0.0715, -0.1898,  0.0909,  ..., -0.0173,  0.2637,  0.1012],
        [-0.0333, -0.1335,  0.2220,  ...,  0.0333,  0.1546,  0.1426]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0920,  0.1285, -0.0384, -0.0591, -0.0317, -0.0382, -0.0346, -0.0630,
         0.1121, -0.1811,  0.1245, -0.1331,  0.1671, -0.0225, -0.1439,  0.1107,
        -0.1300, -0.1560,  0.0159, -0.0297,  0.0070,  0.1060, -0.1948,  0.2077,
        -0.0656, -0.0272,  0.0883, -0.0323, -0.1142, -0.0622,  0.1168,  0.0043],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.6518,  0.5761, -0.6580, -0.6576,  0.5045,  0.5146, -0.5604,  0.5714,
          0.5671, -0.5934, -0.5833,  0.5423,  0.5638, -0.5057,  0.5864,  0.5354,
         -0.6627, -0.6532,  0.5296,  0.5489, -0.6185, -0.5908, -0.6530,  0.4867,
          0.6285,  0.6529, -0.6291,  0.6977, -0.5635, -0.6448,  0.6318,  0.6436]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.3602], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.6955e-02,  2.8835e-01,  2.8358e-01, -2.5794e-01, -4.2982e-01,
         -2.1588e-01, -9.3034e-02, -5.4120e-01, -2.9715e-01, -5.5346e-02,
          1.0038e-02,  2.7503e-01,  1.4133e-01, -6.7674e-02,  1.3218e-01,
          3.1878e-01],
        [-2.3793e-01, -2.7598e-01, -9.0435e-02, -5.5718e-02,  1.6531e-01,
          2.9795e-01,  2.0210e-01,  2.8126e-01,  4.9240e-01,  1.3103e-01,
          2.5328e-01, -3.3749e-01, -5.4876e-02, -4.8393e-02,  1.6350e-01,
         -4.7355e-02],
        [ 5.1637e-02,  1.7687e-01,  3.5371e-01, -5.4112e-02, -2.8118e-01,
         -3.8621e-01, -7.6892e-02, -5.5041e-01, -6.2775e-02, -4.9046e-02,
         -1.0064e-01,  1.0291e-02,  4.6085e-01,  3.2214e-01,  2.5994e-01,
          2.1621e-01],
        [ 2.5187e-01,  8.3057e-03,  6.6472e-02, -1.9493e-02, -2.4980e-01,
         -2.4392e-01, -1.8577e-01, -2.2596e-01, -5.2205e-01, -3.9584e-01,
         -8.2910e-02,  4.4293e-01,  3.3355e-01, -1.1176e-01, -2.8509e-02,
          1.1738e-01],
        [-7.2226e-02,  1.5498e-01, -1.5003e-01, -8.3248e-02,  3.6476e-01,
          1.3605e-01,  7.8497e-02,  4.5485e-01,  2.4396e-01,  2.8754e-01,
          2.8244e-01, -2.3809e-01, -1.0964e-01, -2.3987e-01,  9.0910e-02,
         -1.1467e-01],
        [ 9.0103e-03,  1.9063e-01, -3.4714e-01,  3.5361e-01,  5.3838e-01,
          2.5992e-02,  3.0087e-01,  9.5010e-02,  3.5293e-01,  2.0949e-01,
         -1.2668e-01, -1.6111e-01, -3.0905e-01,  1.2133e-01,  2.1342e-01,
         -4.5938e-02],
        [ 3.5889e-01,  5.5718e-02,  3.9787e-01, -1.4124e-01, -2.4373e-01,
         -2.6225e-01, -2.1670e-01, -3.6109e-01, -3.5574e-01, -2.4184e-02,
         -2.4704e-02,  1.3973e-01, -9.1383e-03,  2.3598e-01, -8.6685e-02,
          1.2564e-01],
        [-7.6411e-02,  2.1227e-01,  3.4361e-01, -3.1301e-01, -4.9254e-01,
         -3.3216e-01, -1.1045e-01, -3.5584e-01, -2.7090e-01, -2.0930e-01,
         -7.2224e-02,  8.4312e-02,  2.8549e-01, -8.1078e-02,  9.7202e-02,
          3.3118e-01],
        [ 3.3348e-02,  2.4927e-01,  3.0354e-01, -2.0497e-01, -2.3870e-01,
         -4.0826e-01, -2.1500e-01, -2.2969e-01, -6.0828e-02, -3.2580e-01,
         -2.3499e-01,  1.4395e-01,  7.3931e-03,  1.8468e-01, -1.5561e-01,
          7.2206e-02],
        [-2.7198e-01, -3.8841e-02, -8.5268e-02, -6.4653e-02,  2.7669e-01,
          2.1326e-01,  9.3600e-02,  3.7457e-01,  3.7539e-01, -2.3188e-03,
          2.9494e-01, -8.7479e-02, -3.3949e-01, -9.1852e-02, -7.4997e-03,
         -1.6439e-01],
        [-3.3944e-01,  1.1240e-01, -5.0356e-02, -8.4104e-02,  1.5980e-01,
          4.8058e-01,  2.7110e-01,  2.5646e-01,  4.5483e-01,  2.5308e-01,
          9.6558e-02, -7.5678e-02, -2.1759e-01,  1.0527e-01, -1.8101e-01,
         -2.9952e-01],
        [-1.1270e-01, -1.0161e-01, -1.4536e-02,  4.3459e-02,  3.5127e-01,
          1.7280e-01,  4.0754e-01,  2.7692e-01,  2.6138e-01,  3.5167e-01,
          2.1219e-01, -1.6222e-02, -4.3841e-01, -2.4802e-01, -1.1355e-01,
         -1.7441e-01],
        [ 3.1024e-01,  1.7180e-01,  1.4632e-01, -1.1185e-01, -3.6134e-01,
         -5.0988e-02, -1.3759e-01, -5.0782e-01, -4.5246e-01, -1.0496e-01,
         -1.2347e-01,  1.3490e-01,  2.7405e-02,  1.8079e-01, -6.2302e-02,
         -1.0451e-02],
        [ 2.0139e-01,  2.7741e-01,  3.6311e-01,  2.6048e-02, -4.8319e-01,
         -6.9667e-02, -7.8521e-02, -1.8214e-01, -3.0525e-01, -1.6975e-01,
         -2.4214e-01,  1.8032e-01,  1.7779e-01,  7.6600e-02, -1.5439e-01,
          2.1731e-01],
        [-3.5939e-01, -2.3664e-01, -5.4489e-02, -8.9598e-02,  5.4929e-01,
          4.5393e-01,  1.3009e-01,  2.3540e-01,  5.8007e-02,  1.7942e-01,
          1.5132e-01, -3.8012e-01, -1.3619e-01, -1.2514e-01, -1.4837e-01,
         -1.3347e-01],
        [-1.2555e-01, -1.6514e-01,  1.5063e-01,  1.6996e-01, -5.6505e-01,
         -8.0624e-02, -2.2507e-01, -4.8753e-01, -3.2876e-01, -3.5116e-02,
         -7.4394e-02,  4.9419e-01,  2.4080e-01, -3.1035e-02,  2.5626e-01,
          4.1331e-03],
        [ 3.0338e-01,  2.1161e-01,  1.9089e-01, -3.1135e-01, -5.4138e-01,
         -8.7211e-02, -1.3664e-01, -1.1777e-01, -4.6352e-01, -1.9020e-01,
          1.3460e-01,  3.6503e-01,  4.1631e-01,  3.0144e-01,  2.3314e-02,
         -5.0030e-02],
        [-2.8048e-01,  4.8004e-02, -2.3264e-01,  9.9698e-02,  2.9988e-01,
          3.3604e-01,  3.1035e-01,  3.7469e-01,  2.2251e-01,  2.8015e-01,
         -3.4551e-02, -3.0592e-01, -2.0025e-01, -2.3482e-01,  1.1620e-01,
         -1.5140e-01],
        [ 1.8496e-01,  4.2237e-02,  1.0867e-01, -2.0756e-01, -4.2294e-01,
         -4.1263e-01, -3.0946e-01, -1.0620e-01, -5.0953e-01, -8.3177e-02,
         -6.5882e-02, -1.1329e-02,  2.8438e-01,  2.6784e-01,  2.1935e-01,
          1.3400e-01],
        [ 3.5630e-01,  7.1001e-02,  2.5777e-01, -4.0487e-02, -5.0746e-01,
         -2.8210e-01, -3.9237e-01, -1.0019e-01, -1.4693e-01, -2.7445e-01,
         -1.1282e-01,  3.2703e-01, -7.1716e-03,  1.2112e-01,  2.0819e-01,
          1.6708e-01],
        [-1.6217e-01,  1.1530e-01, -3.2617e-02, -1.1467e-01,  4.4537e-01,
          6.0069e-05,  3.3186e-01,  4.6405e-01,  2.5387e-01,  6.6266e-02,
         -4.6425e-02, -3.2983e-01, -2.3914e-01, -2.1117e-01,  2.0780e-01,
         -2.2741e-01],
        [-6.6301e-02, -2.7369e-01, -4.4153e-02,  3.3798e-01,  1.7415e-01,
          1.7945e-01,  3.0589e-01,  7.7027e-02,  1.3222e-01,  2.7404e-01,
          3.5786e-01, -3.4386e-01, -2.6945e-01, -3.8361e-01, -2.7518e-01,
          7.8902e-02],
        [ 3.5614e-01, -2.1749e-02,  4.7139e-02, -1.2595e-01, -1.6753e-01,
         -4.4079e-01, -3.3028e-01, -3.3138e-01, -3.3866e-01, -1.6016e-01,
          9.6841e-02,  2.7747e-01, -4.0509e-02,  3.3563e-01,  2.8037e-01,
          2.0193e-01],
        [ 2.4396e-01,  1.5143e-01,  3.2976e-01, -3.3309e-01, -3.8224e-01,
         -1.9716e-01, -2.0176e-01, -3.7143e-01, -4.3242e-01, -3.1958e-01,
         -6.5499e-02,  3.9752e-01,  2.8099e-01,  1.5537e-01, -6.8211e-02,
          5.9678e-03],
        [ 2.0018e-01, -1.7882e-01,  1.6452e-01, -7.3720e-02, -1.4703e-01,
         -3.2665e-01, -1.0810e-02, -3.2004e-01, -4.8567e-01,  4.5332e-02,
          1.0733e-01,  9.5396e-02,  1.4486e-01,  2.6216e-01, -1.3079e-01,
          3.1185e-01],
        [ 2.1006e-02, -3.5068e-02,  7.1279e-02,  1.3056e-01, -4.0065e-01,
         -2.5103e-01, -4.5340e-02, -4.3895e-01, -2.4086e-01, -3.4537e-01,
         -3.2078e-01,  1.6802e-01,  2.2152e-01,  3.2271e-01, -1.8228e-01,
          4.9635e-02],
        [ 2.0686e-01,  1.3754e-01,  2.8954e-01, -3.0789e-01, -3.4142e-01,
         -1.3882e-01, -3.8973e-01, -1.2209e-01, -4.6750e-01,  7.3686e-03,
         -6.5017e-03,  1.4812e-01,  2.6537e-01,  3.0919e-01,  2.9462e-01,
          2.7259e-01],
        [-3.0123e-01,  8.8796e-03,  3.0442e-02,  1.5619e-01,  4.9433e-01,
          7.2761e-02,  4.0200e-01,  2.9647e-01,  4.1320e-02,  1.0352e-01,
          2.5666e-01, -3.4481e-01, -2.7387e-01, -2.1308e-01, -1.9748e-01,
         -8.2474e-02],
        [ 2.9179e-01,  1.1171e-01,  1.2804e-01, -9.1379e-02, -4.6903e-01,
         -3.3018e-01, -1.7495e-01, -4.4992e-01, -1.0416e-01, -1.1128e-01,
          3.0909e-02,  2.0905e-01,  3.3886e-01,  3.2770e-01,  1.5992e-01,
          2.4408e-01],
        [-2.6076e-01,  7.6013e-02, -3.0993e-01,  2.1642e-01,  8.5017e-02,
          1.8529e-01,  3.6320e-01,  4.0101e-01,  4.3480e-01,  2.3246e-01,
          2.0810e-01, -1.3975e-01,  6.1457e-03,  3.4324e-02, -3.5875e-02,
         -2.0801e-01],
        [-2.7080e-01, -1.2362e-01, -3.3008e-02, -2.5651e-02,  3.7558e-01,
          4.3235e-01,  4.1388e-01,  8.8934e-02,  3.2051e-01,  3.2267e-01,
         -1.6613e-01, -8.3736e-02, -3.5715e-01, -2.8735e-01, -1.8533e-01,
         -2.2065e-01],
        [ 3.7002e-02,  1.1066e-01,  2.3716e-01,  2.4106e-03, -1.8195e-01,
         -3.6769e-01, -4.3799e-01, -5.0378e-01, -4.1276e-01, -2.6428e-01,
          3.6992e-03,  6.8906e-02,  3.9426e-02,  2.7860e-01, -6.4936e-02,
          1.5923e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0379, -0.0253,  0.1352, -0.0314, -0.0926, -0.1342,  0.0861,  0.1002,
        -0.0118, -0.0954, -0.0325,  0.0424,  0.1770,  0.0966,  0.0037, -0.0179,
        -0.0469, -0.0012,  0.1195,  0.0181, -0.0718, -0.1690, -0.0113, -0.0152,
         0.0390,  0.1893,  0.1416, -0.0112, -0.0575, -0.1606,  0.0155, -0.0425],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2792,  0.3632, -0.2686, -0.3052,  0.3869,  0.4276, -0.3117, -0.4171,
         -0.3420,  0.4120,  0.3107,  0.4187, -0.3233, -0.4330,  0.3471, -0.4191,
         -0.3585,  0.3608, -0.2726, -0.2831,  0.4641,  0.3516, -0.4064, -0.4038,
         -0.3947, -0.3948, -0.3433,  0.4076, -0.3968,  0.4105,  0.3269, -0.2710]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0094, -0.0089,  0.0481,  ...,  0.2368, -0.4021, -0.1137],
        [-0.0827, -0.1926,  0.0930,  ...,  0.1477, -0.3882,  0.0871],
        [-0.0432,  0.1774,  0.0677,  ..., -0.0062,  0.3214,  0.0345],
        ...,
        [ 0.0291, -0.1918,  0.0474,  ...,  0.0672, -0.3488, -0.1180],
        [ 0.0455, -0.0502, -0.0225,  ..., -0.3074,  0.1947,  0.1557],
        [-0.2036,  0.0467,  0.0088,  ...,  0.0407, -0.3010, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0555,  0.0550, -0.0858, -0.1215, -0.0600,  0.0546, -0.1258,  0.0584,
        -0.0472,  0.0818,  0.0290,  0.0118,  0.0279,  0.0754, -0.0758, -0.0178,
         0.0461, -0.1517, -0.0319, -0.0250, -0.0735,  0.0526,  0.0905, -0.0048,
        -0.0886,  0.0885,  0.0327, -0.0873,  0.0475,  0.1369,  0.1472, -0.1088],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0202, -0.1962, -0.0776,  ..., -0.1152, -0.0185,  0.0714],
        [-0.2629, -0.0509,  0.1188,  ..., -0.0472,  0.0034,  0.0592],
        [ 0.1848, -0.0215, -0.1815,  ...,  0.0535, -0.0175,  0.1693],
        ...,
        [ 0.1622,  0.1007,  0.0893,  ...,  0.2248, -0.2066,  0.2406],
        [-0.0813, -0.1746,  0.0855,  ...,  0.0323,  0.2469, -0.1701],
        [-0.0447, -0.1291,  0.2154,  ...,  0.0741,  0.1412, -0.0297]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0878,  0.1260, -0.0285, -0.0619, -0.0312, -0.0618, -0.0302, -0.0590,
         0.0985, -0.1416,  0.1363, -0.1242,  0.1540,  0.0610, -0.1336,  0.0924,
        -0.1223, -0.1506,  0.0052, -0.0118,  0.0031,  0.1061, -0.1891,  0.1781,
        -0.0611, -0.0287,  0.0872, -0.0394, -0.1129, -0.0574,  0.1018,  0.0064],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.7022,  0.6263, -0.7017, -0.7030,  0.5695,  0.5615, -0.6162,  0.6094,
          0.6332, -0.6423, -0.5935,  0.5938,  0.5914,  0.6043,  0.6306,  0.5898,
         -0.7021, -0.7071,  0.5688,  0.5964, -0.6581, -0.6353, -0.7044,  0.5627,
          0.6880,  0.7073, -0.6856,  0.7352, -0.6147, -0.6979,  0.6833,  0.7008]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.4049], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-5.3213e-03, -8.7002e-02,  2.2547e-01, -2.6220e-01, -3.8375e-01,
         -8.4331e-02, -2.4714e-02, -5.0705e-01, -2.8697e-01,  1.4841e-02,
          1.7388e-01,  1.4946e-01, -4.8766e-02, -1.3630e-01, -2.4381e-01,
          2.6965e-01],
        [-2.6503e-01,  5.5466e-02, -6.3156e-02, -2.5860e-02,  1.0863e-01,
          2.1127e-01,  1.4075e-01,  2.4753e-01,  5.0847e-01,  9.3576e-02,
          9.4083e-02, -2.5591e-01,  5.6596e-02, -1.0168e-03,  5.2170e-01,
         -1.9582e-02],
        [ 6.3298e-02, -1.3651e-01,  3.2292e-01, -8.2478e-02, -2.2475e-01,
         -3.1153e-01, -4.4865e-02, -4.9831e-01, -7.3187e-03, -2.8956e-02,
         -4.2519e-02, -8.8841e-02,  3.5486e-01,  2.9044e-01, -1.1636e-01,
          2.1449e-01],
        [ 2.7697e-01, -1.6246e-01,  2.8298e-02, -3.5824e-02, -1.7201e-01,
         -1.3414e-01, -9.8860e-02, -1.7811e-01, -5.3283e-01, -3.3625e-01,
          2.7913e-03,  3.4138e-01,  2.1415e-01, -1.8319e-01, -3.5066e-01,
          6.9800e-02],
        [-7.4250e-02,  4.9450e-01, -1.0214e-01, -6.5762e-02,  2.9363e-01,
          2.9505e-02,  5.8923e-03,  3.9142e-01,  2.0453e-01,  2.4255e-01,
          4.3316e-02, -1.1666e-01,  4.0085e-02, -1.7573e-01,  4.2016e-01,
         -8.2108e-02],
        [ 1.7201e-02,  4.3697e-01, -3.0496e-01,  3.6778e-01,  4.2955e-01,
         -8.3440e-02,  2.3296e-01,  1.7776e-02,  2.9502e-01,  1.7062e-01,
         -1.3098e-01, -5.0957e-02, -1.6024e-01,  1.6142e-01,  4.8825e-01,
         -2.3951e-02],
        [ 3.6040e-01, -1.1339e-01,  3.5230e-01, -1.4969e-01, -1.6233e-01,
         -1.6060e-01, -1.3720e-01, -3.0133e-01, -3.2489e-01,  2.6018e-02,
         -3.9179e-03,  3.3415e-02, -1.3697e-01,  1.1979e-01, -3.9970e-01,
          8.5274e-02],
        [-8.2260e-02,  3.8460e-02,  3.1069e-01, -3.2927e-01, -4.3233e-01,
         -2.6611e-01, -7.2115e-02, -3.1596e-01, -2.3352e-01, -1.8786e-01,
         -2.9700e-02,  6.5648e-03,  2.0886e-01, -1.3058e-01, -1.7675e-01,
          3.1554e-01],
        [ 4.0849e-02, -1.3303e-01,  2.6433e-01, -2.3322e-01, -1.9904e-01,
         -3.2787e-01, -1.6277e-01, -2.0003e-01, -3.8473e-02, -2.8770e-01,
          4.2165e-02,  5.2242e-02, -8.5194e-02,  1.4301e-01, -5.0595e-01,
          5.3973e-02],
        [-2.9784e-01,  3.1011e-01, -6.2924e-02, -2.6297e-02,  2.1134e-01,
          1.2508e-01,  3.5343e-02,  3.2489e-01,  3.6340e-01, -2.9036e-02,
          1.1759e-01, -2.2144e-03, -2.1613e-01, -5.8643e-02,  3.3779e-01,
         -1.5120e-01],
        [-3.5665e-01,  3.4354e-01, -1.3441e-02, -6.3403e-02,  9.6339e-02,
          3.8425e-01,  2.0756e-01,  2.1194e-01,  4.4586e-01,  2.0867e-01,
          2.4591e-03,  2.1412e-02, -1.4342e-01,  1.4092e-01,  1.5016e-01,
         -2.6958e-01],
        [-1.1766e-01,  1.5449e-01,  2.4117e-02,  6.9210e-02,  2.8112e-01,
          9.6375e-02,  3.3947e-01,  2.2211e-01,  2.2027e-01,  3.0968e-01,
          5.7942e-02,  8.3752e-02, -3.8771e-01, -1.8945e-01,  1.9221e-01,
         -1.5359e-01],
        [ 3.2427e-01, -1.6420e-01,  8.6491e-02, -1.2129e-01, -2.7908e-01,
          9.7259e-02, -4.3534e-02, -4.3551e-01, -4.3998e-01, -3.8032e-02,
         -1.0462e-01, -4.0463e-03, -1.4900e-01,  1.1445e-01, -4.5467e-01,
         -6.2318e-02],
        [ 2.0987e-01, -1.6360e-02,  3.3177e-01,  3.0708e-03, -4.1719e-01,
          3.5617e-03, -2.0878e-02, -1.4058e-01, -2.9244e-01, -1.3682e-01,
         -1.0566e-01,  1.0003e-01,  8.6226e-02,  1.8348e-02, -4.8283e-01,
          1.9433e-01],
        [-3.7106e-01,  7.1726e-02, -2.4258e-02, -6.2853e-02,  4.9913e-01,
          3.8237e-01,  8.6658e-02,  2.0160e-01,  4.0455e-02,  1.5388e-01,
          1.5364e-02, -2.9632e-01, -5.1570e-02, -8.7532e-02,  2.0828e-01,
         -1.1677e-01],
        [-8.8391e-02, -6.0895e-01,  8.2163e-02,  1.4242e-01, -5.6672e-01,
          8.3698e-02, -1.4061e-01, -4.6558e-01, -3.3899e-01,  3.6293e-02,
         -2.8601e-02,  3.4747e-01,  7.7071e-03, -1.4238e-01, -1.6985e-01,
         -3.0696e-02],
        [ 3.1912e-01,  2.7960e-03,  1.5394e-01, -3.2384e-01, -4.3897e-01,
          6.4347e-03, -4.9211e-02, -7.0490e-02, -4.7146e-01, -1.3395e-01,
          1.7314e-01,  2.7438e-01,  2.9009e-01,  2.0110e-01, -2.5749e-01,
         -9.3862e-02],
        [-2.5944e-01,  1.9772e-01, -1.7800e-01,  9.4291e-02,  1.7729e-01,
          2.3647e-01,  2.3214e-01,  2.9560e-01,  1.6079e-01,  2.2616e-01,
         -6.8429e-02, -1.8600e-01, -7.0648e-02, -1.3303e-01,  2.9989e-01,
         -1.0764e-01],
        [ 2.1657e-01, -2.2292e-01,  8.4863e-02, -2.3756e-01, -3.2332e-01,
         -3.3154e-01, -2.4696e-01, -5.6087e-02, -4.7523e-01, -5.2477e-02,
          3.7565e-02, -1.1203e-01,  1.3239e-01,  1.8634e-01, -1.3026e-01,
          1.2332e-01],
        [ 3.5571e-01, -2.0516e-01,  2.0477e-01, -5.3023e-02, -4.5321e-01,
         -1.9691e-01, -3.2944e-01, -6.2405e-02, -1.1453e-01, -2.2557e-01,
          1.2550e-01,  2.1535e-01, -9.3626e-02,  4.9601e-02, -1.6380e-01,
          1.3242e-01],
        [-1.4690e-01,  3.5098e-01,  1.3672e-02, -1.0911e-01,  3.3471e-01,
         -9.3895e-02,  2.6849e-01,  3.8401e-01,  1.9382e-01,  2.7701e-02,
         -1.2957e-01, -2.1925e-01, -1.1132e-01, -1.4775e-01,  4.2235e-01,
         -1.9612e-01],
        [-9.9428e-02,  1.9017e-01, -1.9475e-02,  3.8277e-01,  1.7256e-01,
          1.1945e-01,  2.7459e-01,  8.4799e-02,  1.4725e-01,  2.5406e-01,
          1.7425e-01, -2.9058e-01, -2.0904e-01, -3.6039e-01,  1.1075e-01,
          8.3312e-02],
        [ 3.5779e-01, -2.6238e-01,  9.6006e-03, -1.4272e-01, -9.7907e-02,
         -3.6867e-01, -2.7339e-01, -2.9315e-01, -3.1326e-01, -1.2567e-01,
          2.2278e-01,  1.9347e-01, -1.1636e-01,  2.7018e-01, -1.8533e-02,
          1.7478e-01],
        [ 2.3890e-01,  5.4725e-02,  2.8029e-01, -3.2372e-01, -2.3836e-01,
         -1.0139e-01, -1.0703e-01, -3.1022e-01, -4.2253e-01, -2.5168e-01,
         -7.2022e-04,  2.9908e-01,  1.8291e-01,  4.4376e-02, -2.4508e-01,
         -5.5884e-02],
        [ 2.1786e-01, -5.0156e-01,  1.3518e-01, -1.0912e-01, -5.6613e-02,
         -2.1756e-01,  6.7629e-02, -2.4649e-01, -4.4940e-01,  8.4539e-02,
          1.7743e-01, -9.2740e-03, -4.2196e-03,  2.2098e-01, -4.6752e-01,
          2.9320e-01],
        [ 1.1048e-02, -3.1276e-01,  2.8484e-02,  1.1826e-01, -3.0869e-01,
         -1.6351e-01,  2.3396e-04, -3.6906e-01, -1.8297e-01, -3.1588e-01,
         -2.2922e-01,  5.9622e-02,  1.1005e-01,  2.8246e-01, -4.8319e-01,
          2.6510e-02],
        [ 2.0369e-01, -1.2609e-01,  2.4386e-01, -3.1909e-01, -2.7443e-01,
         -7.1249e-02, -3.3144e-01, -8.6826e-02, -4.2939e-01,  4.3539e-02,
          7.6817e-02,  5.7499e-02,  1.9503e-01,  2.1649e-01, -1.5225e-02,
          2.4255e-01],
        [-3.1706e-01,  3.1428e-01,  6.4746e-02,  1.8564e-01,  4.3684e-01,
         -4.0222e-03,  3.4069e-01,  2.5349e-01,  1.4523e-02,  6.8787e-02,
          4.6382e-02, -2.5019e-01, -1.8632e-01, -1.5438e-01,  1.3241e-01,
         -6.3271e-02],
        [ 2.8392e-01, -5.3832e-02,  8.2860e-02, -1.0086e-01, -3.7548e-01,
         -2.4977e-01, -1.1291e-01, -3.8919e-01, -6.1415e-02, -6.6878e-02,
          1.3077e-01,  1.0428e-01,  3.0220e-01,  2.6908e-01, -8.2022e-02,
          2.0999e-01],
        [-2.5172e-01,  2.5163e-01, -2.6720e-01,  2.2238e-01,  5.9430e-03,
          1.0694e-01,  3.0137e-01,  3.4967e-01,  3.9862e-01,  1.9451e-01,
          1.3347e-01, -5.0468e-02,  1.0561e-01,  1.0686e-01,  2.3332e-01,
         -1.7537e-01],
        [-2.6811e-01,  1.3595e-01,  1.2100e-02, -1.1586e-02,  3.0300e-01,
          3.4827e-01,  3.5347e-01,  4.3773e-02,  2.8032e-01,  2.8060e-01,
         -2.6487e-01,  2.2079e-02, -2.6623e-01, -2.2444e-01,  1.3519e-01,
         -1.9327e-01],
        [ 3.1258e-02, -1.3559e-01,  1.8025e-01, -3.9235e-03, -9.9278e-02,
         -2.5726e-01, -3.5064e-01, -4.2095e-01, -3.5552e-01, -2.0317e-01,
          1.1358e-01, -7.2861e-02, -1.2759e-01,  1.4848e-01, -3.7648e-01,
          1.1670e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0838, -0.0138,  0.1560, -0.1279, -0.0600, -0.0385,  0.0581,  0.1623,
        -0.0270, -0.0391,  0.0413,  0.0470,  0.1602,  0.0951, -0.0639,  0.1034,
        -0.1978, -0.0084,  0.0286,  0.0225, -0.0302, -0.1430, -0.0574, -0.0693,
        -0.1971,  0.2897,  0.1242,  0.0097, -0.0770, -0.2285,  0.1377, -0.0250],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.3516,  0.4385, -0.3147, -0.3334,  0.4555,  0.4744, -0.3637, -0.4357,
         -0.4133,  0.5009,  0.3391,  0.4665, -0.4055, -0.5019,  0.3966, -0.4866,
         -0.3910,  0.3789, -0.3033, -0.3196,  0.5078,  0.4440, -0.4330, -0.4213,
         -0.4905, -0.4531, -0.3718,  0.4570, -0.4025,  0.4428,  0.3474, -0.3069]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0329,  0.1009,  0.0516,  ...,  0.2253, -0.3934, -0.1137],
        [-0.0986, -0.0632,  0.1123,  ...,  0.1586, -0.3752,  0.0871],
        [-0.0130, -0.0234,  0.0238,  ...,  0.0227,  0.2993,  0.0345],
        ...,
        [ 0.0187,  0.0024,  0.0528,  ...,  0.0887, -0.3925, -0.1180],
        [ 0.0756, -0.1969, -0.0484,  ..., -0.3323,  0.2077,  0.1557],
        [-0.1938,  0.1371,  0.0326,  ...,  0.1010, -0.3463, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0429,  0.0405, -0.0666, -0.1339, -0.0724,  0.0584, -0.1104,  0.0463,
        -0.0394,  0.0809,  0.0193,  0.0115,  0.0294,  0.0785, -0.0523, -0.0193,
         0.0588, -0.1524,  0.0012,  0.0286, -0.0531,  0.0349,  0.1082,  0.0063,
        -0.0931,  0.1034,  0.0473, -0.0983,  0.0549,  0.1395,  0.1668, -0.1230],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0707, -0.2007, -0.0979,  ..., -0.1574, -0.0034,  0.0704],
        [-0.2104, -0.0568,  0.1041,  ..., -0.0899,  0.0201,  0.0450],
        [ 0.1448, -0.0059, -0.1817,  ...,  0.1093, -0.0447,  0.1960],
        ...,
        [ 0.1239,  0.1115,  0.1058,  ...,  0.2782, -0.2386,  0.2491],
        [-0.0105, -0.1706,  0.0615,  ..., -0.0107,  0.2511, -0.1750],
        [-0.0082, -0.1532,  0.2179,  ...,  0.0106,  0.1781, -0.0562]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1069,  0.1511, -0.0639, -0.0866,  0.0015, -0.0459, -0.0605, -0.0422,
         0.1268, -0.1719,  0.1316, -0.1153,  0.1753,  0.0876, -0.1202,  0.1313,
        -0.1388, -0.1757, -0.0536, -0.0015, -0.0058,  0.0821, -0.2148,  0.2177,
        -0.0449, -0.0039,  0.0717, -0.0281, -0.1374, -0.0744,  0.1273,  0.0466],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.6799,  0.6048, -0.6995, -0.6803,  0.5660,  0.5449, -0.6073,  0.5867,
          0.5965, -0.6279, -0.5712,  0.5919,  0.5692,  0.5523,  0.6220,  0.6200,
         -0.6765, -0.6899, -0.5522,  0.5992, -0.6423, -0.6245, -0.6952,  0.5311,
          0.6665,  0.6907, -0.6767,  0.6877, -0.6095, -0.6775,  0.6665,  0.6935]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.4078], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.6916e-02,  2.5372e-01,  2.1801e-01, -2.5527e-01, -4.1488e-01,
         -7.5445e-02,  1.3452e-02, -4.9559e-01, -3.0781e-01,  4.3524e-02,
          1.7066e-01,  1.9125e-01, -8.0977e-03, -1.6730e-01, -2.6341e-01,
          2.6877e-01],
        [-2.3953e-01, -2.5480e-01, -3.5757e-02, -4.5848e-02,  1.4521e-01,
          1.9077e-01,  1.1000e-01,  2.2163e-01,  5.0627e-01,  5.6445e-02,
          7.1297e-02, -2.6530e-01,  5.4332e-02,  3.9824e-02,  5.3285e-01,
         -2.2110e-03],
        [ 7.2783e-02,  2.0780e-01,  3.1324e-01, -8.8241e-02, -2.4669e-01,
         -3.3559e-01, -5.1103e-02, -5.3409e-01, -1.8410e-02, -1.5984e-02,
         -1.3937e-02, -5.5214e-02,  4.3904e-01,  3.0005e-01, -1.5088e-01,
          2.4395e-01],
        [ 2.4956e-01, -3.5028e-02,  2.9645e-03, -1.9713e-02, -2.3651e-01,
         -1.1315e-01, -6.6467e-02, -1.4952e-01, -5.4668e-01, -3.0051e-01,
          2.1035e-02,  3.6331e-01,  2.1182e-01, -2.2525e-01, -3.7307e-01,
          4.6647e-02],
        [-9.2596e-02,  1.8142e-01, -1.0270e-01, -6.2321e-02,  3.7410e-01,
          2.8620e-02, -6.0091e-03,  4.1888e-01,  2.8384e-01,  2.1884e-01,
          8.4266e-02, -1.7901e-01, -1.1978e-02, -1.6458e-01,  4.9595e-01,
         -7.8176e-02],
        [ 3.5920e-03,  2.1349e-01, -3.0518e-01,  3.6870e-01,  4.9195e-01,
         -8.2950e-02,  2.1130e-01,  2.1617e-02,  3.5417e-01,  1.4600e-01,
         -1.0607e-01, -9.4108e-02, -1.9042e-01,  1.8918e-01,  5.7137e-01,
         -1.3310e-02],
        [ 3.4703e-01,  4.2788e-02,  3.3581e-01, -1.4347e-01, -2.0793e-01,
         -1.5967e-01, -1.2531e-01, -2.9230e-01, -3.2363e-01,  4.8257e-02,
          2.3767e-02,  5.5288e-02, -1.0713e-01,  9.9654e-02, -4.3352e-01,
          8.2869e-02],
        [-8.6319e-02,  2.3033e-01,  2.9755e-01, -3.2500e-01, -4.3946e-01,
         -2.7073e-01, -6.1805e-02, -3.1415e-01, -2.2601e-01, -1.7047e-01,
         -2.0556e-02,  1.8872e-02,  2.4029e-01, -1.4184e-01, -1.9930e-01,
          3.2113e-01],
        [ 3.6308e-02,  2.5428e-01,  2.4584e-01, -2.2830e-01, -2.2197e-01,
         -3.2626e-01, -1.4930e-01, -1.9802e-01, -4.6593e-02, -2.6181e-01,
          6.3901e-02,  7.7584e-02, -5.0444e-02,  1.2376e-01, -5.3371e-01,
          5.5148e-02],
        [-2.9316e-01, -2.5812e-02, -4.7238e-02, -3.6924e-02,  2.6835e-01,
          1.1576e-01,  1.4988e-02,  3.3012e-01,  3.9689e-01, -6.0265e-02,
          1.2382e-01, -3.1820e-02, -2.4228e-01, -2.9755e-02,  3.8415e-01,
         -1.4118e-01],
        [-3.5349e-01,  1.2681e-01, -2.6343e-03, -6.1664e-02,  1.5621e-01,
          3.8572e-01,  1.9586e-01,  2.1912e-01,  4.7232e-01,  1.8801e-01,
         -3.6707e-02, -1.6662e-02, -1.7996e-01,  1.5532e-01,  2.0268e-01,
         -2.6955e-01],
        [-1.1277e-01, -8.7350e-02,  4.2130e-02,  6.2741e-02,  3.1906e-01,
          8.7662e-02,  3.2843e-01,  2.2987e-01,  2.3568e-01,  2.8483e-01,
          5.5131e-02,  5.7600e-02, -4.0709e-01, -1.7744e-01,  2.2841e-01,
         -1.5061e-01],
        [ 3.1668e-01,  1.3650e-01,  7.8995e-02, -1.1540e-01, -3.4120e-01,
          1.0797e-01, -1.8471e-02, -4.3387e-01, -4.8198e-01, -9.7312e-03,
         -1.0759e-01,  4.0509e-02, -1.0374e-01,  9.1810e-02, -4.8314e-01,
         -6.6914e-02],
        [ 1.9395e-01,  2.6819e-01,  3.0959e-01,  1.6151e-02, -4.3994e-01,
          1.5986e-02, -2.0330e-03, -1.2351e-01, -2.8669e-01, -1.0764e-01,
         -8.8678e-02,  1.0916e-01,  9.4144e-02, -9.1592e-03, -4.9675e-01,
          1.8479e-01],
        [-3.6528e-01, -2.4276e-01, -1.1083e-02, -6.7372e-02,  5.2279e-01,
          3.7953e-01,  7.3040e-02,  1.9565e-01,  4.7403e-02,  1.3204e-01,
          1.9974e-03, -3.1684e-01, -7.9602e-02, -7.0979e-02,  2.2534e-01,
         -1.1773e-01],
        [-2.9294e-01, -1.1101e-01,  9.2760e-02,  2.0256e-01,  3.1066e-01,
          1.0528e-01,  5.3646e-02,  1.6587e-01,  3.1118e-01,  3.8835e-02,
          3.1906e-02,  1.2326e-01, -9.8190e-02, -1.8937e-01,  7.0140e-01,
         -6.1931e-03],
        [ 2.9064e-01,  1.4079e-01,  1.2746e-01, -3.0469e-01, -4.9445e-01,
          3.1331e-02, -2.0323e-02, -3.2364e-02, -4.7367e-01, -9.8438e-02,
          1.7472e-01,  2.8687e-01,  2.7267e-01,  1.6327e-01, -2.5227e-01,
         -1.1762e-01],
        [-2.5633e-01,  1.1031e-01, -1.6766e-01,  9.2300e-02,  2.2479e-01,
          2.4287e-01,  2.2396e-01,  2.9884e-01,  1.7344e-01,  2.0979e-01,
         -8.5008e-02, -2.1271e-01, -1.0885e-01, -1.1188e-01,  3.4592e-01,
         -1.0790e-01],
        [ 2.1306e-01,  3.0908e-02,  7.1338e-02, -2.3449e-01, -3.7432e-01,
         -3.2755e-01, -2.2970e-01, -6.1867e-02, -5.1186e-01, -2.6021e-02,
          6.0963e-02, -7.1515e-02,  1.6723e-01,  1.6429e-01, -1.5328e-01,
          1.1636e-01],
        [ 3.5971e-01,  6.1505e-02,  1.9574e-01, -5.5899e-02, -4.9576e-01,
         -1.9202e-01, -3.1745e-01, -6.5313e-02, -1.5131e-01, -2.0257e-01,
          1.3169e-01,  2.6019e-01, -6.1890e-02,  3.8954e-02, -1.9521e-01,
          1.2973e-01],
        [-1.5311e-01,  1.4301e-01,  1.6404e-02, -1.1143e-01,  3.7961e-01,
         -9.1780e-02,  2.5912e-01,  3.9353e-01,  2.3159e-01,  8.1269e-03,
         -9.5252e-02, -2.5148e-01, -1.4996e-01, -1.3748e-01,  5.0652e-01,
         -1.9431e-01],
        [-9.9392e-02, -2.7472e-01, -3.9325e-03,  3.8056e-01,  1.8856e-01,
          1.2054e-01,  2.6306e-01,  8.4299e-02,  1.5520e-01,  2.2890e-01,
          1.5549e-01, -3.2050e-01, -2.4993e-01, -3.4485e-01,  1.3388e-01,
          7.5078e-02],
        [ 3.5910e-01, -4.0789e-02,  1.2981e-03, -1.4419e-01, -1.4752e-01,
         -3.7293e-01, -2.7245e-01, -3.0169e-01, -3.3375e-01, -1.1040e-01,
          2.3066e-01,  2.2646e-01, -7.9564e-02,  2.6283e-01, -5.8005e-02,
          1.7848e-01],
        [ 2.0689e-01,  8.8156e-02,  2.5303e-01, -3.0601e-01, -2.9017e-01,
         -8.6841e-02, -8.6790e-02, -2.7573e-01, -3.9992e-01, -2.2418e-01,
          2.5575e-02,  3.0199e-01,  1.8408e-01,  1.1157e-02, -2.4403e-01,
         -6.8812e-02],
        [ 2.1989e-01, -1.8287e-01,  1.2707e-01, -1.0600e-01, -1.2741e-01,
         -2.1589e-01,  8.0422e-02, -2.5519e-01, -4.9051e-01,  1.0866e-01,
          1.9762e-01,  3.0303e-02,  2.8530e-02,  2.0067e-01, -5.2547e-01,
          2.8820e-01],
        [ 2.2684e-02, -2.2915e-02,  2.7725e-02,  1.1311e-01, -3.4542e-01,
         -1.7529e-01,  7.1268e-03, -3.9099e-01, -2.1702e-01, -3.0236e-01,
         -2.4421e-01,  9.5018e-02,  1.6776e-01,  2.8042e-01, -5.5401e-01,
          3.7927e-02],
        [ 2.0079e-01,  1.0577e-01,  2.2977e-01, -3.1744e-01, -3.0589e-01,
         -6.8743e-02, -3.2638e-01, -8.9252e-02, -4.3917e-01,  6.3839e-02,
          8.6263e-02,  8.4391e-02,  2.2085e-01,  2.1484e-01, -4.2017e-02,
          2.4629e-01],
        [-3.2278e-01,  2.4520e-02,  7.0507e-02,  1.8554e-01,  4.8676e-01,
         -1.1717e-02,  3.2848e-01,  2.6066e-01,  5.4887e-02,  4.7499e-02,
          6.4788e-02, -2.9188e-01, -2.0997e-01, -1.4758e-01,  1.8104e-01,
         -6.1090e-02],
        [ 2.7525e-01,  9.9150e-02,  6.7528e-02, -9.6681e-02, -4.0640e-01,
         -2.4615e-01, -1.0622e-01, -3.8864e-01, -6.0133e-02, -4.7936e-02,
          1.4258e-01,  1.2290e-01,  3.2602e-01,  2.6063e-01, -1.0825e-01,
          2.1323e-01],
        [-2.5300e-01,  7.9244e-02, -2.6049e-01,  2.2509e-01,  4.9384e-02,
          1.1635e-01,  3.0170e-01,  3.5835e-01,  4.1187e-01,  1.8294e-01,
          1.1294e-01, -7.9670e-02,  6.0948e-02,  1.0961e-01,  2.8672e-01,
         -1.8306e-01],
        [-2.6518e-01, -9.8515e-02,  2.7262e-02, -1.4937e-02,  3.4109e-01,
          3.4713e-01,  3.4239e-01,  4.6530e-02,  2.9764e-01,  2.5708e-01,
         -2.7808e-01, -8.0992e-03, -2.9896e-01, -2.0568e-01,  1.5768e-01,
         -1.9074e-01],
        [ 2.5515e-02,  5.7462e-02,  1.6671e-01, -1.0182e-04, -1.4554e-01,
         -2.5854e-01, -3.3957e-01, -4.3651e-01, -3.8174e-01, -1.8070e-01,
          1.3375e-01, -3.3887e-02, -7.9992e-02,  1.3260e-01, -4.0748e-01,
          1.1757e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1092,  0.0147,  0.2028, -0.1389, -0.0058,  0.0323,  0.0757,  0.1862,
        -0.0119, -0.0065,  0.0113,  0.0531,  0.0990,  0.0821, -0.0527, -0.0264,
        -0.2279, -0.0151,  0.0217,  0.0078,  0.0175, -0.1572, -0.0476, -0.0546,
        -0.1900,  0.2764,  0.1296,  0.0456, -0.0675, -0.2485,  0.1397, -0.0240],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.3652,  0.4476, -0.3286, -0.3595,  0.5100,  0.5254, -0.3813, -0.4454,
         -0.4297,  0.5322,  0.3652,  0.4725, -0.4329, -0.5183,  0.4058,  0.4897,
         -0.4057,  0.3950, -0.3168, -0.3305,  0.5369,  0.4269, -0.4448, -0.4306,
         -0.5566, -0.4779, -0.3808,  0.4752, -0.4165,  0.4563,  0.3581, -0.3196]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0019,  0.0820,  0.0746,  ...,  0.1626, -0.3733, -0.1137],
        [-0.0975, -0.0648,  0.1149,  ...,  0.1338, -0.3792,  0.0871],
        [-0.0190, -0.0147,  0.0345,  ...,  0.0224,  0.3320,  0.0345],
        ...,
        [ 0.0195,  0.0045,  0.0517,  ...,  0.0717, -0.4202, -0.1180],
        [ 0.0778, -0.1982, -0.0498,  ..., -0.3080,  0.2306,  0.1557],
        [-0.1788,  0.1331,  0.0368,  ...,  0.0679, -0.3723, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0459,  0.0398, -0.0696, -0.1358, -0.0744,  0.0496, -0.1099,  0.0496,
        -0.0408,  0.0790,  0.0248,  0.0120,  0.0243,  0.0764, -0.0502, -0.0209,
         0.0571, -0.1564, -0.0644,  0.0380, -0.0579,  0.0329,  0.1053,  0.0082,
        -0.0881,  0.0521,  0.0439, -0.1181,  0.0549,  0.1424,  0.1667, -0.1283],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0351, -0.1988, -0.0880,  ..., -0.1447,  0.0125,  0.0620],
        [-0.2405, -0.0551,  0.1273,  ..., -0.0715,  0.0223,  0.0353],
        [ 0.1661, -0.0085, -0.1911,  ...,  0.0897, -0.0374,  0.1970],
        ...,
        [ 0.1403,  0.0935,  0.1080,  ...,  0.2551, -0.2392,  0.2408],
        [-0.0334, -0.1703,  0.0764,  ...,  0.0171,  0.2431, -0.1820],
        [-0.0259, -0.1406,  0.2153,  ...,  0.0382,  0.1707, -0.0488]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1109,  0.1655, -0.0676, -0.0858, -0.0017, -0.0430, -0.0616, -0.0393,
         0.1390, -0.1832,  0.1173, -0.1262,  0.1975,  0.1077, -0.1212,  0.1430,
        -0.1399, -0.1769,  0.0494, -0.0097, -0.0100,  0.0832, -0.2049,  0.2451,
        -0.0399, -0.0046,  0.0697, -0.0261, -0.1393, -0.0712,  0.1364,  0.0413],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.7497,  0.6812, -0.7591, -0.7321,  0.6220,  0.6330, -0.6676,  0.6406,
          0.6441, -0.7000, -0.6444,  0.6384,  0.6326,  0.6247,  0.6694,  0.6870,
         -0.7328, -0.7431,  0.5944,  0.6510, -0.7058, -0.6867, -0.7463,  0.5822,
          0.7331,  0.7432, -0.7241,  0.7455, -0.6655, -0.7313,  0.7253,  0.7414]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.4507], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-5.3837e-01,  7.2702e-01, -1.9493e-01, -3.3086e-01,  2.7412e-01,
         -3.0798e-01,  6.1703e-01,  6.2870e-02,  2.8243e-01,  1.7214e-01,
          1.9351e-01, -2.6005e-01, -1.9788e-01,  6.6576e-02,  3.1255e-01,
         -1.5089e-01],
        [-3.7115e-01,  1.2374e-01, -2.1648e-01, -2.8929e-01,  1.7580e-01,
         -1.7275e-01,  3.4782e-01,  3.1930e-01,  5.4761e-01,  3.5867e-02,
          1.3562e-01, -4.0833e-01,  1.1934e-01,  3.2943e-01,  5.2352e-01,
         -1.8851e-01],
        [-3.5986e-01,  4.2028e-01, -6.4014e-02, -6.1959e-02,  4.2392e-01,
         -3.6183e-01,  5.2031e-01,  8.4714e-02,  5.2276e-01,  1.1813e-01,
          2.7734e-02, -5.4907e-01,  1.3491e-01,  3.4011e-01,  4.6333e-01,
         -1.7115e-01],
        [ 3.9837e-01, -3.9444e-01,  1.8363e-01,  1.8033e-01, -1.8521e-01,
          1.6234e-01, -3.4233e-01, -2.0123e-01, -5.0748e-01, -2.9823e-01,
         -2.9200e-02,  4.4898e-01,  1.3411e-01, -4.2386e-01, -2.9336e-01,
          2.6558e-01],
        [-2.4188e-01,  5.4516e-01, -2.7577e-01, -3.1108e-01,  2.9169e-01,
         -2.9718e-01,  1.9810e-01,  4.1706e-01,  2.3062e-01,  1.9628e-01,
          1.8679e-01, -2.5493e-01,  1.0365e-01,  1.0153e-01,  3.8941e-01,
         -2.7086e-01],
        [-1.4023e-01,  5.7374e-01, -4.5548e-01,  7.8976e-02,  4.2817e-01,
         -4.2037e-01,  3.9906e-01,  3.8111e-02,  3.1196e-01,  2.8149e-02,
         -1.4774e-01, -1.6975e-01, -1.9980e-01,  4.7069e-01,  4.2650e-01,
         -1.8753e-01],
        [ 4.2395e-01, -3.0401e-01,  5.3317e-01,  1.7753e-01, -2.1674e-01,
          2.7012e-01, -3.8859e-01, -3.5645e-01, -3.5886e-01,  2.1154e-01,
         -4.9119e-02,  1.6156e-01, -6.0447e-02, -1.7935e-01, -3.2144e-01,
          2.9480e-01],
        [ 5.8355e-02, -1.3191e-01,  4.6483e-01, -2.5854e-02, -5.0198e-01,
          1.1063e-01, -2.6115e-01, -3.9300e-01, -3.0371e-01, -2.7117e-02,
         -8.1026e-02,  1.5452e-01,  2.7884e-01, -4.3162e-01, -2.0340e-01,
          4.8019e-01],
        [ 1.9462e-01, -2.3107e-01,  4.7769e-01,  1.0469e-01, -3.3761e-01,
          1.7914e-01, -4.4719e-01, -3.4293e-01, -1.9478e-01, -2.1675e-01,
         -1.9756e-01,  2.6207e-01, -1.3289e-01, -3.0557e-01, -5.8366e-01,
          2.6054e-01],
        [-4.7660e-01,  3.7318e-01, -2.3884e-01, -2.4791e-01,  2.1751e-01,
         -1.9620e-01,  2.3452e-01,  3.4718e-01,  3.7482e-01,  1.8452e-02,
          1.1207e-01, -1.1742e-01, -2.0511e-02,  2.4860e-01,  3.0132e-01,
         -3.5450e-01],
        [-5.9515e-01,  6.2983e-01, -2.2437e-01, -3.4450e-01,  5.8319e-02,
          6.2385e-03,  4.5954e-01,  1.9992e-01,  4.3749e-01,  2.2008e-01,
          5.5269e-02, -8.7972e-02, -1.9175e-02,  4.8820e-01,  4.8311e-02,
         -5.3378e-01],
        [-3.3517e-01,  3.0603e-01, -1.6938e-01, -1.3947e-01,  3.2512e-01,
         -2.1057e-01,  5.4864e-01,  2.6889e-01,  2.8111e-01,  3.8107e-01,
          1.6625e-01, -5.2794e-02, -1.7107e-01,  8.0690e-02,  2.4210e-01,
         -3.6479e-01],
        [ 4.7470e-01, -3.0048e-01,  2.8961e-01,  1.8287e-01, -2.5471e-01,
          5.0913e-01, -2.7100e-01, -4.3623e-01, -4.2232e-01,  6.5393e-02,
         -1.3734e-01,  1.5147e-01, -9.6756e-02, -2.6334e-01, -3.1693e-01,
          1.6602e-01],
        [ 3.4278e-01, -9.1673e-02,  4.7502e-01,  2.4575e-01, -4.3473e-01,
          3.4164e-01, -1.9840e-01, -1.6767e-01, -2.9692e-01, -6.2745e-02,
         -1.5230e-01,  1.9623e-01,  2.3564e-02, -2.5508e-01, -4.3998e-01,
          3.5705e-01],
        [-5.5335e-01,  2.3952e-01, -2.1126e-01, -3.4780e-01,  5.3579e-01,
         -3.5179e-02,  3.2248e-01,  2.5833e-01,  9.3554e-02,  9.4100e-02,
          9.5142e-02, -4.3106e-01, -1.5728e-04,  2.9831e-01,  1.7027e-01,
         -3.2335e-01],
        [ 9.8096e-02, -3.9652e-01,  3.5183e-01,  2.8781e-01, -4.2914e-01,
          2.6654e-01, -3.3071e-01, -3.9644e-01, -2.9572e-01,  9.5415e-03,
          6.5464e-02,  5.3377e-01, -5.1391e-02, -2.7278e-01, -3.9222e-02,
          2.2700e-01],
        [ 4.4584e-01, -1.7703e-01,  3.5166e-01, -6.9031e-02, -6.3650e-01,
          3.5416e-01, -3.2856e-01, -2.3501e-01, -5.9611e-01, -8.7069e-02,
          2.0565e-01,  5.0301e-01,  2.7296e-01, -1.0141e-01, -3.9733e-01,
          1.2107e-01],
        [-3.2856e-01,  3.8649e-01, -3.3291e-01, -1.4772e-01,  2.9961e-01,
         -7.4463e-02,  4.5923e-01,  4.0348e-01,  2.3422e-01,  8.3389e-02,
          3.3280e-03, -3.4822e-01, -1.7137e-01,  8.6595e-02,  3.1298e-01,
         -2.8426e-01],
        [-2.4803e-01,  3.2648e-01, -2.9904e-01, -2.4155e-01,  2.7383e-01,
         -4.1625e-01,  2.6686e-01,  5.0222e-01,  5.7512e-02,  9.3058e-02,
          1.8852e-02, -5.4483e-01, -9.0493e-03,  3.0839e-01,  4.2365e-01,
         -2.4336e-01],
        [ 5.6920e-01, -4.3295e-01,  4.1467e-01,  2.2311e-01, -4.2363e-01,
          1.8998e-01, -5.7601e-01, -5.5655e-02, -1.2093e-01, -1.6917e-01,
         -1.0325e-01,  3.1930e-01, -1.3452e-01, -2.7875e-01, -4.2976e-02,
          3.8384e-01],
        [-2.4213e-01,  3.4903e-01, -1.1288e-01, -2.7664e-01,  3.9095e-01,
         -3.0155e-01,  4.1781e-01,  4.6062e-01,  2.6262e-01, -4.4447e-02,
         -1.6378e-01, -3.6465e-01, -8.0378e-02, -6.0452e-03,  4.5938e-01,
         -3.1340e-01],
        [ 3.6401e-01, -3.6378e-01,  2.6350e-01,  3.0486e-01, -3.0476e-01,
          1.1503e-01, -4.0561e-02, -3.1009e-01, -3.4805e-01, -9.3806e-02,
          2.4419e-01,  1.5657e-01,  2.5482e-02, -3.3309e-01, -6.1516e-01,
          2.8845e-01],
        [ 5.0563e-01, -4.8052e-01,  1.8830e-01,  1.7350e-01, -1.6514e-01,
          5.2235e-02, -4.9777e-01, -3.5644e-01, -3.6286e-01, -2.3799e-02,
          4.7111e-02,  3.2656e-01, -1.0208e-01, -9.9450e-02,  2.5222e-02,
          3.8781e-01],
        [ 2.9586e-01, -1.6254e-01,  4.3927e-01, -1.1663e-01, -4.6363e-01,
          1.6024e-01, -3.6250e-01, -4.6442e-01, -5.1153e-01, -1.6982e-01,
         -8.8168e-02,  5.0385e-01,  2.6345e-01, -1.3089e-01, -3.2343e-01,
          1.3692e-01],
        [ 3.7573e-01, -6.4963e-01,  3.1369e-01,  1.8841e-01, -1.1462e-01,
          1.9636e-01, -1.7412e-01, -3.1501e-01, -4.9901e-01,  1.1741e-01,
          2.0456e-01,  1.3186e-01, -1.0825e-01, -2.0656e-01, -4.4173e-01,
          4.9702e-01],
        [ 1.5994e-01, -4.1012e-01,  1.8559e-01,  3.8141e-01, -3.7867e-01,
          1.9186e-01, -1.8597e-01, -4.6235e-01, -2.6898e-01, -2.1849e-01,
         -2.8884e-01,  2.2648e-01,  1.4233e-01, -2.1230e-02, -5.0529e-01,
          1.8474e-01],
        [ 4.0158e-01, -3.0867e-01,  4.4880e-01, -5.3759e-02, -3.1799e-01,
          3.0188e-01, -5.6765e-01, -1.2947e-01, -4.8304e-01,  9.5722e-02,
         -1.9998e-03,  1.9343e-01,  1.7047e-01, -6.6695e-02,  4.8843e-03,
          4.7418e-01],
        [-5.3192e-01,  4.1792e-01, -1.3524e-01, -2.4834e-02,  4.4052e-01,
         -3.1176e-01,  5.3916e-01,  2.7097e-01,  5.6291e-02,  1.2376e-01,
          1.4511e-01, -3.7825e-01,  1.2354e-02,  1.0962e-01,  1.4865e-01,
         -2.7689e-01],
        [ 4.6741e-01, -3.0334e-01,  2.6691e-01,  1.1309e-01, -4.7462e-01,
          5.2016e-02, -3.3300e-01, -4.8683e-01, -1.4696e-01, -6.7462e-02,
          4.0711e-02,  2.6820e-01,  2.2447e-01, -1.1276e-02, -1.5002e-01,
          4.0618e-01],
        [-3.7725e-01,  4.3979e-01, -4.2192e-01, -6.8562e-02,  2.7853e-02,
         -2.4883e-01,  4.9518e-01,  3.7552e-01,  4.0524e-01,  5.1678e-02,
          2.3421e-01, -1.5652e-01,  2.8025e-02,  3.5560e-01,  1.2604e-01,
         -3.6935e-01],
        [-4.7864e-01,  3.7085e-01, -1.9151e-01, -2.7878e-01,  3.5964e-01,
         -3.7589e-02,  6.0573e-01,  1.0659e-01,  3.4271e-01,  2.5887e-01,
         -1.7110e-01, -1.2509e-01, -2.0963e-01,  1.5343e-01,  1.3810e-01,
         -4.2175e-01],
        [ 1.2736e-01, -2.7885e-01,  3.6138e-01,  2.7579e-01, -1.7724e-01,
          9.5977e-02, -6.1985e-01, -5.3657e-01, -4.3352e-01, -8.1466e-02,
         -1.8141e-03,  1.3431e-01, -4.2620e-02, -1.1955e-01, -3.7328e-01,
          3.1734e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.2387,  0.0862,  0.1848, -0.0892,  0.0017, -0.0991,  0.0604,  0.1014,
        -0.2213, -0.0735,  0.0299,  0.0561,  0.1098,  0.0839,  0.0106,  0.0830,
        -0.1298,  0.0707, -0.0365, -0.0950, -0.0277, -0.0143, -0.1287, -0.1399,
        -0.1299,  0.1788,  0.1138,  0.0421, -0.0818, -0.1236,  0.1377, -0.1744],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5574,  0.5842,  0.5114, -0.5387,  0.6403,  0.6764, -0.5284, -0.6445,
         -0.5922,  0.6892,  0.5648,  0.6985, -0.5870, -0.6489,  0.5800, -0.5670,
         -0.5632,  0.5940,  0.5190, -0.5342,  0.6370, -0.4639, -0.6477, -0.6167,
         -0.5960, -0.6653, -0.5569,  0.6488, -0.6359,  0.6430,  0.5848, -0.4994]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.2575,  0.1832, -0.0168,  ...,  0.0975, -0.1435, -0.1137],
        [-0.1319, -0.2152,  0.1763,  ..., -0.0118, -0.3764,  0.0871],
        [-0.0138,  0.1439,  0.0820,  ...,  0.1436,  0.1604,  0.0345],
        ...,
        [-0.0357, -0.1795,  0.0660,  ..., -0.1338, -0.1863, -0.1180],
        [ 0.0151, -0.0981, -0.0156,  ..., -0.1592,  0.0292,  0.1557],
        [-0.0835,  0.1422, -0.0267,  ..., -0.0537,  0.0291, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0548,  0.0631, -0.1570, -0.0537, -0.0560,  0.0384, -0.1260,  0.1099,
        -0.0538,  0.1569,  0.0196, -0.0466, -0.0513,  0.0620, -0.0740, -0.0451,
         0.1052, -0.1392, -0.0441,  0.0487, -0.0800,  0.1364,  0.1006, -0.0586,
        -0.0011,  0.1181,  0.0197, -0.1358,  0.0812,  0.1823,  0.0908, -0.1368],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.2028, -0.1900, -0.1089,  ..., -0.0533, -0.1192,  0.1644],
        [ 0.0341,  0.0059,  0.1481,  ..., -0.0382, -0.0362,  0.2492],
        [-0.0805, -0.0916, -0.1826,  ...,  0.0211,  0.0440,  0.0056],
        ...,
        [-0.0649,  0.0268,  0.0739,  ...,  0.1980, -0.1536,  0.1277],
        [ 0.2150, -0.1036,  0.0870,  ...,  0.0611,  0.1864,  0.0204],
        [ 0.1993, -0.0564,  0.2513,  ...,  0.0790,  0.1055,  0.1111]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0593,  0.0213,  0.0596,  0.0240, -0.0779, -0.1284,  0.0634, -0.1813,
         0.0207, -0.0623,  0.2333, -0.1890,  0.0779,  0.1027, -0.2239, -0.0226,
        -0.0500, -0.1079, -0.0683, -0.1091,  0.1006,  0.2003, -0.1048,  0.2094,
        -0.1510, -0.0629,  0.1423, -0.1470, -0.0428,  0.0008, -0.0007, -0.0628],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3331,  0.2484, -0.3489, -0.3058,  0.2067,  0.2005, -0.2391,  0.2714,
          0.2424, -0.2436, -0.2304,  0.2258,  0.2340, -0.2058,  0.2717,  0.2226,
         -0.3273, -0.3354,  0.1965,  0.2287, -0.2925, -0.2728, -0.3432, -0.1610,
          0.3076,  0.3338, -0.3172,  0.3218, -0.2457, -0.3182,  0.3188,  0.3150]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.1478], device='cuda:0', requires_grad=True)

