Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-8.7153e-04,  3.9761e-01,  3.0846e-01, -3.2807e-01, -1.9216e-01,
         -1.5493e-01, -7.6197e-02, -3.9103e-01, -2.5313e-01, -7.8177e-02,
         -3.1671e-02,  1.9508e-01, -3.0811e-01, -6.7591e-02, -2.9216e-02,
          3.8626e-01],
        [-2.4821e-01, -3.9061e-01, -1.0071e-01, -9.4702e-03, -2.5636e-02,
          2.4761e-01,  1.6305e-01,  1.5964e-01,  4.2951e-01,  1.3748e-01,
          3.0017e-01, -2.6025e-01,  3.6268e-01, -3.0375e-02,  3.3809e-01,
         -9.1408e-02],
        [ 9.3139e-02,  2.9761e-01,  3.9110e-01, -1.3229e-01, -1.0189e-01,
         -3.4847e-01, -9.0340e-02, -4.4660e-01, -5.9288e-02, -8.9752e-02,
         -1.6007e-01, -3.6058e-02,  1.8660e-02,  3.5161e-01, -1.4469e-02,
          2.8791e-01],
        [ 2.8447e-01,  1.2159e-01,  9.7882e-02, -8.9873e-02, -6.9594e-02,
         -2.1650e-01, -1.7684e-01, -1.2075e-01, -4.7307e-01, -4.3005e-01,
         -2.2052e-01,  3.8522e-01, -7.9465e-02, -1.1260e-01, -2.0849e-01,
          1.8161e-01],
        [-9.6223e-02,  3.1807e-02, -1.7305e-01, -2.1627e-02,  1.6683e-01,
          8.9196e-02,  4.7037e-02,  3.2713e-01,  1.8216e-01,  3.0527e-01,
          3.5001e-01, -1.6577e-01,  3.2539e-01, -2.3477e-01,  2.9041e-01,
         -1.7462e-01],
        [-2.0147e-02,  5.8097e-02, -3.7502e-01,  4.1820e-01,  3.5803e-01,
         -8.2198e-03,  2.8708e-01, -4.1667e-03,  3.1216e-01,  2.3474e-01,
         -7.3217e-02, -1.0861e-01,  1.2789e-01,  1.1618e-01,  4.2672e-01,
         -1.0607e-01],
        [ 3.6686e-01,  2.4909e-01,  4.0763e-01, -1.8560e-01, -5.8719e-02,
         -2.1012e-01, -1.8607e-01, -2.3938e-01, -2.9432e-01, -3.2960e-02,
         -4.7862e-02,  6.4020e-02, -3.5989e-01,  2.0709e-01, -2.9477e-01,
          1.6385e-01],
        [-5.7990e-02,  3.6534e-01,  3.6297e-01, -3.6238e-01, -3.4824e-01,
         -3.0097e-01, -1.0345e-01, -2.7385e-01, -2.4226e-01, -2.2940e-01,
         -9.6003e-02,  3.9865e-02, -4.1205e-02, -9.3393e-02, -1.2066e-01,
          3.7245e-01],
        [ 3.2710e-02,  3.5873e-01,  3.0342e-01, -2.4617e-01, -5.0996e-02,
         -3.4683e-01, -1.5761e-01, -1.0062e-01,  1.3951e-02, -3.1989e-01,
         -2.8612e-01,  5.3603e-02, -4.1896e-01,  1.6049e-01, -2.8994e-01,
          1.0887e-01],
        [-3.0025e-01, -1.6847e-01, -1.1231e-01,  1.7387e-03,  9.1686e-02,
          1.7012e-01,  7.4064e-02,  2.5684e-01,  3.1856e-01,  1.8623e-02,
          3.6692e-01, -2.2069e-02,  1.1836e-01, -9.5718e-02,  1.9888e-01,
         -2.2877e-01],
        [-3.6998e-01,  1.2161e-02, -7.9007e-02, -1.7136e-02, -2.8594e-02,
          4.4402e-01,  2.6284e-01,  1.4926e-01,  4.0846e-01,  2.8136e-01,
          2.2992e-01, -1.6038e-02,  1.9701e-01,  9.8592e-02,  1.9919e-02,
         -3.6319e-01],
        [-1.3927e-01, -2.0553e-01, -3.9467e-02,  1.0174e-01,  1.8842e-01,
          1.3771e-01,  3.8817e-01,  1.6888e-01,  2.1073e-01,  3.7100e-01,
          4.1122e-01,  4.8312e-02, -5.8164e-02, -2.6536e-01,  3.4927e-02,
         -2.3624e-01],
        [ 3.3506e-01,  2.9420e-01,  1.6892e-01, -1.7497e-01, -1.0484e-01,
          2.1991e-02, -8.6340e-02, -3.2668e-01, -3.6050e-01, -1.1722e-01,
         -1.7974e-01,  3.8229e-02, -4.3680e-01,  1.5862e-01, -2.4248e-01,
          5.3645e-02],
        [ 2.0921e-01,  4.0395e-01,  3.7191e-01, -1.4139e-02, -3.1361e-01,
         -2.4052e-02, -3.9597e-02, -7.5765e-02, -2.4694e-01, -1.7484e-01,
         -2.8338e-01,  1.1145e-01, -2.0236e-01,  6.0653e-02, -3.2571e-01,
          2.5419e-01],
        [-3.7874e-01, -3.5721e-01, -7.4317e-02, -3.1447e-02,  3.7359e-01,
          4.0740e-01,  1.1298e-01,  1.2591e-01,  1.3217e-02,  1.9798e-01,
          1.9523e-01, -3.1525e-01,  2.5602e-01, -1.1685e-01,  6.6207e-02,
         -1.8326e-01],
        [-5.0800e-02,  1.5409e-02,  2.1891e-01,  5.3184e-02, -3.7040e-01,
         -4.4134e-02, -2.2902e-01, -3.4766e-01, -3.0146e-01, -1.0142e-01,
         -1.5700e-01,  4.5360e-01, -2.9700e-01, -1.2833e-02,  1.6086e-02,
          1.3020e-01],
        [ 3.2971e-01,  3.3221e-01,  2.1708e-01, -3.6830e-01, -3.8420e-01,
         -6.1287e-02, -1.1976e-01, -2.9424e-02, -4.2044e-01, -2.1441e-01,
          6.4922e-02,  3.1193e-01,  3.2476e-02,  3.0397e-01, -1.3892e-01,
          4.7036e-03],
        [-3.0081e-01, -6.5136e-02, -2.5409e-01,  1.5016e-01,  1.4587e-01,
          3.1002e-01,  3.0130e-01,  2.8795e-01,  1.8649e-01,  3.0294e-01,
          1.4744e-02, -2.5633e-01,  1.1459e-01, -2.1993e-01,  2.9358e-01,
         -1.9569e-01],
        [ 2.2522e-01,  1.5571e-01,  1.4481e-01, -2.8363e-01, -2.1729e-01,
         -3.7484e-01, -3.2222e-01,  7.2344e-03, -5.0052e-01, -1.2437e-01,
         -1.1913e-01, -6.2956e-02, -1.4533e-01,  2.9510e-01, -4.8447e-02,
          2.0986e-01],
        [ 3.7496e-01,  1.8380e-01,  2.7764e-01, -9.9075e-02, -3.1454e-01,
         -2.3424e-01, -3.6368e-01,  2.2957e-02, -8.8342e-02, -2.9381e-01,
         -1.7651e-01,  2.4983e-01, -4.0429e-01,  1.1132e-01,  3.7098e-02,
          2.1921e-01],
        [-1.9008e-01, -2.0247e-03, -6.0125e-02, -5.8261e-02,  2.8926e-01,
         -2.0765e-02,  3.2114e-01,  3.8467e-01,  2.2993e-01,  9.3319e-02,
          1.2932e-02, -2.9014e-01,  1.2854e-01, -2.1240e-01,  3.9319e-01,
         -2.8038e-01],
        [-7.8191e-02, -4.0967e-01, -5.6144e-02,  3.9549e-01, -1.8447e-02,
          1.1715e-01,  2.6657e-01, -5.2538e-02,  6.5151e-02,  2.7792e-01,
          4.0192e-01, -2.6282e-01,  1.8328e-01, -3.7038e-01, -7.4306e-02,
          2.9043e-02],
        [ 3.6897e-01,  8.2365e-02,  6.0910e-02, -1.7264e-01, -1.5264e-03,
         -3.9981e-01, -3.0620e-01, -2.3325e-01, -2.9391e-01, -1.7265e-01,
          5.1825e-02,  2.1498e-01, -3.9234e-01,  3.2056e-01,  9.4300e-02,
          2.4237e-01],
        [ 2.6272e-01,  2.3823e-01,  3.5049e-01, -3.7813e-01, -2.4499e-01,
         -1.7737e-01, -1.8718e-01, -2.9442e-01, -3.9419e-01, -3.4215e-01,
         -1.4185e-01,  3.5232e-01,  1.2614e-02,  1.3496e-01, -1.8603e-01,
          4.5725e-02],
        [ 2.2407e-01, -4.0414e-02,  1.8624e-01, -1.3945e-01,  3.7351e-02,
         -2.8362e-01,  1.3723e-02, -2.0800e-01, -4.2902e-01,  2.3988e-02,
          3.8267e-02,  2.6192e-02, -3.5925e-01,  2.6564e-01, -3.3298e-01,
          3.7591e-01],
        [ 5.0961e-02,  9.0048e-02,  9.9597e-02,  6.7771e-02, -2.2980e-01,
         -2.1691e-01, -3.9014e-02, -3.4636e-01, -2.1440e-01, -3.7347e-01,
         -3.6814e-01,  1.2125e-01, -1.5424e-01,  3.2367e-01, -3.9889e-01,
          1.0791e-01],
        [ 2.3035e-01,  2.5697e-01,  3.1291e-01, -3.6083e-01, -1.8670e-01,
         -1.0834e-01, -3.7210e-01, -3.4516e-02, -4.3251e-01, -1.6973e-02,
         -6.1431e-02,  9.7636e-02, -8.6347e-02,  3.0783e-01,  1.0247e-01,
          3.2170e-01],
        [-3.2628e-01, -1.0446e-01,  5.9338e-03,  2.1706e-01,  3.1284e-01,
          2.9904e-02,  3.7938e-01,  1.7359e-01, -1.5562e-02,  1.2217e-01,
          3.8217e-01, -2.7416e-01,  1.4134e-01, -2.2220e-01, -1.2926e-02,
         -1.4252e-01],
        [ 3.1749e-01,  1.9760e-01,  1.5370e-01, -1.4813e-01, -3.1503e-01,
         -3.0111e-01, -1.6681e-01, -3.6021e-01, -6.8369e-02, -1.3585e-01,
         -1.0899e-01,  1.5428e-01,  3.0106e-02,  3.3316e-01, -2.2266e-04,
          2.9748e-01],
        [-2.6995e-01, -4.5057e-02, -3.2067e-01,  2.5526e-01, -7.4144e-02,
          1.4753e-01,  3.4013e-01,  3.0654e-01,  3.9331e-01,  2.4388e-01,
          2.2985e-01, -8.3618e-02,  3.2792e-01,  5.9726e-02,  1.3966e-01,
         -2.4098e-01],
        [-3.0203e-01, -2.3726e-01, -6.3106e-02,  3.8137e-02,  2.1386e-01,
          4.0592e-01,  4.0603e-01, -8.7455e-04,  2.8388e-01,  3.5258e-01,
         -8.1766e-02, -3.1303e-02,  3.3018e-02, -2.9935e-01,  2.6036e-02,
         -2.8142e-01],
        [ 4.8133e-02,  2.3447e-01,  2.4890e-01, -4.9079e-02,  5.6796e-03,
         -3.1552e-01, -4.1274e-01, -3.7221e-01, -3.7434e-01, -2.7981e-01,
         -4.1444e-02, -1.0575e-02, -3.5678e-01,  2.7253e-01, -2.5292e-01,
          2.0469e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0652, -0.0204, -0.0109, -0.0318,  0.0102, -0.2376,  0.0983,  0.1246,
        -0.0538, -0.0071,  0.0424,  0.0764,  0.1345,  0.0755,  0.0626, -0.0186,
        -0.0164, -0.0404,  0.0853, -0.0301, -0.1048, -0.0740, -0.0299,  0.0378,
        -0.0357,  0.1336,  0.1601,  0.0456, -0.0980, -0.1824,  0.0222,  0.0234],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2172,  0.3107, -0.2278, -0.2585,  0.3017,  0.3566, -0.2812, -0.3738,
         -0.3217,  0.3392,  0.2638,  0.3760, -0.2633, -0.3963,  0.2842, -0.2334,
         -0.3194,  0.3319, -0.2298, -0.2367,  0.4001,  0.3171, -0.3715, -0.3755,
         -0.2846, -0.3296, -0.3192,  0.3425, -0.3501,  0.3808,  0.3015, -0.2354]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0056,  0.1138,  0.0697,  ...,  0.1974, -0.3097, -0.1137],
        [-0.0748, -0.0645,  0.1191,  ...,  0.1026, -0.2862,  0.0871],
        [-0.1070,  0.1569,  0.0930,  ...,  0.1983,  0.0289,  0.0345],
        ...,
        [ 0.0978, -0.1218, -0.0365,  ..., -0.1712, -0.0251, -0.1180],
        [ 0.0397, -0.1849, -0.0405,  ..., -0.2620,  0.0918,  0.1557],
        [-0.1854,  0.1357,  0.0508,  ...,  0.0710, -0.2434, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0536,  0.0314, -0.0952, -0.1544, -0.0807, -0.0069, -0.1026,  0.0410,
        -0.0331,  0.0583,  0.0282, -0.0030,  0.0081,  0.1014, -0.0447, -0.0124,
         0.0481, -0.1658,  0.0036,  0.0814, -0.0626,  0.0187,  0.1106,  0.0227,
        -0.1101,  0.0980,  0.0438, -0.0982,  0.0460,  0.2029,  0.1683, -0.1279],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0520, -0.1633, -0.1873,  ...,  0.0352, -0.0456,  0.0657],
        [-0.2180, -0.0146, -0.0183,  ...,  0.1382, -0.0293,  0.0488],
        [ 0.1482, -0.0505, -0.0392,  ..., -0.1409,  0.0035,  0.1864],
        ...,
        [ 0.1413,  0.0584,  0.2066,  ...,  0.1041, -0.1762,  0.2452],
        [-0.0152, -0.1357, -0.0461,  ...,  0.2385,  0.2135, -0.1726],
        [-0.0034, -0.1089,  0.1276,  ...,  0.2214,  0.1262, -0.0443]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1006,  0.1477, -0.0462, -0.0995, -0.1071, -0.1756, -0.0629, -0.0278,
         0.1400, -0.1689,  0.1328, -0.1277,  0.1974,  0.0916, -0.1102,  0.1225,
        -0.1367, -0.1782,  0.0762,  0.0102, -0.0147,  0.0819, -0.2076,  0.2169,
        -0.0460, -0.0102,  0.0764, -0.0416, -0.1499, -0.0595,  0.1226,  0.0299],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3757,  0.2993, -0.3383, -0.3692, -0.2229, -0.2176, -0.2835,  0.2497,
          0.2768, -0.2935, -0.2462,  0.2616,  0.2706,  0.2270,  0.2865,  0.2693,
         -0.3677, -0.3735,  0.2195,  0.2645, -0.3251, -0.2754, -0.3771,  0.2227,
          0.3396,  0.3921, -0.3477,  0.3642, -0.2837, -0.3723,  0.3366,  0.3768]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1312], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.1880e-02,  3.5719e-01,  3.2319e-01, -3.4503e-01, -2.1566e-02,
         -1.7734e-01, -6.7275e-02, -3.8740e-01, -1.7285e-01, -8.5857e-02,
          2.3095e-02,  1.7106e-01,  5.5123e-02, -5.1889e-02,  3.1480e-01,
          3.6653e-01],
        [-2.7564e-01, -3.4130e-01, -1.2777e-01,  1.2484e-02, -1.6435e-01,
          2.8459e-01,  1.8855e-01,  1.6694e-01,  3.9733e-01,  1.3564e-01,
          2.2674e-01, -2.6991e-01,  4.8796e-03, -4.4904e-02,  2.6896e-03,
         -8.5788e-02],
        [ 9.9696e-02,  2.5135e-01,  4.0297e-01, -1.3922e-01,  1.4599e-01,
         -3.7427e-01, -6.4687e-02, -4.1037e-01,  5.7392e-02, -8.3588e-02,
         -1.0123e-01, -6.5154e-02,  3.9072e-01,  3.1119e-01,  4.3199e-01,
          2.6833e-01],
        [ 2.9174e-01,  7.1349e-02,  1.0701e-01, -9.0889e-02,  1.0380e-01,
         -2.2986e-01, -1.7125e-01, -9.5550e-02, -4.0446e-01, -4.0377e-01,
         -1.1196e-01,  3.6298e-01,  2.8029e-01, -1.2761e-01,  1.3932e-01,
          1.6176e-01],
        [-1.1547e-01,  1.1815e-01, -1.8932e-01, -5.6343e-03,  4.9425e-02,
          1.2209e-01,  6.5959e-02,  3.4540e-01,  1.5636e-01,  2.9240e-01,
          2.3722e-01, -1.8627e-01, -4.9181e-02, -2.2521e-01, -8.0213e-02,
         -1.3881e-01],
        [-2.0600e-02,  1.4403e-01, -3.7523e-01,  4.1084e-01,  1.5769e-01,
          2.9203e-03,  2.7487e-01, -2.1996e-02,  2.4927e-01,  2.0520e-01,
         -1.3461e-01, -9.4761e-02, -2.4396e-01,  1.3426e-01,  3.6074e-02,
         -7.0923e-02],
        [ 3.9349e-01,  2.0504e-01,  4.3316e-01, -2.0244e-01,  1.3306e-01,
         -2.5018e-01, -2.1107e-01, -2.3680e-01, -2.4774e-01, -2.9302e-02,
         -2.4877e-02,  6.2995e-02, -3.7696e-02,  2.3001e-01, -1.3455e-02,
          1.6433e-01],
        [-4.4752e-02,  3.1794e-01,  3.7520e-01, -3.6198e-01, -1.4313e-01,
         -3.3061e-01, -1.0879e-01, -2.4484e-01, -1.7611e-01, -2.1539e-01,
         -7.6324e-02,  1.8418e-02,  2.5043e-01, -8.3725e-02,  1.5975e-01,
          3.6657e-01],
        [ 5.6451e-02,  3.0830e-01,  3.2636e-01, -2.6846e-01,  3.5938e-02,
         -3.8225e-01, -1.8354e-01, -1.1010e-01,  4.4137e-02, -3.1556e-01,
         -1.1896e-01,  7.2884e-02, -8.5952e-02,  1.4252e-01,  1.2126e-02,
          9.7862e-02],
        [-3.0519e-01, -8.7315e-02, -1.1661e-01,  1.0111e-03, -4.6917e-02,
          1.8821e-01,  6.6343e-02,  2.5010e-01,  2.6891e-01, -6.7208e-03,
          2.4408e-01, -2.1279e-02, -2.5714e-01, -6.7233e-02, -1.8428e-01,
         -1.9049e-01],
        [-3.6862e-01,  6.8092e-02, -7.9999e-02, -2.7644e-02, -1.8027e-01,
          4.5426e-01,  2.4500e-01,  1.1752e-01,  3.3422e-01,  2.4983e-01,
          7.3549e-02,  1.1095e-02, -1.5628e-01,  1.3381e-01, -3.8647e-01,
         -3.3298e-01],
        [-1.4481e-01, -1.4864e-01, -4.4270e-02,  1.0506e-01,  1.0795e-01,
          1.5228e-01,  3.8876e-01,  1.5989e-01,  1.6688e-01,  3.4566e-01,
          1.6131e-01,  5.0495e-02, -3.9659e-01, -2.0364e-01, -2.5740e-01,
         -2.0263e-01],
        [ 3.6641e-01,  2.2466e-01,  2.0199e-01, -2.0178e-01,  7.9934e-02,
         -2.5944e-02, -1.1329e-01, -3.3531e-01, -3.3687e-01, -1.2275e-01,
         -1.2802e-01,  4.0935e-02, -2.8701e-02,  1.9504e-01,  1.6789e-01,
          3.8266e-02],
        [ 2.3662e-01,  3.5725e-01,  3.9734e-01, -3.3725e-02, -1.7452e-01,
         -6.2683e-02, -7.2693e-02, -8.5130e-02, -2.2013e-01, -1.7364e-01,
         -2.2078e-01,  1.2492e-01,  1.2821e-01,  7.2466e-02, -3.6370e-02,
          2.5252e-01],
        [-3.9530e-01, -3.0656e-01, -9.0897e-02, -2.7848e-02,  1.9988e-01,
          4.4509e-01,  1.1977e-01,  1.1901e-01, -4.0236e-02,  1.8601e-01,
          1.3380e-01, -3.1251e-01, -8.1526e-02, -1.1889e-01, -2.8064e-01,
         -1.7240e-01],
        [-8.9988e-02, -1.5208e-01,  1.7833e-01,  9.2827e-02, -1.9463e-01,
         -1.4310e-02, -1.5424e-01, -2.8987e-01, -1.6309e-01, -8.1997e-03,
          4.2603e-03,  4.2462e-01,  1.1146e-01, -9.6204e-02,  4.0886e-01,
          2.9895e-02],
        [ 3.3272e-01,  2.7645e-01,  2.2017e-01, -3.6680e-01, -2.0291e-01,
         -7.0648e-02, -1.2135e-01, -4.4326e-04, -3.5445e-01, -1.8887e-01,
          1.3302e-01,  2.8598e-01,  3.4227e-01,  2.8689e-01,  1.2626e-01,
         -1.5214e-02],
        [-3.1603e-01, -2.3896e-02, -2.6783e-01,  1.5479e-01, -1.5691e-02,
          3.3689e-01,  3.1227e-01,  2.7543e-01,  1.3172e-01,  2.8776e-01,
         -3.1701e-02, -2.4562e-01, -1.6371e-01, -2.2405e-01,  4.3266e-02,
         -1.8863e-01],
        [ 2.5194e-01,  1.3578e-01,  1.7806e-01, -3.1276e-01, -3.0046e-03,
         -4.1279e-01, -3.0903e-01,  3.1518e-02, -3.8575e-01, -1.3893e-01,
         -4.9453e-02, -8.3061e-02,  1.9075e-01,  2.6017e-01,  3.7005e-01,
          2.1190e-01],
        [ 3.8992e-01,  1.4287e-01,  2.9340e-01, -1.0652e-01, -1.6669e-01,
         -2.6529e-01, -3.7390e-01,  3.4746e-02, -3.2879e-02, -2.8073e-01,
         -7.4185e-02,  2.4357e-01, -8.0909e-02,  1.0804e-01,  3.2668e-01,
          2.1011e-01],
        [-2.0066e-01,  7.4465e-02, -6.8968e-02, -5.2400e-02,  1.4851e-01,
          5.0174e-04,  3.3051e-01,  3.9385e-01,  1.9003e-01,  7.4357e-02,
         -6.6658e-02, -3.0045e-01, -1.9955e-01, -2.0449e-01,  4.7385e-02,
         -2.5449e-01],
        [-8.0394e-02, -3.4361e-01, -5.9602e-02,  3.8934e-01, -1.5836e-01,
          1.3817e-01,  2.5210e-01, -7.2440e-02,  3.5531e-03,  2.5436e-01,
          2.5871e-01, -2.5301e-01, -1.4719e-01, -3.4065e-01, -4.4654e-01,
          5.8073e-02],
        [ 3.7652e-01,  3.6881e-02,  6.8490e-02, -1.6854e-01,  1.6433e-01,
         -4.2153e-01, -3.0836e-01, -2.0728e-01, -2.2728e-01, -1.5287e-01,
          1.1322e-01,  1.9622e-01, -1.1532e-01,  3.1257e-01,  3.7747e-01,
          2.2899e-01],
        [ 2.7592e-01,  2.0488e-01,  3.6184e-01, -3.8156e-01, -8.4134e-02,
         -2.0047e-01, -2.0300e-01, -2.6787e-01, -3.3983e-01, -3.2636e-01,
         -1.0868e-01,  3.3247e-01,  2.5087e-01,  1.4786e-01,  5.1003e-03,
          4.4406e-02],
        [ 2.2716e-01, -1.3153e-01,  1.9048e-01, -1.4255e-01,  1.9687e-01,
         -2.8861e-01,  2.3512e-02, -1.8916e-01, -3.6256e-01,  5.5915e-02,
          1.6306e-01,  1.2621e-02,  4.5324e-02,  2.3466e-01,  7.3612e-02,
          3.3143e-01],
        [ 7.1790e-02,  1.8106e-02,  1.2020e-01,  5.6973e-02, -7.5626e-02,
         -2.6106e-01, -5.4967e-02, -3.6145e-01, -1.8020e-01, -3.6488e-01,
         -2.9998e-01,  1.3781e-01,  1.9364e-01,  3.3162e-01, -2.3255e-02,
          8.7201e-02],
        [ 2.3429e-01,  2.1204e-01,  3.1779e-01, -3.5672e-01,  1.3409e-03,
         -1.2514e-01, -3.7477e-01,  3.5851e-03, -3.5619e-01,  5.4515e-03,
         -3.4210e-03,  6.8013e-02,  1.9532e-01,  2.9980e-01,  3.6429e-01,
          3.0842e-01],
        [-3.3382e-01, -4.3189e-02, -4.1602e-04,  2.1658e-01,  1.9550e-01,
          4.9295e-02,  3.7858e-01,  1.6722e-01, -6.2309e-02,  9.8662e-02,
          2.2547e-01, -2.7100e-01, -2.0423e-01, -1.8882e-01, -3.4026e-01,
         -1.1293e-01],
        [ 3.2223e-01,  1.4923e-01,  1.5819e-01, -1.4121e-01, -1.7767e-01,
         -3.1923e-01, -1.6268e-01, -3.3997e-01, -8.4342e-03, -1.1212e-01,
         -4.2576e-03,  1.3841e-01,  3.0911e-01,  3.0961e-01,  2.9765e-01,
          2.7778e-01],
        [-2.8670e-01, -4.1983e-03, -3.3613e-01,  2.6095e-01, -2.4086e-01,
          1.7827e-01,  3.5290e-01,  2.9068e-01,  3.3848e-01,  2.3210e-01,
          1.9170e-01, -7.3264e-02,  5.4623e-02,  4.8815e-02, -1.0290e-01,
         -2.3676e-01],
        [-3.0247e-01, -1.8514e-01, -6.5206e-02,  3.2403e-02,  4.7921e-02,
          4.1598e-01,  3.9927e-01, -3.3352e-02,  2.1093e-01,  3.2523e-01,
         -1.8447e-01, -5.6109e-03, -2.8244e-01, -2.7034e-01, -3.0018e-01,
         -2.5882e-01],
        [ 8.6249e-02,  2.1240e-01,  2.8807e-01, -8.9926e-02,  1.8352e-01,
         -3.6023e-01, -4.3754e-01, -3.7613e-01, -2.9790e-01, -2.9809e-01,
          2.2795e-02, -4.5358e-03, -1.6342e-02,  2.6640e-01,  4.9727e-02,
          2.1672e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1000, -0.0544,  0.1793, -0.0314, -0.0782, -0.0369,  0.0687,  0.0593,
        -0.0295, -0.0517, -0.0270,  0.0591,  0.1221,  0.0955, -0.0115, -0.0020,
        -0.1452,  0.0260,  0.1128,  0.0145, -0.0196, -0.1717, -0.0161, -0.0516,
        -0.0445,  0.2212,  0.1201,  0.0235, -0.0532, -0.1449,  0.0188,  0.0261],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1927,  0.2840, -0.2096, -0.2405,  0.2619,  0.3118, -0.2614, -0.3638,
         -0.2873,  0.3035,  0.2464,  0.3581, -0.2195, -0.3627,  0.2835, -0.1469,
         -0.2811,  0.3224, -0.2137, -0.2284,  0.3382,  0.3397, -0.3591, -0.3650,
         -0.2575, -0.2891, -0.3051,  0.3247, -0.3484,  0.3707,  0.2833, -0.2226]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0108, -0.0032,  0.0258,  ...,  0.2090, -0.3522, -0.1137],
        [-0.0818, -0.1899,  0.0830,  ...,  0.1452, -0.3289,  0.0871],
        [-0.0542,  0.1577,  0.0909,  ...,  0.0109,  0.2353,  0.0345],
        ...,
        [ 0.0420, -0.1560,  0.0129,  ...,  0.0670, -0.2797, -0.1180],
        [ 0.0347, -0.0701,  0.0058,  ..., -0.3026,  0.1274,  0.1557],
        [-0.0851,  0.1614,  0.0122,  ..., -0.1724,  0.0626, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0510,  0.0540, -0.0928, -0.1204, -0.0577,  0.0458, -0.1289,  0.0620,
        -0.0464,  0.0922,  0.0329,  0.0082,  0.0095,  0.0630, -0.0783, -0.0203,
         0.0465, -0.1422, -0.0324, -0.0152, -0.1095,  0.0476,  0.0820, -0.0064,
        -0.0850,  0.0666,  0.0242, -0.0960,  0.0639,  0.1472,  0.1371, -0.0658],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0382, -0.1963, -0.0805,  ..., -0.1401, -0.0154,  0.2628],
        [-0.2361, -0.0450,  0.1049,  ..., -0.0706, -0.0021,  0.2713],
        [ 0.1650, -0.0193, -0.1766,  ...,  0.0831, -0.0243, -0.0689],
        ...,
        [ 0.1520,  0.1118,  0.0815,  ...,  0.2633, -0.2227,  0.0551],
        [-0.0531, -0.1739,  0.0767,  ...,  0.0024,  0.2496,  0.0865],
        [-0.0184, -0.1218,  0.2114,  ...,  0.0510,  0.1401,  0.1317]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0869,  0.1225, -0.0354, -0.0548, -0.0311, -0.0352, -0.0325, -0.0624,
         0.1100, -0.1751,  0.1224, -0.1328,  0.1652, -0.0186, -0.1428,  0.1054,
        -0.1272, -0.1539,  0.0136, -0.0295,  0.0086,  0.1086, -0.1892,  0.2025,
        -0.0698, -0.0287,  0.0880, -0.0375, -0.1122, -0.0601,  0.1110,  0.0009],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5162,  0.4405, -0.5186, -0.5219,  0.3668,  0.3749, -0.4230,  0.4317,
          0.4317, -0.4545, -0.4446,  0.4055,  0.4277, -0.3686,  0.4486,  0.3970,
         -0.5265, -0.5177,  0.3946,  0.4118, -0.4796, -0.4526, -0.5161,  0.3516,
          0.4908,  0.5173, -0.4912,  0.5592, -0.4268, -0.5086,  0.4933,  0.5084]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2381], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.1880e-02,  3.5719e-01,  3.2319e-01, -3.4503e-01, -2.1567e-02,
         -1.7734e-01, -6.7275e-02, -3.8740e-01, -1.7285e-01, -8.5857e-02,
          2.3095e-02,  1.7106e-01,  5.5124e-02, -5.1889e-02,  3.1480e-01,
          3.6653e-01],
        [-2.7564e-01, -3.4130e-01, -1.2777e-01,  1.2484e-02, -1.6435e-01,
          2.8459e-01,  1.8855e-01,  1.6694e-01,  3.9733e-01,  1.3564e-01,
          2.2674e-01, -2.6991e-01,  4.8792e-03, -4.4903e-02,  2.6897e-03,
         -8.5787e-02],
        [ 9.9696e-02,  2.5135e-01,  4.0297e-01, -1.3922e-01,  1.4599e-01,
         -3.7427e-01, -6.4687e-02, -4.1037e-01,  5.7392e-02, -8.3587e-02,
         -1.0123e-01, -6.5154e-02,  3.9072e-01,  3.1119e-01,  4.3199e-01,
          2.6833e-01],
        [ 2.9174e-01,  7.1348e-02,  1.0701e-01, -9.0888e-02,  1.0380e-01,
         -2.2986e-01, -1.7125e-01, -9.5551e-02, -4.0446e-01, -4.0377e-01,
         -1.1196e-01,  3.6298e-01,  2.8029e-01, -1.2761e-01,  1.3932e-01,
          1.6176e-01],
        [-1.1547e-01,  1.1815e-01, -1.8932e-01, -5.6346e-03,  4.9426e-02,
          1.2209e-01,  6.5959e-02,  3.4540e-01,  1.5636e-01,  2.9240e-01,
          2.3722e-01, -1.8627e-01, -4.9182e-02, -2.2521e-01, -8.0213e-02,
         -1.3881e-01],
        [-2.0600e-02,  1.4403e-01, -3.7523e-01,  4.1084e-01,  1.5769e-01,
          2.9202e-03,  2.7487e-01, -2.1995e-02,  2.4927e-01,  2.0520e-01,
         -1.3461e-01, -9.4761e-02, -2.4396e-01,  1.3426e-01,  3.6074e-02,
         -7.0923e-02],
        [ 3.9349e-01,  2.0504e-01,  4.3316e-01, -2.0244e-01,  1.3306e-01,
         -2.5018e-01, -2.1107e-01, -2.3680e-01, -2.4774e-01, -2.9302e-02,
         -2.4877e-02,  6.2995e-02, -3.7695e-02,  2.3001e-01, -1.3455e-02,
          1.6433e-01],
        [-4.4752e-02,  3.1794e-01,  3.7520e-01, -3.6198e-01, -1.4313e-01,
         -3.3061e-01, -1.0879e-01, -2.4484e-01, -1.7611e-01, -2.1539e-01,
         -7.6324e-02,  1.8418e-02,  2.5043e-01, -8.3725e-02,  1.5975e-01,
          3.6657e-01],
        [ 5.6451e-02,  3.0830e-01,  3.2636e-01, -2.6846e-01,  3.5938e-02,
         -3.8225e-01, -1.8354e-01, -1.1010e-01,  4.4137e-02, -3.1556e-01,
         -1.1896e-01,  7.2885e-02, -8.5952e-02,  1.4252e-01,  1.2126e-02,
          9.7862e-02],
        [-3.0519e-01, -8.7314e-02, -1.1661e-01,  1.0108e-03, -4.6916e-02,
          1.8821e-01,  6.6343e-02,  2.5010e-01,  2.6891e-01, -6.7212e-03,
          2.4407e-01, -2.1280e-02, -2.5714e-01, -6.7232e-02, -1.8428e-01,
         -1.9049e-01],
        [-3.6862e-01,  6.8093e-02, -7.9999e-02, -2.7645e-02, -1.8027e-01,
          4.5426e-01,  2.4500e-01,  1.1752e-01,  3.3422e-01,  2.4983e-01,
          7.3549e-02,  1.1095e-02, -1.5628e-01,  1.3381e-01, -3.8647e-01,
         -3.3298e-01],
        [-1.4481e-01, -1.4864e-01, -4.4270e-02,  1.0506e-01,  1.0795e-01,
          1.5228e-01,  3.8876e-01,  1.5989e-01,  1.6688e-01,  3.4566e-01,
          1.6131e-01,  5.0495e-02, -3.9659e-01, -2.0364e-01, -2.5740e-01,
         -2.0263e-01],
        [ 3.6641e-01,  2.2466e-01,  2.0199e-01, -2.0178e-01,  7.9933e-02,
         -2.5944e-02, -1.1329e-01, -3.3531e-01, -3.3687e-01, -1.2275e-01,
         -1.2802e-01,  4.0936e-02, -2.8700e-02,  1.9504e-01,  1.6789e-01,
          3.8265e-02],
        [ 2.3662e-01,  3.5725e-01,  3.9734e-01, -3.3725e-02, -1.7452e-01,
         -6.2683e-02, -7.2693e-02, -8.5131e-02, -2.2013e-01, -1.7364e-01,
         -2.2078e-01,  1.2492e-01,  1.2821e-01,  7.2465e-02, -3.6371e-02,
          2.5252e-01],
        [-3.9530e-01, -3.0656e-01, -9.0896e-02, -2.7848e-02,  1.9988e-01,
          4.4509e-01,  1.1977e-01,  1.1901e-01, -4.0236e-02,  1.8601e-01,
          1.3380e-01, -3.1251e-01, -8.1527e-02, -1.1889e-01, -2.8064e-01,
         -1.7240e-01],
        [-8.9988e-02, -1.5208e-01,  1.7833e-01,  9.2827e-02, -1.9464e-01,
         -1.4310e-02, -1.5424e-01, -2.8987e-01, -1.6309e-01, -8.1993e-03,
          4.2608e-03,  4.2463e-01,  1.1146e-01, -9.6204e-02,  4.0886e-01,
          2.9894e-02],
        [ 3.3272e-01,  2.7645e-01,  2.2017e-01, -3.6680e-01, -2.0291e-01,
         -7.0648e-02, -1.2135e-01, -4.4367e-04, -3.5445e-01, -1.8887e-01,
          1.3302e-01,  2.8598e-01,  3.4227e-01,  2.8689e-01,  1.2625e-01,
         -1.5214e-02],
        [-3.1603e-01, -2.3895e-02, -2.6783e-01,  1.5479e-01, -1.5690e-02,
          3.3689e-01,  3.1227e-01,  2.7543e-01,  1.3172e-01,  2.8776e-01,
         -3.1702e-02, -2.4562e-01, -1.6371e-01, -2.2405e-01,  4.3266e-02,
         -1.8863e-01],
        [ 2.5194e-01,  1.3578e-01,  1.7806e-01, -3.1276e-01, -3.0050e-03,
         -4.1279e-01, -3.0903e-01,  3.1518e-02, -3.8575e-01, -1.3893e-01,
         -4.9453e-02, -8.3061e-02,  1.9075e-01,  2.6017e-01,  3.7005e-01,
          2.1190e-01],
        [ 3.8992e-01,  1.4287e-01,  2.9340e-01, -1.0652e-01, -1.6669e-01,
         -2.6529e-01, -3.7390e-01,  3.4745e-02, -3.2880e-02, -2.8073e-01,
         -7.4185e-02,  2.4357e-01, -8.0909e-02,  1.0804e-01,  3.2668e-01,
          2.1011e-01],
        [-2.0066e-01,  7.4465e-02, -6.8968e-02, -5.2401e-02,  1.4851e-01,
          5.0164e-04,  3.3051e-01,  3.9386e-01,  1.9003e-01,  7.4357e-02,
         -6.6659e-02, -3.0045e-01, -1.9955e-01, -2.0449e-01,  4.7385e-02,
         -2.5449e-01],
        [-8.0394e-02, -3.4361e-01, -5.9601e-02,  3.8934e-01, -1.5836e-01,
          1.3817e-01,  2.5210e-01, -7.2440e-02,  3.5531e-03,  2.5436e-01,
          2.5871e-01, -2.5301e-01, -1.4719e-01, -3.4065e-01, -4.4654e-01,
          5.8074e-02],
        [ 3.7652e-01,  3.6881e-02,  6.8490e-02, -1.6853e-01,  1.6433e-01,
         -4.2153e-01, -3.0836e-01, -2.0728e-01, -2.2728e-01, -1.5287e-01,
          1.1322e-01,  1.9622e-01, -1.1532e-01,  3.1257e-01,  3.7747e-01,
          2.2899e-01],
        [ 2.7591e-01,  2.0488e-01,  3.6184e-01, -3.8156e-01, -8.4135e-02,
         -2.0047e-01, -2.0300e-01, -2.6787e-01, -3.3983e-01, -3.2636e-01,
         -1.0868e-01,  3.3247e-01,  2.5087e-01,  1.4786e-01,  5.1002e-03,
          4.4405e-02],
        [ 2.2716e-01, -1.3153e-01,  1.9048e-01, -1.4255e-01,  1.9687e-01,
         -2.8861e-01,  2.3512e-02, -1.8916e-01, -3.6256e-01,  5.5915e-02,
          1.6306e-01,  1.2621e-02,  4.5325e-02,  2.3466e-01,  7.3612e-02,
          3.3143e-01],
        [ 7.1790e-02,  1.8106e-02,  1.2020e-01,  5.6973e-02, -7.5627e-02,
         -2.6106e-01, -5.4967e-02, -3.6145e-01, -1.8020e-01, -3.6488e-01,
         -2.9998e-01,  1.3781e-01,  1.9364e-01,  3.3161e-01, -2.3255e-02,
          8.7201e-02],
        [ 2.3429e-01,  2.1204e-01,  3.1779e-01, -3.5672e-01,  1.3405e-03,
         -1.2514e-01, -3.7477e-01,  3.5848e-03, -3.5619e-01,  5.4518e-03,
         -3.4207e-03,  6.8013e-02,  1.9532e-01,  2.9980e-01,  3.6429e-01,
          3.0842e-01],
        [-3.3382e-01, -4.3189e-02, -4.1572e-04,  2.1658e-01,  1.9551e-01,
          4.9295e-02,  3.7858e-01,  1.6722e-01, -6.2309e-02,  9.8662e-02,
          2.2547e-01, -2.7100e-01, -2.0423e-01, -1.8882e-01, -3.4026e-01,
         -1.1293e-01],
        [ 3.2223e-01,  1.4923e-01,  1.5819e-01, -1.4121e-01, -1.7767e-01,
         -3.1923e-01, -1.6268e-01, -3.3997e-01, -8.4342e-03, -1.1212e-01,
         -4.2573e-03,  1.3842e-01,  3.0911e-01,  3.0961e-01,  2.9765e-01,
          2.7778e-01],
        [-2.8670e-01, -4.1978e-03, -3.3613e-01,  2.6095e-01, -2.4086e-01,
          1.7827e-01,  3.5290e-01,  2.9068e-01,  3.3848e-01,  2.3210e-01,
          1.9170e-01, -7.3264e-02,  5.4622e-02,  4.8815e-02, -1.0290e-01,
         -2.3676e-01],
        [-3.0247e-01, -1.8514e-01, -6.5206e-02,  3.2403e-02,  4.7922e-02,
          4.1598e-01,  3.9927e-01, -3.3352e-02,  2.1093e-01,  3.2523e-01,
         -1.8448e-01, -5.6111e-03, -2.8244e-01, -2.7034e-01, -3.0018e-01,
         -2.5882e-01],
        [ 8.6249e-02,  2.1240e-01,  2.8807e-01, -8.9926e-02,  1.8352e-01,
         -3.6023e-01, -4.3754e-01, -3.7614e-01, -2.9790e-01, -2.9809e-01,
          2.2796e-02, -4.5356e-03, -1.6341e-02,  2.6640e-01,  4.9727e-02,
          2.1672e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1000, -0.0544,  0.1793, -0.0314, -0.0782, -0.0369,  0.0687,  0.0593,
        -0.0295, -0.0517, -0.0270,  0.0591,  0.1221,  0.0955, -0.0115, -0.0020,
        -0.1452,  0.0260,  0.1128,  0.0145, -0.0196, -0.1717, -0.0161, -0.0516,
        -0.0445,  0.2212,  0.1201,  0.0235, -0.0532, -0.1449,  0.0188,  0.0261],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1927,  0.2840, -0.2096, -0.2405,  0.2619,  0.3118, -0.2614, -0.3638,
         -0.2873,  0.3035,  0.2464,  0.3581, -0.2195, -0.3627,  0.2835, -0.1469,
         -0.2811,  0.3224, -0.2137, -0.2284,  0.3382,  0.3397, -0.3591, -0.3650,
         -0.2575, -0.2891, -0.3051,  0.3247, -0.3484,  0.3707,  0.2833, -0.2226]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0108, -0.0032,  0.0258,  ...,  0.2090, -0.3522, -0.1137],
        [-0.0818, -0.1899,  0.0830,  ...,  0.1452, -0.3289,  0.0871],
        [-0.0542,  0.1577,  0.0909,  ...,  0.0109,  0.2353,  0.0345],
        ...,
        [ 0.0420, -0.1560,  0.0129,  ...,  0.0670, -0.2797, -0.1180],
        [ 0.0347, -0.0701,  0.0058,  ..., -0.3026,  0.1274,  0.1557],
        [-0.0851,  0.1614,  0.0122,  ..., -0.1724,  0.0626, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0510,  0.0540, -0.0928, -0.1204, -0.0577,  0.0458, -0.1289,  0.0620,
        -0.0464,  0.0922,  0.0329,  0.0082,  0.0095,  0.0630, -0.0783, -0.0203,
         0.0465, -0.1422, -0.0324, -0.0152, -0.1095,  0.0476,  0.0820, -0.0064,
        -0.0850,  0.0666,  0.0242, -0.0960,  0.0639,  0.1472,  0.1371, -0.0658],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0382, -0.1963, -0.0805,  ..., -0.1401, -0.0154,  0.2628],
        [-0.2361, -0.0450,  0.1049,  ..., -0.0706, -0.0021,  0.2713],
        [ 0.1650, -0.0193, -0.1766,  ...,  0.0831, -0.0243, -0.0689],
        ...,
        [ 0.1520,  0.1118,  0.0815,  ...,  0.2633, -0.2227,  0.0551],
        [-0.0531, -0.1739,  0.0767,  ...,  0.0024,  0.2496,  0.0865],
        [-0.0184, -0.1218,  0.2114,  ...,  0.0510,  0.1401,  0.1317]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0869,  0.1225, -0.0354, -0.0548, -0.0311, -0.0352, -0.0325, -0.0624,
         0.1100, -0.1751,  0.1224, -0.1328,  0.1652, -0.0186, -0.1428,  0.1054,
        -0.1272, -0.1539,  0.0136, -0.0295,  0.0086,  0.1086, -0.1892,  0.2025,
        -0.0698, -0.0287,  0.0880, -0.0375, -0.1122, -0.0601,  0.1110,  0.0009],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5162,  0.4405, -0.5186, -0.5219,  0.3668,  0.3749, -0.4230,  0.4317,
          0.4317, -0.4545, -0.4446,  0.4055,  0.4277, -0.3686,  0.4486,  0.3970,
         -0.5265, -0.5177,  0.3946,  0.4118, -0.4796, -0.4526, -0.5161,  0.3516,
          0.4908,  0.5173, -0.4912,  0.5592, -0.4268, -0.5086,  0.4933,  0.5084]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2381], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 0.0103,  0.3641,  0.3236, -0.3166, -0.3109, -0.2013, -0.0917, -0.4755,
         -0.2513, -0.0889, -0.0306,  0.2466,  0.1055, -0.0262,  0.0250,  0.3717],
        [-0.2617, -0.3402, -0.1164, -0.0104,  0.0566,  0.2842,  0.1969,  0.2266,
          0.4520,  0.1535,  0.2892, -0.3097, -0.0195, -0.0816,  0.2632, -0.0839],
        [ 0.0914,  0.2514,  0.3950, -0.1108, -0.1686, -0.3809, -0.0818, -0.4953,
         -0.0297, -0.0867, -0.1420, -0.0076,  0.4343,  0.3704,  0.1368,  0.2673],
        [ 0.2870,  0.0762,  0.1039, -0.0736, -0.1421, -0.2390, -0.1917, -0.1741,
         -0.4884, -0.4290, -0.1246,  0.4232,  0.3093, -0.0701, -0.1310,  0.1643],
        [-0.1047,  0.0825, -0.1848, -0.0297,  0.2490,  0.1237,  0.0762,  0.3944,
          0.2034,  0.3181,  0.3248, -0.2120, -0.0721, -0.2823,  0.1973, -0.1604],
        [-0.0193,  0.1212, -0.3772,  0.4029,  0.4237,  0.0144,  0.2964,  0.0404,
          0.3133,  0.2372, -0.0892, -0.1385, -0.2712,  0.0856,  0.3129, -0.0848],
        [ 0.3858,  0.1200,  0.4260, -0.1873, -0.1345, -0.2522, -0.2161, -0.3105,
         -0.3187, -0.0504, -0.0587,  0.1158, -0.0344,  0.2727, -0.1914,  0.1637],
        [-0.0499,  0.2704,  0.3704, -0.3550, -0.3963, -0.3300, -0.1148, -0.3210,
         -0.2482, -0.2363, -0.1050,  0.0726,  0.2711, -0.0452,  0.0007,  0.3643],
        [ 0.0474,  0.3068,  0.3194, -0.2434, -0.1336, -0.3878, -0.2010, -0.1745,
         -0.0151, -0.3376, -0.2606,  0.1101, -0.0376,  0.2074, -0.2478,  0.1006],
        [-0.3011, -0.1096, -0.1166, -0.0141,  0.1630,  0.1990,  0.0879,  0.3156,
          0.3326,  0.0252,  0.3349, -0.0611, -0.2976, -0.1303,  0.0968, -0.2066],
        [-0.3727,  0.0439, -0.0857, -0.0319,  0.0518,  0.4729,  0.2728,  0.2041,
          0.4203,  0.2846,  0.1378, -0.0554, -0.1861,  0.0629, -0.0724, -0.3450],
        [-0.1395, -0.1629, -0.0434,  0.0906,  0.2541,  0.1629,  0.4071,  0.2287,
          0.2267,  0.3767,  0.2527,  0.0075, -0.4047, -0.2886, -0.0099, -0.2148],
        [ 0.3540,  0.2539,  0.1929, -0.1751, -0.2356, -0.0372, -0.1375, -0.4336,
         -0.4060, -0.1449, -0.1667,  0.1072, -0.0107,  0.2289, -0.1770,  0.0477],
        [ 0.2218,  0.3365,  0.3849, -0.0138, -0.3829, -0.0585, -0.0742, -0.1372,
         -0.2701, -0.1897, -0.2760,  0.1569,  0.1470,  0.1078, -0.2542,  0.2482],
        [-0.3883, -0.3003, -0.0850, -0.0421,  0.4450,  0.4477,  0.1324,  0.1889,
          0.0279,  0.2075,  0.1891, -0.3610, -0.1126, -0.1635, -0.0449, -0.1726],
        [-0.0581, -0.0669,  0.2205,  0.0886, -0.4341, -0.0841, -0.2400, -0.4138,
         -0.2857, -0.0950, -0.1305,  0.4796,  0.2029,  0.0326,  0.1522,  0.0838],
        [ 0.3299,  0.2726,  0.2190, -0.3568, -0.4414, -0.0801, -0.1397, -0.0748,
         -0.4290, -0.2161,  0.0957,  0.3443,  0.3895,  0.3365, -0.0734, -0.0137],
        [-0.3080, -0.0106, -0.2615,  0.1443,  0.2002,  0.3334,  0.3175,  0.3343,
          0.1952,  0.3080,  0.0024, -0.2886, -0.1841, -0.2724,  0.2123, -0.1870],
        [ 0.2302,  0.1208,  0.1553, -0.2691, -0.3134, -0.4105, -0.3192, -0.0540,
         -0.4770, -0.1255, -0.1124, -0.0270,  0.2594,  0.3220,  0.0894,  0.1915],
        [ 0.3881,  0.1384,  0.2911, -0.0916, -0.4020, -0.2753, -0.3957, -0.0510,
         -0.1151, -0.3049, -0.1525,  0.3059, -0.0315,  0.1645,  0.0913,  0.2111],
        [-0.1919,  0.0504, -0.0642, -0.0667,  0.3431, -0.0033,  0.3366,  0.4212,
          0.2258,  0.0964, -0.0050, -0.3147, -0.2145, -0.2497,  0.2990, -0.2659],
        [-0.0828, -0.3367, -0.0627,  0.3786,  0.0577,  0.1557,  0.2878,  0.0148,
          0.0826,  0.2888,  0.3842, -0.3090, -0.2196, -0.4096, -0.1733,  0.0490],
        [ 0.3788,  0.0353,  0.0711, -0.1667, -0.0673, -0.4328, -0.3301, -0.2887,
         -0.3073, -0.1828,  0.0630,  0.2568, -0.0665,  0.3692,  0.1855,  0.2336],
        [ 0.2694,  0.2043,  0.3567, -0.3750, -0.2910, -0.1968, -0.2109, -0.3371,
         -0.4080, -0.3458, -0.0997,  0.3831,  0.2705,  0.1887, -0.1513,  0.0383],
        [ 0.2235, -0.1071,  0.1908, -0.1226, -0.0238, -0.3023,  0.0026, -0.2515,
         -0.4283,  0.0237,  0.0692,  0.0573,  0.0871,  0.2951, -0.2288,  0.3506],
        [ 0.0537,  0.0336,  0.1055,  0.0799, -0.2923, -0.2471, -0.0495, -0.3910,
         -0.2121, -0.3777, -0.3611,  0.1518,  0.1980,  0.3650, -0.2884,  0.0916],
        [ 0.2354,  0.1995,  0.3188, -0.3529, -0.2451, -0.1352, -0.3942, -0.0841,
         -0.4406, -0.0217, -0.0443,  0.1339,  0.2443,  0.3502,  0.1814,  0.3096],
        [-0.3321, -0.0573, -0.0024,  0.2066,  0.3891,  0.0637,  0.4020,  0.2446,
          0.0072,  0.1328,  0.2985, -0.3228, -0.2419, -0.2559, -0.0888, -0.1262],
        [ 0.3181,  0.1675,  0.1565, -0.1354, -0.3736, -0.3257, -0.1802, -0.4085,
         -0.0757, -0.1377, -0.0077,  0.1905,  0.3158,  0.3661,  0.0698,  0.2800],
        [-0.2847,  0.0193, -0.3346,  0.2567, -0.0131,  0.1803,  0.3644,  0.3619,
          0.4092,  0.2571,  0.2405, -0.1240,  0.0254, -0.0011,  0.0637, -0.2397],
        [-0.3010, -0.1887, -0.0647,  0.0226,  0.2746,  0.4267,  0.4189,  0.0449,
          0.2888,  0.3520, -0.1247, -0.0643, -0.3309, -0.3293, -0.0748, -0.2614],
        [ 0.0700,  0.1806,  0.2722, -0.0503, -0.0721, -0.3585, -0.4417, -0.4477,
         -0.3741, -0.2948, -0.0374,  0.0426,  0.0113,  0.3215, -0.1765,  0.2060]],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0569, -0.0091,  0.1055, -0.0387, -0.0547, -0.0881,  0.0721,  0.0802,
        -0.0213, -0.0545, -0.0028,  0.0611,  0.1439,  0.0774,  0.0223, -0.0533,
        -0.0526, -0.0030,  0.0889,  0.0039, -0.0392, -0.1369, -0.0314, -0.0002,
        -0.0082,  0.1582,  0.1171,  0.0227, -0.0672, -0.1390,  0.0328, -0.0458],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2315,  0.3229, -0.2292, -0.2628,  0.3237,  0.3612, -0.2838, -0.3857,
         -0.3165,  0.3471,  0.2649,  0.3756, -0.2645, -0.4001,  0.3051, -0.2818,
         -0.3221,  0.3335, -0.2296, -0.2519,  0.4008,  0.3139, -0.3732, -0.3806,
         -0.3298, -0.3405, -0.3153,  0.3523, -0.3613,  0.3848,  0.2914, -0.2390]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0146, -0.0098,  0.0440,  ...,  0.2363, -0.3680, -0.1137],
        [-0.0874, -0.1932,  0.0880,  ...,  0.1479, -0.3482,  0.0871],
        [-0.0392,  0.1772,  0.0727,  ..., -0.0052,  0.2677,  0.0345],
        ...,
        [ 0.0248, -0.1919,  0.0429,  ...,  0.0660, -0.2934, -0.1180],
        [ 0.0521, -0.0480, -0.0199,  ..., -0.3044,  0.1536,  0.1557],
        [-0.2057,  0.0486,  0.0024,  ...,  0.0417, -0.2383, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0569,  0.0575, -0.0881, -0.1189, -0.0574,  0.0528, -0.1278,  0.0610,
        -0.0490,  0.0818,  0.0312,  0.0093,  0.0257,  0.0733, -0.0781, -0.0170,
         0.0498, -0.1498, -0.0286, -0.0239, -0.0747,  0.0444,  0.0887, -0.0072,
        -0.0871,  0.0868,  0.0330, -0.0874,  0.0487,  0.1384,  0.1476, -0.1051],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0170, -0.1915, -0.0777,  ..., -0.1183, -0.0265,  0.0699],
        [-0.2667, -0.0456,  0.1183,  ..., -0.0505, -0.0056,  0.0579],
        [ 0.1849, -0.0286, -0.1785,  ...,  0.0559, -0.0095,  0.1677],
        ...,
        [ 0.1672,  0.0977,  0.0872,  ...,  0.2300, -0.2016,  0.2429],
        [-0.0798, -0.1648,  0.0798,  ...,  0.0307,  0.2372, -0.1660],
        [-0.0500, -0.1263,  0.2181,  ...,  0.0692,  0.1356, -0.0329]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0832,  0.1210, -0.0223, -0.0584, -0.0348, -0.0628, -0.0254, -0.0601,
         0.0938, -0.1342,  0.1352, -0.1270,  0.1506,  0.0570, -0.1347,  0.0865,
        -0.1172, -0.1448,  0.0024, -0.0143,  0.0077,  0.1101, -0.1828,  0.1721,
        -0.0644, -0.0314,  0.0912, -0.0427, -0.1085, -0.0529,  0.0941,  0.0028],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5169,  0.4389, -0.5159, -0.5188,  0.3835,  0.3745, -0.4305,  0.4251,
          0.4500, -0.4540, -0.4142,  0.4103,  0.4092,  0.4194,  0.4481,  0.4014,
         -0.5173, -0.5228,  0.3871,  0.4127, -0.4723, -0.4506, -0.5167,  0.3775,
          0.5008,  0.5250, -0.5005,  0.5497, -0.4290, -0.5142,  0.4954,  0.5168]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2356], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.1924e-02,  7.2487e-02,  3.0005e-01, -3.3621e-01, -2.8084e-01,
         -1.5338e-01, -6.0180e-02, -4.4473e-01, -2.0018e-01, -6.1891e-02,
          1.8009e-01,  2.0016e-01,  6.5199e-02, -4.6847e-02, -1.7298e-01,
          3.7395e-01],
        [-2.6313e-01, -7.8301e-02, -1.0313e-01,  1.7936e-02,  4.0123e-02,
          2.4953e-01,  1.6810e-01,  2.0130e-01,  4.3462e-01,  1.4254e-01,
          6.5412e-02, -2.7637e-01, -1.2374e-02, -6.5992e-02,  4.5677e-01,
         -8.6810e-02],
        [ 8.9906e-02,  1.2189e-02,  3.7447e-01, -1.2981e-01, -1.3198e-01,
         -3.4213e-01, -4.0706e-02, -4.5335e-01,  1.4912e-02, -6.5921e-02,
         -8.2423e-02, -4.8170e-02,  4.0484e-01,  3.3032e-01, -4.7279e-02,
          2.6474e-01],
        [ 2.7314e-01, -5.2629e-02,  7.4336e-02, -8.7618e-02, -1.0459e-01,
         -1.8432e-01, -1.4080e-01, -1.2487e-01, -4.4035e-01, -3.9908e-01,
          3.2587e-02,  3.6463e-01,  2.9948e-01, -1.0805e-01, -2.8242e-01,
          1.4909e-01],
        [-1.0169e-01,  3.3316e-01, -1.6526e-01, -3.3078e-03,  2.2326e-01,
          8.2138e-02,  3.8415e-02,  3.5977e-01,  1.7274e-01,  3.0240e-01,
          6.4047e-02, -1.7130e-01, -5.7455e-02, -2.5586e-01,  3.7185e-01,
         -1.6002e-01],
        [-4.9828e-03,  3.1333e-01, -3.5104e-01,  4.1709e-01,  3.7151e-01,
         -4.0638e-02,  2.4908e-01, -7.1497e-03,  2.7398e-01,  2.1241e-01,
         -1.1380e-01, -9.1557e-02, -2.3597e-01,  1.1534e-01,  4.3960e-01,
         -7.6370e-02],
        [ 3.7499e-01, -6.4736e-03,  4.0139e-01, -2.0295e-01, -1.0924e-01,
         -2.0726e-01, -1.7048e-01, -2.6953e-01, -2.7604e-01, -2.9130e-02,
          4.9195e-03,  7.0998e-02, -5.8097e-02,  1.9101e-01, -3.5136e-01,
          1.5396e-01],
        [-5.8849e-02,  1.3819e-01,  3.5126e-01, -3.7176e-01, -3.8003e-01,
         -2.9649e-01, -8.1952e-02, -2.9486e-01, -2.2473e-01, -2.2354e-01,
         -5.8893e-02,  4.4637e-02,  2.5532e-01, -9.1109e-02, -1.3518e-01,
          3.5674e-01],
        [ 5.0891e-02,  2.5765e-02,  3.0796e-01, -2.7630e-01, -1.2067e-01,
         -3.5241e-01, -1.7314e-01, -1.4995e-01,  6.0169e-03, -3.2908e-01,
          1.5144e-02,  7.7321e-02, -4.3629e-02,  1.9581e-01, -4.3315e-01,
          1.0788e-01],
        [-3.0120e-01,  1.6213e-01, -1.0264e-01,  1.5429e-02,  1.3834e-01,
          1.6009e-01,  5.3210e-02,  2.8194e-01,  3.0432e-01,  1.2911e-02,
          1.0443e-01, -2.5696e-02, -2.8172e-01, -1.1336e-01,  2.7402e-01,
         -2.1125e-01],
        [-3.6518e-01,  2.1100e-01, -6.1754e-02, -1.3236e-02,  2.3079e-02,
          4.2632e-01,  2.3428e-01,  1.6485e-01,  3.8467e-01,  2.6178e-01,
          2.2770e-03, -9.3681e-03, -2.1656e-01,  7.6503e-02,  8.3153e-02,
         -3.3815e-01],
        [-1.2900e-01,  1.6267e-02, -1.9202e-02,  1.1092e-01,  2.1220e-01,
          1.1851e-01,  3.5438e-01,  1.7779e-01,  1.8239e-01,  3.5318e-01,
          8.7128e-02,  5.7067e-02, -4.2234e-01, -2.4617e-01,  1.3106e-01,
         -2.0631e-01],
        [ 3.4813e-01,  4.5998e-04,  1.6404e-01, -1.9897e-01, -1.9106e-01,
          1.8908e-02, -9.2473e-02, -3.8548e-01, -3.6807e-01, -1.1754e-01,
         -9.1453e-02,  5.4821e-02, -1.0261e-02,  2.1311e-01, -3.8960e-01,
          4.2117e-02],
        [ 2.1693e-01,  1.1261e-01,  3.6828e-01, -3.6056e-02, -3.6030e-01,
         -2.4009e-02, -3.8465e-02, -1.0613e-01, -2.4943e-01, -1.7623e-01,
         -1.0550e-01,  1.2352e-01,  1.3368e-01,  7.2637e-02, -4.2752e-01,
          2.4528e-01],
        [-3.8681e-01, -6.6585e-02, -6.9275e-02, -1.7040e-02,  4.3290e-01,
          4.1584e-01,  1.0274e-01,  1.6554e-01,  5.9001e-03,  1.9665e-01,
          3.2516e-02, -3.3019e-01, -1.0909e-01, -1.4188e-01,  1.4971e-01,
         -1.7173e-01],
        [-3.4765e-02, -3.9680e-01,  2.0496e-01,  3.1679e-02, -4.4082e-01,
         -2.7978e-02, -2.0352e-01, -3.9900e-01, -2.6661e-01, -7.8587e-02,
         -4.8229e-02,  4.4645e-01,  1.9286e-01, -1.1257e-02, -8.9032e-02,
          1.0545e-01],
        [ 3.1837e-01,  1.0179e-01,  1.9523e-01, -3.7153e-01, -3.8712e-01,
         -3.2941e-02, -8.7781e-02, -2.4473e-02, -3.9580e-01, -1.9162e-01,
          1.9710e-01,  2.9508e-01,  3.5366e-01,  2.7574e-01, -1.9103e-01,
         -2.6020e-02],
        [-2.9156e-01,  1.1612e-01, -2.3323e-01,  1.5385e-01,  1.4957e-01,
          2.8770e-01,  2.6681e-01,  2.8764e-01,  1.5116e-01,  2.8473e-01,
         -5.3122e-02, -2.4341e-01, -1.5026e-01, -1.9897e-01,  2.8362e-01,
         -1.7105e-01],
        [ 2.3889e-01, -8.3898e-02,  1.4628e-01, -2.9843e-01, -2.4544e-01,
         -3.7710e-01, -2.7669e-01, -6.3856e-03, -4.2824e-01, -1.1437e-01,
          1.8545e-02, -6.7499e-02,  2.0601e-01,  2.6295e-01, -5.9496e-02,
          1.9871e-01],
        [ 3.8028e-01, -5.8304e-02,  2.6552e-01, -1.1155e-01, -3.7685e-01,
         -2.3297e-01, -3.5370e-01, -1.5339e-02, -8.0833e-02, -2.8310e-01,
          9.4244e-02,  2.6018e-01, -3.5434e-02,  1.2491e-01, -9.7691e-02,
          2.0174e-01],
        [-1.7813e-01,  2.3706e-01, -3.7741e-02, -5.4971e-02,  3.0074e-01,
         -4.6230e-02,  2.9427e-01,  3.8227e-01,  1.9387e-01,  7.4758e-02,
         -1.1030e-01, -2.7420e-01, -1.9672e-01, -2.0823e-01,  4.1590e-01,
         -2.5443e-01],
        [-9.4649e-02,  4.9265e-03, -5.8463e-02,  4.1930e-01,  5.9157e-02,
          1.2697e-01,  2.6599e-01, -5.8641e-04,  7.4087e-02,  2.8899e-01,
          2.1124e-01, -2.9356e-01, -2.2092e-01, -3.9954e-01, -3.8895e-03,
          3.8833e-02],
        [ 3.7259e-01, -1.4706e-01,  5.1954e-02, -1.8713e-01, -4.3905e-02,
         -3.9872e-01, -2.9351e-01, -2.6163e-01, -2.8207e-01, -1.6938e-01,
          2.0862e-01,  2.2555e-01, -6.6919e-02,  3.2819e-01,  3.3518e-02,
          2.2630e-01],
        [ 2.5329e-01,  1.1737e-01,  3.3097e-01, -3.8450e-01, -2.2905e-01,
         -1.5538e-01, -1.6174e-01, -2.9141e-01, -3.6951e-01, -3.2178e-01,
          1.9791e-02,  3.4292e-01,  2.6659e-01,  1.2716e-01, -2.2191e-01,
          1.8072e-02],
        [ 2.1717e-01, -3.6342e-01,  1.7106e-01, -1.4847e-01,  1.2222e-02,
         -2.5181e-01,  4.8091e-02, -2.0348e-01, -3.8582e-01,  4.3345e-02,
          1.9930e-01,  9.6095e-03,  6.0729e-02,  2.7385e-01, -4.0129e-01,
          3.5163e-01],
        [ 4.7126e-02, -1.7512e-01,  8.4672e-02,  6.1832e-02, -2.5872e-01,
         -2.1171e-01, -2.0495e-02, -3.5963e-01, -1.8679e-01, -3.6239e-01,
         -2.6547e-01,  1.1826e-01,  1.9800e-01,  3.4135e-01, -4.6095e-01,
          8.5421e-02],
        [ 2.2462e-01, -3.3780e-03,  2.9219e-01, -3.6695e-01, -2.1140e-01,
         -9.7890e-02, -3.4640e-01, -4.9833e-02, -4.0555e-01, -1.6221e-03,
          4.9145e-02,  9.3517e-02,  2.3375e-01,  2.7632e-01,  4.3203e-02,
          2.9441e-01],
        [-3.2964e-01,  1.6239e-01,  1.5927e-02,  2.3257e-01,  3.5875e-01,
          2.4198e-02,  3.5785e-01,  2.0495e-01, -3.0211e-02,  1.1648e-01,
          7.1128e-02, -2.8097e-01, -2.3358e-01, -2.1800e-01,  6.6583e-02,
         -1.2475e-01],
        [ 3.0435e-01,  5.1319e-02,  1.2919e-01, -1.4868e-01, -3.2733e-01,
         -2.8410e-01, -1.3541e-01, -3.6490e-01, -3.8412e-02, -1.1389e-01,
          1.1295e-01,  1.4496e-01,  3.5727e-01,  3.2708e-01, -4.3554e-02,
          2.6467e-01],
        [-2.7384e-01,  1.5290e-01, -3.1302e-01,  2.7191e-01, -3.5851e-02,
          1.4548e-01,  3.2609e-01,  3.3100e-01,  3.7949e-01,  2.4134e-01,
          1.4612e-01, -9.2972e-02,  4.1740e-02,  4.8199e-02,  1.9949e-01,
         -2.2938e-01],
        [-2.8898e-01,  9.7669e-03, -3.7644e-02,  3.7680e-02,  2.3560e-01,
          3.8028e-01,  3.7211e-01,  4.2334e-03,  2.5197e-01,  3.2912e-01,
         -2.3175e-01, -1.5963e-02, -3.1609e-01, -2.8344e-01,  7.0445e-02,
         -2.4853e-01],
        [ 6.4008e-02, -8.5428e-03,  2.4805e-01, -7.0902e-02, -3.6128e-02,
         -3.1426e-01, -3.9042e-01, -3.9211e-01, -3.2434e-01, -2.7114e-01,
          9.6071e-02, -1.1532e-02, -3.0315e-02,  2.3481e-01, -3.3455e-01,
          2.0034e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0615, -0.0629,  0.1169, -0.0738, -0.0541, -0.0289,  0.0864,  0.1367,
        -0.0447, -0.0675,  0.0241,  0.0679,  0.1950,  0.1102, -0.0581,  0.1027,
        -0.1493, -0.0054,  0.0240,  0.0020, -0.0211, -0.1114, -0.0589, -0.0237,
        -0.1572,  0.2601,  0.1048,  0.0244, -0.0839, -0.2287,  0.1612, -0.0285],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2503,  0.3372, -0.2454, -0.2593,  0.3396,  0.3809, -0.2974, -0.3827,
         -0.3316,  0.3834,  0.2639,  0.3912, -0.2832, -0.4225,  0.3208, -0.3102,
         -0.3270,  0.3284, -0.2374, -0.2572,  0.4188,  0.3394, -0.3736, -0.3757,
         -0.3800, -0.3575, -0.3199,  0.3651, -0.3478,  0.3859,  0.2896, -0.2392]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0536,  0.1280,  0.0576,  ...,  0.2198, -0.3267, -0.1137],
        [-0.1225, -0.0302,  0.1171,  ...,  0.1552, -0.3280,  0.0871],
        [ 0.0122, -0.0587,  0.0185,  ...,  0.0283,  0.2301,  0.0345],
        ...,
        [-0.0045,  0.0339,  0.0580,  ...,  0.0847, -0.3159, -0.1180],
        [ 0.0989, -0.2288, -0.0536,  ..., -0.3280,  0.1499,  0.1557],
        [-0.2183,  0.1708,  0.0377,  ...,  0.0978, -0.2750, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0409,  0.0408, -0.0664, -0.1340, -0.0720,  0.0602, -0.1104,  0.0455,
        -0.0384,  0.0799,  0.0171,  0.0117,  0.0301,  0.0790, -0.0527, -0.0185,
         0.0585, -0.1554,  0.0025,  0.0280, -0.0495,  0.0325,  0.1092,  0.0058,
        -0.0938,  0.1046,  0.0473, -0.0936,  0.0537,  0.1392,  0.1671, -0.1229],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0769, -0.1804, -0.1187,  ..., -0.1317, -0.0181,  0.0753],
        [-0.2036, -0.0362,  0.0813,  ..., -0.0647,  0.0053,  0.0499],
        [ 0.1349, -0.0272, -0.1560,  ...,  0.0827, -0.0246,  0.1868],
        ...,
        [ 0.1154,  0.0935,  0.1233,  ...,  0.2533, -0.2228,  0.2452],
        [-0.0041, -0.1477,  0.0353,  ...,  0.0171,  0.2343, -0.1667],
        [-0.0011, -0.1333,  0.1959,  ...,  0.0356,  0.1619, -0.0499]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1025,  0.1468, -0.0577, -0.0830, -0.0007, -0.0432, -0.0572, -0.0442,
         0.1233, -0.1687,  0.1272, -0.1174,  0.1716,  0.0866, -0.1234,  0.1241,
        -0.1387, -0.1721, -0.0585, -0.0036, -0.0021,  0.0856, -0.2096,  0.2124,
        -0.0462, -0.0048,  0.0751, -0.0290, -0.1354, -0.0725,  0.1195,  0.0413],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4537,  0.3734, -0.4575, -0.4479,  0.3252,  0.3076, -0.3710,  0.3429,
          0.3731, -0.3956, -0.3423,  0.3589,  0.3424,  0.3220,  0.3857,  0.3801,
         -0.4494, -0.4625, -0.3164,  0.3620, -0.4066, -0.3848, -0.4588,  0.3057,
          0.4287,  0.4637, -0.4471,  0.4519, -0.3728, -0.4508,  0.4346,  0.4600]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2162], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-6.7126e-03,  3.5941e-01,  2.8913e-01, -3.0524e-01, -2.7458e-01,
         -1.3146e-01, -4.0571e-02, -4.3680e-01, -1.9891e-01, -4.1331e-02,
          1.4865e-01,  1.7849e-01,  4.5806e-02, -6.1358e-02, -1.6357e-01,
          3.5029e-01],
        [-2.4572e-01, -3.4925e-01, -8.8353e-02, -6.8321e-03,  2.9139e-02,
          2.3403e-01,  1.5692e-01,  1.8997e-01,  4.2180e-01,  1.2625e-01,
          7.7657e-02, -2.5711e-01,  1.4883e-03, -5.4678e-02,  4.4642e-01,
         -6.6351e-02],
        [ 7.1385e-02,  2.4637e-01,  3.6003e-01, -1.0462e-01, -1.3194e-01,
         -3.2881e-01, -3.1417e-02, -4.5140e-01,  1.5959e-02, -4.8920e-02,
         -9.1968e-02, -6.4940e-02,  3.9558e-01,  3.2555e-01, -4.2037e-02,
          2.4440e-01],
        [ 2.5845e-01,  7.2921e-02,  6.5167e-02, -6.8107e-02, -1.0215e-01,
         -1.7376e-01, -1.3620e-01, -1.1823e-01, -4.3735e-01, -3.8710e-01,
          2.1709e-02,  3.5186e-01,  2.9232e-01, -1.1051e-01, -2.8360e-01,
          1.3104e-01],
        [-9.7218e-02,  8.1476e-02, -1.6152e-01, -1.9835e-02,  2.3840e-01,
          7.5706e-02,  4.3373e-02,  3.7239e-01,  1.8364e-01,  2.9549e-01,
          9.5452e-02, -1.6585e-01, -6.5463e-02, -2.6423e-01,  3.9374e-01,
         -1.4852e-01],
        [-6.8838e-04,  1.2148e-01, -3.4912e-01,  4.0453e-01,  3.8253e-01,
         -3.9920e-02,  2.5195e-01, -5.1130e-03,  2.7738e-01,  2.0796e-01,
         -1.1254e-01, -8.6972e-02, -2.4703e-01,  1.0996e-01,  4.8476e-01,
         -6.8156e-02],
        [ 3.5854e-01,  1.2633e-01,  3.8915e-01, -1.8131e-01, -1.0371e-01,
         -1.9781e-01, -1.6436e-01, -2.6007e-01, -2.6189e-01, -1.6018e-02,
         -8.6528e-04,  5.6558e-02, -6.6061e-02,  1.8656e-01, -3.5316e-01,
          1.3627e-01],
        [-7.5491e-02,  2.7731e-01,  3.3825e-01, -3.4938e-01, -3.6278e-01,
         -2.8617e-01, -7.1864e-02, -2.7986e-01, -2.0922e-01, -2.0997e-01,
         -7.4876e-02,  2.7455e-02,  2.4417e-01, -9.7821e-02, -1.2603e-01,
          3.4043e-01],
        [ 3.5205e-02,  3.2215e-01,  2.9488e-01, -2.5375e-01, -1.0716e-01,
         -3.3912e-01, -1.6314e-01, -1.3763e-01,  1.5173e-02, -3.1411e-01,
          3.6789e-03,  6.0481e-02, -5.4404e-02,  1.8665e-01, -4.2636e-01,
          8.7820e-02],
        [-2.9320e-01, -1.1567e-01, -9.5576e-02, -2.8050e-03,  1.4299e-01,
          1.5171e-01,  5.1949e-02,  2.8560e-01,  3.0706e-01,  3.6959e-03,
          1.3433e-01, -1.5888e-02, -2.8210e-01, -1.1319e-01,  2.8325e-01,
         -1.9802e-01],
        [-3.5690e-01,  4.1877e-02, -5.7236e-02, -2.6195e-02,  2.8825e-02,
          4.2010e-01,  2.3275e-01,  1.6676e-01,  3.8899e-01,  2.5439e-01,
         -2.1928e-03, -2.7518e-03, -2.1170e-01,  7.1398e-02,  9.9722e-02,
         -3.2539e-01],
        [-1.1775e-01, -1.5600e-01, -1.0823e-02,  9.3003e-02,  2.0749e-01,
          1.0730e-01,  3.5283e-01,  1.7700e-01,  1.7851e-01,  3.4350e-01,
          1.1213e-01,  6.7662e-02, -4.1442e-01, -2.5016e-01,  1.2957e-01,
         -1.9167e-01],
        [ 3.3089e-01,  2.5250e-01,  1.5041e-01, -1.7146e-01, -1.9870e-01,
          3.7842e-02, -8.4005e-02, -3.8792e-01, -3.6723e-01, -9.9550e-02,
         -1.0288e-01,  3.5067e-02, -2.1275e-02,  2.0584e-01, -3.8858e-01,
          2.1707e-02],
        [ 2.0031e-01,  3.4303e-01,  3.5342e-01, -1.3851e-02, -3.4785e-01,
         -1.0802e-02, -3.0063e-02, -9.4338e-02, -2.3386e-01, -1.6130e-01,
         -1.1456e-01,  1.0665e-01,  1.2188e-01,  6.4908e-02, -4.1902e-01,
          2.2695e-01],
        [-3.7130e-01, -3.1011e-01, -5.6745e-02, -3.8799e-02,  4.2295e-01,
          4.0333e-01,  9.4245e-02,  1.5509e-01, -3.2379e-03,  1.8262e-01,
          4.1854e-02, -3.1415e-01, -9.8368e-02, -1.3493e-01,  1.3986e-01,
         -1.5380e-01],
        [-3.0585e-01, -2.3514e-01,  8.1519e-03,  2.6576e-01,  1.3918e-01,
          1.8146e-01,  1.0458e-01,  7.5713e-02,  1.6538e-01,  1.3956e-01,
          5.0220e-02,  1.4163e-01, -1.5222e-01, -3.0360e-01,  5.8560e-01,
         -9.7250e-02],
        [ 3.0095e-01,  2.4363e-01,  1.8435e-01, -3.5031e-01, -3.7681e-01,
         -2.0578e-02, -8.1844e-02, -8.2632e-03, -3.8323e-01, -1.7866e-01,
          1.7309e-01,  2.7991e-01,  3.3949e-01,  2.7529e-01, -1.7113e-01,
         -4.3952e-02],
        [-2.7697e-01,  3.6580e-02, -2.2340e-01,  1.3321e-01,  1.4475e-01,
          2.8149e-01,  2.6312e-01,  2.7890e-01,  1.4261e-01,  2.7402e-01,
         -4.6263e-02, -2.3053e-01, -1.4923e-01, -1.9378e-01,  2.8546e-01,
         -1.5502e-01],
        [ 2.2240e-01,  1.2026e-01,  1.3653e-01, -2.7624e-01, -2.4551e-01,
         -3.6563e-01, -2.7173e-01, -3.3439e-03, -4.3058e-01, -1.0035e-01,
          1.8912e-02, -8.1060e-02,  1.9838e-01,  2.6177e-01, -5.2215e-02,
          1.7779e-01],
        [ 3.6657e-01,  1.4522e-01,  2.5741e-01, -9.3394e-02, -3.7291e-01,
         -2.2179e-01, -3.5176e-01, -8.1581e-03, -7.8150e-02, -2.7169e-01,
          8.4879e-02,  2.4888e-01, -4.2781e-02,  1.2936e-01, -9.4755e-02,
          1.8365e-01],
        [-1.6940e-01,  5.9991e-02, -3.0735e-02, -7.1514e-02,  3.0550e-01,
         -5.1521e-02,  2.9572e-01,  3.8287e-01,  1.9209e-01,  6.7040e-02,
         -8.7328e-02, -2.6551e-01, -2.0091e-01, -2.1454e-01,  4.4869e-01,
         -2.4321e-01],
        [-8.4380e-02, -3.4236e-01, -5.2339e-02,  3.9986e-01,  4.6164e-02,
          1.1802e-01,  2.6176e-01, -8.0033e-03,  7.0397e-02,  2.7835e-01,
          2.3042e-01, -2.7927e-01, -2.1579e-01, -3.9736e-01, -5.5519e-03,
          5.3043e-02],
        [ 3.6322e-01,  2.6494e-02,  4.6343e-02, -1.7177e-01, -4.1827e-02,
         -3.9279e-01, -2.9463e-01, -2.5706e-01, -2.7949e-01, -1.6245e-01,
          1.8515e-01,  2.1789e-01, -6.8218e-02,  3.3089e-01,  3.6664e-02,
          2.1414e-01],
        [ 2.3300e-01,  1.8296e-01,  3.1765e-01, -3.5993e-01, -2.1184e-01,
         -1.4254e-01, -1.5267e-01, -2.6932e-01, -3.5244e-01, -3.0741e-01,
          5.4889e-03,  3.2333e-01,  2.5202e-01,  1.2030e-01, -1.9583e-01,
         -2.3342e-04],
        [ 2.1521e-01, -9.1737e-02,  1.7046e-01, -1.3708e-01,  1.4677e-03,
         -2.5012e-01,  4.3385e-02, -2.1107e-01, -3.9364e-01,  4.6401e-02,
          1.9665e-01,  7.5590e-03,  6.8263e-02,  2.8276e-01, -4.1896e-01,
          3.4502e-01],
        [ 3.5888e-02,  4.4021e-02,  7.4647e-02,  8.0147e-02, -2.6162e-01,
         -2.0347e-01, -1.4123e-02, -3.5985e-01, -1.8403e-01, -3.5192e-01,
         -2.8196e-01,  1.0629e-01,  1.9561e-01,  3.4163e-01, -4.7969e-01,
          7.2229e-02],
        [ 2.0930e-01,  1.7068e-01,  2.8242e-01, -3.4773e-01, -2.0304e-01,
         -8.6608e-02, -3.4506e-01, -3.8368e-02, -3.9670e-01,  9.6079e-03,
          2.8841e-02,  8.1492e-02,  2.2378e-01,  2.8552e-01,  5.1010e-02,
          2.7875e-01],
        [-3.2274e-01, -5.6163e-02,  1.9543e-02,  2.1678e-01,  3.6271e-01,
          1.6188e-02,  3.6047e-01,  2.0876e-01, -2.6952e-02,  1.1012e-01,
          9.8181e-02, -2.7410e-01, -2.3354e-01, -2.2903e-01,  7.9427e-02,
         -1.1315e-01],
        [ 2.8870e-01,  1.6140e-01,  1.1813e-01, -1.2924e-01, -3.1869e-01,
         -2.7095e-01, -1.3128e-01, -3.5411e-01, -2.8830e-02, -1.0189e-01,
          9.1701e-02,  1.3118e-01,  3.4522e-01,  3.2719e-01, -3.4011e-02,
          2.4878e-01],
        [-2.6260e-01,  1.5192e-02, -3.0488e-01,  2.5425e-01, -3.9643e-02,
          1.3981e-01,  3.2465e-01,  3.2595e-01,  3.7354e-01,  2.3290e-01,
          1.5497e-01, -8.2684e-02,  4.2497e-02,  4.5663e-02,  2.0883e-01,
         -2.1672e-01],
        [-2.7502e-01, -1.6848e-01, -2.9129e-02,  1.9203e-02,  2.2901e-01,
          3.7105e-01,  3.6912e-01, -6.5374e-03,  2.4660e-01,  3.1809e-01,
         -2.1623e-01, -4.7333e-03, -3.0972e-01, -2.8213e-01,  5.8514e-02,
         -2.3152e-01],
        [ 4.3931e-02,  1.4149e-01,  2.3443e-01, -4.4515e-02, -2.9950e-02,
         -3.0004e-01, -3.8387e-01, -3.8956e-01, -3.2084e-01, -2.5511e-01,
          8.6329e-02, -2.7402e-02, -4.2307e-02,  2.2804e-01, -3.1940e-01,
          1.7754e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0893, -0.0296,  0.1114, -0.0800, -0.0466, -0.0243,  0.0838,  0.1321,
        -0.0586, -0.0450,  0.0102,  0.0926,  0.1580,  0.0883, -0.0340, -0.0506,
        -0.1765,  0.0024,  0.0092, -0.0143, -0.0130, -0.0858, -0.0718, -0.0388,
        -0.1338,  0.2598,  0.0836,  0.0459, -0.1039, -0.2245,  0.1853, -0.0463],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2536,  0.3382, -0.2470, -0.2659,  0.3637,  0.3976, -0.3020, -0.3814,
         -0.3467,  0.3905,  0.2727,  0.3906, -0.2936, -0.4277,  0.3208,  0.3005,
         -0.3272,  0.3322, -0.2400, -0.2590,  0.4246,  0.3371, -0.3765, -0.3759,
         -0.4095, -0.3668, -0.3205,  0.3671, -0.3506,  0.3889,  0.2929, -0.2437]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0165,  0.1024,  0.0777,  ...,  0.1580, -0.2606, -0.1137],
        [-0.1138, -0.0408,  0.1177,  ...,  0.1307, -0.3105,  0.0871],
        [-0.0026, -0.0393,  0.0316,  ...,  0.0274,  0.2294,  0.0345],
        ...,
        [ 0.0073,  0.0208,  0.0546,  ...,  0.0660, -0.3097, -0.1180],
        [ 0.0933, -0.2198, -0.0538,  ..., -0.3022,  0.1374,  0.1557],
        [-0.1974,  0.1620,  0.0396,  ...,  0.0656, -0.2688, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0467,  0.0413, -0.0708, -0.1353, -0.0728,  0.0518, -0.1112,  0.0502,
        -0.0400,  0.0782,  0.0231,  0.0119,  0.0253,  0.0748, -0.0519, -0.0199,
         0.0576, -0.1578, -0.0613,  0.0361, -0.0552,  0.0304,  0.1056,  0.0063,
        -0.0890,  0.0536,  0.0430, -0.1126,  0.0543,  0.1429,  0.1669, -0.1265],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0650, -0.1799, -0.1084,  ..., -0.1212, -0.0260,  0.0751],
        [-0.2139, -0.0357,  0.1043,  ..., -0.0506, -0.0094,  0.0486],
        [ 0.1393, -0.0303, -0.1646,  ...,  0.0665, -0.0097,  0.1818],
        ...,
        [ 0.1121,  0.0782,  0.1247,  ...,  0.2330, -0.2016,  0.2306],
        [-0.0098, -0.1476,  0.0490,  ...,  0.0372,  0.2179, -0.1664],
        [-0.0009, -0.1226,  0.1944,  ...,  0.0584,  0.1411, -0.0369]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1058,  0.1586, -0.0584, -0.0817, -0.0069, -0.0419, -0.0563, -0.0438,
         0.1330, -0.1765,  0.1143, -0.1297,  0.1907,  0.1022, -0.1275,  0.1320,
        -0.1374, -0.1711,  0.0430, -0.0120, -0.0050,  0.0877, -0.1986,  0.2338,
        -0.0441, -0.0081,  0.0780, -0.0276, -0.1339, -0.0681,  0.1259,  0.0350],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4761,  0.4011, -0.4775, -0.4550,  0.3397,  0.3428, -0.3879,  0.3542,
          0.3767, -0.4205, -0.3680,  0.3648,  0.3613,  0.3503,  0.3960,  0.4069,
         -0.4623, -0.4748,  0.3252,  0.3727, -0.4230, -0.4029, -0.4712,  0.3199,
          0.4471,  0.4749, -0.4572,  0.4660, -0.3876, -0.4618,  0.4519,  0.4675]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2269], device='cuda:0', requires_grad=True)

