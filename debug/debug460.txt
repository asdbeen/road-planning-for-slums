Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 8.0745e-03,  3.8828e-01,  3.0098e-01, -3.0172e-01, -1.9403e-01,
         -1.5143e-01, -1.0554e-01, -4.1538e-01, -3.4038e-01, -7.7672e-02,
         -1.4727e-02,  2.1856e-01, -3.5005e-01, -8.0342e-02, -7.2422e-02,
          3.9435e-01],
        [-2.5019e-01, -3.7565e-01, -9.0514e-02, -3.6387e-02, -2.6483e-02,
          2.4840e-01,  1.7933e-01,  1.8160e-01,  4.9779e-01,  1.3498e-01,
          2.8388e-01, -2.8049e-01,  3.9406e-01, -1.1128e-02,  3.7169e-01,
         -9.1255e-02],
        [ 1.1077e-01,  2.9363e-01,  3.9026e-01, -1.1483e-01, -1.1816e-01,
         -3.4649e-01, -1.3089e-01, -4.8463e-01, -1.5545e-01, -9.8906e-02,
         -1.5170e-01, -2.4650e-04, -3.6191e-02,  3.4600e-01, -7.0636e-02,
          3.0270e-01],
        [ 2.8712e-01,  1.0451e-01,  8.5771e-02, -5.8165e-02, -6.8653e-02,
         -2.1866e-01, -1.9538e-01, -1.4772e-01, -5.4910e-01, -4.2702e-01,
         -2.0173e-01,  4.1009e-01, -1.1507e-01, -1.3319e-01, -2.4478e-01,
          1.8141e-01],
        [-1.0375e-01,  4.4648e-02, -1.6617e-01, -4.6302e-02,  1.7458e-01,
          9.6446e-02,  7.0006e-02,  3.6071e-01,  2.5883e-01,  3.0794e-01,
          3.3777e-01, -1.9700e-01,  3.6664e-01, -2.2058e-01,  3.3200e-01,
         -1.7859e-01],
        [-3.5979e-02,  6.4136e-02, -3.7515e-01,  4.0037e-01,  3.7698e-01,
          1.4942e-03,  3.2314e-01,  3.5562e-02,  4.0270e-01,  2.4526e-01,
         -7.8079e-02, -1.4771e-01,  1.7835e-01,  1.1966e-01,  4.8842e-01,
         -1.1798e-01],
        [ 3.6788e-01,  2.3541e-01,  3.9702e-01, -1.6095e-01, -5.5353e-02,
         -2.0419e-01, -2.0365e-01, -2.5599e-01, -3.6430e-01, -2.9074e-02,
         -3.0922e-02,  7.9044e-02, -3.8923e-01,  1.8619e-01, -3.3124e-01,
          1.6384e-01],
        [-5.1985e-02,  3.5815e-01,  3.5882e-01, -3.4700e-01, -3.5461e-01,
         -2.9873e-01, -1.2574e-01, -2.9459e-01, -3.1046e-01, -2.3204e-01,
         -8.7364e-02,  6.0401e-02, -7.4412e-02, -1.0536e-01, -1.6200e-01,
          3.7714e-01],
        [ 4.1776e-02,  3.5650e-01,  3.0245e-01, -2.3247e-01, -5.7462e-02,
         -3.4544e-01, -1.8489e-01, -1.1799e-01, -5.8594e-02, -3.2303e-01,
         -2.7768e-01,  7.1879e-02, -4.5115e-01,  1.5623e-01, -3.3369e-01,
          1.1798e-01],
        [-3.1458e-01, -1.6383e-01, -1.1258e-01, -1.4694e-02,  1.0748e-01,
          1.7909e-01,  1.0654e-01,  2.9201e-01,  4.0209e-01,  2.7349e-02,
          3.6167e-01, -5.6164e-02,  1.6407e-01, -9.3035e-02,  2.5163e-01,
         -2.4006e-01],
        [-3.7750e-01,  2.4622e-02, -7.1807e-02, -4.2678e-02, -2.1672e-02,
          4.4979e-01,  2.8762e-01,  1.8180e-01,  4.8770e-01,  2.8390e-01,
          2.1760e-01, -4.6034e-02,  2.3869e-01,  1.1327e-01,  6.1454e-02,
         -3.6764e-01],
        [-1.5382e-01, -2.0788e-01, -4.3398e-02,  9.2551e-02,  2.0169e-01,
          1.4276e-01,  4.2190e-01,  1.9256e-01,  2.8811e-01,  3.7835e-01,
          4.0795e-01,  2.4324e-02, -2.2453e-02, -2.6974e-01,  8.5157e-02,
         -2.5045e-01],
        [ 3.4020e-01,  2.7832e-01,  1.5786e-01, -1.4587e-01, -1.0794e-01,
          2.1145e-02, -1.0997e-01, -3.5802e-01, -4.4107e-01, -1.1674e-01,
         -1.6328e-01,  6.5886e-02, -4.7893e-01,  1.3832e-01, -2.8327e-01,
          5.5730e-02],
        [ 2.1539e-01,  3.9880e-01,  3.6884e-01,  6.2664e-04, -3.1774e-01,
         -2.2375e-02, -6.1065e-02, -9.1896e-02, -3.1300e-01, -1.7615e-01,
         -2.7383e-01,  1.2795e-01, -2.3098e-01,  5.3231e-02, -3.6704e-01,
          2.5983e-01],
        [-3.8334e-01, -3.4680e-01, -6.7144e-02, -5.1315e-02,  3.7652e-01,
          4.0560e-01,  1.3253e-01,  1.4961e-01,  8.1132e-02,  1.9813e-01,
          1.8244e-01, -3.3811e-01,  2.9091e-01, -1.0083e-01,  1.0203e-01,
         -1.8614e-01],
        [-3.6186e-02, -2.1897e-02,  1.9375e-01,  1.1762e-01, -3.8379e-01,
         -6.9437e-02, -2.6688e-01, -4.2259e-01, -4.3556e-01, -1.0519e-01,
         -1.2606e-01,  5.2139e-01, -4.0259e-01, -4.4973e-02, -3.8727e-02,
          1.3284e-01],
        [ 3.3887e-01,  3.3002e-01,  2.1562e-01, -3.5483e-01, -3.8862e-01,
         -5.8172e-02, -1.4553e-01, -4.4974e-02, -4.9612e-01, -2.1592e-01,
          7.6118e-02,  3.2988e-01,  2.5233e-03,  3.0216e-01, -1.9010e-01,
          1.3931e-02],
        [-3.0046e-01, -4.9544e-02, -2.4293e-01,  1.2512e-01,  1.4245e-01,
          3.0683e-01,  3.1521e-01,  3.0615e-01,  2.5073e-01,  2.9886e-01,
         -2.4537e-03, -2.7287e-01,  1.4143e-01, -1.9705e-01,  3.2623e-01,
         -1.9356e-01],
        [ 2.3609e-01,  1.4379e-01,  1.3590e-01, -2.5470e-01, -2.2287e-01,
         -3.7044e-01, -3.5708e-01, -2.3989e-02, -5.9752e-01, -1.2581e-01,
         -1.0223e-01, -3.4638e-02, -1.9519e-01,  2.8002e-01, -9.9183e-02,
          2.1867e-01],
        [ 3.7688e-01,  1.7302e-01,  2.6819e-01, -7.5117e-02, -3.0989e-01,
         -2.2698e-01, -3.8372e-01,  8.8372e-03, -1.5767e-01, -2.8941e-01,
         -1.5913e-01,  2.6256e-01, -4.3350e-01,  9.3279e-02,  5.0928e-03,
          2.2124e-01],
        [-1.9572e-01,  1.1895e-02, -5.3046e-02, -8.2185e-02,  2.9629e-01,
         -1.4423e-02,  3.4106e-01,  4.1394e-01,  3.0133e-01,  9.5276e-02,
          1.1946e-03, -3.1788e-01,  1.6426e-01, -1.9793e-01,  4.3846e-01,
         -2.8236e-01],
        [-9.6203e-02, -4.1412e-01, -6.2282e-02,  3.8938e-01,  1.1075e-03,
          1.2153e-01,  3.0445e-01, -2.2837e-02,  1.4829e-01,  2.9005e-01,
          4.0210e-01, -2.9407e-01,  2.2902e-01, -3.7663e-01, -1.8126e-02,
          1.2257e-02],
        [ 3.7058e-01,  7.0435e-02,  5.2650e-02, -1.5193e-01, -6.3781e-04,
         -3.9813e-01, -3.2059e-01, -2.5090e-01, -3.5503e-01, -1.7060e-01,
          6.5567e-02,  2.3191e-01, -4.1993e-01,  3.0303e-01,  6.2129e-02,
          2.4257e-01],
        [ 2.6067e-01,  2.2438e-01,  3.3937e-01, -3.5437e-01, -2.3700e-01,
         -1.7004e-01, -1.9944e-01, -3.0459e-01, -4.5342e-01, -3.3596e-01,
         -1.2286e-01,  3.6138e-01, -7.9851e-03,  1.1248e-01, -2.1272e-01,
          4.3199e-02],
        [ 2.4043e-01, -5.0100e-02,  1.8243e-01, -1.1296e-01,  2.3660e-02,
         -2.9306e-01, -2.1146e-02, -2.4843e-01, -5.3245e-01,  1.6790e-02,
          5.0905e-02,  6.6487e-02, -4.1663e-01,  2.5913e-01, -3.9204e-01,
          3.8807e-01],
        [ 5.7178e-02,  7.4346e-02,  9.0930e-02,  9.2567e-02, -2.3930e-01,
         -2.2277e-01, -6.1104e-02, -3.8331e-01, -2.8980e-01, -3.7694e-01,
         -3.5641e-01,  1.5561e-01, -1.9914e-01,  3.0361e-01, -4.3963e-01,
          1.0991e-01],
        [ 2.3713e-01,  2.5203e-01,  3.0938e-01, -3.4540e-01, -1.9072e-01,
         -1.0294e-01, -3.9814e-01, -5.0059e-02, -5.0655e-01, -1.8252e-02,
         -5.1160e-02,  1.1312e-01, -1.1715e-01,  2.9963e-01,  5.5913e-02,
          3.2849e-01],
        [-3.3816e-01, -1.0259e-01,  5.1861e-03,  2.0405e-01,  3.2417e-01,
          3.3584e-02,  4.0983e-01,  1.9836e-01,  5.8867e-02,  1.2781e-01,
          3.7638e-01, -2.9851e-01,  1.7693e-01, -2.2090e-01,  3.5107e-02,
         -1.5322e-01],
        [ 3.2470e-01,  1.9298e-01,  1.5090e-01, -1.3385e-01, -3.2032e-01,
         -2.9860e-01, -1.9120e-01, -3.7862e-01, -1.3819e-01, -1.3764e-01,
         -9.9213e-02,  1.7311e-01,  4.6999e-04,  3.2648e-01, -4.4813e-02,
          3.0402e-01],
        [-2.6965e-01, -2.9325e-02, -3.1013e-01,  2.3077e-01, -7.5983e-02,
          1.4642e-01,  3.5361e-01,  3.2574e-01,  4.5473e-01,  2.4115e-01,
          2.1509e-01, -1.0031e-01,  3.5609e-01,  8.3636e-02,  1.6776e-01,
         -2.3882e-01],
        [-3.1167e-01, -2.3262e-01, -6.0971e-02,  2.2023e-02,  2.2122e-01,
          4.0629e-01,  4.3345e-01,  2.1422e-02,  3.6171e-01,  3.5590e-01,
         -9.1180e-02, -5.4067e-02,  6.8112e-02, -2.9441e-01,  7.6130e-02,
         -2.9004e-01],
        [ 4.6142e-02,  2.1326e-01,  2.3211e-01, -1.2358e-02,  1.3377e-02,
         -3.1258e-01, -4.2816e-01, -3.9409e-01, -4.5065e-01, -2.7238e-01,
         -1.8274e-02,  7.3403e-03, -3.8923e-01,  2.4396e-01, -2.8416e-01,
          2.0043e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0816, -0.0244, -0.0438, -0.0241,  0.0010, -0.2294,  0.0859,  0.1060,
        -0.0737, -0.0017,  0.0380,  0.0875,  0.1317,  0.0585,  0.0723,  0.0117,
        -0.0403, -0.0380,  0.0645, -0.0445, -0.1178, -0.0371, -0.0340,  0.0292,
        -0.0381,  0.1367,  0.1330,  0.0572, -0.1174, -0.1838,  0.0391,  0.0270],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2704,  0.3656, -0.2824, -0.3147,  0.3654,  0.4379, -0.3233, -0.4108,
         -0.3630,  0.4140,  0.3230,  0.4312, -0.3237, -0.4405,  0.3278, -0.3691,
         -0.3710,  0.3725, -0.2908, -0.2749,  0.4752,  0.3698, -0.4166, -0.4100,
         -0.3822, -0.3920, -0.3612,  0.3964, -0.3927,  0.4208,  0.3537, -0.2841]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0108,  0.1671,  0.0599,  ...,  0.2072, -0.3318, -0.1137],
        [-0.0561, -0.0701,  0.1186,  ...,  0.1023, -0.3023,  0.0871],
        [-0.1266,  0.2421,  0.0808,  ...,  0.2141, -0.0288,  0.0345],
        ...,
        [ 0.0855, -0.1222, -0.0390,  ..., -0.1671, -0.0063, -0.1180],
        [ 0.0248, -0.1928, -0.0381,  ..., -0.2630,  0.1072,  0.1557],
        [-0.1662,  0.1398,  0.0452,  ...,  0.0755, -0.2689, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0605,  0.0281, -0.0854, -0.1561, -0.0823, -0.0107, -0.1000,  0.0462,
        -0.0366,  0.0581,  0.0343, -0.0111,  0.0215,  0.1032, -0.0410, -0.0213,
         0.0544, -0.1677,  0.0088,  0.0841, -0.0655,  0.0150,  0.1111,  0.0263,
        -0.1080,  0.0986,  0.0449, -0.1079,  0.0517,  0.2094,  0.1699, -0.1263],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0435, -0.1649, -0.1943,  ...,  0.0355, -0.0430,  0.0695],
        [-0.2214, -0.0201, -0.0190,  ...,  0.1421, -0.0238,  0.0528],
        [ 0.1565, -0.0456, -0.0332,  ..., -0.1439, -0.0020,  0.1859],
        ...,
        [ 0.1752,  0.0474,  0.2449,  ...,  0.1161, -0.1720,  0.2477],
        [-0.0118, -0.1515, -0.0372,  ...,  0.2526,  0.2269, -0.1765],
        [-0.0009, -0.1195,  0.1333,  ...,  0.2310,  0.1353, -0.0434]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0999,  0.1504, -0.0478, -0.1090, -0.0971, -0.1812, -0.0749, -0.0169,
         0.1517, -0.1814,  0.1420, -0.1352,  0.2085,  0.1053, -0.0986,  0.1363,
        -0.1288, -0.1882,  0.0840,  0.0141, -0.0232,  0.0702, -0.2053,  0.2284,
        -0.0395, -0.0178,  0.0760, -0.0496, -0.1627, -0.0476,  0.1340,  0.0375],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4445,  0.3693, -0.4123, -0.4404, -0.3036, -0.2930, -0.3512,  0.3279,
          0.3384, -0.3557, -0.3207,  0.3333,  0.3368,  0.2906,  0.3559,  0.3358,
         -0.4362, -0.4375,  0.2918,  0.3435, -0.3990, -0.3458, -0.4508,  0.2849,
          0.4128,  0.4623, -0.4164,  0.4417, -0.3516, -0.4441,  0.4042,  0.4436]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1817], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 2.1947e-02,  2.9192e-01,  3.0898e-01, -3.4055e-01, -8.2949e-02,
         -1.9325e-01, -1.0913e-01, -4.5631e-01, -1.8975e-01, -5.4118e-02,
          3.9415e-02,  2.0955e-01,  9.8980e-02, -7.6789e-02,  4.0483e-01,
          3.1961e-01],
        [-2.9592e-01, -2.8320e-01, -1.2696e-01,  2.0894e-02, -1.0048e-01,
          3.1126e-01,  2.3634e-01,  2.3951e-01,  4.2624e-01,  1.1916e-01,
          2.1076e-01, -3.1518e-01, -4.8326e-02, -3.2149e-02, -9.0600e-02,
         -5.1913e-02],
        [ 9.7369e-02,  1.8442e-01,  3.8027e-01, -1.2349e-01,  8.6530e-02,
         -3.7881e-01, -9.8247e-02, -4.7141e-01,  4.6651e-02, -4.3138e-02,
         -7.8023e-02, -3.2222e-02,  4.2958e-01,  2.7755e-01,  5.0721e-01,
          2.1679e-01],
        [ 2.9752e-01,  8.7366e-03,  9.2388e-02, -8.5484e-02,  4.0608e-02,
         -2.4197e-01, -2.0560e-01, -1.6001e-01, -4.2144e-01, -3.7371e-01,
         -8.9029e-02,  4.0043e-01,  3.2388e-01, -1.5295e-01,  2.1496e-01,
          1.1608e-01],
        [-1.4952e-01,  1.8276e-01, -1.9454e-01,  1.3531e-02,  1.2518e-01,
          1.6479e-01,  1.2736e-01,  4.3399e-01,  1.9950e-01,  2.7925e-01,
          2.1230e-01, -2.4795e-01, -1.1312e-01, -2.2429e-01, -2.0155e-01,
         -1.0168e-01],
        [-4.4464e-02,  2.0475e-01, -3.7804e-01,  4.2732e-01,  2.3121e-01,
          3.6683e-02,  3.1828e-01,  5.5511e-02,  2.9526e-01,  1.9420e-01,
         -1.6650e-01, -1.5679e-01, -3.1079e-01,  1.3227e-01, -5.7781e-02,
         -3.8769e-02],
        [ 3.9955e-01,  1.4317e-01,  4.2080e-01, -1.9687e-01,  7.1895e-02,
         -2.6297e-01, -2.4664e-01, -3.0325e-01, -2.6750e-01,  3.1871e-04,
         -3.2606e-03,  1.0187e-01,  6.5880e-03,  2.0140e-01,  6.0949e-02,
          1.2323e-01],
        [-4.2239e-02,  2.6258e-01,  3.6336e-01, -3.5542e-01, -1.9676e-01,
         -3.3863e-01, -1.3603e-01, -3.0195e-01, -1.9085e-01, -1.8935e-01,
         -5.7648e-02,  5.0567e-02,  2.8779e-01, -1.0844e-01,  2.1896e-01,
          3.3257e-01],
        [ 7.6139e-02,  2.4469e-01,  3.2294e-01, -2.7600e-01, -3.5813e-02,
         -4.0648e-01, -2.2581e-01, -1.8850e-01,  1.1884e-02, -2.9163e-01,
         -1.0084e-01,  1.2663e-01, -2.9994e-02,  1.0919e-01,  1.0608e-01,
          5.9205e-02],
        [-3.3021e-01, -2.7474e-02, -1.1817e-01,  1.3568e-02,  2.3133e-02,
          2.1995e-01,  1.1867e-01,  3.2745e-01,  3.0184e-01, -2.0983e-02,
          2.2444e-01, -7.1592e-02, -3.1327e-01, -5.9194e-02, -2.8662e-01,
         -1.5598e-01],
        [-3.7230e-01,  1.3084e-01, -6.3208e-02, -3.6697e-02, -1.2235e-01,
          4.6295e-01,  2.8075e-01,  1.7655e-01,  3.4556e-01,  2.1759e-01,
          5.5838e-02, -2.1166e-02, -1.9685e-01,  1.6175e-01, -4.6474e-01,
         -2.8656e-01],
        [-1.5656e-01, -8.4253e-02, -3.3725e-02,  1.0199e-01,  1.7658e-01,
          1.6935e-01,  4.3343e-01,  2.3286e-01,  1.9014e-01,  3.1408e-01,
          1.3884e-01,  5.9613e-03, -4.4558e-01, -1.6270e-01, -3.4472e-01,
         -1.5562e-01],
        [ 3.9041e-01,  1.5621e-01,  1.9747e-01, -2.0933e-01,  1.0191e-02,
         -6.0153e-02, -1.7038e-01, -4.1620e-01, -3.6910e-01, -9.8571e-02,
         -1.0488e-01,  9.2268e-02,  2.7206e-02,  1.8437e-01,  2.8189e-01,
         -7.9929e-03],
        [ 2.5754e-01,  3.0238e-01,  3.9988e-01, -4.4651e-02, -2.4047e-01,
         -8.9907e-02, -1.1819e-01, -1.5917e-01, -2.5384e-01, -1.6095e-01,
         -2.0373e-01,  1.7338e-01,  1.8460e-01,  5.8881e-02,  5.1531e-02,
          2.2434e-01],
        [-4.0425e-01, -2.4850e-01, -8.1409e-02, -2.9850e-02,  2.5861e-01,
          4.5903e-01,  1.5563e-01,  1.8129e-01, -2.3105e-02,  1.6166e-01,
          1.1671e-01, -3.4854e-01, -1.2438e-01, -9.7241e-02, -3.5769e-01,
         -1.3514e-01],
        [-4.7373e-02, -2.4625e-01,  1.7199e-01,  5.9313e-02, -2.9713e-01,
         -6.5046e-02, -2.0456e-01, -3.9942e-01, -2.3225e-01,  7.0151e-03,
          4.1106e-02,  5.2784e-01,  2.1572e-01, -7.3958e-02,  5.7042e-01,
         -1.9110e-02],
        [ 3.3520e-01,  2.1183e-01,  2.0517e-01, -3.5899e-01, -2.7428e-01,
         -8.0610e-02, -1.5122e-01, -7.1515e-02, -3.7583e-01, -1.5516e-01,
          1.6399e-01,  3.2904e-01,  3.8575e-01,  2.4750e-01,  1.9088e-01,
         -6.1149e-02],
        [-3.1639e-01,  3.3518e-02, -2.5308e-01,  1.4575e-01,  4.1556e-02,
          3.4262e-01,  3.3927e-01,  3.3215e-01,  1.4406e-01,  2.5831e-01,
         -5.3653e-02, -2.7715e-01, -2.0055e-01, -1.9484e-01, -1.6656e-02,
         -1.4976e-01],
        [ 2.4423e-01,  6.6212e-02,  1.4959e-01, -2.9094e-01, -6.3025e-02,
         -4.1167e-01, -3.3743e-01, -2.9508e-02, -3.9437e-01, -9.2071e-02,
         -2.5249e-02, -4.9734e-02,  2.2814e-01,  2.1868e-01,  4.3890e-01,
          1.5634e-01],
        [ 3.9120e-01,  7.7566e-02,  2.7303e-01, -9.4334e-02, -2.2470e-01,
         -2.7142e-01, -4.0546e-01, -2.7170e-02, -4.5768e-02, -2.4231e-01,
         -5.4926e-02,  2.7975e-01, -3.9735e-02,  7.3557e-02,  4.0356e-01,
          1.6169e-01],
        [-2.2494e-01,  1.3445e-01, -7.0630e-02, -3.3965e-02,  2.1905e-01,
          3.1940e-02,  3.6974e-01,  4.6680e-01,  2.3380e-01,  6.5987e-02,
         -9.3112e-02, -3.6138e-01, -2.6709e-01, -2.1130e-01, -4.9215e-02,
         -2.2515e-01],
        [-9.1413e-02, -2.8055e-01, -5.0526e-02,  3.8841e-01, -9.0310e-02,
          1.5424e-01,  2.8852e-01, -7.6572e-04,  2.7160e-02,  2.2546e-01,
          2.3715e-01, -2.9843e-01, -1.9382e-01, -3.0440e-01, -5.2889e-01,
          9.9588e-02],
        [ 3.7512e-01, -2.0107e-02,  5.1781e-02, -1.5695e-01,  1.1045e-01,
         -4.2394e-01, -3.3267e-01, -2.6060e-01, -2.3477e-01, -1.2162e-01,
          1.3093e-01,  2.2476e-01, -8.2233e-02,  2.8045e-01,  4.3610e-01,
          1.9013e-01],
        [ 2.7100e-01,  1.4958e-01,  3.4261e-01, -3.6762e-01, -1.3415e-01,
         -1.9957e-01, -2.2259e-01, -3.1623e-01, -3.4503e-01, -2.9442e-01,
         -9.1044e-02,  3.5768e-01,  2.8164e-01,  1.1816e-01,  5.5237e-02,
          6.4568e-03],
        [ 2.5509e-01, -2.0162e-01,  1.9186e-01, -1.5638e-01,  1.0801e-01,
         -3.2751e-01, -3.3986e-02, -2.8638e-01, -4.0796e-01,  7.6785e-02,
          1.9804e-01,  7.8677e-02,  1.0987e-01,  2.1427e-01,  1.8395e-01,
          2.8663e-01],
        [ 1.0140e-01, -4.0492e-02,  1.2692e-01,  3.7852e-02, -1.4475e-01,
         -2.9975e-01, -1.0940e-01, -4.4153e-01, -2.2262e-01, -3.5633e-01,
         -2.7750e-01,  1.9505e-01,  2.5607e-01,  3.3535e-01,  8.4112e-02,
          5.6784e-02],
        [ 2.2826e-01,  1.5085e-01,  2.9626e-01, -3.3987e-01, -5.3974e-02,
         -1.2413e-01, -3.9688e-01, -5.0512e-02, -3.6347e-01,  4.2980e-02,
          1.8868e-02,  9.7235e-02,  2.2847e-01,  2.6332e-01,  4.2034e-01,
          2.6425e-01],
        [-3.4617e-01,  1.6201e-02,  7.9756e-03,  2.1660e-01,  2.5843e-01,
          6.6316e-02,  4.1982e-01,  2.3272e-01, -4.3264e-02,  7.4523e-02,
          2.0581e-01, -3.0941e-01, -2.4946e-01, -1.6719e-01, -4.2514e-01,
         -7.2378e-02],
        [ 3.2334e-01,  9.3020e-02,  1.4346e-01, -1.3233e-01, -2.3406e-01,
         -3.2443e-01, -1.9066e-01, -3.9415e-01, -1.7675e-02, -8.3451e-02,
          1.4780e-02,  1.6754e-01,  3.4477e-01,  2.7963e-01,  3.6082e-01,
          2.3791e-01],
        [-2.8780e-01,  4.9954e-02, -3.2296e-01,  2.5306e-01, -1.9053e-01,
          1.8400e-01,  3.7899e-01,  3.4180e-01,  3.4934e-01,  2.0619e-01,
          1.7460e-01, -1.0130e-01,  1.8801e-02,  7.1070e-02, -1.6221e-01,
         -2.0254e-01],
        [-3.0207e-01, -1.2064e-01, -4.6339e-02,  1.9189e-02,  1.1102e-01,
          4.2159e-01,  4.3050e-01,  3.1239e-02,  2.2546e-01,  2.8722e-01,
         -2.0941e-01, -4.2796e-02, -3.2277e-01, -2.2854e-01, -3.6863e-01,
         -2.1084e-01],
        [ 8.8755e-02,  1.4545e-01,  2.6907e-01, -7.8307e-02,  1.2081e-01,
         -3.7015e-01, -4.7544e-01, -4.4379e-01, -3.1628e-01, -2.5921e-01,
          4.7580e-02,  3.5123e-02,  2.8741e-02,  2.3001e-01,  1.2928e-01,
          1.6610e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0763, -0.0834,  0.2127, -0.0013, -0.1235, -0.0785,  0.1034,  0.0889,
         0.0006, -0.0878, -0.0499,  0.0233,  0.1569,  0.1307, -0.0386, -0.0279,
        -0.0968, -0.0060,  0.1457,  0.0401, -0.0387, -0.2083,  0.0102, -0.0301,
         0.0256,  0.2608,  0.1519, -0.0056, -0.0266, -0.1695, -0.0195,  0.0628],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2367,  0.3331, -0.2520, -0.2903,  0.3663,  0.3944, -0.2954, -0.3957,
         -0.3191,  0.3888,  0.2974,  0.4178, -0.2913, -0.4000,  0.3330, -0.3078,
         -0.3261,  0.3606, -0.2518, -0.2665,  0.4456,  0.3879, -0.3997, -0.3961,
         -0.3393, -0.3749, -0.3386,  0.4039, -0.3959,  0.4047,  0.3236, -0.2584]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0097,  0.0020,  0.0248,  ...,  0.2109, -0.3924, -0.1137],
        [-0.0796, -0.1835,  0.0809,  ...,  0.1481, -0.3577,  0.0871],
        [-0.0566,  0.1509,  0.0940,  ...,  0.0059,  0.2735,  0.0345],
        ...,
        [ 0.0435, -0.1503,  0.0112,  ...,  0.0700, -0.3238, -0.1180],
        [ 0.0292, -0.0801,  0.0121,  ..., -0.3106,  0.1555,  0.1557],
        [-0.0866,  0.1558,  0.0138,  ..., -0.1753,  0.1107, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0506,  0.0548, -0.0947, -0.1208, -0.0564,  0.0465, -0.1307,  0.0618,
        -0.0453,  0.0927,  0.0361,  0.0050,  0.0101,  0.0637, -0.0778, -0.0192,
         0.0455, -0.1418, -0.0331, -0.0145, -0.1082,  0.0521,  0.0813, -0.0070,
        -0.0855,  0.0671,  0.0247, -0.0952,  0.0638,  0.1476,  0.1315, -0.0661],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0232, -0.2067, -0.0714,  ..., -0.1568, -0.0034,  0.2739],
        [-0.2537, -0.0534,  0.1107,  ..., -0.0868,  0.0054,  0.2811],
        [ 0.1787, -0.0086, -0.1867,  ...,  0.0980, -0.0369, -0.0790],
        ...,
        [ 0.1658,  0.1212,  0.0724,  ...,  0.2796, -0.2369,  0.0460],
        [-0.0696, -0.1859,  0.0873,  ..., -0.0145,  0.2612,  0.0987],
        [-0.0325, -0.1304,  0.2191,  ...,  0.0353,  0.1521,  0.1408]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0910,  0.1271, -0.0376, -0.0580, -0.0320, -0.0378, -0.0339, -0.0633,
         0.1114, -0.1799,  0.1243, -0.1333,  0.1662, -0.0213, -0.1439,  0.1094,
        -0.1293, -0.1555,  0.0151, -0.0301,  0.0076,  0.1067, -0.1936,  0.2064,
        -0.0665, -0.0276,  0.0884, -0.0333, -0.1135, -0.0617,  0.1156,  0.0035],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.6251,  0.5496, -0.6307, -0.6310,  0.4774,  0.4872, -0.5335,  0.5440,
          0.5405, -0.5663, -0.5560,  0.5153,  0.5371, -0.4790,  0.5592,  0.5084,
         -0.6360, -0.6264,  0.5031,  0.5219, -0.5912, -0.5637, -0.6263,  0.4603,
          0.6015,  0.6261, -0.6019,  0.6706, -0.5367, -0.6179,  0.6048,  0.6169]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.3364], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 2.1936e-02,  2.9147e-01,  3.0868e-01, -3.4040e-01, -8.3315e-02,
         -1.9332e-01, -1.0916e-01, -4.5665e-01, -1.8986e-01, -5.3811e-02,
          3.9572e-02,  2.0978e-01,  9.9374e-02, -7.6982e-02,  4.0520e-01,
          3.1923e-01],
        [-2.9591e-01, -2.8278e-01, -1.2672e-01,  2.0764e-02, -1.0012e-01,
          3.1132e-01,  2.3636e-01,  2.3983e-01,  4.2634e-01,  1.1890e-01,
          2.1059e-01, -3.1539e-01, -4.8696e-02, -3.1949e-02, -9.0904e-02,
         -5.1574e-02],
        [ 9.7362e-02,  1.8399e-01,  3.7999e-01, -1.2334e-01,  8.6205e-02,
         -3.7888e-01, -9.8286e-02, -4.7172e-01,  4.6562e-02, -4.2856e-02,
         -7.7892e-02, -3.2015e-02,  4.2997e-01,  2.7738e-01,  5.0759e-01,
          2.1645e-01],
        [ 2.9750e-01,  8.3089e-03,  9.2117e-02, -8.5341e-02,  4.0253e-02,
         -2.4202e-01, -2.0561e-01, -1.6033e-01, -4.2154e-01, -3.7343e-01,
         -8.8870e-02,  4.0066e-01,  3.2427e-01, -1.5313e-01,  2.1530e-01,
          1.1572e-01],
        [-1.4950e-01,  1.8321e-01, -1.9424e-01,  1.3378e-02,  1.2557e-01,
          1.6485e-01,  1.2736e-01,  4.3434e-01,  1.9960e-01,  2.7895e-01,
          2.1212e-01, -2.4820e-01, -1.1351e-01, -2.2410e-01, -2.0192e-01,
         -1.0129e-01],
        [-4.4447e-02,  2.0514e-01, -3.7781e-01,  4.2720e-01,  2.3155e-01,
          3.6714e-02,  3.1827e-01,  5.5789e-02,  2.9535e-01,  1.9396e-01,
         -1.6666e-01, -1.5701e-01, -3.1114e-01,  1.3242e-01, -5.8069e-02,
         -3.8464e-02],
        [ 3.9955e-01,  1.4276e-01,  4.2057e-01, -1.9674e-01,  7.1560e-02,
         -2.6303e-01, -2.4668e-01, -3.0357e-01, -2.6761e-01,  5.8009e-04,
         -3.1087e-03,  1.0208e-01,  6.9613e-03,  2.0121e-01,  6.1254e-02,
          1.2291e-01],
        [-4.2249e-02,  2.6220e-01,  3.6316e-01, -3.5531e-01, -1.9707e-01,
         -3.3867e-01, -1.3606e-01, -3.0225e-01, -1.9094e-01, -1.8912e-01,
         -5.7513e-02,  5.0762e-02,  2.8815e-01, -1.0861e-01,  2.1922e-01,
          3.3231e-01],
        [ 7.6143e-02,  2.4426e-01,  3.2272e-01, -2.7589e-01, -3.6177e-02,
         -4.0654e-01, -2.2585e-01, -1.8882e-01,  1.1788e-02, -2.9136e-01,
         -1.0070e-01,  1.2684e-01, -2.9596e-02,  1.0898e-01,  1.0642e-01,
          5.8866e-02],
        [-3.3020e-01, -2.7037e-02, -1.1791e-01,  1.3430e-02,  2.3513e-02,
          2.2000e-01,  1.1868e-01,  3.2778e-01,  3.0193e-01, -2.1264e-02,
          2.2426e-01, -7.1824e-02, -3.1365e-01, -5.8997e-02, -2.8695e-01,
         -1.5562e-01],
        [-3.7229e-01,  1.3126e-01, -6.2946e-02, -3.6834e-02, -1.2202e-01,
          4.6301e-01,  2.8078e-01,  1.7686e-01,  3.4565e-01,  2.1732e-01,
          5.5705e-02, -2.1372e-02, -1.9724e-01,  1.6192e-01, -4.6510e-01,
         -2.8622e-01],
        [-1.5657e-01, -8.3823e-02, -3.3485e-02,  1.0187e-01,  1.7694e-01,
          1.6942e-01,  4.3347e-01,  2.3318e-01,  1.9024e-01,  3.1381e-01,
          1.3868e-01,  5.7431e-03, -4.4598e-01, -1.6250e-01, -3.4509e-01,
         -1.5527e-01],
        [ 3.9039e-01,  1.5575e-01,  1.9714e-01, -2.0915e-01,  9.8155e-03,
         -6.0224e-02, -1.7040e-01, -4.1655e-01, -3.6921e-01, -9.8252e-02,
         -1.0471e-01,  9.2511e-02,  2.7592e-02,  1.8418e-01,  2.8226e-01,
         -8.3886e-03],
        [ 2.5753e-01,  3.0198e-01,  3.9969e-01, -4.4541e-02, -2.4083e-01,
         -8.9958e-02, -1.1822e-01, -1.5948e-01, -2.5395e-01, -1.6071e-01,
         -2.0355e-01,  1.7359e-01,  1.8495e-01,  5.8671e-02,  5.1795e-02,
          2.2404e-01],
        [-4.0424e-01, -2.4809e-01, -8.1179e-02, -2.9976e-02,  2.5895e-01,
          4.5908e-01,  1.5566e-01,  1.8160e-01, -2.3018e-02,  1.6140e-01,
          1.1657e-01, -3.4874e-01, -1.2475e-01, -9.7066e-02, -3.5801e-01,
         -1.3482e-01],
        [-4.7372e-02, -2.4677e-01,  1.7156e-01,  5.9458e-02, -2.9746e-01,
         -6.5047e-02, -2.0444e-01, -3.9970e-01, -2.3222e-01,  7.3611e-03,
          4.1021e-02,  5.2805e-01,  2.1616e-01, -7.4015e-02,  5.7098e-01,
         -1.9536e-02],
        [ 3.3518e-01,  2.1142e-01,  2.0493e-01, -3.5886e-01, -2.7463e-01,
         -8.0657e-02, -1.5122e-01, -7.1831e-02, -3.7593e-01, -1.5490e-01,
          1.6415e-01,  3.2927e-01,  3.8613e-01,  2.4732e-01,  1.9119e-01,
         -6.1466e-02],
        [-3.1638e-01,  3.3899e-02, -2.5287e-01,  1.4564e-01,  4.1870e-02,
          3.4267e-01,  3.3929e-01,  3.3244e-01,  1.4414e-01,  2.5808e-01,
         -5.3787e-02, -2.7735e-01, -2.0091e-01, -1.9468e-01, -1.6951e-02,
         -1.4948e-01],
        [ 2.4423e-01,  6.5792e-02,  1.4931e-01, -2.9080e-01, -6.3340e-02,
         -4.1175e-01, -3.3747e-01, -2.9812e-02, -3.9446e-01, -9.1792e-02,
         -2.5123e-02, -4.9529e-02,  2.2854e-01,  2.1852e-01,  4.3928e-01,
          1.5600e-01],
        [ 3.9120e-01,  7.7147e-02,  2.7277e-01, -9.4196e-02, -2.2502e-01,
         -2.7149e-01, -4.0551e-01, -2.7483e-02, -4.5863e-02, -2.4203e-01,
         -5.4796e-02,  2.7996e-01, -3.9335e-02,  7.3384e-02,  4.0394e-01,
          1.6135e-01],
        [-2.2493e-01,  1.3483e-01, -7.0401e-02, -3.4069e-02,  2.1936e-01,
          3.1961e-02,  3.6971e-01,  4.6706e-01,  2.3385e-01,  6.5757e-02,
         -9.3204e-02, -3.6157e-01, -2.6744e-01, -2.1118e-01, -4.9536e-02,
         -2.2486e-01],
        [-9.1415e-02, -2.8012e-01, -5.0308e-02,  3.8829e-01, -8.9952e-02,
          1.5431e-01,  2.8856e-01, -4.4045e-04,  2.7256e-02,  2.2520e-01,
          2.3701e-01, -2.9865e-01, -1.9421e-01, -3.0420e-01, -5.2923e-01,
          9.9918e-02],
        [ 3.7512e-01, -2.0491e-02,  5.1579e-02, -1.5684e-01,  1.1014e-01,
         -4.2399e-01, -3.3271e-01, -2.6089e-01, -2.3485e-01, -1.2139e-01,
          1.3105e-01,  2.2495e-01, -8.1863e-02,  2.8030e-01,  4.3642e-01,
          1.8985e-01],
        [ 2.7099e-01,  1.4921e-01,  3.4241e-01, -3.6751e-01, -1.3445e-01,
         -1.9962e-01, -2.2260e-01, -3.1651e-01, -3.4512e-01, -2.9419e-01,
         -9.0919e-02,  3.5787e-01,  2.8200e-01,  1.1801e-01,  5.5526e-02,
          6.1871e-03],
        [ 2.5507e-01, -2.0207e-01,  1.9157e-01, -1.5623e-01,  1.0761e-01,
         -3.2757e-01, -3.3990e-02, -2.8673e-01, -4.0807e-01,  7.7088e-02,
          1.9823e-01,  7.8931e-02,  1.1026e-01,  2.1406e-01,  1.8429e-01,
          2.8624e-01],
        [ 1.0139e-01, -4.0898e-02,  1.2667e-01,  3.7980e-02, -1.4510e-01,
         -2.9979e-01, -1.0940e-01, -4.4184e-01, -2.2271e-01, -3.5607e-01,
         -2.7734e-01,  1.9527e-01,  2.5642e-01,  3.3518e-01,  8.4424e-02,
          5.6451e-02],
        [ 2.2826e-01,  1.5046e-01,  2.9605e-01, -3.3975e-01, -5.4279e-02,
         -1.2419e-01, -3.9692e-01, -5.0798e-02, -3.6356e-01,  4.3220e-02,
          1.8993e-02,  9.7427e-02,  2.2884e-01,  2.6316e-01,  4.2066e-01,
          2.6396e-01],
        [-3.4616e-01,  1.6628e-02,  8.2296e-03,  2.1647e-01,  2.5879e-01,
          6.6370e-02,  4.1984e-01,  2.3304e-01, -4.3175e-02,  7.4250e-02,
          2.0566e-01, -3.0963e-01, -2.4985e-01, -1.6701e-01, -4.2549e-01,
         -7.2026e-02],
        [ 3.2333e-01,  9.2629e-02,  1.4325e-01, -1.3221e-01, -2.3439e-01,
         -3.2448e-01, -1.9068e-01, -3.9444e-01, -1.7755e-02, -8.3213e-02,
          1.4912e-02,  1.6774e-01,  3.4515e-01,  2.7946e-01,  3.6114e-01,
          2.3761e-01],
        [-2.8779e-01,  5.0327e-02, -3.2277e-01,  2.5294e-01, -1.9022e-01,
          1.8405e-01,  3.7902e-01,  3.4208e-01,  3.4942e-01,  2.0596e-01,
          1.7446e-01, -1.0148e-01,  1.8450e-02,  7.1232e-02, -1.6249e-01,
         -2.0227e-01],
        [-3.0207e-01, -1.2024e-01, -4.6111e-02,  1.9066e-02,  1.1134e-01,
          4.2165e-01,  4.3054e-01,  3.1537e-02,  2.2555e-01,  2.8697e-01,
         -2.0954e-01, -4.2998e-02, -3.2316e-01, -2.2838e-01, -3.6898e-01,
         -2.1052e-01],
        [ 8.8749e-02,  1.4503e-01,  2.6881e-01, -7.8165e-02,  1.2047e-01,
         -3.7022e-01, -4.7549e-01, -4.4411e-01, -3.1639e-01, -2.5893e-01,
          4.7730e-02,  3.5337e-02,  2.9132e-02,  2.2982e-01,  1.2964e-01,
          1.6575e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0764, -0.0834,  0.2127, -0.0014, -0.1233, -0.0784,  0.1034,  0.0888,
         0.0005, -0.0877, -0.0498,  0.0233,  0.1568,  0.1307, -0.0386, -0.0286,
        -0.0968, -0.0060,  0.1456,  0.0400, -0.0383, -0.2083,  0.0102, -0.0302,
         0.0255,  0.2607,  0.1519, -0.0055, -0.0267, -0.1695, -0.0194,  0.0627],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2366,  0.3331, -0.2520, -0.2903,  0.3664,  0.3945, -0.2953, -0.3956,
         -0.3190,  0.3889,  0.2975,  0.4179, -0.2913, -0.3999,  0.3331, -0.3082,
         -0.3261,  0.3606, -0.2518, -0.2665,  0.4458,  0.3879, -0.3998, -0.3961,
         -0.3394, -0.3750, -0.3386,  0.4040, -0.3960,  0.4046,  0.3237, -0.2583]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0097,  0.0020,  0.0248,  ...,  0.2109, -0.3924, -0.1137],
        [-0.0796, -0.1835,  0.0809,  ...,  0.1481, -0.3577,  0.0871],
        [-0.0566,  0.1509,  0.0940,  ...,  0.0059,  0.2735,  0.0345],
        ...,
        [ 0.0435, -0.1503,  0.0112,  ...,  0.0700, -0.3238, -0.1180],
        [ 0.0292, -0.0801,  0.0121,  ..., -0.3106,  0.1555,  0.1557],
        [-0.0866,  0.1558,  0.0138,  ..., -0.1753,  0.1107, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0506,  0.0548, -0.0947, -0.1208, -0.0564,  0.0465, -0.1307,  0.0618,
        -0.0453,  0.0927,  0.0361,  0.0050,  0.0101,  0.0637, -0.0778, -0.0192,
         0.0455, -0.1418, -0.0331, -0.0145, -0.1082,  0.0521,  0.0813, -0.0070,
        -0.0855,  0.0671,  0.0247, -0.0952,  0.0638,  0.1476,  0.1315, -0.0661],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0232, -0.2067, -0.0714,  ..., -0.1568, -0.0034,  0.2739],
        [-0.2537, -0.0534,  0.1107,  ..., -0.0868,  0.0054,  0.2811],
        [ 0.1787, -0.0086, -0.1867,  ...,  0.0980, -0.0369, -0.0790],
        ...,
        [ 0.1658,  0.1212,  0.0724,  ...,  0.2796, -0.2369,  0.0460],
        [-0.0696, -0.1859,  0.0873,  ..., -0.0145,  0.2612,  0.0987],
        [-0.0325, -0.1304,  0.2191,  ...,  0.0353,  0.1521,  0.1408]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0910,  0.1271, -0.0376, -0.0580, -0.0320, -0.0378, -0.0339, -0.0633,
         0.1114, -0.1799,  0.1243, -0.1333,  0.1662, -0.0213, -0.1439,  0.1094,
        -0.1293, -0.1555,  0.0151, -0.0301,  0.0076,  0.1067, -0.1936,  0.2064,
        -0.0665, -0.0276,  0.0884, -0.0333, -0.1135, -0.0617,  0.1156,  0.0035],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.6251,  0.5496, -0.6307, -0.6310,  0.4774,  0.4872, -0.5335,  0.5440,
          0.5405, -0.5663, -0.5560,  0.5153,  0.5371, -0.4790,  0.5592,  0.5084,
         -0.6360, -0.6264,  0.5031,  0.5219, -0.5912, -0.5637, -0.6263,  0.4603,
          0.6015,  0.6261, -0.6019,  0.6706, -0.5367, -0.6179,  0.6048,  0.6169]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.3364], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5778e-02,  2.9304e-01,  2.8472e-01, -2.6207e-01, -4.2315e-01,
         -2.1317e-01, -9.0459e-02, -5.3815e-01, -2.9215e-01, -5.6936e-02,
          8.8713e-03,  2.7656e-01,  1.3359e-01, -7.2428e-02,  1.3436e-01,
          3.2153e-01],
        [-2.3905e-01, -2.8138e-01, -9.1615e-02, -5.1374e-02,  1.5665e-01,
          2.9534e-01,  1.9941e-01,  2.7610e-01,  4.8701e-01,  1.3251e-01,
          2.5482e-01, -3.3655e-01, -4.6774e-02, -4.5836e-02,  1.6342e-01,
         -5.0289e-02],
        [ 5.3720e-02,  1.8256e-01,  3.5557e-01, -5.8954e-02, -2.7408e-01,
         -3.8414e-01, -7.4590e-02, -5.4724e-01, -5.7728e-02, -5.1865e-02,
         -1.0289e-01,  1.2428e-02,  4.5177e-01,  3.1894e-01,  2.5866e-01,
          2.1966e-01],
        [ 2.5381e-01,  1.3436e-02,  6.8382e-02, -2.4295e-02, -2.4356e-01,
         -2.4283e-01, -1.8432e-01, -2.2329e-01, -5.1840e-01, -3.9822e-01,
         -8.4662e-02,  4.4501e-01,  3.2698e-01, -1.1503e-01, -2.6814e-02,
          1.2077e-01],
        [-7.4150e-02,  1.4925e-01, -1.5172e-01, -7.8639e-02,  3.5802e-01,
          1.3415e-01,  7.6770e-02,  4.5231e-01,  2.3889e-01,  2.8978e-01,
          2.8496e-01, -2.3949e-01, -1.0073e-01, -2.3618e-01,  8.9210e-02,
         -1.1792e-01],
        [ 5.4727e-03,  1.8291e-01, -3.5031e-01,  3.5978e-01,  5.3212e-01,
          2.6382e-02,  3.0132e-01,  9.4297e-02,  3.4945e-01,  2.1374e-01,
         -1.2244e-01, -1.6494e-01, -3.0090e-01,  1.2279e-01,  2.1501e-01,
         -5.0331e-02],
        [ 3.6057e-01,  6.1706e-02,  3.9964e-01, -1.4618e-01, -2.3466e-01,
         -2.5995e-01, -2.1445e-01, -3.5562e-01, -3.5031e-01, -2.6663e-02,
         -2.6894e-02,  1.3890e-01, -1.6658e-02,  2.3472e-01, -8.8880e-02,
          1.2919e-01],
        [-7.4977e-02,  2.1675e-01,  3.4496e-01, -3.1679e-01, -4.8651e-01,
         -3.3128e-01, -1.0904e-01, -3.5403e-01, -2.6770e-01, -2.1142e-01,
         -7.3793e-02,  8.6278e-02,  2.7981e-01, -8.3600e-02,  9.6228e-02,
          3.3355e-01],
        [ 3.4761e-02,  2.5628e-01,  3.0521e-01, -2.0997e-01, -2.2723e-01,
         -4.0516e-01, -2.1241e-01, -2.2266e-01, -5.4853e-02, -3.2738e-01,
         -2.3710e-01,  1.4049e-01, -9.2891e-04,  1.8525e-01, -1.6035e-01,
          7.6035e-02],
        [-2.7399e-01, -4.5095e-02, -8.7003e-02, -5.9904e-02,  2.6923e-01,
          2.1126e-01,  9.1837e-02,  3.7168e-01,  3.6994e-01,  7.9551e-05,
          2.9779e-01, -8.8737e-02, -3.2977e-01, -8.8586e-02, -7.7371e-03,
         -1.6771e-01],
        [-3.4148e-01,  1.0684e-01, -5.2183e-02, -7.9463e-02,  1.5317e-01,
          4.7911e-01,  2.6948e-01,  2.5407e-01,  4.5053e-01,  2.5552e-01,
          9.8810e-02, -7.7686e-02, -2.0941e-01,  1.0826e-01, -1.8072e-01,
         -3.0286e-01],
        [-1.1501e-01, -1.0793e-01, -1.6954e-02,  4.8691e-02,  3.4274e-01,
          1.7091e-01,  4.0605e-01,  2.7197e-01,  2.5682e-01,  3.5442e-01,
          2.1499e-01, -1.5170e-02, -4.3053e-01, -2.4846e-01, -1.0995e-01,
         -1.7879e-01],
        [ 3.1185e-01,  1.7728e-01,  1.4766e-01, -1.1648e-01, -3.5419e-01,
         -4.7801e-02, -1.3468e-01, -5.0457e-01, -4.4634e-01, -1.0712e-01,
         -1.2542e-01,  1.3712e-01,  1.7587e-02,  1.7557e-01, -6.0607e-02,
         -7.4594e-03],
        [ 2.0282e-01,  2.8320e-01,  3.6460e-01,  2.1648e-02, -4.7437e-01,
         -6.7673e-02, -7.6508e-02, -1.7759e-01, -3.0030e-01, -1.7172e-01,
         -2.4434e-01,  1.7945e-01,  1.7008e-01,  7.5363e-02, -1.5667e-01,
          2.2034e-01],
        [-3.6054e-01, -2.4101e-01, -5.5614e-02, -8.5902e-02,  5.4289e-01,
          4.5222e-01,  1.2806e-01,  2.3276e-01,  5.3929e-02,  1.8094e-01,
          1.5262e-01, -3.8115e-01, -1.2930e-01, -1.2169e-01, -1.4959e-01,
         -1.3590e-01],
        [-1.1198e-01, -1.5072e-01,  1.6298e-01,  1.5754e-01, -5.6242e-01,
         -9.2996e-02, -2.3686e-01, -4.9731e-01, -3.2995e-01, -4.8621e-02,
         -8.5794e-02,  5.0695e-01,  2.3443e-01, -2.4242e-02,  2.4958e-01,
          1.7019e-02],
        [ 3.0566e-01,  2.1743e-01,  1.9322e-01, -3.1645e-01, -5.3413e-01,
         -8.6328e-02, -1.3586e-01, -1.1453e-01, -4.5990e-01, -1.9309e-01,
          1.3201e-01,  3.6575e-01,  4.0980e-01,  3.0036e-01,  2.2685e-02,
         -4.6243e-02],
        [-2.8225e-01,  4.2732e-02, -2.3455e-01,  1.0446e-01,  2.9242e-01,
          3.3483e-01,  3.0892e-01,  3.7049e-01,  2.1854e-01,  2.8272e-01,
         -3.2467e-02, -3.0596e-01, -1.9397e-01, -2.3360e-01,  1.1665e-01,
         -1.5474e-01],
        [ 1.8817e-01,  4.8788e-02,  1.1164e-01, -2.1343e-01, -4.1598e-01,
         -4.1167e-01, -3.0830e-01, -1.0347e-01, -5.0547e-01, -8.7136e-02,
         -6.8789e-02, -8.3487e-03,  2.7615e-01,  2.6617e-01,  2.1633e-01,
          1.3863e-01],
        [ 3.5802e-01,  7.6379e-02,  2.5955e-01, -4.5253e-02, -4.9976e-01,
         -2.8025e-01, -3.9012e-01, -9.5867e-02, -1.4257e-01, -2.7675e-01,
         -1.1444e-01,  3.2724e-01, -1.4204e-02,  1.1925e-01,  2.0625e-01,
          1.7057e-01],
        [-1.6462e-01,  1.0943e-01, -3.4764e-02, -1.0997e-01,  4.4063e-01,
          6.2924e-05,  3.3204e-01,  4.6409e-01,  2.5070e-01,  6.9228e-02,
         -4.3003e-02, -3.3305e-01, -2.3157e-01, -2.0844e-01,  2.0568e-01,
         -2.3070e-01],
        [-6.6927e-02, -2.7975e-01, -4.4860e-02,  3.4215e-01,  1.6286e-01,
          1.7536e-01,  3.0176e-01,  7.0205e-02,  1.2498e-01,  2.7509e-01,
          3.5924e-01, -3.4159e-01, -2.5891e-01, -3.8102e-01, -2.7172e-01,
          7.6432e-02],
        [ 3.5743e-01, -1.6827e-02,  4.8453e-02, -1.2989e-01, -1.6007e-01,
         -4.3918e-01, -3.2849e-01, -3.2785e-01, -3.3453e-01, -1.6196e-01,
          9.5092e-02,  2.7748e-01, -4.7393e-02,  3.3394e-01,  2.7938e-01,
          2.0460e-01],
        [ 2.4550e-01,  1.5622e-01,  3.3153e-01, -3.3776e-01, -3.7521e-01,
         -1.9628e-01, -2.0028e-01, -3.6743e-01, -4.2883e-01, -3.2207e-01,
         -6.7201e-02,  3.9783e-01,  2.7546e-01,  1.5384e-01, -6.8211e-02,
          9.0365e-03],
        [ 2.0352e-01, -1.7035e-01,  1.6766e-01, -8.0162e-02, -1.3795e-01,
         -3.2504e-01, -1.0241e-02, -3.1581e-01, -4.7999e-01,  4.1510e-02,
          1.0293e-01,  9.5622e-02,  1.3483e-01,  2.6179e-01, -1.3299e-01,
          3.1688e-01],
        [ 2.2960e-02, -2.9601e-02,  7.2982e-02,  1.2606e-01, -3.9452e-01,
         -2.4990e-01, -4.3959e-02, -4.3723e-01, -2.3656e-01, -3.4783e-01,
         -3.2331e-01,  1.7039e-01,  2.1332e-01,  3.1926e-01, -1.8103e-01,
          5.2617e-02],
        [ 2.0892e-01,  1.4331e-01,  2.9157e-01, -3.1270e-01, -3.3382e-01,
         -1.3760e-01, -3.8820e-01, -1.1869e-01, -4.6352e-01,  4.3368e-03,
         -8.9632e-03,  1.4922e-01,  2.5794e-01,  3.0832e-01,  2.9036e-01,
          2.7603e-01],
        [-3.0251e-01,  4.2512e-03,  2.9307e-02,  1.5998e-01,  4.8785e-01,
          7.0696e-02,  3.9976e-01,  2.9389e-01,  3.6744e-02,  1.0506e-01,
          2.5827e-01, -3.4581e-01, -2.6576e-01, -2.0941e-01, -1.9836e-01,
         -8.5104e-02],
        [ 2.9340e-01,  1.1651e-01,  1.2974e-01, -9.5616e-02, -4.6236e-01,
         -3.2894e-01, -1.7357e-01, -4.4669e-01, -1.0040e-01, -1.1349e-01,
          2.8881e-02,  2.0948e-01,  3.3196e-01,  3.2610e-01,  1.5981e-01,
          2.4715e-01],
        [-2.6168e-01,  7.1559e-02, -3.1082e-01,  2.2006e-01,  7.7512e-02,
          1.8352e-01,  3.6075e-01,  3.9740e-01,  4.3040e-01,  2.3405e-01,
          2.0938e-01, -1.4014e-01,  1.3111e-02,  3.6945e-02, -3.4436e-02,
         -2.1016e-01],
        [-2.7348e-01, -1.3005e-01, -3.5698e-02, -2.0221e-02,  3.6781e-01,
          4.3126e-01,  4.1304e-01,  8.5119e-02,  3.1659e-01,  3.2602e-01,
         -1.6312e-01, -8.4207e-02, -3.4985e-01, -2.8737e-01, -1.8216e-01,
         -2.2499e-01],
        [ 3.9132e-02,  1.1701e-01,  2.3951e-01, -3.1146e-03, -1.7291e-01,
         -3.6516e-01, -4.3584e-01, -4.9717e-01, -4.0738e-01, -2.6705e-01,
          1.3765e-03,  6.7319e-02,  3.1694e-02,  2.7825e-01, -6.6801e-02,
          1.6375e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0342, -0.0266,  0.1336, -0.0280, -0.0943, -0.1336,  0.0848,  0.1008,
        -0.0127, -0.0950, -0.0330,  0.0452,  0.1788,  0.0957,  0.0008, -0.0223,
        -0.0465, -0.0020,  0.1167,  0.0187, -0.0733, -0.1675, -0.0115, -0.0131,
         0.0350,  0.1906,  0.1382, -0.0125, -0.0574, -0.1607,  0.0182, -0.0436],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2760,  0.3600, -0.2650, -0.3018,  0.3817,  0.4217, -0.3092, -0.4147,
         -0.3402,  0.4064,  0.3069,  0.4146, -0.3187, -0.4303,  0.3439, -0.4101,
         -0.3551,  0.3582, -0.2684, -0.2806,  0.4585,  0.3489, -0.4036, -0.4017,
         -0.3884, -0.3899, -0.3407,  0.4032, -0.3936,  0.4086,  0.3234, -0.2679]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0063, -0.0058,  0.0457,  ...,  0.2369, -0.3937, -0.1137],
        [-0.0799, -0.1897,  0.0908,  ...,  0.1474, -0.3785,  0.0871],
        [-0.0462,  0.1743,  0.0700,  ..., -0.0059,  0.3091,  0.0345],
        ...,
        [ 0.0324, -0.1885,  0.0448,  ...,  0.0672, -0.3358, -0.1180],
        [ 0.0428, -0.0531, -0.0205,  ..., -0.3067,  0.1843,  0.1557],
        [-0.2007,  0.0496,  0.0066,  ...,  0.0404, -0.2874, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0559,  0.0551, -0.0861, -0.1213, -0.0597,  0.0540, -0.1261,  0.0588,
        -0.0478,  0.0817,  0.0294,  0.0115,  0.0275,  0.0750, -0.0763, -0.0179,
         0.0464, -0.1514, -0.0315, -0.0250, -0.0737,  0.0515,  0.0901, -0.0050,
        -0.0883,  0.0882,  0.0325, -0.0877,  0.0480,  0.1374,  0.1474, -0.1087],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0275, -0.1908, -0.0842,  ..., -0.1082, -0.0251,  0.0746],
        [-0.2549, -0.0454,  0.1120,  ..., -0.0401, -0.0033,  0.0624],
        [ 0.1777, -0.0260, -0.1758,  ...,  0.0472, -0.0120,  0.1668],
        ...,
        [ 0.1546,  0.0958,  0.0954,  ...,  0.2182, -0.2006,  0.2377],
        [-0.0741, -0.1702,  0.0801,  ...,  0.0385,  0.2415, -0.1677],
        [-0.0377, -0.1238,  0.2090,  ...,  0.0806,  0.1350, -0.0265]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0870,  0.1251, -0.0282, -0.0609, -0.0319, -0.0633, -0.0296, -0.0599,
         0.0981, -0.1412,  0.1371, -0.1254,  0.1546,  0.0606, -0.1343,  0.0922,
        -0.1218, -0.1505,  0.0047, -0.0128,  0.0038,  0.1071, -0.1886,  0.1779,
        -0.0623, -0.0295,  0.0880, -0.0408, -0.1125, -0.0568,  0.1016,  0.0055],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.6776,  0.6016, -0.6772, -0.6787,  0.5450,  0.5368, -0.5917,  0.5852,
          0.6090, -0.6177, -0.5697,  0.5694,  0.5674,  0.5799,  0.6065,  0.5651,
         -0.6777, -0.6828,  0.5447,  0.5722, -0.6336, -0.6109, -0.6797,  0.5382,
          0.6633,  0.6831, -0.6611,  0.7108, -0.5903, -0.6735,  0.6587,  0.6764]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.3838], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 4.5989e-04, -5.1420e-02,  2.5031e-01, -2.8778e-01, -3.5011e-01,
         -1.0108e-01, -4.5656e-02, -4.8033e-01, -2.6543e-01, -8.4837e-03,
          1.6805e-01,  1.6080e-01, -9.7696e-03, -1.0645e-01, -2.1920e-01,
          3.0208e-01],
        [-2.6625e-01,  2.3103e-02, -8.0208e-02, -7.4148e-03,  8.6747e-02,
          2.2173e-01,  1.5660e-01,  2.2805e-01,  4.9026e-01,  1.1125e-01,
          9.5373e-02, -2.6195e-01,  3.0585e-02, -2.6367e-02,  4.9930e-01,
         -4.3575e-02],
        [ 6.9935e-02, -1.0507e-01,  3.3980e-01, -9.9146e-02, -1.9516e-01,
         -3.1785e-01, -5.2208e-02, -4.7810e-01,  1.2741e-03, -4.1635e-02,
         -5.4676e-02, -8.0973e-02,  3.7555e-01,  3.0835e-01, -9.4492e-02,
          2.3312e-01],
        [ 2.7676e-01, -1.3261e-01,  4.6003e-02, -5.5317e-02, -1.4783e-01,
         -1.4622e-01, -1.1651e-01, -1.5489e-01, -5.0988e-01, -3.5580e-01,
          3.1722e-03,  3.4684e-01,  2.4228e-01, -1.5799e-01, -3.2686e-01,
          9.5165e-02],
        [-8.1035e-02,  4.5823e-01, -1.2310e-01, -4.4002e-02,  2.6769e-01,
          4.2379e-02,  2.3282e-02,  3.7242e-01,  1.9278e-01,  2.6156e-01,
          5.1277e-02, -1.2822e-01,  6.8229e-03, -2.0398e-01,  3.9872e-01,
         -1.0838e-01],
        [ 1.1822e-02,  4.0640e-01, -3.2051e-01,  3.8486e-01,  4.0823e-01,
         -7.3798e-02,  2.4342e-01,  2.9226e-03,  2.8685e-01,  1.8425e-01,
         -1.2352e-01, -5.9301e-02, -1.8629e-01,  1.4310e-01,  4.6811e-01,
         -4.2254e-02],
        [ 3.6372e-01, -8.4385e-02,  3.6922e-01, -1.6810e-01, -1.4070e-01,
         -1.7119e-01, -1.5203e-01, -2.8328e-01, -3.0996e-01,  8.9087e-03,
         -7.3871e-03,  4.1087e-02, -1.1125e-01,  1.4392e-01, -3.7882e-01,
          1.0766e-01],
        [-7.6949e-02,  6.4891e-02,  3.2359e-01, -3.4312e-01, -4.1163e-01,
         -2.7183e-01, -7.8811e-02, -3.0237e-01, -2.2823e-01, -1.9877e-01,
         -4.0122e-02,  1.3731e-02,  2.2423e-01, -1.1570e-01, -1.5808e-01,
          3.2937e-01],
        [ 4.5578e-02, -9.9074e-02,  2.8145e-01, -2.5076e-01, -1.7640e-01,
         -3.3496e-01, -1.7406e-01, -1.8199e-01, -2.8203e-02, -3.0310e-01,
          3.0533e-02,  5.9823e-02, -6.6460e-02,  1.6563e-01, -4.8453e-01,
          7.4553e-02],
        [-3.0008e-01,  2.7738e-01, -7.9329e-02, -8.6333e-03,  1.8915e-01,
          1.3492e-01,  4.9143e-02,  3.0689e-01,  3.4796e-01, -1.3206e-02,
          1.2013e-01, -8.5515e-03, -2.4203e-01, -8.2007e-02,  3.1671e-01,
         -1.7372e-01],
        [-3.5928e-01,  3.1254e-01, -3.0962e-02, -4.4637e-02,  7.2157e-02,
          3.9487e-01,  2.2242e-01,  1.9140e-01,  4.2896e-01,  2.2609e-01,
          6.5268e-03,  1.4482e-02, -1.7004e-01,  1.1723e-01,  1.2810e-01,
         -2.9312e-01],
        [-1.2124e-01,  1.2361e-01,  8.8976e-03,  8.4758e-02,  2.6019e-01,
          1.0198e-01,  3.4944e-01,  2.0517e-01,  2.1016e-01,  3.2382e-01,
          6.7077e-02,  7.7391e-02, -4.0192e-01, -2.1035e-01,  1.7313e-01,
         -1.7213e-01],
        [ 3.2957e-01, -1.2664e-01,  1.1121e-01, -1.4688e-01, -2.4660e-01,
          7.9444e-02, -6.5880e-02, -4.0926e-01, -4.1832e-01, -6.1381e-02,
         -1.0826e-01,  7.3397e-03, -1.0652e-01,  1.4579e-01, -4.2872e-01,
         -3.0094e-02],
        [ 2.1260e-01,  1.4500e-02,  3.4593e-01, -1.2281e-02, -3.9874e-01,
         -3.5107e-03, -3.1844e-02, -1.2568e-01, -2.8119e-01, -1.5067e-01,
         -1.1145e-01,  1.0605e-01,  1.0434e-01,  3.9671e-02, -4.6338e-01,
          2.1269e-01],
        [-3.7580e-01,  4.0022e-02, -4.0713e-02, -4.5462e-02,  4.7746e-01,
          3.9109e-01,  9.8781e-02,  1.8498e-01,  3.0120e-02,  1.6909e-01,
          2.3741e-02, -3.0451e-01, -7.4141e-02, -1.0981e-01,  1.8785e-01,
         -1.3706e-01],
        [-8.3365e-02, -5.6641e-01,  1.0942e-01,  1.1390e-01, -5.2396e-01,
          6.3799e-02, -1.6294e-01, -4.3170e-01, -3.1136e-01,  1.2092e-02,
         -2.8996e-02,  3.5894e-01,  5.3380e-02, -1.1084e-01, -1.3930e-01,
          4.1843e-03],
        [ 3.1907e-01,  3.0629e-02,  1.6903e-01, -3.4086e-01, -4.1974e-01,
         -2.6629e-03, -6.3796e-02, -5.1104e-02, -4.5238e-01, -1.5121e-01,
          1.7298e-01,  2.7894e-01,  3.1069e-01,  2.2454e-01, -2.3515e-01,
         -7.2553e-02],
        [-2.6535e-01,  1.7302e-01, -1.9416e-01,  1.1203e-01,  1.5783e-01,
          2.4648e-01,  2.4466e-01,  2.8115e-01,  1.5227e-01,  2.4207e-01,
         -6.2030e-02, -1.9594e-01, -9.3517e-02, -1.5364e-01,  2.8320e-01,
         -1.2677e-01],
        [ 2.2156e-01, -1.9134e-01,  1.0405e-01, -2.5742e-01, -2.9604e-01,
         -3.4163e-01, -2.6139e-01, -3.3909e-02, -4.6068e-01, -7.0530e-02,
          2.9495e-02, -1.0346e-01,  1.5763e-01,  2.1084e-01, -1.0741e-01,
          1.4731e-01],
        [ 3.6190e-01, -1.7219e-01,  2.2417e-01, -7.2663e-02, -4.2735e-01,
         -2.0526e-01, -3.4307e-01, -4.1973e-02, -1.0359e-01, -2.4321e-01,
          1.1464e-01,  2.2486e-01, -7.2237e-02,  7.4698e-02, -1.4172e-01,
          1.5550e-01],
        [-1.5303e-01,  3.2106e-01, -2.0556e-03, -9.1755e-02,  3.1687e-01,
         -8.3607e-02,  2.8055e-01,  3.7282e-01,  1.8795e-01,  4.1793e-02,
         -1.2403e-01, -2.2930e-01, -1.3781e-01, -1.6906e-01,  4.0694e-01,
         -2.1527e-01],
        [-1.0257e-01,  1.5511e-01, -3.7087e-02,  4.0071e-01,  1.4630e-01,
          1.2425e-01,  2.8333e-01,  6.2243e-02,  1.3325e-01,  2.6970e-01,
          1.8747e-01, -2.9544e-01, -2.2271e-01, -3.8156e-01,  8.5956e-02,
          6.3019e-02],
        [ 3.6143e-01, -2.3399e-01,  2.3985e-02, -1.5828e-01, -7.9094e-02,
         -3.7577e-01, -2.8416e-01, -2.7821e-01, -3.0335e-01, -1.3970e-01,
          2.1613e-01,  2.0033e-01, -9.8623e-02,  2.9102e-01,  3.3573e-04,
          1.9251e-01],
        [ 2.4043e-01,  7.7056e-02,  2.9557e-01, -3.4153e-01, -2.2377e-01,
         -1.1179e-01, -1.2254e-01, -2.9393e-01, -4.0567e-01, -2.6967e-01,
         -5.3462e-04,  3.0613e-01,  2.0457e-01,  6.6975e-02, -2.2791e-01,
         -3.5373e-02],
        [ 2.1944e-01, -4.6933e-01,  1.5085e-01, -1.2628e-01, -3.5744e-02,
         -2.2730e-01,  5.3905e-02, -2.2888e-01, -4.3369e-01,  6.8867e-02,
          1.7558e-01, -3.5924e-03,  2.1279e-02,  2.4372e-01, -4.4592e-01,
          3.1508e-01],
        [ 1.8448e-02, -2.7979e-01,  4.5604e-02,  1.0005e-01, -2.8659e-01,
         -1.7390e-01, -1.1647e-02, -3.5526e-01, -1.7764e-01, -3.3015e-01,
         -2.3833e-01,  7.0431e-02,  1.3849e-01,  3.0425e-01, -4.6490e-01,
          4.6441e-02],
        [ 2.0801e-01, -9.7311e-02,  2.5851e-01, -3.3418e-01, -2.5208e-01,
         -7.6251e-02, -3.3952e-01, -6.9905e-02, -4.2037e-01,  3.0529e-02,
          6.7454e-02,  6.3807e-02,  2.0814e-01,  2.3567e-01,  4.7798e-03,
          2.5926e-01],
        [-3.2119e-01,  2.8156e-01,  4.7290e-02,  2.0349e-01,  4.1329e-01,
          3.5568e-03,  3.5337e-01,  2.3470e-01,  2.3663e-03,  8.4941e-02,
          5.4881e-02, -2.5777e-01, -2.0588e-01, -1.7834e-01,  1.1186e-01,
         -8.5309e-02],
        [ 2.8819e-01, -2.6536e-02,  9.7576e-02, -1.1653e-01, -3.5533e-01,
         -2.5694e-01, -1.2338e-01, -3.7389e-01, -5.2207e-02, -8.0825e-02,
          1.2361e-01,  1.1187e-01,  3.2020e-01,  2.8878e-01, -6.4088e-02,
          2.2771e-01],
        [-2.5615e-01,  2.2497e-01, -2.8155e-01,  2.3825e-01, -1.2884e-02,
          1.1492e-01,  3.1214e-01,  3.3579e-01,  3.8978e-01,  2.0831e-01,
          1.3967e-01, -5.8295e-02,  8.5649e-02,  8.7196e-02,  2.1550e-01,
         -1.9275e-01],
        [-2.7303e-01,  1.0629e-01, -3.7579e-03,  4.8646e-03,  2.7969e-01,
          3.5527e-01,  3.6365e-01,  2.5795e-02,  2.7077e-01,  2.9521e-01,
         -2.5457e-01,  1.4491e-02, -2.8410e-01, -2.4479e-01,  1.1407e-01,
         -2.1170e-01],
        [ 3.8511e-02, -1.0373e-01,  2.0125e-01, -2.5485e-02, -7.2005e-02,
         -2.6990e-01, -3.6809e-01, -4.0063e-01, -3.4326e-01, -2.2282e-01,
          1.0552e-01, -6.0939e-02, -9.6435e-02,  1.7589e-01, -3.5553e-01,
          1.4282e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0810, -0.0223,  0.1467, -0.1184, -0.0607, -0.0362,  0.0623,  0.1545,
        -0.0330, -0.0459,  0.0374,  0.0516,  0.1673,  0.0965, -0.0620,  0.1136,
        -0.1897, -0.0068,  0.0266,  0.0168, -0.0312, -0.1346, -0.0583, -0.0621,
        -0.1891,  0.2864,  0.1185,  0.0123, -0.0794, -0.2277,  0.1435, -0.0267],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.3382,  0.4240, -0.3086, -0.3236,  0.4382,  0.4629, -0.3556, -0.4312,
         -0.4050,  0.4849,  0.3300,  0.4597, -0.3863, -0.4928,  0.3875, -0.4572,
         -0.3839,  0.3735, -0.2967, -0.3132,  0.4950,  0.4369, -0.4267, -0.4166,
         -0.4754, -0.4396, -0.3681,  0.4465, -0.3974,  0.4366,  0.3423, -0.2984]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0358,  0.1055,  0.0521,  ...,  0.2251, -0.3818, -0.1137],
        [-0.1022, -0.0576,  0.1128,  ...,  0.1583, -0.3671,  0.0871],
        [-0.0090, -0.0295,  0.0229,  ...,  0.0233,  0.2870,  0.0345],
        ...,
        [ 0.0154,  0.0076,  0.0533,  ...,  0.0885, -0.3797, -0.1180],
        [ 0.0792, -0.2025, -0.0490,  ..., -0.3321,  0.1979,  0.1557],
        [-0.1975,  0.1428,  0.0332,  ...,  0.1008, -0.3346, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0429,  0.0405, -0.0663, -0.1339, -0.0723,  0.0583, -0.1105,  0.0464,
        -0.0395,  0.0807,  0.0193,  0.0114,  0.0294,  0.0786, -0.0523, -0.0192,
         0.0587, -0.1525,  0.0011,  0.0286, -0.0527,  0.0348,  0.1082,  0.0066,
        -0.0929,  0.1034,  0.0473, -0.0993,  0.0549,  0.1396,  0.1668, -0.1230],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0717, -0.1962, -0.1029,  ..., -0.1524, -0.0092,  0.0721],
        [-0.2093, -0.0523,  0.0990,  ..., -0.0849,  0.0141,  0.0468],
        [ 0.1431, -0.0101, -0.1769,  ...,  0.1042, -0.0396,  0.1941],
        ...,
        [ 0.1226,  0.1072,  0.1105,  ...,  0.2734, -0.2325,  0.2473],
        [-0.0090, -0.1666,  0.0571,  ..., -0.0055,  0.2467, -0.1736],
        [-0.0067, -0.1491,  0.2134,  ...,  0.0156,  0.1731, -0.0546]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1064,  0.1506, -0.0635, -0.0861,  0.0011, -0.0462, -0.0601, -0.0425,
         0.1265, -0.1715,  0.1319, -0.1157,  0.1751,  0.0873, -0.1205,  0.1308,
        -0.1385, -0.1753, -0.0536, -0.0019, -0.0053,  0.0825, -0.2143,  0.2173,
        -0.0453, -0.0042,  0.0721, -0.0287, -0.1370, -0.0741,  0.1269,  0.0463],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.6454,  0.5698, -0.6632, -0.6447,  0.5297,  0.5088, -0.5714,  0.5500,
          0.5622, -0.5926, -0.5361,  0.5562,  0.5345,  0.5172,  0.5859,  0.5843,
         -0.6416, -0.6552, -0.5164,  0.5631, -0.6065, -0.5882, -0.6596,  0.4969,
          0.6304,  0.6558, -0.6417,  0.6517, -0.5737, -0.6427,  0.6318,  0.6581]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.3797], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-3.2536e-02,  2.5388e-01,  2.1725e-01, -2.4730e-01, -4.0382e-01,
         -7.5006e-02,  1.1405e-02, -4.9077e-01, -2.8613e-01,  4.0920e-02,
          1.7662e-01,  1.7264e-01, -4.5716e-03, -1.5975e-01, -2.5843e-01,
          2.6656e-01],
        [-2.2898e-01, -2.5663e-01, -3.6255e-02, -5.1501e-02,  1.3244e-01,
          1.9152e-01,  1.1341e-01,  2.1687e-01,  4.8736e-01,  6.0358e-02,
          6.5902e-02, -2.5101e-01,  5.0456e-02,  3.0950e-02,  5.2614e-01,
         -2.0597e-03],
        [ 6.2798e-02,  1.9597e-01,  3.1017e-01, -7.6204e-02, -2.4640e-01,
         -3.2500e-01, -3.9332e-02, -5.2876e-01, -1.8532e-02, -1.0392e-02,
         -1.9516e-02, -5.9858e-02,  4.2738e-01,  2.9302e-01, -1.4915e-01,
          2.2792e-01],
        [ 2.3606e-01, -3.2069e-02,  3.8468e-03, -1.3761e-02, -2.1998e-01,
         -1.1442e-01, -7.1735e-02, -1.4276e-01, -5.2243e-01, -3.0569e-01,
          2.6024e-02,  3.4337e-01,  2.1675e-01, -2.1463e-01, -3.6387e-01,
          4.7662e-02],
        [-7.9491e-02,  1.8017e-01, -1.0272e-01, -6.8811e-02,  3.5920e-01,
          2.8140e-02, -3.8169e-03,  4.1088e-01,  2.6157e-01,  2.2243e-01,
          7.8435e-02, -1.6174e-01, -1.3853e-02, -1.7230e-01,  4.8710e-01,
         -7.7142e-02],
        [ 1.3783e-02,  2.1241e-01, -3.0442e-01,  3.6260e-01,  4.8001e-01,
         -8.2740e-02,  2.1337e-01,  1.7380e-02,  3.3621e-01,  1.4862e-01,
         -1.1430e-01, -8.0672e-02, -1.9438e-01,  1.8238e-01,  5.6579e-01,
         -1.2608e-02],
        [ 3.3804e-01,  4.2224e-02,  3.3592e-01, -1.3713e-01, -1.9974e-01,
         -1.5912e-01, -1.2650e-01, -2.8912e-01, -3.1035e-01,  4.6062e-02,
          2.6119e-02,  4.4975e-02, -1.0517e-01,  1.0609e-01, -4.2972e-01,
          8.0334e-02],
        [-9.1990e-02,  2.2379e-01,  2.9632e-01, -3.1722e-01, -4.3908e-01,
         -2.6698e-01, -5.7878e-02, -3.1283e-01, -2.2437e-01, -1.6858e-01,
         -2.2815e-02,  1.5402e-02,  2.3733e-01, -1.4259e-01, -1.9943e-01,
          3.1399e-01],
        [ 2.7813e-02,  2.5064e-01,  2.4650e-01, -2.2080e-01, -2.1432e-01,
         -3.2246e-01, -1.4718e-01, -1.9171e-01, -3.8555e-02, -2.6278e-01,
          5.8286e-02,  6.8925e-02, -5.4956e-02,  1.2749e-01, -5.2737e-01,
          4.8800e-02],
        [-2.8236e-01, -2.6780e-02, -4.7205e-02, -4.2931e-02,  2.5597e-01,
          1.1551e-01,  1.6875e-02,  3.2428e-01,  3.7854e-01, -5.7180e-02,
          1.1806e-01, -1.7928e-02, -2.4452e-01, -3.6994e-02,  3.7717e-01,
         -1.3999e-01],
        [-3.4306e-01,  1.2732e-01, -3.1928e-03, -6.8255e-02,  1.4616e-01,
          3.8449e-01,  1.9700e-01,  2.1361e-01,  4.5754e-01,  1.9072e-01,
         -3.7126e-02, -4.1266e-03, -1.8024e-01,  1.4861e-01,  1.9665e-01,
         -2.6672e-01],
        [-1.0576e-01, -8.5522e-02,  3.9974e-02,  5.7113e-02,  3.1060e-01,
          8.5370e-02,  3.2826e-01,  2.2334e-01,  2.2778e-01,  2.8759e-01,
          6.1945e-02,  6.5532e-02, -4.0377e-01, -1.8337e-01,  2.2133e-01,
         -1.4638e-01],
        [ 3.0054e-01,  1.3834e-01,  7.8209e-02, -1.0826e-01, -3.2640e-01,
          1.0735e-01, -2.1414e-02, -4.2721e-01, -4.5542e-01, -1.3198e-02,
         -9.6993e-02,  1.9862e-02, -9.8732e-02,  1.0014e-01, -4.7622e-01,
         -6.7350e-02],
        [ 1.8668e-01,  2.6766e-01,  3.0970e-01,  2.1778e-02, -4.3214e-01,
          1.6478e-02, -3.0021e-03, -1.2058e-01, -2.7552e-01, -1.0968e-01,
         -8.6384e-02,  1.0051e-01,  9.5700e-02, -3.0630e-03, -4.9289e-01,
          1.8259e-01],
        [-3.5714e-01, -2.4031e-01, -1.0506e-02, -7.4368e-02,  5.1699e-01,
          3.7784e-01,  7.2325e-02,  1.9299e-01,  3.7596e-02,  1.3278e-01,
          4.6791e-04, -3.0851e-01, -7.9953e-02, -7.5128e-02,  2.2287e-01,
         -1.1339e-01],
        [-2.7347e-01, -1.1032e-01,  9.4621e-02,  1.9342e-01,  2.9928e-01,
          1.0345e-01,  5.3574e-02,  1.5878e-01,  2.8615e-01,  4.0439e-02,
          2.2667e-02,  1.4561e-01, -1.0106e-01, -1.9544e-01,  6.9666e-01,
         -2.4719e-03],
        [ 2.8067e-01,  1.4465e-01,  1.2968e-01, -3.0029e-01, -4.7868e-01,
          2.9426e-02, -2.6244e-02, -2.6574e-02, -4.5360e-01, -1.0443e-01,
          1.7699e-01,  2.7104e-01,  2.7748e-01,  1.7533e-01, -2.4300e-01,
         -1.1579e-01],
        [-2.4990e-01,  1.1185e-01, -1.6859e-01,  8.6614e-02,  2.1976e-01,
          2.4234e-01,  2.2482e-01,  2.9705e-01,  1.6550e-01,  2.1198e-01,
         -8.4091e-02, -2.0619e-01, -1.1027e-01, -1.1758e-01,  3.4387e-01,
         -1.0489e-01],
        [ 2.0188e-01,  2.9761e-02,  7.2475e-02, -2.2731e-01, -3.6479e-01,
         -3.2547e-01, -2.3038e-01, -5.5601e-02, -4.9832e-01, -2.8733e-02,
          5.8914e-02, -8.4242e-02,  1.6626e-01,  1.7152e-01, -1.4714e-01,
          1.1228e-01],
        [ 3.4927e-01,  6.0151e-02,  1.9683e-01, -4.8689e-02, -4.8622e-01,
         -1.8986e-01, -3.1794e-01, -5.9339e-02, -1.3855e-01, -2.0513e-01,
          1.2921e-01,  2.4806e-01, -6.3386e-02,  4.5931e-02, -1.8888e-01,
          1.2559e-01],
        [-1.4695e-01,  1.4169e-01,  1.5744e-02, -1.1506e-01,  3.7119e-01,
         -9.0756e-02,  2.6085e-01,  3.9080e-01,  2.1889e-01,  1.1228e-02,
         -1.0245e-01, -2.4372e-01, -1.5354e-01, -1.4383e-01,  5.0321e-01,
         -1.9413e-01],
        [-8.9365e-02, -2.7043e-01, -5.9688e-03,  3.7214e-01,  1.7808e-01,
          1.1395e-01,  2.5931e-01,  7.3622e-02,  1.4702e-01,  2.3025e-01,
          1.6656e-01, -3.0984e-01, -2.4046e-01, -3.4884e-01,  1.2343e-01,
          8.3642e-02],
        [ 3.5234e-01, -4.2322e-02,  2.5517e-03, -1.3846e-01, -1.3934e-01,
         -3.7112e-01, -2.7250e-01, -2.9669e-01, -3.2522e-01, -1.1257e-01,
          2.2675e-01,  2.1858e-01, -8.1522e-02,  2.6852e-01, -5.1860e-02,
          1.7492e-01],
        [ 2.0055e-01,  9.1031e-02,  2.5624e-01, -3.0245e-01, -2.8043e-01,
         -8.9439e-02, -9.2779e-02, -2.7363e-01, -3.8718e-01, -2.3012e-01,
          2.5150e-02,  2.9209e-01,  1.8957e-01,  2.2723e-02, -2.3926e-01,
         -6.7543e-02],
        [ 2.0861e-01, -1.8139e-01,  1.2683e-01, -9.9931e-02, -1.1315e-01,
         -2.1557e-01,  7.8151e-02, -2.4858e-01, -4.7089e-01,  1.0537e-01,
          2.0399e-01,  1.5084e-02,  3.0574e-02,  2.0828e-01, -5.1678e-01,
          2.8754e-01],
        [ 1.5880e-02, -2.5950e-02,  2.7194e-02,  1.1915e-01, -3.4112e-01,
         -1.7306e-01,  9.4745e-03, -3.8704e-01, -2.0857e-01, -3.0251e-01,
         -2.4230e-01,  8.8968e-02,  1.6672e-01,  2.8246e-01, -5.5215e-01,
          3.3093e-02],
        [ 1.9371e-01,  1.0181e-01,  2.3080e-01, -3.1032e-01, -2.9994e-01,
         -6.5240e-02, -3.2425e-01, -8.4033e-02, -4.3385e-01,  6.3000e-02,
          8.0558e-02,  7.7777e-02,  2.1679e-01,  2.1868e-01, -3.6948e-02,
          2.3991e-01],
        [-3.1258e-01,  2.4657e-02,  6.9858e-02,  1.7912e-01,  4.7572e-01,
         -1.2852e-02,  3.2988e-01,  2.5477e-01,  3.9870e-02,  5.0463e-02,
          6.4619e-02, -2.7909e-01, -2.1018e-01, -1.5485e-01,  1.7416e-01,
         -5.8616e-02],
        [ 2.6916e-01,  9.6179e-02,  6.8215e-02, -9.0547e-02, -4.0205e-01,
         -2.4430e-01, -1.0536e-01, -3.8584e-01, -5.4515e-02, -4.9123e-02,
          1.3969e-01,  1.1725e-01,  3.2495e-01,  2.6461e-01, -1.0570e-01,
          2.0862e-01],
        [-2.4670e-01,  8.2284e-02, -2.6050e-01,  2.1867e-01,  4.4474e-02,
          1.1433e-01,  3.0057e-01,  3.5567e-01,  4.0526e-01,  1.8354e-01,
          1.1455e-01, -7.3444e-02,  6.2255e-02,  1.0640e-01,  2.8383e-01,
         -1.7862e-01],
        [-2.5789e-01, -9.6017e-02,  2.5328e-02, -2.1150e-02,  3.3377e-01,
          3.4441e-01,  3.4179e-01,  4.0557e-02,  2.9057e-01,  2.5939e-01,
         -2.7163e-01, -5.6455e-04, -2.9550e-01, -2.1134e-01,  1.5170e-01,
         -1.8579e-01],
        [ 1.5735e-02,  5.5566e-02,  1.6777e-01,  6.6610e-03, -1.3790e-01,
         -2.5642e-01, -3.3943e-01, -4.3106e-01, -3.7003e-01, -1.8298e-01,
          1.3138e-01, -4.4033e-02, -8.1412e-02,  1.3826e-01, -4.0267e-01,
          1.1305e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0977,  0.0029,  0.1904, -0.1265, -0.0180,  0.0175,  0.0810,  0.1808,
        -0.0197, -0.0182,  0.0080,  0.0611,  0.1169,  0.0874, -0.0554, -0.0408,
        -0.2192, -0.0150,  0.0208,  0.0062,  0.0060, -0.1412, -0.0515, -0.0512,
        -0.1766,  0.2788,  0.1216,  0.0423, -0.0712, -0.2464,  0.1478, -0.0259],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.3456,  0.4292, -0.3129, -0.3431,  0.4888,  0.5056, -0.3673, -0.4329,
         -0.4143,  0.5102,  0.3491,  0.4581, -0.4112, -0.5026,  0.3907,  0.4620,
         -0.3912,  0.3838, -0.3027, -0.3171,  0.5205,  0.4092, -0.4319, -0.4200,
         -0.5336, -0.4616, -0.3686,  0.4569, -0.4044,  0.4438,  0.3459, -0.3068]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0064,  0.0918,  0.0749,  ...,  0.1624, -0.3605, -0.1137],
        [-0.1021, -0.0551,  0.1152,  ...,  0.1336, -0.3695,  0.0871],
        [-0.0136, -0.0261,  0.0340,  ...,  0.0229,  0.3175,  0.0345],
        ...,
        [ 0.0151,  0.0142,  0.0519,  ...,  0.0716, -0.4078, -0.1180],
        [ 0.0825, -0.2078, -0.0503,  ..., -0.3075,  0.2180,  0.1557],
        [-0.1838,  0.1440,  0.0370,  ...,  0.0679, -0.3595, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0463,  0.0401, -0.0697, -0.1356, -0.0739,  0.0496, -0.1102,  0.0501,
        -0.0412,  0.0788,  0.0249,  0.0119,  0.0240,  0.0759, -0.0505, -0.0211,
         0.0574, -0.1562, -0.0640,  0.0377, -0.0580,  0.0322,  0.1050,  0.0079,
        -0.0879,  0.0525,  0.0435, -0.1172,  0.0551,  0.1429,  0.1667, -0.1280],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0397, -0.1956, -0.0916,  ..., -0.1404,  0.0095,  0.0635],
        [-0.2358, -0.0519,  0.1239,  ..., -0.0668,  0.0199,  0.0367],
        [ 0.1612, -0.0115, -0.1881,  ...,  0.0842, -0.0354,  0.1960],
        ...,
        [ 0.1359,  0.0908,  0.1112,  ...,  0.2508, -0.2367,  0.2397],
        [-0.0286, -0.1673,  0.0733,  ...,  0.0224,  0.2413, -0.1810],
        [-0.0212, -0.1379,  0.2124,  ...,  0.0430,  0.1684, -0.0479]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1098,  0.1644, -0.0667, -0.0851, -0.0027, -0.0435, -0.0606, -0.0397,
         0.1382, -0.1821,  0.1169, -0.1271,  0.1969,  0.1068, -0.1216,  0.1420,
        -0.1391, -0.1758,  0.0488, -0.0104, -0.0091,  0.0839, -0.2038,  0.2441,
        -0.0409, -0.0053,  0.0709, -0.0264, -0.1383, -0.0703,  0.1354,  0.0406],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.7011,  0.6322, -0.7103, -0.6830,  0.5726,  0.5828, -0.6184,  0.5911,
          0.5964, -0.6509, -0.5959,  0.5896,  0.5848,  0.5764,  0.6212,  0.6386,
         -0.6846, -0.6954,  0.5465,  0.6018, -0.6562, -0.6371, -0.6976,  0.5360,
          0.6831,  0.6953, -0.6769,  0.6966, -0.6166, -0.6831,  0.6775,  0.6929]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.4106], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-0.5341,  0.7225, -0.1897, -0.3280,  0.2664, -0.3025,  0.6090,  0.0542,
          0.2686,  0.1643,  0.2018, -0.2505, -0.1938,  0.0714,  0.3008, -0.1455],
        [-0.3807,  0.1340, -0.2208, -0.2935,  0.1626, -0.1734,  0.3496,  0.3051,
          0.5280,  0.0407,  0.1497, -0.3990,  0.1237,  0.3419,  0.5039, -0.1963],
        [-0.3685,  0.4300, -0.0680, -0.0659,  0.4108, -0.3635,  0.5214,  0.0705,
          0.5028,  0.1214,  0.0410, -0.5393,  0.1373,  0.3514,  0.4441, -0.1783],
        [ 0.4029, -0.3989,  0.1849,  0.1829, -0.1758,  0.1623, -0.3402, -0.1907,
         -0.4918, -0.2984, -0.0395,  0.4419,  0.1325, -0.4324, -0.2782,  0.2689],
        [-0.2462,  0.5494, -0.2772, -0.3129,  0.2817, -0.2969,  0.1963,  0.4065,
          0.2160,  0.1955,  0.1971, -0.2478,  0.1055,  0.1100,  0.3739, -0.2740],
        [-0.1433,  0.5773, -0.4557,  0.0773,  0.4193, -0.4199,  0.3973,  0.0289,
          0.2980,  0.0272, -0.1376, -0.1623, -0.1978,  0.4783,  0.4115, -0.1894],
        [ 0.4272, -0.3072,  0.5332,  0.1793, -0.2084,  0.2685, -0.3867, -0.3470,
         -0.3443,  0.2116, -0.0590,  0.1538, -0.0638, -0.1875, -0.3076,  0.2971],
        [ 0.0637, -0.1375,  0.4663, -0.0236, -0.4918,  0.1101, -0.2604, -0.3826,
         -0.2888, -0.0279, -0.0920,  0.1466,  0.2759, -0.4401, -0.1870,  0.4840],
        [ 0.2021, -0.2396,  0.4807,  0.1085, -0.3243,  0.1806, -0.4468, -0.3281,
         -0.1745, -0.2191, -0.2118,  0.2519, -0.1354, -0.3172, -0.5645,  0.2666],
        [-0.4782,  0.3746, -0.2382, -0.2485,  0.2092, -0.1938,  0.2316,  0.3383,
          0.3614,  0.0160,  0.1218, -0.1103, -0.0172,  0.2560,  0.2876, -0.3551],
        [-0.5880,  0.6229, -0.2173, -0.3405,  0.0522,  0.0132,  0.4524,  0.1933,
          0.4247,  0.2127,  0.0630, -0.0793, -0.0146,  0.4909,  0.0374, -0.5258],
        [-0.3364,  0.3074, -0.1690, -0.1400,  0.3169, -0.2098,  0.5459,  0.2604,
          0.2689,  0.3777,  0.1761, -0.0464, -0.1699,  0.0873,  0.2283, -0.3652],
        [ 0.4795, -0.3054,  0.2910,  0.1849, -0.2444,  0.5081, -0.2696, -0.4249,
         -0.4065,  0.0655, -0.1483,  0.1430, -0.1001, -0.2728, -0.3012,  0.1698],
        [ 0.3469, -0.0956,  0.4760,  0.2477, -0.4264,  0.3405, -0.1971, -0.1587,
         -0.2835, -0.0631, -0.1619,  0.1898,  0.0207, -0.2633, -0.4258,  0.3600],
        [-0.5548,  0.2399, -0.2106, -0.3485,  0.5270, -0.0329,  0.3178,  0.2485,
          0.0792,  0.0912,  0.1040, -0.4242,  0.0021,  0.3056,  0.1567, -0.3237],
        [ 0.1032, -0.4018,  0.3535,  0.2902, -0.4180,  0.2664, -0.3291, -0.3845,
         -0.2794,  0.0094,  0.0547,  0.5255, -0.0536, -0.2816, -0.0227,  0.2308],
        [ 0.4574, -0.1907,  0.3573, -0.0634, -0.6209,  0.3576, -0.3323, -0.2187,
         -0.5732, -0.0941,  0.1883,  0.4925,  0.2691, -0.1160, -0.3746,  0.1305],
        [-0.3344,  0.3925, -0.3350, -0.1505,  0.2900, -0.0749,  0.4588,  0.3932,
          0.2192,  0.0848,  0.0138, -0.3409, -0.1695,  0.0950,  0.2972, -0.2887],
        [-0.2549,  0.3333, -0.3020, -0.2447,  0.2619, -0.4166,  0.2659,  0.4891,
          0.0396,  0.0945,  0.0301, -0.5364, -0.0069,  0.3184,  0.4064, -0.2488],
        [ 0.5629, -0.4267,  0.4087,  0.2208, -0.4175,  0.1855, -0.5684, -0.0488,
         -0.1086, -0.1623, -0.1103,  0.3120, -0.1367, -0.2817, -0.0323,  0.3769],
        [-0.2527,  0.3598, -0.1183, -0.2802,  0.3791, -0.3021,  0.4209,  0.4487,
          0.2459, -0.0394, -0.1515, -0.3567, -0.0766,  0.0048,  0.4409, -0.3221],
        [ 0.3765, -0.3746,  0.2701,  0.3098, -0.2902,  0.1141, -0.0429, -0.2939,
         -0.3254, -0.1008,  0.2288,  0.1454,  0.0178, -0.3480, -0.5941,  0.2992],
        [ 0.5051, -0.4802,  0.1863,  0.1738, -0.1576,  0.0504, -0.4941, -0.3485,
         -0.3500, -0.0202,  0.0376,  0.3196, -0.1039, -0.1052,  0.0386,  0.3865],
        [ 0.3046, -0.1733,  0.4430, -0.1120, -0.4506,  0.1632, -0.3644, -0.4512,
         -0.4922, -0.1738, -0.1024,  0.4945,  0.2617, -0.1419, -0.3033,  0.1436],
        [ 0.3818, -0.6559,  0.3158,  0.1919, -0.1052,  0.1964, -0.1738, -0.3043,
         -0.4827,  0.1150,  0.1927,  0.1247, -0.1115, -0.2170, -0.4261,  0.5019],
        [ 0.1675, -0.4174,  0.1894,  0.3840, -0.3675,  0.1918, -0.1864, -0.4508,
         -0.2539, -0.2202, -0.3003,  0.2190,  0.1392, -0.0315, -0.4882,  0.1908],
        [ 0.3993, -0.3070,  0.4454, -0.0543, -0.3121,  0.2987, -0.5640, -0.1229,
         -0.4712,  0.0993, -0.0107,  0.1862,  0.1674, -0.0716,  0.0164,  0.4714],
        [-0.5312,  0.4173, -0.1333, -0.0247,  0.4319, -0.3101,  0.5346,  0.2620,
          0.0432,  0.1187,  0.1543, -0.3710,  0.0135,  0.1154,  0.1349, -0.2754],
        [ 0.4724, -0.3087,  0.2685,  0.1158, -0.4654,  0.0523, -0.3321, -0.4772,
         -0.1329, -0.0684,  0.0300,  0.2616,  0.2226, -0.0198, -0.1346,  0.4098],
        [-0.3739,  0.4368, -0.4176, -0.0664,  0.0204, -0.2443,  0.4907,  0.3682,
          0.3930,  0.0469,  0.2416, -0.1476,  0.0317,  0.3589,  0.1135, -0.3655],
        [-0.4789,  0.3711, -0.1905, -0.2797,  0.3532, -0.0367,  0.6024,  0.0992,
          0.3304,  0.2563, -0.1619, -0.1196, -0.2085,  0.1599,  0.1260, -0.4214],
        [ 0.1365, -0.2891,  0.3656,  0.2798, -0.1647,  0.0975, -0.6221, -0.5231,
         -0.4147, -0.0857, -0.0154,  0.1249, -0.0458, -0.1311, -0.3544,  0.3250]],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.2398,  0.0770,  0.1781, -0.0863, -0.0016, -0.1023,  0.0646,  0.1069,
        -0.2153, -0.0767,  0.0295,  0.0552,  0.1150,  0.0882,  0.0092,  0.0873,
        -0.1188,  0.0662, -0.0413, -0.0965, -0.0373, -0.0018, -0.1280, -0.1322,
        -0.1241,  0.1855,  0.1151,  0.0423, -0.0777, -0.1255,  0.1375, -0.1660],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5428,  0.5676,  0.4967, -0.5252,  0.6256,  0.6625, -0.5153, -0.6311,
         -0.5744,  0.6742,  0.5524,  0.6844, -0.5719, -0.6354,  0.5663, -0.5533,
         -0.5452,  0.5811,  0.5049, -0.5231,  0.6227, -0.4414, -0.6348, -0.6021,
         -0.5795, -0.6489, -0.5450,  0.6360, -0.6225,  0.6321,  0.5709, -0.4850]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.2441,  0.1726, -0.0137,  ...,  0.0884, -0.1185, -0.1137],
        [-0.1322, -0.2137,  0.1761,  ..., -0.0091, -0.3815,  0.0871],
        [-0.0268,  0.1331,  0.0856,  ...,  0.1371,  0.1712,  0.0345],
        ...,
        [-0.0294, -0.1732,  0.0645,  ..., -0.1282, -0.1958, -0.1180],
        [ 0.0097, -0.1028, -0.0160,  ..., -0.1615,  0.0375,  0.1557],
        [-0.0907,  0.1348, -0.0244,  ..., -0.0593,  0.0374, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0543,  0.0637, -0.1582, -0.0550, -0.0557,  0.0375, -0.1270,  0.1097,
        -0.0561,  0.1552,  0.0209, -0.0492, -0.0503,  0.0607, -0.0733, -0.0438,
         0.1044, -0.1387, -0.0451,  0.0478, -0.0805,  0.1348,  0.0999, -0.0579,
        -0.0030,  0.1177,  0.0192, -0.1350,  0.0823,  0.1822,  0.0921, -0.1376],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.2012, -0.1897, -0.1083,  ..., -0.0541, -0.1185,  0.1650],
        [ 0.0243,  0.0042,  0.1459,  ..., -0.0359, -0.0376,  0.2469],
        [-0.0725, -0.0924, -0.1825,  ...,  0.0209,  0.0433,  0.0057],
        ...,
        [-0.0530,  0.0301,  0.0775,  ...,  0.1943, -0.1508,  0.1315],
        [ 0.2062, -0.1036,  0.0863,  ...,  0.0618,  0.1866,  0.0197],
        [ 0.1907, -0.0576,  0.2495,  ...,  0.0811,  0.1045,  0.1089]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0586,  0.0227,  0.0601,  0.0230, -0.0772, -0.1288,  0.0620, -0.1820,
         0.0238, -0.0632,  0.2332, -0.1862,  0.0775,  0.1027, -0.2225, -0.0205,
        -0.0519, -0.1119, -0.0678, -0.1101,  0.1004,  0.2003, -0.1051,  0.2098,
        -0.1497, -0.0623,  0.1425, -0.1463, -0.0451, -0.0017, -0.0008, -0.0619],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3340,  0.2465, -0.3467, -0.3042,  0.2073,  0.2013, -0.2375,  0.2695,
          0.2413, -0.2446, -0.2287,  0.2246,  0.2322, -0.2035,  0.2701,  0.2198,
         -0.3259, -0.3348,  0.1945,  0.2271, -0.2909, -0.2712, -0.3413, -0.1592,
          0.3058,  0.3350, -0.3179,  0.3202, -0.2437, -0.3169,  0.3163,  0.3135]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.1465], device='cuda:0', requires_grad=True)

