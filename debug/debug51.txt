Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.6075e-01,  3.2425e-01,  4.8527e-02, -7.7644e-02,  6.2738e-02,
          1.0634e-01,  2.3317e-01, -1.0964e-01,  1.1297e-01,  1.9405e-01,
          1.0624e-01, -8.2301e-02, -2.2531e-01, -3.1140e-01,  1.9581e-01,
          1.2127e-01],
        [-1.8669e-01, -1.3063e-01, -4.1977e-02, -7.4432e-02, -1.0562e-01,
          1.8360e-01,  8.7107e-02,  8.7065e-02,  3.2615e-01,  6.6560e-02,
          1.0562e-01, -1.9010e-01,  8.0537e-02,  5.7996e-03,  2.7960e-01,
         -2.0879e-02],
        [ 1.2677e-02,  2.2378e-02,  3.1880e-01, -5.7890e-02,  1.5241e-02,
         -2.7697e-01,  3.4773e-02, -3.3879e-01,  1.2052e-01, -4.6152e-03,
          9.1112e-03, -1.3587e-01,  3.2592e-01,  2.6545e-01,  1.3603e-01,
          1.9931e-01],
        [ 2.0639e-01, -1.6897e-01,  2.3183e-02, -8.1175e-03,  2.0963e-02,
         -1.3479e-01, -7.8482e-02, -2.6571e-02, -3.4822e-01, -3.3800e-01,
          1.9891e-02,  2.9413e-01,  2.3788e-01, -1.6088e-01, -1.4424e-01,
          9.5461e-02],
        [-2.5653e-02,  2.9406e-01, -1.0574e-01, -9.7943e-02,  6.8809e-02,
          1.6557e-02, -4.5566e-02,  2.4101e-01,  6.4063e-02,  2.2547e-01,
          1.4264e-01, -8.5815e-02,  3.4582e-02, -1.8535e-01,  1.9139e-01,
         -9.3222e-02],
        [ 5.8045e-02,  3.3224e-01, -3.0046e-01,  3.3509e-01,  2.4979e-01,
         -8.8567e-02,  1.8119e-01, -1.0042e-01,  1.8204e-01,  1.4703e-01,
         -2.4220e-01, -1.9150e-02, -1.7218e-01,  1.7986e-01,  3.0321e-01,
         -1.8258e-02],
        [ 3.1207e-01, -1.0424e-02,  3.5412e-01, -1.2353e-01,  6.2697e-03,
         -1.5885e-01, -1.1525e-01, -1.8289e-01, -1.9910e-01,  3.6548e-02,
          5.0316e-02,  3.5796e-03, -1.1012e-01,  1.8808e-01, -2.5853e-01,
          1.0118e-01],
        [-1.1003e-01,  1.1851e-01,  3.1224e-01, -2.9897e-01, -2.8237e-01,
         -2.5614e-01, -3.4236e-02, -2.2420e-01, -1.5269e-01, -1.6503e-01,
          5.9191e-04, -1.2403e-02,  2.1599e-01, -1.1788e-01, -5.9385e-02,
          3.1131e-01],
        [-3.0586e-02,  1.0400e-01,  2.4170e-01, -1.7819e-01,  3.3915e-02,
         -2.8215e-01, -8.6505e-02, -3.0598e-02,  1.1833e-01, -2.4753e-01,
         -9.7262e-02, -1.4742e-02, -1.4105e-01,  1.1828e-01, -2.5932e-01,
          3.6236e-02],
        [-2.2112e-01,  1.0626e-01, -3.7479e-02, -8.2582e-02, -1.7272e-02,
          8.9888e-02, -3.5372e-02,  1.6207e-01,  1.9191e-01, -6.8686e-02,
          1.4419e-01,  6.6086e-02, -1.8356e-01, -3.2326e-02,  8.6715e-02,
         -1.4037e-01],
        [-2.8821e-01,  2.9385e-01, -1.8115e-03, -9.9592e-02, -1.2571e-01,
          3.6210e-01,  1.5535e-01,  5.0678e-02,  2.8081e-01,  1.9182e-01,
          1.8165e-03,  7.7556e-02, -1.2361e-01,  1.5710e-01, -8.7391e-02,
         -2.7268e-01],
        [-6.8350e-02,  5.6404e-02,  2.8581e-02,  2.9018e-02,  9.2464e-02,
          6.5924e-02,  2.9539e-01,  8.7460e-02,  9.8737e-02,  2.9195e-01,
          1.6219e-01,  1.2563e-01, -3.5409e-01, -2.1066e-01,  6.4261e-03,
         -1.5933e-01],
        [ 2.4595e-01,  3.0938e-02,  8.6603e-02, -8.9524e-02, -3.3493e-04,
          1.0719e-01,  2.1171e-02, -2.2230e-01, -2.2998e-01, -2.8298e-02,
          1.2141e-02, -5.5592e-02, -1.4109e-01,  1.0655e-01, -1.4095e-01,
         -4.7603e-02],
        [ 1.5471e-01,  1.5057e-01,  3.1911e-01,  4.5913e-02, -2.4244e-01,
          3.0004e-02,  2.2126e-02, -1.6643e-02, -1.5996e-01, -1.1108e-01,
         -1.0531e-01,  5.2717e-02,  6.2669e-02,  3.1182e-02, -3.0005e-01,
          1.9298e-01],
        [-3.1871e-01, -8.9315e-02, -1.6646e-02, -1.0125e-01,  3.0096e-01,
          3.5631e-01,  3.3467e-02,  6.5233e-02, -8.7729e-02,  1.2687e-01,
          1.4043e-02, -2.5161e-01, -2.9763e-02, -8.2229e-02, -1.4573e-02,
         -1.1313e-01],
        [-1.3978e-01, -2.6411e-01,  1.3894e-01,  1.4884e-01, -1.9911e-01,
          5.3673e-02, -8.0393e-02, -2.0619e-01, -9.4801e-02,  1.5632e-02,
          3.4799e-02,  3.2699e-01,  5.5397e-02, -1.0279e-01,  1.8051e-01,
          2.5402e-02],
        [ 2.6453e-01,  7.2231e-02,  1.5266e-01, -2.9827e-01, -2.9740e-01,
          5.0513e-03, -4.3382e-02,  4.5725e-02, -3.1628e-01, -1.4035e-01,
          2.5912e-01,  2.3996e-01,  3.1158e-01,  2.6204e-01, -1.1443e-01,
         -6.8240e-02],
        [-2.5063e-01,  1.7633e-01, -2.0236e-01,  8.8481e-02,  9.1946e-02,
          2.6294e-01,  2.3944e-01,  2.3963e-01,  1.0075e-01,  2.3950e-01,
         -1.2280e-01, -2.0541e-01, -1.4142e-01, -2.0546e-01,  2.6662e-01,
         -1.3555e-01],
        [ 1.6499e-01, -8.9320e-02,  9.2129e-02, -2.3251e-01, -1.1570e-01,
         -3.1822e-01, -2.0983e-01,  9.8546e-02, -3.2727e-01, -5.9696e-02,
          8.1765e-02, -1.4764e-01,  1.4144e-01,  2.2097e-01,  8.5102e-02,
          1.3813e-01],
        [ 3.1309e-01, -9.0019e-02,  2.1691e-01, -3.0416e-02, -2.4328e-01,
         -1.7782e-01, -2.8939e-01,  8.7763e-02,  1.6330e-02, -2.1945e-01,
          2.7727e-02,  1.8535e-01, -1.0751e-01,  8.0157e-02,  5.7702e-02,
          1.4827e-01],
        [-1.2673e-01,  2.5485e-01,  2.9048e-03, -1.3084e-01,  2.0705e-01,
         -8.6471e-02,  2.4493e-01,  3.0984e-01,  1.1950e-01,  1.8558e-02,
         -1.8547e-01, -2.1988e-01, -1.4821e-01, -1.7112e-01,  3.0821e-01,
         -2.0770e-01],
        [ 5.8582e-03, -1.4951e-01,  2.5028e-02,  3.0114e-01, -1.3109e-01,
          3.8962e-02,  1.5687e-01, -1.4558e-01, -6.7544e-02,  1.8463e-01,
          2.3743e-01, -1.7622e-01, -9.8461e-02, -3.0038e-01, -1.9983e-01,
          1.2464e-01],
        [ 3.1492e-01, -1.6500e-01,  7.2400e-03, -1.0706e-01,  6.5659e-02,
         -3.5070e-01, -2.4035e-01, -1.7954e-01, -2.0065e-01, -1.0786e-01,
          2.2961e-01,  1.6040e-01, -1.2661e-01,  2.9362e-01,  1.5179e-01,
          1.7818e-01],
        [ 2.1903e-01,  9.8882e-03,  3.0310e-01, -3.2193e-01, -2.0026e-01,
         -1.3863e-01, -1.4315e-01, -2.5726e-01, -3.2406e-01, -2.8602e-01,
          3.5843e-02,  3.1457e-01,  2.6280e-01,  1.2941e-01, -2.0274e-01,
         -8.3844e-03],
        [ 1.3475e-01, -3.2628e-01,  1.0289e-01, -4.8126e-02,  1.6970e-01,
         -1.8136e-01,  1.3623e-01, -8.5718e-02, -2.7278e-01,  1.2767e-01,
          2.6782e-01, -8.4673e-02, -3.8617e-02,  1.8889e-01, -2.0843e-01,
          2.7762e-01],
        [-1.3361e-02, -1.7024e-01,  3.7967e-02,  1.4139e-01, -1.4753e-01,
         -1.5806e-01,  4.2605e-02, -2.7129e-01, -1.0634e-01, -2.9965e-01,
         -2.1069e-01,  5.1491e-02,  1.2864e-01,  2.8302e-01, -3.0208e-01,
          3.1128e-02],
        [ 1.7068e-01,  4.0214e-03,  2.5422e-01, -2.9332e-01, -1.1001e-01,
         -5.3475e-02, -3.0283e-01,  2.7833e-02, -3.3033e-01,  5.3517e-02,
          9.8431e-02,  3.6107e-02,  1.8466e-01,  2.7436e-01,  1.3706e-01,
          2.5328e-01],
        [-2.5801e-01,  1.6550e-01,  7.2088e-02,  1.4271e-01,  2.1959e-01,
         -3.6926e-02,  2.8609e-01,  9.7619e-02, -1.2577e-01,  4.5405e-02,
          1.5252e-01, -2.0171e-01, -1.5456e-01, -1.6967e-01, -7.8914e-02,
         -6.5549e-02],
        [ 2.5583e-01, -4.6984e-02,  9.2526e-02, -7.7880e-02, -2.4239e-01,
         -2.4456e-01, -9.2312e-02, -2.9575e-01,  3.0222e-02, -6.6683e-02,
          9.1432e-02,  9.2735e-02,  3.0839e-01,  2.9630e-01,  5.4090e-02,
          2.2648e-01],
        [-2.2344e-01,  1.8987e-01, -2.7440e-01,  1.9793e-01, -1.3043e-01,
          1.0562e-01,  2.8081e-01,  2.6207e-01,  3.1019e-01,  1.8386e-01,
          1.0918e-01, -3.7037e-02,  8.2346e-02,  7.2544e-02,  1.1182e-01,
         -1.8558e-01],
        [-2.3023e-01,  3.2957e-02,  6.6893e-03, -3.8797e-02,  1.2664e-01,
          3.3374e-01,  3.1959e-01, -8.2548e-02,  1.6921e-01,  2.7074e-01,
         -2.8754e-01,  4.7772e-02, -2.6042e-01, -2.5015e-01, -4.5634e-02,
         -2.0110e-01],
        [-4.2975e-04, -2.1529e-02,  2.0374e-01, -1.3123e-03,  8.7463e-02,
         -2.6734e-01, -3.3592e-01, -3.0078e-01, -2.3408e-01, -2.2018e-01,
          1.3619e-01, -7.7656e-02, -7.9070e-02,  2.2995e-01, -2.4061e-01,
          1.4939e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1500,  0.0123,  0.0733, -0.0901,  0.0286, -0.1130,  0.0988,  0.1452,
        -0.1203,  0.0247,  0.0660,  0.1287,  0.2081,  0.0734,  0.0554,  0.0344,
        -0.1071, -0.0261,  0.0284, -0.0383, -0.0513,  0.0049, -0.0669,  0.0109,
        -0.1773,  0.1992,  0.0994,  0.0958, -0.1036, -0.2128,  0.1066, -0.0337],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0814,  0.1665, -0.1045, -0.1255,  0.1621,  0.2191, -0.1675, -0.2691,
         -0.1526,  0.2063,  0.1295,  0.2539, -0.0723, -0.2636,  0.1686, -0.0832,
         -0.1869,  0.2244, -0.1022, -0.1328,  0.2737,  0.1216, -0.2580, -0.2756,
         -0.1887, -0.1990, -0.2058,  0.2076, -0.2359,  0.2743,  0.1727, -0.1142]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0107,  0.0665,  0.0893,  ...,  0.0114, -0.1712, -0.1137],
        [-0.1085, -0.0703,  0.1208,  ..., -0.0190, -0.2293,  0.0871],
        [-0.0416,  0.0342,  0.0862,  ...,  0.1370,  0.1292,  0.0345],
        ...,
        [ 0.1048, -0.1136, -0.0138,  ..., -0.0913, -0.0712, -0.1180],
        [ 0.0758, -0.1732, -0.0440,  ..., -0.1453,  0.0388,  0.1557],
        [-0.1748,  0.1116,  0.0618,  ..., -0.0562, -0.1546, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0297,  0.0360, -0.0924, -0.1464, -0.0791,  0.0531, -0.0944,  0.0495,
        -0.0083,  0.0622,  0.0210,  0.0102, -0.0441,  0.0655, -0.0454, -0.0124,
         0.0437, -0.1771, -0.0637,  0.0644, -0.0456,  0.0479,  0.1183,  0.0056,
        -0.0768,  0.1130,  0.0495, -0.0922,  0.0295,  0.1886,  0.1686, -0.1290],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1278, -0.1142, -0.1478,  ...,  0.0189, -0.1099,  0.1115],
        [-0.1353,  0.0465,  0.0277,  ...,  0.1074, -0.1033,  0.1046],
        [ 0.0591, -0.1203, -0.0912,  ..., -0.0969,  0.0874,  0.1190],
        ...,
        [ 0.0618,  0.0258,  0.1539,  ...,  0.0978, -0.1239,  0.2081],
        [ 0.0597, -0.0648, -0.0167,  ...,  0.1921,  0.1311, -0.1113],
        [ 0.0631, -0.0539,  0.1519,  ...,  0.1992,  0.0570,  0.0023]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0969,  0.1344, -0.0255, -0.0764, -0.0374, -0.0615, -0.0380, -0.0821,
         0.1334, -0.1520,  0.1258, -0.1240,  0.1777,  0.0802, -0.1381,  0.0865,
        -0.1394, -0.1690,  0.0439, -0.0209,  0.0133,  0.1102, -0.1923,  0.2064,
        -0.0663, -0.0106,  0.0860, -0.0438, -0.1210, -0.0723,  0.0989,  0.0217],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2077,  0.1262, -0.1757, -0.1560,  0.0190,  0.0250, -0.0869,  0.0120,
          0.1178, -0.1486, -0.0558,  0.0810,  0.0830,  0.0746,  0.1170,  0.0961,
         -0.2076, -0.2109,  0.0497,  0.0426, -0.1148, -0.0975, -0.1918,  0.0703,
          0.1348,  0.2154, -0.1824,  0.1479, -0.0937, -0.1970,  0.1525,  0.1897]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0218], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5966e-01,  3.2378e-01,  4.9772e-02, -7.9186e-02,  6.1587e-02,
          1.0627e-01,  2.3211e-01, -1.1040e-01,  1.1178e-01,  1.9293e-01,
          1.0731e-01, -8.1940e-02, -2.2479e-01, -3.1043e-01,  1.9581e-01,
          1.2251e-01],
        [-1.8611e-01, -1.3082e-01, -4.1230e-02, -7.5408e-02, -1.0603e-01,
          1.8348e-01,  8.6735e-02,  8.6832e-02,  3.2560e-01,  6.5803e-02,
          1.0779e-01, -1.8991e-01,  8.0797e-02,  6.4702e-03,  2.7962e-01,
         -2.0200e-02],
        [ 1.1781e-02,  2.2274e-02,  3.1772e-01, -5.6549e-02,  1.5682e-02,
         -2.7688e-01,  3.5435e-02, -3.3848e-01,  1.2131e-01, -3.6657e-03,
          7.5952e-03, -1.3596e-01,  3.2570e-01,  2.6471e-01,  1.3570e-01,
          1.9824e-01],
        [ 2.0587e-01, -1.6885e-01,  2.2422e-02, -7.1286e-03,  2.1195e-02,
         -1.3479e-01, -7.8160e-02, -2.6418e-02, -3.4771e-01, -3.3732e-01,
          1.7688e-02,  2.9407e-01,  2.3770e-01, -1.6142e-01, -1.4446e-01,
          9.4768e-02],
        [-2.5110e-02,  2.9376e-01, -1.0503e-01, -9.8872e-02,  6.8356e-02,
          1.6424e-02, -4.5927e-02,  2.4075e-01,  6.3508e-02,  2.2472e-01,
          1.4236e-01, -8.5583e-02,  3.4893e-02, -1.8466e-01,  1.9131e-01,
         -9.2604e-02],
        [ 5.8273e-02,  3.3253e-01, -3.0004e-01,  3.3441e-01,  2.4978e-01,
         -8.8399e-02,  1.8122e-01, -1.0023e-01,  1.8192e-01,  1.4661e-01,
         -2.3968e-01, -1.9334e-02, -1.7233e-01,  1.8014e-01,  3.0357e-01,
         -1.7935e-02],
        [ 3.1180e-01, -1.1032e-02,  3.5362e-01, -1.2268e-01,  6.0562e-03,
         -1.5916e-01, -1.1532e-01, -1.8321e-01, -1.9900e-01,  3.6990e-02,
          4.8443e-02,  3.9601e-03, -1.0977e-01,  1.8789e-01, -2.5624e-01,
          1.0076e-01],
        [-1.1006e-01,  1.1778e-01,  3.1198e-01, -2.9838e-01, -2.8278e-01,
         -2.5656e-01, -3.4524e-02, -2.2471e-01, -1.5284e-01, -1.6479e-01,
         -1.2962e-03, -1.1893e-02,  2.1646e-01, -1.1787e-01, -5.7115e-02,
          3.1116e-01],
        [-3.1299e-02,  1.0442e-01,  2.4084e-01, -1.7719e-01,  3.4325e-02,
         -2.8169e-01, -8.6055e-02, -3.0224e-02,  1.1898e-01, -2.4661e-01,
         -9.7319e-02, -1.5205e-02, -1.4159e-01,  1.1737e-01, -2.5901e-01,
          3.5474e-02],
        [-2.2061e-01,  1.0605e-01, -3.6812e-02, -8.3452e-02, -1.7600e-02,
          8.9741e-02, -3.5657e-02,  1.6189e-01,  1.9145e-01, -6.9389e-02,
          1.4391e-01,  6.6280e-02, -1.8330e-01, -3.1684e-02,  8.6689e-02,
         -1.3978e-01],
        [-2.8763e-01,  2.9381e-01, -1.0128e-03, -1.0059e-01, -1.2585e-01,
          3.6202e-01,  1.5502e-01,  5.0540e-02,  2.8031e-01,  1.9111e-01,
          4.0159e-03,  7.7641e-02, -1.2339e-01,  1.5768e-01, -8.7120e-02,
         -2.7194e-01],
        [-6.8070e-02,  5.6174e-02,  2.9072e-02,  2.8464e-02,  9.2720e-02,
          6.5765e-02,  2.9542e-01,  8.7505e-02,  9.8596e-02,  2.9144e-01,
          1.6164e-01,  1.2576e-01, -3.5383e-01, -2.1021e-01,  6.4815e-03,
         -1.5894e-01],
        [ 2.4458e-01,  3.1947e-02,  8.5082e-02, -8.7803e-02,  9.1717e-04,
          1.0812e-01,  2.2480e-02, -2.2122e-01, -2.2850e-01, -2.6740e-02,
          1.0968e-02, -5.6594e-02, -1.4234e-01,  1.0492e-01, -1.4021e-01,
         -4.9037e-02],
        [ 1.5447e-01,  1.5036e-01,  3.1868e-01,  4.6575e-02, -2.4251e-01,
          2.9895e-02,  2.2085e-02, -1.6810e-02, -1.5984e-01, -1.1064e-01,
         -1.0750e-01,  5.2844e-02,  6.2751e-02,  3.0861e-02, -3.0038e-01,
          1.9265e-01],
        [-3.1826e-01, -8.9274e-02, -1.6008e-02, -1.0215e-01,  3.0063e-01,
          3.5640e-01,  3.3214e-02,  6.5152e-02, -8.8140e-02,  1.2625e-01,
          1.6206e-02, -2.5163e-01, -2.9720e-02, -8.1755e-02, -1.4292e-02,
         -1.1255e-01],
        [-1.4045e-01, -2.6359e-01,  1.3815e-01,  1.4987e-01, -1.9838e-01,
          5.4045e-02, -7.9922e-02, -2.0578e-01, -9.4102e-02,  1.6574e-02,
          3.4515e-02,  3.2652e-01,  5.4874e-02, -1.0375e-01,  1.8096e-01,
          2.4729e-02],
        [ 2.6445e-01,  7.1904e-02,  1.5236e-01, -2.9775e-01, -2.9779e-01,
          4.8910e-03, -4.3638e-02,  4.5353e-02, -3.1638e-01, -1.4003e-01,
          2.5939e-01,  2.4020e-01,  3.1176e-01,  2.6185e-01, -1.1481e-01,
         -6.8415e-02],
        [-2.5089e-01,  1.7711e-01, -2.0233e-01,  8.8013e-02,  9.2228e-02,
          2.6377e-01,  2.3985e-01,  2.4026e-01,  1.0101e-01,  2.3950e-01,
         -1.2130e-01, -2.0617e-01, -1.4214e-01, -2.0574e-01,  2.6461e-01,
         -1.3565e-01],
        [ 1.6424e-01, -8.9359e-02,  9.1181e-02, -2.3135e-01, -1.1561e-01,
         -3.1798e-01, -2.0941e-01,  9.8710e-02, -3.2669e-01, -5.8846e-02,
          7.9416e-02, -1.4779e-01,  1.4118e-01,  2.2027e-01,  8.4903e-02,
          1.3722e-01],
        [ 3.1264e-01, -9.0116e-02,  2.1625e-01, -2.9605e-02, -2.4352e-01,
         -1.7765e-01, -2.8931e-01,  8.7697e-02,  1.6569e-02, -2.1881e-01,
          2.6446e-02,  1.8530e-01, -1.0766e-01,  7.9661e-02,  5.7486e-02,
          1.4769e-01],
        [-1.2682e-01,  2.5507e-01,  2.9868e-03, -1.3122e-01,  2.0690e-01,
         -8.5973e-02,  2.4513e-01,  3.1011e-01,  1.1955e-01,  1.8409e-02,
         -1.8635e-01, -2.2023e-01, -1.4854e-01, -1.7110e-01,  3.0863e-01,
         -2.0772e-01],
        [ 6.0778e-03, -1.4957e-01,  2.5384e-02,  3.0057e-01, -1.3133e-01,
          3.8918e-02,  1.5688e-01, -1.4555e-01, -6.7723e-02,  1.8411e-01,
          2.3733e-01, -1.7613e-01, -9.8374e-02, -2.9988e-01, -1.9991e-01,
          1.2485e-01],
        [ 3.1498e-01, -1.6558e-01,  7.0408e-03, -1.0656e-01,  6.5228e-02,
         -3.5112e-01, -2.4067e-01, -1.8004e-01, -2.0084e-01, -1.0768e-01,
          2.2744e-01,  1.6087e-01, -1.2621e-01,  2.9363e-01,  1.5404e-01,
          1.7811e-01],
        [ 2.1944e-01,  1.2143e-02,  3.0320e-01, -3.2175e-01, -1.9805e-01,
         -1.3930e-01, -1.4380e-01, -2.5809e-01, -3.2460e-01, -2.8616e-01,
          3.3944e-02,  3.1533e-01,  2.6343e-01,  1.2979e-01, -2.0069e-01,
         -8.1189e-03],
        [ 1.3431e-01, -3.2618e-01,  1.0226e-01, -4.7290e-02,  1.6989e-01,
         -1.8127e-01,  1.3643e-01, -8.5632e-02, -2.7241e-01,  1.2831e-01,
          2.6815e-01, -8.4782e-02, -3.8797e-02,  1.8833e-01, -2.0851e-01,
          2.7708e-01],
        [-1.3518e-02, -1.7042e-01,  3.7621e-02,  1.4212e-01, -1.4704e-01,
         -1.5865e-01,  4.2734e-02, -2.7132e-01, -1.0608e-01, -2.9930e-01,
         -2.1178e-01,  5.1796e-02,  1.2892e-01,  2.8284e-01, -3.0260e-01,
          3.0861e-02],
        [ 1.7067e-01,  3.4041e-03,  2.5397e-01, -2.9286e-01, -1.1072e-01,
         -5.3655e-02, -3.0323e-01,  2.7268e-02, -3.3059e-01,  5.3755e-02,
          9.7623e-02,  3.6492e-02,  1.8498e-01,  2.7429e-01,  1.3650e-01,
          2.5316e-01],
        [-2.5758e-01,  1.6520e-01,  7.2677e-02,  1.4203e-01,  2.1960e-01,
         -3.7200e-02,  2.8597e-01,  9.7529e-02, -1.2607e-01,  4.4768e-02,
          1.5232e-01, -2.0146e-01, -1.5422e-01, -1.6907e-01, -7.9042e-02,
         -6.5043e-02],
        [ 2.5590e-01, -4.7343e-02,  9.2293e-02, -7.7421e-02, -2.4281e-01,
         -2.4495e-01, -9.2578e-02, -2.9617e-01,  3.0068e-02, -6.6521e-02,
          8.9449e-02,  9.3134e-02,  3.0865e-01,  2.9632e-01,  5.3405e-02,
          2.2638e-01],
        [-2.2356e-01,  1.9068e-01, -2.7424e-01,  1.9744e-01, -1.2981e-01,
          1.0616e-01,  2.8123e-01,  2.6272e-01,  3.1048e-01,  1.8375e-01,
          1.1107e-01, -3.7686e-02,  8.1765e-02,  7.2389e-02,  1.0970e-01,
         -1.8556e-01],
        [-2.3010e-01,  3.3390e-02,  7.0735e-03, -3.9487e-02,  1.2683e-01,
          3.3406e-01,  3.1972e-01, -8.2220e-02,  1.6919e-01,  2.7041e-01,
         -2.8533e-01,  4.7423e-02, -2.6069e-01, -2.5000e-01, -4.5036e-02,
         -2.0082e-01],
        [-8.7568e-04, -2.1731e-02,  2.0303e-01, -3.4556e-04,  8.7387e-02,
         -2.6741e-01, -3.3579e-01, -3.0087e-01, -2.3376e-01, -2.1956e-01,
          1.3389e-01, -7.7547e-02, -7.9062e-02,  2.2952e-01, -2.4099e-01,
          1.4877e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1525,  0.0125,  0.0752, -0.0914,  0.0297, -0.1124,  0.0983,  0.1448,
        -0.1207,  0.0233,  0.0671,  0.1284,  0.2092,  0.0728,  0.0532,  0.0357,
        -0.1063, -0.0258,  0.0299, -0.0380, -0.0536,  0.0050, -0.0682,  0.0093,
        -0.1762,  0.2016,  0.0999,  0.0959, -0.1021, -0.2120,  0.1073, -0.0323],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0805,  0.1654, -0.1036, -0.1249,  0.1610,  0.2183, -0.1670, -0.2687,
         -0.1514,  0.2051,  0.1289,  0.2531, -0.0702, -0.2626,  0.1678, -0.0820,
         -0.1863,  0.2243, -0.1015, -0.1321,  0.2734,  0.1210, -0.2577, -0.2755,
         -0.1876, -0.1985, -0.2054,  0.2067, -0.2355,  0.2740,  0.1723, -0.1137]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0110,  0.0668,  0.0894,  ...,  0.0111, -0.1713, -0.1137],
        [-0.1090, -0.0697,  0.1211,  ..., -0.0180, -0.2297,  0.0871],
        [-0.0412,  0.0339,  0.0857,  ...,  0.1382,  0.1301,  0.0345],
        ...,
        [ 0.1050, -0.1138, -0.0139,  ..., -0.0913, -0.0710, -0.1180],
        [ 0.0761, -0.1735, -0.0441,  ..., -0.1444,  0.0392,  0.1557],
        [-0.1751,  0.1119,  0.0619,  ..., -0.0562, -0.1546, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0291,  0.0351, -0.0913, -0.1469, -0.0801,  0.0533, -0.0935,  0.0485,
        -0.0071,  0.0617,  0.0196,  0.0111, -0.0448,  0.0657, -0.0447, -0.0113,
         0.0426, -0.1779, -0.0646,  0.0649, -0.0448,  0.0481,  0.1192,  0.0064,
        -0.0769,  0.1134,  0.0503, -0.0937,  0.0288,  0.1892,  0.1693, -0.1296],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1272, -0.1146, -0.1464,  ...,  0.0194, -0.1094,  0.1111],
        [-0.1355,  0.0465,  0.0288,  ...,  0.1075, -0.1032,  0.1046],
        [ 0.0594, -0.1202, -0.0924,  ..., -0.0971,  0.0871,  0.1191],
        ...,
        [ 0.0624,  0.0262,  0.1526,  ...,  0.0972, -0.1244,  0.2085],
        [ 0.0595, -0.0648, -0.0155,  ...,  0.1921,  0.1314, -0.1113],
        [ 0.0625, -0.0543,  0.1532,  ...,  0.1998,  0.0576,  0.0019]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0978,  0.1349, -0.0262, -0.0768, -0.0372, -0.0617, -0.0384, -0.0811,
         0.1341, -0.1528,  0.1253, -0.1233,  0.1781,  0.0808, -0.1375,  0.0868,
        -0.1404, -0.1700,  0.0441, -0.0204,  0.0129,  0.1097, -0.1928,  0.2071,
        -0.0659, -0.0095,  0.0851, -0.0432, -0.1215, -0.0732,  0.0994,  0.0226],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2074,  0.1258, -0.1753, -0.1553,  0.0185,  0.0240, -0.0864,  0.0132,
          0.1177, -0.1484, -0.0554,  0.0805,  0.0827,  0.0745,  0.1166,  0.0957,
         -0.2074, -0.2107,  0.0493,  0.0437, -0.1143, -0.0970, -0.1910,  0.0703,
          0.1342,  0.2153, -0.1822,  0.1471, -0.0931, -0.1967,  0.1520,  0.1894]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0221], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5966e-01,  3.2378e-01,  4.9772e-02, -7.9186e-02,  6.1587e-02,
          1.0627e-01,  2.3211e-01, -1.1040e-01,  1.1178e-01,  1.9293e-01,
          1.0731e-01, -8.1940e-02, -2.2479e-01, -3.1043e-01,  1.9581e-01,
          1.2251e-01],
        [-1.8611e-01, -1.3082e-01, -4.1230e-02, -7.5408e-02, -1.0603e-01,
          1.8348e-01,  8.6735e-02,  8.6832e-02,  3.2560e-01,  6.5803e-02,
          1.0779e-01, -1.8991e-01,  8.0797e-02,  6.4702e-03,  2.7962e-01,
         -2.0200e-02],
        [ 1.1781e-02,  2.2274e-02,  3.1772e-01, -5.6549e-02,  1.5682e-02,
         -2.7688e-01,  3.5435e-02, -3.3848e-01,  1.2131e-01, -3.6657e-03,
          7.5952e-03, -1.3596e-01,  3.2570e-01,  2.6471e-01,  1.3570e-01,
          1.9824e-01],
        [ 2.0587e-01, -1.6885e-01,  2.2422e-02, -7.1286e-03,  2.1195e-02,
         -1.3479e-01, -7.8160e-02, -2.6418e-02, -3.4771e-01, -3.3732e-01,
          1.7688e-02,  2.9407e-01,  2.3770e-01, -1.6142e-01, -1.4446e-01,
          9.4768e-02],
        [-2.5110e-02,  2.9376e-01, -1.0503e-01, -9.8872e-02,  6.8356e-02,
          1.6424e-02, -4.5927e-02,  2.4075e-01,  6.3508e-02,  2.2472e-01,
          1.4236e-01, -8.5583e-02,  3.4893e-02, -1.8466e-01,  1.9131e-01,
         -9.2604e-02],
        [ 5.8273e-02,  3.3253e-01, -3.0004e-01,  3.3441e-01,  2.4978e-01,
         -8.8399e-02,  1.8122e-01, -1.0023e-01,  1.8192e-01,  1.4661e-01,
         -2.3968e-01, -1.9334e-02, -1.7233e-01,  1.8014e-01,  3.0357e-01,
         -1.7935e-02],
        [ 3.1180e-01, -1.1032e-02,  3.5362e-01, -1.2268e-01,  6.0562e-03,
         -1.5916e-01, -1.1532e-01, -1.8321e-01, -1.9900e-01,  3.6990e-02,
          4.8443e-02,  3.9601e-03, -1.0977e-01,  1.8789e-01, -2.5624e-01,
          1.0076e-01],
        [-1.1006e-01,  1.1778e-01,  3.1198e-01, -2.9838e-01, -2.8278e-01,
         -2.5656e-01, -3.4524e-02, -2.2471e-01, -1.5284e-01, -1.6479e-01,
         -1.2962e-03, -1.1893e-02,  2.1646e-01, -1.1787e-01, -5.7115e-02,
          3.1116e-01],
        [-3.1299e-02,  1.0442e-01,  2.4084e-01, -1.7719e-01,  3.4325e-02,
         -2.8169e-01, -8.6055e-02, -3.0224e-02,  1.1898e-01, -2.4661e-01,
         -9.7319e-02, -1.5205e-02, -1.4159e-01,  1.1737e-01, -2.5901e-01,
          3.5474e-02],
        [-2.2061e-01,  1.0605e-01, -3.6812e-02, -8.3452e-02, -1.7600e-02,
          8.9741e-02, -3.5657e-02,  1.6189e-01,  1.9145e-01, -6.9389e-02,
          1.4391e-01,  6.6280e-02, -1.8330e-01, -3.1684e-02,  8.6689e-02,
         -1.3978e-01],
        [-2.8763e-01,  2.9381e-01, -1.0128e-03, -1.0059e-01, -1.2585e-01,
          3.6202e-01,  1.5502e-01,  5.0540e-02,  2.8031e-01,  1.9111e-01,
          4.0159e-03,  7.7641e-02, -1.2339e-01,  1.5768e-01, -8.7120e-02,
         -2.7194e-01],
        [-6.8070e-02,  5.6174e-02,  2.9072e-02,  2.8464e-02,  9.2720e-02,
          6.5765e-02,  2.9542e-01,  8.7505e-02,  9.8596e-02,  2.9144e-01,
          1.6164e-01,  1.2576e-01, -3.5383e-01, -2.1021e-01,  6.4815e-03,
         -1.5894e-01],
        [ 2.4458e-01,  3.1947e-02,  8.5082e-02, -8.7803e-02,  9.1717e-04,
          1.0812e-01,  2.2480e-02, -2.2122e-01, -2.2850e-01, -2.6740e-02,
          1.0968e-02, -5.6594e-02, -1.4234e-01,  1.0492e-01, -1.4021e-01,
         -4.9037e-02],
        [ 1.5447e-01,  1.5036e-01,  3.1868e-01,  4.6575e-02, -2.4251e-01,
          2.9895e-02,  2.2085e-02, -1.6810e-02, -1.5984e-01, -1.1064e-01,
         -1.0750e-01,  5.2844e-02,  6.2751e-02,  3.0861e-02, -3.0038e-01,
          1.9265e-01],
        [-3.1826e-01, -8.9274e-02, -1.6008e-02, -1.0215e-01,  3.0063e-01,
          3.5640e-01,  3.3214e-02,  6.5152e-02, -8.8140e-02,  1.2625e-01,
          1.6206e-02, -2.5163e-01, -2.9720e-02, -8.1755e-02, -1.4292e-02,
         -1.1255e-01],
        [-1.4045e-01, -2.6359e-01,  1.3815e-01,  1.4987e-01, -1.9838e-01,
          5.4045e-02, -7.9922e-02, -2.0578e-01, -9.4102e-02,  1.6574e-02,
          3.4515e-02,  3.2652e-01,  5.4874e-02, -1.0375e-01,  1.8096e-01,
          2.4729e-02],
        [ 2.6445e-01,  7.1904e-02,  1.5236e-01, -2.9775e-01, -2.9779e-01,
          4.8910e-03, -4.3638e-02,  4.5353e-02, -3.1638e-01, -1.4003e-01,
          2.5939e-01,  2.4020e-01,  3.1176e-01,  2.6185e-01, -1.1481e-01,
         -6.8415e-02],
        [-2.5089e-01,  1.7711e-01, -2.0233e-01,  8.8013e-02,  9.2228e-02,
          2.6377e-01,  2.3985e-01,  2.4026e-01,  1.0101e-01,  2.3950e-01,
         -1.2130e-01, -2.0617e-01, -1.4214e-01, -2.0574e-01,  2.6461e-01,
         -1.3565e-01],
        [ 1.6424e-01, -8.9359e-02,  9.1181e-02, -2.3135e-01, -1.1561e-01,
         -3.1798e-01, -2.0941e-01,  9.8710e-02, -3.2669e-01, -5.8846e-02,
          7.9416e-02, -1.4779e-01,  1.4118e-01,  2.2027e-01,  8.4903e-02,
          1.3722e-01],
        [ 3.1264e-01, -9.0116e-02,  2.1625e-01, -2.9605e-02, -2.4352e-01,
         -1.7765e-01, -2.8931e-01,  8.7697e-02,  1.6569e-02, -2.1881e-01,
          2.6446e-02,  1.8530e-01, -1.0766e-01,  7.9661e-02,  5.7486e-02,
          1.4769e-01],
        [-1.2682e-01,  2.5507e-01,  2.9868e-03, -1.3122e-01,  2.0690e-01,
         -8.5973e-02,  2.4513e-01,  3.1011e-01,  1.1955e-01,  1.8409e-02,
         -1.8635e-01, -2.2023e-01, -1.4854e-01, -1.7110e-01,  3.0863e-01,
         -2.0772e-01],
        [ 6.0778e-03, -1.4957e-01,  2.5384e-02,  3.0057e-01, -1.3133e-01,
          3.8918e-02,  1.5688e-01, -1.4555e-01, -6.7723e-02,  1.8411e-01,
          2.3733e-01, -1.7613e-01, -9.8374e-02, -2.9988e-01, -1.9991e-01,
          1.2485e-01],
        [ 3.1498e-01, -1.6558e-01,  7.0408e-03, -1.0656e-01,  6.5228e-02,
         -3.5112e-01, -2.4067e-01, -1.8004e-01, -2.0084e-01, -1.0768e-01,
          2.2744e-01,  1.6087e-01, -1.2621e-01,  2.9363e-01,  1.5404e-01,
          1.7811e-01],
        [ 2.1944e-01,  1.2143e-02,  3.0320e-01, -3.2175e-01, -1.9805e-01,
         -1.3930e-01, -1.4380e-01, -2.5809e-01, -3.2460e-01, -2.8616e-01,
          3.3944e-02,  3.1533e-01,  2.6343e-01,  1.2979e-01, -2.0069e-01,
         -8.1189e-03],
        [ 1.3431e-01, -3.2618e-01,  1.0226e-01, -4.7290e-02,  1.6989e-01,
         -1.8127e-01,  1.3643e-01, -8.5632e-02, -2.7241e-01,  1.2831e-01,
          2.6815e-01, -8.4782e-02, -3.8797e-02,  1.8833e-01, -2.0851e-01,
          2.7708e-01],
        [-1.3518e-02, -1.7042e-01,  3.7621e-02,  1.4212e-01, -1.4704e-01,
         -1.5865e-01,  4.2734e-02, -2.7132e-01, -1.0608e-01, -2.9930e-01,
         -2.1178e-01,  5.1796e-02,  1.2892e-01,  2.8284e-01, -3.0260e-01,
          3.0861e-02],
        [ 1.7067e-01,  3.4041e-03,  2.5397e-01, -2.9286e-01, -1.1072e-01,
         -5.3655e-02, -3.0323e-01,  2.7268e-02, -3.3059e-01,  5.3755e-02,
          9.7623e-02,  3.6492e-02,  1.8498e-01,  2.7429e-01,  1.3650e-01,
          2.5316e-01],
        [-2.5758e-01,  1.6520e-01,  7.2677e-02,  1.4203e-01,  2.1960e-01,
         -3.7200e-02,  2.8597e-01,  9.7529e-02, -1.2607e-01,  4.4768e-02,
          1.5232e-01, -2.0146e-01, -1.5422e-01, -1.6907e-01, -7.9042e-02,
         -6.5043e-02],
        [ 2.5590e-01, -4.7343e-02,  9.2293e-02, -7.7421e-02, -2.4281e-01,
         -2.4495e-01, -9.2578e-02, -2.9617e-01,  3.0068e-02, -6.6521e-02,
          8.9449e-02,  9.3134e-02,  3.0865e-01,  2.9632e-01,  5.3405e-02,
          2.2638e-01],
        [-2.2356e-01,  1.9068e-01, -2.7424e-01,  1.9744e-01, -1.2981e-01,
          1.0616e-01,  2.8123e-01,  2.6272e-01,  3.1048e-01,  1.8375e-01,
          1.1107e-01, -3.7686e-02,  8.1765e-02,  7.2389e-02,  1.0970e-01,
         -1.8556e-01],
        [-2.3010e-01,  3.3390e-02,  7.0735e-03, -3.9487e-02,  1.2683e-01,
          3.3406e-01,  3.1972e-01, -8.2220e-02,  1.6919e-01,  2.7041e-01,
         -2.8533e-01,  4.7423e-02, -2.6069e-01, -2.5000e-01, -4.5036e-02,
         -2.0082e-01],
        [-8.7568e-04, -2.1731e-02,  2.0303e-01, -3.4556e-04,  8.7387e-02,
         -2.6741e-01, -3.3579e-01, -3.0087e-01, -2.3376e-01, -2.1956e-01,
          1.3389e-01, -7.7547e-02, -7.9062e-02,  2.2952e-01, -2.4099e-01,
          1.4877e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1525,  0.0125,  0.0752, -0.0914,  0.0297, -0.1124,  0.0983,  0.1448,
        -0.1207,  0.0233,  0.0671,  0.1284,  0.2092,  0.0728,  0.0532,  0.0357,
        -0.1063, -0.0258,  0.0299, -0.0380, -0.0536,  0.0050, -0.0682,  0.0093,
        -0.1762,  0.2016,  0.0999,  0.0959, -0.1021, -0.2120,  0.1073, -0.0323],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0805,  0.1654, -0.1036, -0.1249,  0.1610,  0.2183, -0.1670, -0.2687,
         -0.1514,  0.2051,  0.1289,  0.2531, -0.0702, -0.2626,  0.1678, -0.0820,
         -0.1863,  0.2243, -0.1015, -0.1321,  0.2734,  0.1210, -0.2577, -0.2755,
         -0.1876, -0.1985, -0.2054,  0.2067, -0.2355,  0.2740,  0.1723, -0.1137]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0110,  0.0668,  0.0894,  ...,  0.0111, -0.1713, -0.1137],
        [-0.1090, -0.0697,  0.1211,  ..., -0.0180, -0.2297,  0.0871],
        [-0.0412,  0.0339,  0.0857,  ...,  0.1382,  0.1301,  0.0345],
        ...,
        [ 0.1050, -0.1138, -0.0139,  ..., -0.0913, -0.0710, -0.1180],
        [ 0.0761, -0.1735, -0.0441,  ..., -0.1444,  0.0392,  0.1557],
        [-0.1751,  0.1119,  0.0619,  ..., -0.0562, -0.1546, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0291,  0.0351, -0.0913, -0.1469, -0.0801,  0.0533, -0.0935,  0.0485,
        -0.0071,  0.0617,  0.0196,  0.0111, -0.0448,  0.0657, -0.0447, -0.0113,
         0.0426, -0.1779, -0.0646,  0.0649, -0.0448,  0.0481,  0.1192,  0.0064,
        -0.0769,  0.1134,  0.0503, -0.0937,  0.0288,  0.1892,  0.1693, -0.1296],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1272, -0.1146, -0.1464,  ...,  0.0194, -0.1094,  0.1111],
        [-0.1355,  0.0465,  0.0288,  ...,  0.1075, -0.1032,  0.1046],
        [ 0.0594, -0.1202, -0.0924,  ..., -0.0971,  0.0871,  0.1191],
        ...,
        [ 0.0624,  0.0262,  0.1526,  ...,  0.0972, -0.1244,  0.2085],
        [ 0.0595, -0.0648, -0.0155,  ...,  0.1921,  0.1314, -0.1113],
        [ 0.0625, -0.0543,  0.1532,  ...,  0.1998,  0.0576,  0.0019]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0978,  0.1349, -0.0262, -0.0768, -0.0372, -0.0617, -0.0384, -0.0811,
         0.1341, -0.1528,  0.1253, -0.1233,  0.1781,  0.0808, -0.1375,  0.0868,
        -0.1404, -0.1700,  0.0441, -0.0204,  0.0129,  0.1097, -0.1928,  0.2071,
        -0.0659, -0.0095,  0.0851, -0.0432, -0.1215, -0.0732,  0.0994,  0.0226],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2074,  0.1258, -0.1753, -0.1553,  0.0185,  0.0240, -0.0864,  0.0132,
          0.1177, -0.1484, -0.0554,  0.0805,  0.0827,  0.0745,  0.1166,  0.0957,
         -0.2074, -0.2107,  0.0493,  0.0437, -0.1143, -0.0970, -0.1910,  0.0703,
          0.1342,  0.2153, -0.1822,  0.1471, -0.0931, -0.1967,  0.1520,  0.1894]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0221], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5966e-01,  3.2378e-01,  4.9772e-02, -7.9186e-02,  6.1587e-02,
          1.0627e-01,  2.3211e-01, -1.1040e-01,  1.1178e-01,  1.9293e-01,
          1.0731e-01, -8.1940e-02, -2.2479e-01, -3.1043e-01,  1.9581e-01,
          1.2251e-01],
        [-1.8611e-01, -1.3082e-01, -4.1230e-02, -7.5408e-02, -1.0603e-01,
          1.8348e-01,  8.6735e-02,  8.6832e-02,  3.2560e-01,  6.5803e-02,
          1.0779e-01, -1.8991e-01,  8.0797e-02,  6.4702e-03,  2.7962e-01,
         -2.0200e-02],
        [ 1.1781e-02,  2.2274e-02,  3.1772e-01, -5.6549e-02,  1.5682e-02,
         -2.7688e-01,  3.5435e-02, -3.3848e-01,  1.2131e-01, -3.6657e-03,
          7.5952e-03, -1.3596e-01,  3.2570e-01,  2.6471e-01,  1.3570e-01,
          1.9824e-01],
        [ 2.0587e-01, -1.6885e-01,  2.2422e-02, -7.1286e-03,  2.1195e-02,
         -1.3479e-01, -7.8160e-02, -2.6418e-02, -3.4771e-01, -3.3732e-01,
          1.7688e-02,  2.9407e-01,  2.3770e-01, -1.6142e-01, -1.4446e-01,
          9.4768e-02],
        [-2.5110e-02,  2.9376e-01, -1.0503e-01, -9.8872e-02,  6.8356e-02,
          1.6424e-02, -4.5927e-02,  2.4075e-01,  6.3508e-02,  2.2472e-01,
          1.4236e-01, -8.5583e-02,  3.4893e-02, -1.8466e-01,  1.9131e-01,
         -9.2604e-02],
        [ 5.8273e-02,  3.3253e-01, -3.0004e-01,  3.3441e-01,  2.4978e-01,
         -8.8399e-02,  1.8122e-01, -1.0023e-01,  1.8192e-01,  1.4661e-01,
         -2.3968e-01, -1.9334e-02, -1.7233e-01,  1.8014e-01,  3.0357e-01,
         -1.7935e-02],
        [ 3.1180e-01, -1.1032e-02,  3.5362e-01, -1.2268e-01,  6.0562e-03,
         -1.5916e-01, -1.1532e-01, -1.8321e-01, -1.9900e-01,  3.6990e-02,
          4.8443e-02,  3.9601e-03, -1.0977e-01,  1.8789e-01, -2.5624e-01,
          1.0076e-01],
        [-1.1006e-01,  1.1778e-01,  3.1198e-01, -2.9838e-01, -2.8278e-01,
         -2.5656e-01, -3.4524e-02, -2.2471e-01, -1.5284e-01, -1.6479e-01,
         -1.2962e-03, -1.1893e-02,  2.1646e-01, -1.1787e-01, -5.7115e-02,
          3.1116e-01],
        [-3.1299e-02,  1.0442e-01,  2.4084e-01, -1.7719e-01,  3.4325e-02,
         -2.8169e-01, -8.6055e-02, -3.0224e-02,  1.1898e-01, -2.4661e-01,
         -9.7319e-02, -1.5205e-02, -1.4159e-01,  1.1737e-01, -2.5901e-01,
          3.5474e-02],
        [-2.2061e-01,  1.0605e-01, -3.6812e-02, -8.3452e-02, -1.7600e-02,
          8.9741e-02, -3.5657e-02,  1.6189e-01,  1.9145e-01, -6.9389e-02,
          1.4391e-01,  6.6280e-02, -1.8330e-01, -3.1684e-02,  8.6689e-02,
         -1.3978e-01],
        [-2.8763e-01,  2.9381e-01, -1.0128e-03, -1.0059e-01, -1.2585e-01,
          3.6202e-01,  1.5502e-01,  5.0540e-02,  2.8031e-01,  1.9111e-01,
          4.0159e-03,  7.7641e-02, -1.2339e-01,  1.5768e-01, -8.7120e-02,
         -2.7194e-01],
        [-6.8070e-02,  5.6174e-02,  2.9072e-02,  2.8464e-02,  9.2720e-02,
          6.5765e-02,  2.9542e-01,  8.7505e-02,  9.8596e-02,  2.9144e-01,
          1.6164e-01,  1.2576e-01, -3.5383e-01, -2.1021e-01,  6.4815e-03,
         -1.5894e-01],
        [ 2.4458e-01,  3.1947e-02,  8.5082e-02, -8.7803e-02,  9.1717e-04,
          1.0812e-01,  2.2480e-02, -2.2122e-01, -2.2850e-01, -2.6740e-02,
          1.0968e-02, -5.6594e-02, -1.4234e-01,  1.0492e-01, -1.4021e-01,
         -4.9037e-02],
        [ 1.5447e-01,  1.5036e-01,  3.1868e-01,  4.6575e-02, -2.4251e-01,
          2.9895e-02,  2.2085e-02, -1.6810e-02, -1.5984e-01, -1.1064e-01,
         -1.0750e-01,  5.2844e-02,  6.2751e-02,  3.0861e-02, -3.0038e-01,
          1.9265e-01],
        [-3.1826e-01, -8.9274e-02, -1.6008e-02, -1.0215e-01,  3.0063e-01,
          3.5640e-01,  3.3214e-02,  6.5152e-02, -8.8140e-02,  1.2625e-01,
          1.6206e-02, -2.5163e-01, -2.9720e-02, -8.1755e-02, -1.4292e-02,
         -1.1255e-01],
        [-1.4045e-01, -2.6359e-01,  1.3815e-01,  1.4987e-01, -1.9838e-01,
          5.4045e-02, -7.9922e-02, -2.0578e-01, -9.4102e-02,  1.6574e-02,
          3.4515e-02,  3.2652e-01,  5.4874e-02, -1.0375e-01,  1.8096e-01,
          2.4729e-02],
        [ 2.6445e-01,  7.1904e-02,  1.5236e-01, -2.9775e-01, -2.9779e-01,
          4.8910e-03, -4.3638e-02,  4.5353e-02, -3.1638e-01, -1.4003e-01,
          2.5939e-01,  2.4020e-01,  3.1176e-01,  2.6185e-01, -1.1481e-01,
         -6.8415e-02],
        [-2.5089e-01,  1.7711e-01, -2.0233e-01,  8.8013e-02,  9.2228e-02,
          2.6377e-01,  2.3985e-01,  2.4026e-01,  1.0101e-01,  2.3950e-01,
         -1.2130e-01, -2.0617e-01, -1.4214e-01, -2.0574e-01,  2.6461e-01,
         -1.3565e-01],
        [ 1.6424e-01, -8.9359e-02,  9.1181e-02, -2.3135e-01, -1.1561e-01,
         -3.1798e-01, -2.0941e-01,  9.8710e-02, -3.2669e-01, -5.8846e-02,
          7.9416e-02, -1.4779e-01,  1.4118e-01,  2.2027e-01,  8.4903e-02,
          1.3722e-01],
        [ 3.1264e-01, -9.0116e-02,  2.1625e-01, -2.9605e-02, -2.4352e-01,
         -1.7765e-01, -2.8931e-01,  8.7697e-02,  1.6569e-02, -2.1881e-01,
          2.6446e-02,  1.8530e-01, -1.0766e-01,  7.9661e-02,  5.7486e-02,
          1.4769e-01],
        [-1.2682e-01,  2.5507e-01,  2.9868e-03, -1.3122e-01,  2.0690e-01,
         -8.5973e-02,  2.4513e-01,  3.1011e-01,  1.1955e-01,  1.8409e-02,
         -1.8635e-01, -2.2023e-01, -1.4854e-01, -1.7110e-01,  3.0863e-01,
         -2.0772e-01],
        [ 6.0778e-03, -1.4957e-01,  2.5384e-02,  3.0057e-01, -1.3133e-01,
          3.8918e-02,  1.5688e-01, -1.4555e-01, -6.7723e-02,  1.8411e-01,
          2.3733e-01, -1.7613e-01, -9.8374e-02, -2.9988e-01, -1.9991e-01,
          1.2485e-01],
        [ 3.1498e-01, -1.6558e-01,  7.0408e-03, -1.0656e-01,  6.5228e-02,
         -3.5112e-01, -2.4067e-01, -1.8004e-01, -2.0084e-01, -1.0768e-01,
          2.2744e-01,  1.6087e-01, -1.2621e-01,  2.9363e-01,  1.5404e-01,
          1.7811e-01],
        [ 2.1944e-01,  1.2143e-02,  3.0320e-01, -3.2175e-01, -1.9805e-01,
         -1.3930e-01, -1.4380e-01, -2.5809e-01, -3.2460e-01, -2.8616e-01,
          3.3944e-02,  3.1533e-01,  2.6343e-01,  1.2979e-01, -2.0069e-01,
         -8.1189e-03],
        [ 1.3431e-01, -3.2618e-01,  1.0226e-01, -4.7290e-02,  1.6989e-01,
         -1.8127e-01,  1.3643e-01, -8.5632e-02, -2.7241e-01,  1.2831e-01,
          2.6815e-01, -8.4782e-02, -3.8797e-02,  1.8833e-01, -2.0851e-01,
          2.7708e-01],
        [-1.3518e-02, -1.7042e-01,  3.7621e-02,  1.4212e-01, -1.4704e-01,
         -1.5865e-01,  4.2734e-02, -2.7132e-01, -1.0608e-01, -2.9930e-01,
         -2.1178e-01,  5.1796e-02,  1.2892e-01,  2.8284e-01, -3.0260e-01,
          3.0861e-02],
        [ 1.7067e-01,  3.4041e-03,  2.5397e-01, -2.9286e-01, -1.1072e-01,
         -5.3655e-02, -3.0323e-01,  2.7268e-02, -3.3059e-01,  5.3755e-02,
          9.7623e-02,  3.6492e-02,  1.8498e-01,  2.7429e-01,  1.3650e-01,
          2.5316e-01],
        [-2.5758e-01,  1.6520e-01,  7.2677e-02,  1.4203e-01,  2.1960e-01,
         -3.7200e-02,  2.8597e-01,  9.7529e-02, -1.2607e-01,  4.4768e-02,
          1.5232e-01, -2.0146e-01, -1.5422e-01, -1.6907e-01, -7.9042e-02,
         -6.5043e-02],
        [ 2.5590e-01, -4.7343e-02,  9.2293e-02, -7.7421e-02, -2.4281e-01,
         -2.4495e-01, -9.2578e-02, -2.9617e-01,  3.0068e-02, -6.6521e-02,
          8.9449e-02,  9.3134e-02,  3.0865e-01,  2.9632e-01,  5.3405e-02,
          2.2638e-01],
        [-2.2356e-01,  1.9068e-01, -2.7424e-01,  1.9744e-01, -1.2981e-01,
          1.0616e-01,  2.8123e-01,  2.6272e-01,  3.1048e-01,  1.8375e-01,
          1.1107e-01, -3.7686e-02,  8.1765e-02,  7.2389e-02,  1.0970e-01,
         -1.8556e-01],
        [-2.3010e-01,  3.3390e-02,  7.0735e-03, -3.9487e-02,  1.2683e-01,
          3.3406e-01,  3.1972e-01, -8.2220e-02,  1.6919e-01,  2.7041e-01,
         -2.8533e-01,  4.7423e-02, -2.6069e-01, -2.5000e-01, -4.5036e-02,
         -2.0082e-01],
        [-8.7568e-04, -2.1731e-02,  2.0303e-01, -3.4556e-04,  8.7387e-02,
         -2.6741e-01, -3.3579e-01, -3.0087e-01, -2.3376e-01, -2.1956e-01,
          1.3389e-01, -7.7547e-02, -7.9062e-02,  2.2952e-01, -2.4099e-01,
          1.4877e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1525,  0.0125,  0.0752, -0.0914,  0.0297, -0.1124,  0.0983,  0.1448,
        -0.1207,  0.0233,  0.0671,  0.1284,  0.2092,  0.0728,  0.0532,  0.0357,
        -0.1063, -0.0258,  0.0299, -0.0380, -0.0536,  0.0050, -0.0682,  0.0093,
        -0.1762,  0.2016,  0.0999,  0.0959, -0.1021, -0.2120,  0.1073, -0.0323],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0805,  0.1654, -0.1036, -0.1249,  0.1610,  0.2183, -0.1670, -0.2687,
         -0.1514,  0.2051,  0.1289,  0.2531, -0.0702, -0.2626,  0.1678, -0.0820,
         -0.1863,  0.2243, -0.1015, -0.1321,  0.2734,  0.1210, -0.2577, -0.2755,
         -0.1876, -0.1985, -0.2054,  0.2067, -0.2355,  0.2740,  0.1723, -0.1137]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0110,  0.0668,  0.0894,  ...,  0.0111, -0.1713, -0.1137],
        [-0.1090, -0.0697,  0.1211,  ..., -0.0180, -0.2297,  0.0871],
        [-0.0412,  0.0339,  0.0857,  ...,  0.1382,  0.1301,  0.0345],
        ...,
        [ 0.1050, -0.1138, -0.0139,  ..., -0.0913, -0.0710, -0.1180],
        [ 0.0761, -0.1735, -0.0441,  ..., -0.1444,  0.0392,  0.1557],
        [-0.1751,  0.1119,  0.0619,  ..., -0.0562, -0.1546, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0291,  0.0351, -0.0913, -0.1469, -0.0801,  0.0533, -0.0935,  0.0485,
        -0.0071,  0.0617,  0.0196,  0.0111, -0.0448,  0.0657, -0.0447, -0.0113,
         0.0426, -0.1779, -0.0646,  0.0649, -0.0448,  0.0481,  0.1192,  0.0064,
        -0.0769,  0.1134,  0.0503, -0.0937,  0.0288,  0.1892,  0.1693, -0.1296],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1272, -0.1146, -0.1464,  ...,  0.0194, -0.1094,  0.1111],
        [-0.1355,  0.0465,  0.0288,  ...,  0.1075, -0.1032,  0.1046],
        [ 0.0594, -0.1202, -0.0924,  ..., -0.0971,  0.0871,  0.1191],
        ...,
        [ 0.0624,  0.0262,  0.1526,  ...,  0.0972, -0.1244,  0.2085],
        [ 0.0595, -0.0648, -0.0155,  ...,  0.1921,  0.1314, -0.1113],
        [ 0.0625, -0.0543,  0.1532,  ...,  0.1998,  0.0576,  0.0019]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0978,  0.1349, -0.0262, -0.0768, -0.0372, -0.0617, -0.0384, -0.0811,
         0.1341, -0.1528,  0.1253, -0.1233,  0.1781,  0.0808, -0.1375,  0.0868,
        -0.1404, -0.1700,  0.0441, -0.0204,  0.0129,  0.1097, -0.1928,  0.2071,
        -0.0659, -0.0095,  0.0851, -0.0432, -0.1215, -0.0732,  0.0994,  0.0226],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2074,  0.1258, -0.1753, -0.1553,  0.0185,  0.0240, -0.0864,  0.0132,
          0.1177, -0.1484, -0.0554,  0.0805,  0.0827,  0.0745,  0.1166,  0.0957,
         -0.2074, -0.2107,  0.0493,  0.0437, -0.1143, -0.0970, -0.1910,  0.0703,
          0.1342,  0.2153, -0.1822,  0.1471, -0.0931, -0.1967,  0.1520,  0.1894]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0221], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5966e-01,  3.2378e-01,  4.9772e-02, -7.9186e-02,  6.1587e-02,
          1.0627e-01,  2.3211e-01, -1.1040e-01,  1.1178e-01,  1.9293e-01,
          1.0731e-01, -8.1940e-02, -2.2479e-01, -3.1043e-01,  1.9581e-01,
          1.2251e-01],
        [-1.8611e-01, -1.3082e-01, -4.1230e-02, -7.5408e-02, -1.0603e-01,
          1.8348e-01,  8.6735e-02,  8.6832e-02,  3.2560e-01,  6.5803e-02,
          1.0779e-01, -1.8991e-01,  8.0797e-02,  6.4702e-03,  2.7962e-01,
         -2.0200e-02],
        [ 1.1781e-02,  2.2274e-02,  3.1772e-01, -5.6549e-02,  1.5682e-02,
         -2.7688e-01,  3.5435e-02, -3.3848e-01,  1.2131e-01, -3.6657e-03,
          7.5952e-03, -1.3596e-01,  3.2570e-01,  2.6471e-01,  1.3570e-01,
          1.9824e-01],
        [ 2.0587e-01, -1.6885e-01,  2.2422e-02, -7.1286e-03,  2.1195e-02,
         -1.3479e-01, -7.8160e-02, -2.6418e-02, -3.4771e-01, -3.3732e-01,
          1.7688e-02,  2.9407e-01,  2.3770e-01, -1.6142e-01, -1.4446e-01,
          9.4768e-02],
        [-2.5110e-02,  2.9376e-01, -1.0503e-01, -9.8872e-02,  6.8356e-02,
          1.6424e-02, -4.5927e-02,  2.4075e-01,  6.3508e-02,  2.2472e-01,
          1.4236e-01, -8.5583e-02,  3.4893e-02, -1.8466e-01,  1.9131e-01,
         -9.2604e-02],
        [ 5.8273e-02,  3.3253e-01, -3.0004e-01,  3.3441e-01,  2.4978e-01,
         -8.8399e-02,  1.8122e-01, -1.0023e-01,  1.8192e-01,  1.4661e-01,
         -2.3968e-01, -1.9334e-02, -1.7233e-01,  1.8014e-01,  3.0357e-01,
         -1.7935e-02],
        [ 3.1180e-01, -1.1032e-02,  3.5362e-01, -1.2268e-01,  6.0562e-03,
         -1.5916e-01, -1.1532e-01, -1.8321e-01, -1.9900e-01,  3.6990e-02,
          4.8443e-02,  3.9601e-03, -1.0977e-01,  1.8789e-01, -2.5624e-01,
          1.0076e-01],
        [-1.1006e-01,  1.1778e-01,  3.1198e-01, -2.9838e-01, -2.8278e-01,
         -2.5656e-01, -3.4524e-02, -2.2471e-01, -1.5284e-01, -1.6479e-01,
         -1.2962e-03, -1.1893e-02,  2.1646e-01, -1.1787e-01, -5.7115e-02,
          3.1116e-01],
        [-3.1299e-02,  1.0442e-01,  2.4084e-01, -1.7719e-01,  3.4325e-02,
         -2.8169e-01, -8.6055e-02, -3.0224e-02,  1.1898e-01, -2.4661e-01,
         -9.7319e-02, -1.5205e-02, -1.4159e-01,  1.1737e-01, -2.5901e-01,
          3.5474e-02],
        [-2.2061e-01,  1.0605e-01, -3.6812e-02, -8.3452e-02, -1.7600e-02,
          8.9741e-02, -3.5657e-02,  1.6189e-01,  1.9145e-01, -6.9389e-02,
          1.4391e-01,  6.6280e-02, -1.8330e-01, -3.1684e-02,  8.6689e-02,
         -1.3978e-01],
        [-2.8763e-01,  2.9381e-01, -1.0128e-03, -1.0059e-01, -1.2585e-01,
          3.6202e-01,  1.5502e-01,  5.0540e-02,  2.8031e-01,  1.9111e-01,
          4.0159e-03,  7.7641e-02, -1.2339e-01,  1.5768e-01, -8.7120e-02,
         -2.7194e-01],
        [-6.8070e-02,  5.6174e-02,  2.9072e-02,  2.8464e-02,  9.2720e-02,
          6.5765e-02,  2.9542e-01,  8.7505e-02,  9.8596e-02,  2.9144e-01,
          1.6164e-01,  1.2576e-01, -3.5383e-01, -2.1021e-01,  6.4815e-03,
         -1.5894e-01],
        [ 2.4458e-01,  3.1947e-02,  8.5082e-02, -8.7803e-02,  9.1717e-04,
          1.0812e-01,  2.2480e-02, -2.2122e-01, -2.2850e-01, -2.6740e-02,
          1.0968e-02, -5.6594e-02, -1.4234e-01,  1.0492e-01, -1.4021e-01,
         -4.9037e-02],
        [ 1.5447e-01,  1.5036e-01,  3.1868e-01,  4.6575e-02, -2.4251e-01,
          2.9895e-02,  2.2085e-02, -1.6810e-02, -1.5984e-01, -1.1064e-01,
         -1.0750e-01,  5.2844e-02,  6.2751e-02,  3.0861e-02, -3.0038e-01,
          1.9265e-01],
        [-3.1826e-01, -8.9274e-02, -1.6008e-02, -1.0215e-01,  3.0063e-01,
          3.5640e-01,  3.3214e-02,  6.5152e-02, -8.8140e-02,  1.2625e-01,
          1.6206e-02, -2.5163e-01, -2.9720e-02, -8.1755e-02, -1.4292e-02,
         -1.1255e-01],
        [-1.4045e-01, -2.6359e-01,  1.3815e-01,  1.4987e-01, -1.9838e-01,
          5.4045e-02, -7.9922e-02, -2.0578e-01, -9.4102e-02,  1.6574e-02,
          3.4515e-02,  3.2652e-01,  5.4874e-02, -1.0375e-01,  1.8096e-01,
          2.4729e-02],
        [ 2.6445e-01,  7.1904e-02,  1.5236e-01, -2.9775e-01, -2.9779e-01,
          4.8910e-03, -4.3638e-02,  4.5353e-02, -3.1638e-01, -1.4003e-01,
          2.5939e-01,  2.4020e-01,  3.1176e-01,  2.6185e-01, -1.1481e-01,
         -6.8415e-02],
        [-2.5089e-01,  1.7711e-01, -2.0233e-01,  8.8013e-02,  9.2228e-02,
          2.6377e-01,  2.3985e-01,  2.4026e-01,  1.0101e-01,  2.3950e-01,
         -1.2130e-01, -2.0617e-01, -1.4214e-01, -2.0574e-01,  2.6461e-01,
         -1.3565e-01],
        [ 1.6424e-01, -8.9359e-02,  9.1181e-02, -2.3135e-01, -1.1561e-01,
         -3.1798e-01, -2.0941e-01,  9.8710e-02, -3.2669e-01, -5.8846e-02,
          7.9416e-02, -1.4779e-01,  1.4118e-01,  2.2027e-01,  8.4903e-02,
          1.3722e-01],
        [ 3.1264e-01, -9.0116e-02,  2.1625e-01, -2.9605e-02, -2.4352e-01,
         -1.7765e-01, -2.8931e-01,  8.7697e-02,  1.6569e-02, -2.1881e-01,
          2.6446e-02,  1.8530e-01, -1.0766e-01,  7.9661e-02,  5.7486e-02,
          1.4769e-01],
        [-1.2682e-01,  2.5507e-01,  2.9868e-03, -1.3122e-01,  2.0690e-01,
         -8.5973e-02,  2.4513e-01,  3.1011e-01,  1.1955e-01,  1.8409e-02,
         -1.8635e-01, -2.2023e-01, -1.4854e-01, -1.7110e-01,  3.0863e-01,
         -2.0772e-01],
        [ 6.0778e-03, -1.4957e-01,  2.5384e-02,  3.0057e-01, -1.3133e-01,
          3.8918e-02,  1.5688e-01, -1.4555e-01, -6.7723e-02,  1.8411e-01,
          2.3733e-01, -1.7613e-01, -9.8374e-02, -2.9988e-01, -1.9991e-01,
          1.2485e-01],
        [ 3.1498e-01, -1.6558e-01,  7.0408e-03, -1.0656e-01,  6.5228e-02,
         -3.5112e-01, -2.4067e-01, -1.8004e-01, -2.0084e-01, -1.0768e-01,
          2.2744e-01,  1.6087e-01, -1.2621e-01,  2.9363e-01,  1.5404e-01,
          1.7811e-01],
        [ 2.1944e-01,  1.2143e-02,  3.0320e-01, -3.2175e-01, -1.9805e-01,
         -1.3930e-01, -1.4380e-01, -2.5809e-01, -3.2460e-01, -2.8616e-01,
          3.3944e-02,  3.1533e-01,  2.6343e-01,  1.2979e-01, -2.0069e-01,
         -8.1189e-03],
        [ 1.3431e-01, -3.2618e-01,  1.0226e-01, -4.7290e-02,  1.6989e-01,
         -1.8127e-01,  1.3643e-01, -8.5632e-02, -2.7241e-01,  1.2831e-01,
          2.6815e-01, -8.4782e-02, -3.8797e-02,  1.8833e-01, -2.0851e-01,
          2.7708e-01],
        [-1.3518e-02, -1.7042e-01,  3.7621e-02,  1.4212e-01, -1.4704e-01,
         -1.5865e-01,  4.2734e-02, -2.7132e-01, -1.0608e-01, -2.9930e-01,
         -2.1178e-01,  5.1796e-02,  1.2892e-01,  2.8284e-01, -3.0260e-01,
          3.0861e-02],
        [ 1.7067e-01,  3.4041e-03,  2.5397e-01, -2.9286e-01, -1.1072e-01,
         -5.3655e-02, -3.0323e-01,  2.7268e-02, -3.3059e-01,  5.3755e-02,
          9.7623e-02,  3.6492e-02,  1.8498e-01,  2.7429e-01,  1.3650e-01,
          2.5316e-01],
        [-2.5758e-01,  1.6520e-01,  7.2677e-02,  1.4203e-01,  2.1960e-01,
         -3.7200e-02,  2.8597e-01,  9.7529e-02, -1.2607e-01,  4.4768e-02,
          1.5232e-01, -2.0146e-01, -1.5422e-01, -1.6907e-01, -7.9042e-02,
         -6.5043e-02],
        [ 2.5590e-01, -4.7343e-02,  9.2293e-02, -7.7421e-02, -2.4281e-01,
         -2.4495e-01, -9.2578e-02, -2.9617e-01,  3.0068e-02, -6.6521e-02,
          8.9449e-02,  9.3134e-02,  3.0865e-01,  2.9632e-01,  5.3405e-02,
          2.2638e-01],
        [-2.2356e-01,  1.9068e-01, -2.7424e-01,  1.9744e-01, -1.2981e-01,
          1.0616e-01,  2.8123e-01,  2.6272e-01,  3.1048e-01,  1.8375e-01,
          1.1107e-01, -3.7686e-02,  8.1765e-02,  7.2389e-02,  1.0970e-01,
         -1.8556e-01],
        [-2.3010e-01,  3.3390e-02,  7.0735e-03, -3.9487e-02,  1.2683e-01,
          3.3406e-01,  3.1972e-01, -8.2220e-02,  1.6919e-01,  2.7041e-01,
         -2.8533e-01,  4.7423e-02, -2.6069e-01, -2.5000e-01, -4.5036e-02,
         -2.0082e-01],
        [-8.7568e-04, -2.1731e-02,  2.0303e-01, -3.4556e-04,  8.7387e-02,
         -2.6741e-01, -3.3579e-01, -3.0087e-01, -2.3376e-01, -2.1956e-01,
          1.3389e-01, -7.7547e-02, -7.9062e-02,  2.2952e-01, -2.4099e-01,
          1.4877e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1525,  0.0125,  0.0752, -0.0914,  0.0297, -0.1124,  0.0983,  0.1448,
        -0.1207,  0.0233,  0.0671,  0.1284,  0.2092,  0.0728,  0.0532,  0.0357,
        -0.1063, -0.0258,  0.0299, -0.0380, -0.0536,  0.0050, -0.0682,  0.0093,
        -0.1762,  0.2016,  0.0999,  0.0959, -0.1021, -0.2120,  0.1073, -0.0323],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0805,  0.1654, -0.1036, -0.1249,  0.1610,  0.2183, -0.1670, -0.2687,
         -0.1514,  0.2051,  0.1289,  0.2531, -0.0702, -0.2626,  0.1678, -0.0820,
         -0.1863,  0.2243, -0.1015, -0.1321,  0.2734,  0.1210, -0.2577, -0.2755,
         -0.1876, -0.1985, -0.2054,  0.2067, -0.2355,  0.2740,  0.1723, -0.1137]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0110,  0.0668,  0.0894,  ...,  0.0111, -0.1713, -0.1137],
        [-0.1090, -0.0697,  0.1211,  ..., -0.0180, -0.2297,  0.0871],
        [-0.0412,  0.0339,  0.0857,  ...,  0.1382,  0.1301,  0.0345],
        ...,
        [ 0.1050, -0.1138, -0.0139,  ..., -0.0913, -0.0710, -0.1180],
        [ 0.0761, -0.1735, -0.0441,  ..., -0.1444,  0.0392,  0.1557],
        [-0.1751,  0.1119,  0.0619,  ..., -0.0562, -0.1546, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0291,  0.0351, -0.0913, -0.1469, -0.0801,  0.0533, -0.0935,  0.0485,
        -0.0071,  0.0617,  0.0196,  0.0111, -0.0448,  0.0657, -0.0447, -0.0113,
         0.0426, -0.1779, -0.0646,  0.0649, -0.0448,  0.0481,  0.1192,  0.0064,
        -0.0769,  0.1134,  0.0503, -0.0937,  0.0288,  0.1892,  0.1693, -0.1296],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1272, -0.1146, -0.1464,  ...,  0.0194, -0.1094,  0.1111],
        [-0.1355,  0.0465,  0.0288,  ...,  0.1075, -0.1032,  0.1046],
        [ 0.0594, -0.1202, -0.0924,  ..., -0.0971,  0.0871,  0.1191],
        ...,
        [ 0.0624,  0.0262,  0.1526,  ...,  0.0972, -0.1244,  0.2085],
        [ 0.0595, -0.0648, -0.0155,  ...,  0.1921,  0.1314, -0.1113],
        [ 0.0625, -0.0543,  0.1532,  ...,  0.1998,  0.0576,  0.0019]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0978,  0.1349, -0.0262, -0.0768, -0.0372, -0.0617, -0.0384, -0.0811,
         0.1341, -0.1528,  0.1253, -0.1233,  0.1781,  0.0808, -0.1375,  0.0868,
        -0.1404, -0.1700,  0.0441, -0.0204,  0.0129,  0.1097, -0.1928,  0.2071,
        -0.0659, -0.0095,  0.0851, -0.0432, -0.1215, -0.0732,  0.0994,  0.0226],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2074,  0.1258, -0.1753, -0.1553,  0.0185,  0.0240, -0.0864,  0.0132,
          0.1177, -0.1484, -0.0554,  0.0805,  0.0827,  0.0745,  0.1166,  0.0957,
         -0.2074, -0.2107,  0.0493,  0.0437, -0.1143, -0.0970, -0.1910,  0.0703,
          0.1342,  0.2153, -0.1822,  0.1471, -0.0931, -0.1967,  0.1520,  0.1894]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0221], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5961e-01,  3.2372e-01,  4.9827e-02, -7.9242e-02,  6.1530e-02,
          1.0622e-01,  2.3205e-01, -1.1046e-01,  1.1172e-01,  1.9287e-01,
          1.0728e-01, -8.1885e-02, -2.2474e-01, -3.1037e-01,  1.9574e-01,
          1.2256e-01],
        [-1.8605e-01, -1.3090e-01, -4.1175e-02, -7.5464e-02, -1.0610e-01,
          1.8342e-01,  8.6679e-02,  8.6777e-02,  3.2555e-01,  6.5747e-02,
          1.0816e-01, -1.8985e-01,  8.0855e-02,  6.5293e-03,  2.7656e-01,
         -2.0145e-02],
        [ 1.1726e-02,  2.5321e-02,  3.1766e-01, -5.6494e-02,  1.5765e-02,
         -2.7682e-01,  3.5491e-02, -3.3842e-01,  1.2137e-01, -3.6088e-03,
          7.6384e-03, -1.3604e-01,  3.2563e-01,  2.6464e-01,  1.3862e-01,
          1.9819e-01],
        [ 2.0581e-01, -1.6878e-01,  2.2367e-02, -7.0726e-03,  2.1258e-02,
         -1.3474e-01, -7.8104e-02, -2.6363e-02, -3.4766e-01, -3.3726e-01,
          1.7706e-02,  2.9402e-01,  2.3764e-01, -1.6148e-01, -1.4144e-01,
          9.4713e-02],
        [-2.5055e-02,  2.9369e-01, -1.0497e-01, -9.8928e-02,  6.8295e-02,
          1.6370e-02, -4.5983e-02,  2.4069e-01,  6.3451e-02,  2.2467e-01,
          1.4527e-01, -8.5527e-02,  3.4949e-02, -1.8460e-01,  1.8826e-01,
         -9.2549e-02],
        [ 5.8328e-02,  3.3246e-01, -2.9999e-01,  3.3435e-01,  2.4972e-01,
         -8.8451e-02,  1.8116e-01, -1.0028e-01,  1.8187e-01,  1.4655e-01,
         -2.3953e-01, -1.9281e-02, -1.7228e-01,  1.8019e-01,  3.0052e-01,
         -1.7880e-02],
        [ 3.1175e-01, -7.9783e-03,  3.5356e-01, -1.2263e-01,  6.3176e-03,
         -1.5910e-01, -1.1526e-01, -1.8316e-01, -1.9894e-01,  3.7046e-02,
          4.8490e-02,  3.8863e-03, -1.0984e-01,  1.8782e-01, -2.5622e-01,
          1.0071e-01],
        [-1.1011e-01,  1.2084e-01,  3.1192e-01, -2.9833e-01, -2.7978e-01,
         -2.5651e-01, -3.4467e-02, -2.2465e-01, -1.5278e-01, -1.6474e-01,
         -1.2431e-03, -1.1976e-02,  2.1640e-01, -1.1794e-01, -5.7159e-02,
          3.1110e-01],
        [-3.1355e-02,  1.0470e-01,  2.4079e-01, -1.7713e-01,  3.4399e-02,
         -2.8164e-01, -8.5998e-02, -3.0168e-02,  1.1904e-01, -2.4655e-01,
         -1.0036e-01, -1.5265e-02, -1.4165e-01,  1.1730e-01, -2.5594e-01,
          3.5419e-02],
        [-2.2056e-01,  1.0595e-01, -3.6757e-02, -8.3507e-02, -1.7666e-02,
          8.9686e-02, -3.5713e-02,  1.6184e-01,  1.9139e-01, -6.9445e-02,
          1.4692e-01,  6.6337e-02, -1.8324e-01, -3.1624e-02,  8.3618e-02,
         -1.3973e-01],
        [-2.8758e-01,  2.9077e-01, -9.5754e-04, -1.0065e-01, -1.2594e-01,
          3.6196e-01,  1.5496e-01,  5.0484e-02,  2.8025e-01,  1.9105e-01,
          4.0115e-03,  7.7702e-02, -1.2333e-01,  1.5774e-01, -9.0167e-02,
         -2.7188e-01],
        [-6.8015e-02,  5.3119e-02,  2.9127e-02,  2.8408e-02,  8.9925e-02,
          6.5710e-02,  2.9536e-01,  8.7449e-02,  9.8536e-02,  2.9139e-01,
          1.6470e-01,  1.2581e-01, -3.5377e-01, -2.1015e-01,  3.4117e-03,
         -1.5888e-01],
        [ 2.4452e-01,  3.2129e-02,  8.5026e-02, -8.7748e-02,  9.8770e-04,
          1.0818e-01,  2.2536e-02, -2.2116e-01, -2.2844e-01, -2.6682e-02,
          9.2898e-03, -5.6658e-02, -1.4240e-01,  1.0486e-01, -1.3716e-01,
         -4.9092e-02],
        [ 1.5442e-01,  1.5342e-01,  3.1863e-01,  4.6630e-02, -2.4243e-01,
          2.9950e-02,  2.2142e-02, -1.6754e-02, -1.5978e-01, -1.1058e-01,
         -1.0781e-01,  5.2786e-02,  6.2692e-02,  3.0801e-02, -2.9732e-01,
          1.9259e-01],
        [-3.1820e-01, -8.9370e-02, -1.5953e-02, -1.0221e-01,  3.0057e-01,
          3.5635e-01,  3.3158e-02,  6.5096e-02, -8.8197e-02,  1.2620e-01,
          1.6161e-02, -2.5158e-01, -2.9664e-02, -8.1696e-02, -1.7346e-02,
         -1.1250e-01],
        [-1.4050e-01, -2.6352e-01,  1.3809e-01,  1.4992e-01, -1.9831e-01,
          5.4101e-02, -7.9866e-02, -2.0572e-01, -9.4044e-02,  1.6631e-02,
          3.1512e-02,  3.2646e-01,  5.4815e-02, -1.0381e-01,  1.8400e-01,
          2.4674e-02],
        [ 2.6440e-01,  7.2004e-02,  1.5230e-01, -2.9770e-01, -2.9770e-01,
          4.9429e-03, -4.3582e-02,  4.5408e-02, -3.1632e-01, -1.3998e-01,
          2.5652e-01,  2.4015e-01,  3.1171e-01,  2.6180e-01, -1.1177e-01,
         -6.8470e-02],
        [-2.5083e-01,  1.7650e-01, -2.0228e-01,  8.7957e-02,  9.2172e-02,
          2.6372e-01,  2.3979e-01,  2.4020e-01,  1.0095e-01,  2.3944e-01,
         -1.2136e-01, -2.0612e-01, -1.4208e-01, -2.0568e-01,  2.6466e-01,
         -1.3560e-01],
        [ 1.6418e-01, -8.6327e-02,  9.1125e-02, -2.3130e-01, -1.1540e-01,
         -3.1792e-01, -2.0936e-01,  9.8765e-02, -3.2663e-01, -5.8789e-02,
          7.9116e-02, -1.4786e-01,  1.4112e-01,  2.2021e-01,  8.7936e-02,
          1.3716e-01],
        [ 3.1258e-01, -8.7063e-02,  2.1620e-01, -2.9549e-02, -2.4050e-01,
         -1.7759e-01, -2.8925e-01,  8.7753e-02,  1.6631e-02, -2.1876e-01,
          2.5057e-02,  1.8523e-01, -1.0773e-01,  7.9590e-02,  6.0522e-02,
          1.4763e-01],
        [-1.2677e-01,  2.5501e-01,  3.0419e-03, -1.3127e-01,  2.0684e-01,
         -8.6025e-02,  2.4507e-01,  3.1005e-01,  1.1949e-01,  1.8354e-02,
         -1.8333e-01, -2.2017e-01, -1.4849e-01, -1.7105e-01,  3.0857e-01,
         -2.0767e-01],
        [ 6.1332e-03, -1.4965e-01,  2.5439e-02,  3.0051e-01, -1.3139e-01,
          3.8861e-02,  1.5683e-01, -1.4560e-01, -6.7781e-02,  1.8406e-01,
          2.4037e-01, -1.7607e-01, -9.8314e-02, -2.9982e-01, -2.0297e-01,
          1.2491e-01],
        [ 3.1493e-01, -1.6253e-01,  6.9856e-03, -1.0651e-01,  6.7905e-02,
         -3.5106e-01, -2.4062e-01, -1.7998e-01, -2.0078e-01, -1.0763e-01,
          2.2749e-01,  1.6082e-01, -1.2627e-01,  2.9357e-01,  1.5411e-01,
          1.7806e-01],
        [ 2.1939e-01,  1.2097e-02,  3.0314e-01, -3.2169e-01, -1.9809e-01,
         -1.3925e-01, -1.4374e-01, -2.5804e-01, -3.2454e-01, -2.8611e-01,
          3.4002e-02,  3.1528e-01,  2.6338e-01,  1.2974e-01, -2.0074e-01,
         -8.1736e-03],
        [ 1.3425e-01, -3.2610e-01,  1.0221e-01, -4.7235e-02,  1.6996e-01,
         -1.8122e-01,  1.3648e-01, -8.5577e-02, -2.7235e-01,  1.2837e-01,
          2.6514e-01, -8.4838e-02, -3.8854e-02,  1.8827e-01, -2.0544e-01,
          2.7702e-01],
        [-1.3573e-02, -1.7037e-01,  3.7566e-02,  1.4218e-01, -1.4699e-01,
         -1.5859e-01,  4.2789e-02, -2.7127e-01, -1.0602e-01, -2.9925e-01,
         -2.1172e-01,  5.1742e-02,  1.2887e-01,  2.8279e-01, -3.0254e-01,
          3.0806e-02],
        [ 1.7061e-01,  6.4587e-03,  2.5391e-01, -2.9280e-01, -1.0768e-01,
         -5.3598e-02, -3.0317e-01,  2.7324e-02, -3.3053e-01,  5.3812e-02,
          9.5803e-02,  3.6386e-02,  1.8491e-01,  2.7421e-01,  1.3950e-01,
          2.5311e-01],
        [-2.5753e-01,  1.6218e-01,  7.2732e-02,  1.4197e-01,  2.1950e-01,
         -3.7255e-02,  2.8592e-01,  9.7473e-02, -1.2613e-01,  4.4712e-02,
          1.5537e-01, -2.0140e-01, -1.5416e-01, -1.6901e-01, -8.2111e-02,
         -6.4987e-02],
        [ 2.5585e-01, -4.4308e-02,  9.2238e-02, -7.7365e-02, -2.4088e-01,
         -2.4490e-01, -9.2521e-02, -2.9611e-01,  3.0126e-02, -6.6466e-02,
          8.9488e-02,  9.3082e-02,  3.0860e-01,  2.9626e-01,  5.6434e-02,
          2.2632e-01],
        [-2.2351e-01,  1.8766e-01, -2.7419e-01,  1.9739e-01, -1.3287e-01,
          1.0610e-01,  2.8118e-01,  2.6267e-01,  3.1042e-01,  1.8369e-01,
          1.1102e-01, -3.4631e-02,  8.4462e-02,  7.2498e-02,  1.0976e-01,
         -1.8550e-01],
        [-2.3005e-01,  3.1177e-02,  7.1286e-03, -3.9543e-02,  1.2676e-01,
          3.3401e-01,  3.1966e-01, -8.2276e-02,  1.6914e-01,  2.7035e-01,
         -2.8537e-01,  4.7476e-02, -2.6063e-01, -2.4995e-01, -4.8060e-02,
         -2.0077e-01],
        [-9.3079e-04, -1.8716e-02,  2.0297e-01, -2.8917e-04,  8.7566e-02,
         -2.6736e-01, -3.3573e-01, -3.0081e-01, -2.3370e-01, -2.1950e-01,
          1.3388e-01, -7.7607e-02, -7.9120e-02,  2.2945e-01, -2.3796e-01,
          1.4871e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1526,  0.0124,  0.0753, -0.0883,  0.0271, -0.1153,  0.0984,  0.1448,
        -0.1208,  0.0233,  0.0642,  0.1284,  0.2093,  0.0747,  0.0531,  0.0357,
        -0.1063, -0.0285,  0.0299, -0.0380, -0.0536,  0.0051, -0.0651,  0.0124,
        -0.1762,  0.2016,  0.0998,  0.0959, -0.1021, -0.2120,  0.1045, -0.0323],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0805,  0.1654, -0.1036, -0.1248,  0.1610,  0.2182, -0.1669, -0.2686,
         -0.1513,  0.2050,  0.1288,  0.2531, -0.0702, -0.2626,  0.1678, -0.0820,
         -0.1863,  0.2242, -0.1014, -0.1321,  0.2733,  0.1210, -0.2576, -0.2754,
         -0.1875, -0.1984, -0.2053,  0.2066, -0.2355,  0.2740,  0.1722, -0.1137]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0110,  0.0668,  0.0894,  ...,  0.0111, -0.1713, -0.1137],
        [-0.1090, -0.0697,  0.1211,  ..., -0.0180, -0.2297,  0.0871],
        [-0.0413,  0.0340,  0.0858,  ...,  0.1382,  0.1300,  0.0345],
        ...,
        [ 0.1050, -0.1138, -0.0138,  ..., -0.0914, -0.0710, -0.1180],
        [ 0.0761, -0.1734, -0.0440,  ..., -0.1445,  0.0391,  0.1557],
        [-0.1751,  0.1118,  0.0618,  ..., -0.0562, -0.1546, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0291,  0.0351, -0.0914, -0.1468, -0.0800,  0.0533, -0.0935,  0.0485,
        -0.0071,  0.0618,  0.0197,  0.0111, -0.0448,  0.0656, -0.0447, -0.0113,
         0.0426, -0.1779, -0.0645,  0.0648, -0.0449,  0.0481,  0.1191,  0.0064,
        -0.0768,  0.1133,  0.0503, -0.0936,  0.0289,  0.1891,  0.1693, -0.1296],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1273, -0.1146, -0.1465,  ...,  0.0194, -0.1094,  0.1112],
        [-0.1355,  0.0466,  0.0288,  ...,  0.1074, -0.1032,  0.1047],
        [ 0.0593, -0.1203, -0.0923,  ..., -0.0971,  0.0872,  0.1190],
        ...,
        [ 0.0624,  0.0262,  0.1526,  ...,  0.0973, -0.1244,  0.2084],
        [ 0.0596, -0.0648, -0.0156,  ...,  0.1921,  0.1313, -0.1112],
        [ 0.0626, -0.0543,  0.1532,  ...,  0.1997,  0.0576,  0.0019]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0977,  0.1349, -0.0261, -0.0767, -0.0372, -0.0617, -0.0383, -0.0812,
         0.1340, -0.1528,  0.1253, -0.1234,  0.1781,  0.0808, -0.1375,  0.0868,
        -0.1403, -0.1699,  0.0441, -0.0204,  0.0129,  0.1098, -0.1928,  0.2070,
        -0.0659, -0.0095,  0.0851, -0.0433, -0.1214, -0.0731,  0.0994,  0.0225],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2074,  0.1257, -0.1752, -0.1553,  0.0185,  0.0240, -0.0863,  0.0132,
          0.1177, -0.1484, -0.0554,  0.0805,  0.0826,  0.0745,  0.1166,  0.0956,
         -0.2073, -0.2107,  0.0493,  0.0437, -0.1143, -0.0970, -0.1910,  0.0702,
          0.1342,  0.2152, -0.1821,  0.1471, -0.0931, -0.1967,  0.1520,  0.1894]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0220], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5961e-01,  3.2372e-01,  4.9827e-02, -7.9242e-02,  6.1530e-02,
          1.0622e-01,  2.3205e-01, -1.1046e-01,  1.1172e-01,  1.9287e-01,
          1.0728e-01, -8.1885e-02, -2.2474e-01, -3.1037e-01,  1.9574e-01,
          1.2256e-01],
        [-1.8605e-01, -1.3090e-01, -4.1175e-02, -7.5464e-02, -1.0610e-01,
          1.8342e-01,  8.6679e-02,  8.6777e-02,  3.2555e-01,  6.5747e-02,
          1.0816e-01, -1.8985e-01,  8.0855e-02,  6.5293e-03,  2.7656e-01,
         -2.0145e-02],
        [ 1.1726e-02,  2.5321e-02,  3.1766e-01, -5.6494e-02,  1.5765e-02,
         -2.7682e-01,  3.5491e-02, -3.3842e-01,  1.2137e-01, -3.6088e-03,
          7.6384e-03, -1.3604e-01,  3.2563e-01,  2.6464e-01,  1.3862e-01,
          1.9819e-01],
        [ 2.0581e-01, -1.6878e-01,  2.2367e-02, -7.0726e-03,  2.1258e-02,
         -1.3474e-01, -7.8104e-02, -2.6363e-02, -3.4766e-01, -3.3726e-01,
          1.7706e-02,  2.9402e-01,  2.3764e-01, -1.6148e-01, -1.4144e-01,
          9.4713e-02],
        [-2.5055e-02,  2.9369e-01, -1.0497e-01, -9.8928e-02,  6.8295e-02,
          1.6370e-02, -4.5983e-02,  2.4069e-01,  6.3451e-02,  2.2467e-01,
          1.4527e-01, -8.5527e-02,  3.4949e-02, -1.8460e-01,  1.8826e-01,
         -9.2549e-02],
        [ 5.8328e-02,  3.3246e-01, -2.9999e-01,  3.3435e-01,  2.4972e-01,
         -8.8451e-02,  1.8116e-01, -1.0028e-01,  1.8187e-01,  1.4655e-01,
         -2.3953e-01, -1.9281e-02, -1.7228e-01,  1.8019e-01,  3.0052e-01,
         -1.7880e-02],
        [ 3.1175e-01, -7.9783e-03,  3.5356e-01, -1.2263e-01,  6.3176e-03,
         -1.5910e-01, -1.1526e-01, -1.8316e-01, -1.9894e-01,  3.7046e-02,
          4.8490e-02,  3.8863e-03, -1.0984e-01,  1.8782e-01, -2.5622e-01,
          1.0071e-01],
        [-1.1011e-01,  1.2084e-01,  3.1192e-01, -2.9833e-01, -2.7978e-01,
         -2.5651e-01, -3.4467e-02, -2.2465e-01, -1.5278e-01, -1.6474e-01,
         -1.2431e-03, -1.1976e-02,  2.1640e-01, -1.1794e-01, -5.7159e-02,
          3.1110e-01],
        [-3.1355e-02,  1.0470e-01,  2.4079e-01, -1.7713e-01,  3.4399e-02,
         -2.8164e-01, -8.5998e-02, -3.0168e-02,  1.1904e-01, -2.4655e-01,
         -1.0036e-01, -1.5265e-02, -1.4165e-01,  1.1730e-01, -2.5594e-01,
          3.5419e-02],
        [-2.2056e-01,  1.0595e-01, -3.6757e-02, -8.3507e-02, -1.7666e-02,
          8.9686e-02, -3.5713e-02,  1.6184e-01,  1.9139e-01, -6.9445e-02,
          1.4692e-01,  6.6337e-02, -1.8324e-01, -3.1624e-02,  8.3618e-02,
         -1.3973e-01],
        [-2.8758e-01,  2.9077e-01, -9.5754e-04, -1.0065e-01, -1.2594e-01,
          3.6196e-01,  1.5496e-01,  5.0484e-02,  2.8025e-01,  1.9105e-01,
          4.0115e-03,  7.7702e-02, -1.2333e-01,  1.5774e-01, -9.0167e-02,
         -2.7188e-01],
        [-6.8015e-02,  5.3119e-02,  2.9127e-02,  2.8408e-02,  8.9925e-02,
          6.5710e-02,  2.9536e-01,  8.7449e-02,  9.8536e-02,  2.9139e-01,
          1.6470e-01,  1.2581e-01, -3.5377e-01, -2.1015e-01,  3.4117e-03,
         -1.5888e-01],
        [ 2.4452e-01,  3.2129e-02,  8.5026e-02, -8.7748e-02,  9.8770e-04,
          1.0818e-01,  2.2536e-02, -2.2116e-01, -2.2844e-01, -2.6682e-02,
          9.2898e-03, -5.6658e-02, -1.4240e-01,  1.0486e-01, -1.3716e-01,
         -4.9092e-02],
        [ 1.5442e-01,  1.5342e-01,  3.1863e-01,  4.6630e-02, -2.4243e-01,
          2.9950e-02,  2.2142e-02, -1.6754e-02, -1.5978e-01, -1.1058e-01,
         -1.0781e-01,  5.2786e-02,  6.2692e-02,  3.0801e-02, -2.9732e-01,
          1.9259e-01],
        [-3.1820e-01, -8.9370e-02, -1.5953e-02, -1.0221e-01,  3.0057e-01,
          3.5635e-01,  3.3158e-02,  6.5096e-02, -8.8197e-02,  1.2620e-01,
          1.6161e-02, -2.5158e-01, -2.9664e-02, -8.1696e-02, -1.7346e-02,
         -1.1250e-01],
        [-1.4050e-01, -2.6352e-01,  1.3809e-01,  1.4992e-01, -1.9831e-01,
          5.4101e-02, -7.9866e-02, -2.0572e-01, -9.4044e-02,  1.6631e-02,
          3.1512e-02,  3.2646e-01,  5.4815e-02, -1.0381e-01,  1.8400e-01,
          2.4674e-02],
        [ 2.6440e-01,  7.2004e-02,  1.5230e-01, -2.9770e-01, -2.9770e-01,
          4.9429e-03, -4.3582e-02,  4.5408e-02, -3.1632e-01, -1.3998e-01,
          2.5652e-01,  2.4015e-01,  3.1171e-01,  2.6180e-01, -1.1177e-01,
         -6.8470e-02],
        [-2.5083e-01,  1.7650e-01, -2.0228e-01,  8.7957e-02,  9.2172e-02,
          2.6372e-01,  2.3979e-01,  2.4020e-01,  1.0095e-01,  2.3944e-01,
         -1.2136e-01, -2.0612e-01, -1.4208e-01, -2.0568e-01,  2.6466e-01,
         -1.3560e-01],
        [ 1.6418e-01, -8.6327e-02,  9.1125e-02, -2.3130e-01, -1.1540e-01,
         -3.1792e-01, -2.0936e-01,  9.8765e-02, -3.2663e-01, -5.8789e-02,
          7.9116e-02, -1.4786e-01,  1.4112e-01,  2.2021e-01,  8.7936e-02,
          1.3716e-01],
        [ 3.1258e-01, -8.7063e-02,  2.1620e-01, -2.9549e-02, -2.4050e-01,
         -1.7759e-01, -2.8925e-01,  8.7753e-02,  1.6631e-02, -2.1876e-01,
          2.5057e-02,  1.8523e-01, -1.0773e-01,  7.9590e-02,  6.0522e-02,
          1.4763e-01],
        [-1.2677e-01,  2.5501e-01,  3.0419e-03, -1.3127e-01,  2.0684e-01,
         -8.6025e-02,  2.4507e-01,  3.1005e-01,  1.1949e-01,  1.8354e-02,
         -1.8333e-01, -2.2017e-01, -1.4849e-01, -1.7105e-01,  3.0857e-01,
         -2.0767e-01],
        [ 6.1332e-03, -1.4965e-01,  2.5439e-02,  3.0051e-01, -1.3139e-01,
          3.8861e-02,  1.5683e-01, -1.4560e-01, -6.7781e-02,  1.8406e-01,
          2.4037e-01, -1.7607e-01, -9.8314e-02, -2.9982e-01, -2.0297e-01,
          1.2491e-01],
        [ 3.1493e-01, -1.6253e-01,  6.9856e-03, -1.0651e-01,  6.7905e-02,
         -3.5106e-01, -2.4062e-01, -1.7998e-01, -2.0078e-01, -1.0763e-01,
          2.2749e-01,  1.6082e-01, -1.2627e-01,  2.9357e-01,  1.5411e-01,
          1.7806e-01],
        [ 2.1939e-01,  1.2097e-02,  3.0314e-01, -3.2169e-01, -1.9809e-01,
         -1.3925e-01, -1.4374e-01, -2.5804e-01, -3.2454e-01, -2.8611e-01,
          3.4002e-02,  3.1528e-01,  2.6338e-01,  1.2974e-01, -2.0074e-01,
         -8.1736e-03],
        [ 1.3425e-01, -3.2610e-01,  1.0221e-01, -4.7235e-02,  1.6996e-01,
         -1.8122e-01,  1.3648e-01, -8.5577e-02, -2.7235e-01,  1.2837e-01,
          2.6514e-01, -8.4838e-02, -3.8854e-02,  1.8827e-01, -2.0544e-01,
          2.7702e-01],
        [-1.3573e-02, -1.7037e-01,  3.7566e-02,  1.4218e-01, -1.4699e-01,
         -1.5859e-01,  4.2789e-02, -2.7127e-01, -1.0602e-01, -2.9925e-01,
         -2.1172e-01,  5.1742e-02,  1.2887e-01,  2.8279e-01, -3.0254e-01,
          3.0806e-02],
        [ 1.7061e-01,  6.4587e-03,  2.5391e-01, -2.9280e-01, -1.0768e-01,
         -5.3598e-02, -3.0317e-01,  2.7324e-02, -3.3053e-01,  5.3812e-02,
          9.5803e-02,  3.6386e-02,  1.8491e-01,  2.7421e-01,  1.3950e-01,
          2.5311e-01],
        [-2.5753e-01,  1.6218e-01,  7.2732e-02,  1.4197e-01,  2.1950e-01,
         -3.7255e-02,  2.8592e-01,  9.7473e-02, -1.2613e-01,  4.4712e-02,
          1.5537e-01, -2.0140e-01, -1.5416e-01, -1.6901e-01, -8.2111e-02,
         -6.4987e-02],
        [ 2.5585e-01, -4.4308e-02,  9.2238e-02, -7.7365e-02, -2.4088e-01,
         -2.4490e-01, -9.2521e-02, -2.9611e-01,  3.0126e-02, -6.6466e-02,
          8.9488e-02,  9.3082e-02,  3.0860e-01,  2.9626e-01,  5.6434e-02,
          2.2632e-01],
        [-2.2351e-01,  1.8766e-01, -2.7419e-01,  1.9739e-01, -1.3287e-01,
          1.0610e-01,  2.8118e-01,  2.6267e-01,  3.1042e-01,  1.8369e-01,
          1.1102e-01, -3.4631e-02,  8.4462e-02,  7.2498e-02,  1.0976e-01,
         -1.8550e-01],
        [-2.3005e-01,  3.1177e-02,  7.1286e-03, -3.9543e-02,  1.2676e-01,
          3.3401e-01,  3.1966e-01, -8.2276e-02,  1.6914e-01,  2.7035e-01,
         -2.8537e-01,  4.7476e-02, -2.6063e-01, -2.4995e-01, -4.8060e-02,
         -2.0077e-01],
        [-9.3079e-04, -1.8716e-02,  2.0297e-01, -2.8917e-04,  8.7566e-02,
         -2.6736e-01, -3.3573e-01, -3.0081e-01, -2.3370e-01, -2.1950e-01,
          1.3388e-01, -7.7607e-02, -7.9120e-02,  2.2945e-01, -2.3796e-01,
          1.4871e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1526,  0.0124,  0.0753, -0.0883,  0.0271, -0.1153,  0.0984,  0.1448,
        -0.1208,  0.0233,  0.0642,  0.1284,  0.2093,  0.0747,  0.0531,  0.0357,
        -0.1063, -0.0285,  0.0299, -0.0380, -0.0536,  0.0051, -0.0651,  0.0124,
        -0.1762,  0.2016,  0.0998,  0.0959, -0.1021, -0.2120,  0.1045, -0.0323],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0805,  0.1654, -0.1036, -0.1248,  0.1610,  0.2182, -0.1669, -0.2686,
         -0.1513,  0.2050,  0.1288,  0.2531, -0.0702, -0.2626,  0.1678, -0.0820,
         -0.1863,  0.2242, -0.1014, -0.1321,  0.2733,  0.1210, -0.2576, -0.2754,
         -0.1875, -0.1984, -0.2053,  0.2066, -0.2355,  0.2740,  0.1722, -0.1137]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0110,  0.0668,  0.0894,  ...,  0.0111, -0.1713, -0.1137],
        [-0.1090, -0.0697,  0.1211,  ..., -0.0180, -0.2297,  0.0871],
        [-0.0413,  0.0340,  0.0858,  ...,  0.1382,  0.1300,  0.0345],
        ...,
        [ 0.1050, -0.1138, -0.0138,  ..., -0.0914, -0.0710, -0.1180],
        [ 0.0761, -0.1734, -0.0440,  ..., -0.1445,  0.0391,  0.1557],
        [-0.1751,  0.1118,  0.0618,  ..., -0.0562, -0.1546, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0291,  0.0351, -0.0914, -0.1468, -0.0800,  0.0533, -0.0935,  0.0485,
        -0.0071,  0.0618,  0.0197,  0.0111, -0.0448,  0.0656, -0.0447, -0.0113,
         0.0426, -0.1779, -0.0645,  0.0648, -0.0449,  0.0481,  0.1191,  0.0064,
        -0.0768,  0.1133,  0.0503, -0.0936,  0.0289,  0.1891,  0.1693, -0.1296],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1273, -0.1146, -0.1465,  ...,  0.0194, -0.1094,  0.1112],
        [-0.1355,  0.0466,  0.0288,  ...,  0.1074, -0.1032,  0.1047],
        [ 0.0593, -0.1203, -0.0923,  ..., -0.0971,  0.0872,  0.1190],
        ...,
        [ 0.0624,  0.0262,  0.1526,  ...,  0.0973, -0.1244,  0.2084],
        [ 0.0596, -0.0648, -0.0156,  ...,  0.1921,  0.1313, -0.1112],
        [ 0.0626, -0.0543,  0.1532,  ...,  0.1997,  0.0576,  0.0019]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0977,  0.1349, -0.0261, -0.0767, -0.0372, -0.0617, -0.0383, -0.0812,
         0.1340, -0.1528,  0.1253, -0.1234,  0.1781,  0.0808, -0.1375,  0.0868,
        -0.1403, -0.1699,  0.0441, -0.0204,  0.0129,  0.1098, -0.1928,  0.2070,
        -0.0659, -0.0095,  0.0851, -0.0433, -0.1214, -0.0731,  0.0994,  0.0225],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2074,  0.1257, -0.1752, -0.1553,  0.0185,  0.0240, -0.0863,  0.0132,
          0.1177, -0.1484, -0.0554,  0.0805,  0.0826,  0.0745,  0.1166,  0.0956,
         -0.2073, -0.2107,  0.0493,  0.0437, -0.1143, -0.0970, -0.1910,  0.0702,
          0.1342,  0.2152, -0.1821,  0.1471, -0.0931, -0.1967,  0.1520,  0.1894]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0220], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5961e-01,  3.2372e-01,  4.9827e-02, -7.9242e-02,  6.1530e-02,
          1.0622e-01,  2.3205e-01, -1.1046e-01,  1.1172e-01,  1.9287e-01,
          1.0728e-01, -8.1885e-02, -2.2474e-01, -3.1037e-01,  1.9574e-01,
          1.2256e-01],
        [-1.8605e-01, -1.3090e-01, -4.1175e-02, -7.5464e-02, -1.0610e-01,
          1.8342e-01,  8.6679e-02,  8.6777e-02,  3.2555e-01,  6.5747e-02,
          1.0816e-01, -1.8985e-01,  8.0855e-02,  6.5293e-03,  2.7656e-01,
         -2.0145e-02],
        [ 1.1726e-02,  2.5321e-02,  3.1766e-01, -5.6494e-02,  1.5765e-02,
         -2.7682e-01,  3.5491e-02, -3.3842e-01,  1.2137e-01, -3.6088e-03,
          7.6384e-03, -1.3604e-01,  3.2563e-01,  2.6464e-01,  1.3862e-01,
          1.9819e-01],
        [ 2.0581e-01, -1.6878e-01,  2.2367e-02, -7.0726e-03,  2.1258e-02,
         -1.3474e-01, -7.8104e-02, -2.6363e-02, -3.4766e-01, -3.3726e-01,
          1.7706e-02,  2.9402e-01,  2.3764e-01, -1.6148e-01, -1.4144e-01,
          9.4713e-02],
        [-2.5055e-02,  2.9369e-01, -1.0497e-01, -9.8928e-02,  6.8295e-02,
          1.6370e-02, -4.5983e-02,  2.4069e-01,  6.3451e-02,  2.2467e-01,
          1.4527e-01, -8.5527e-02,  3.4949e-02, -1.8460e-01,  1.8826e-01,
         -9.2549e-02],
        [ 5.8328e-02,  3.3246e-01, -2.9999e-01,  3.3435e-01,  2.4972e-01,
         -8.8451e-02,  1.8116e-01, -1.0028e-01,  1.8187e-01,  1.4655e-01,
         -2.3953e-01, -1.9281e-02, -1.7228e-01,  1.8019e-01,  3.0052e-01,
         -1.7880e-02],
        [ 3.1175e-01, -7.9783e-03,  3.5356e-01, -1.2263e-01,  6.3176e-03,
         -1.5910e-01, -1.1526e-01, -1.8316e-01, -1.9894e-01,  3.7046e-02,
          4.8490e-02,  3.8863e-03, -1.0984e-01,  1.8782e-01, -2.5622e-01,
          1.0071e-01],
        [-1.1011e-01,  1.2084e-01,  3.1192e-01, -2.9833e-01, -2.7978e-01,
         -2.5651e-01, -3.4467e-02, -2.2465e-01, -1.5278e-01, -1.6474e-01,
         -1.2431e-03, -1.1976e-02,  2.1640e-01, -1.1794e-01, -5.7159e-02,
          3.1110e-01],
        [-3.1355e-02,  1.0470e-01,  2.4079e-01, -1.7713e-01,  3.4399e-02,
         -2.8164e-01, -8.5998e-02, -3.0168e-02,  1.1904e-01, -2.4655e-01,
         -1.0036e-01, -1.5265e-02, -1.4165e-01,  1.1730e-01, -2.5594e-01,
          3.5419e-02],
        [-2.2056e-01,  1.0595e-01, -3.6757e-02, -8.3507e-02, -1.7666e-02,
          8.9686e-02, -3.5713e-02,  1.6184e-01,  1.9139e-01, -6.9445e-02,
          1.4692e-01,  6.6337e-02, -1.8324e-01, -3.1624e-02,  8.3618e-02,
         -1.3973e-01],
        [-2.8758e-01,  2.9077e-01, -9.5754e-04, -1.0065e-01, -1.2594e-01,
          3.6196e-01,  1.5496e-01,  5.0484e-02,  2.8025e-01,  1.9105e-01,
          4.0115e-03,  7.7702e-02, -1.2333e-01,  1.5774e-01, -9.0167e-02,
         -2.7188e-01],
        [-6.8015e-02,  5.3119e-02,  2.9127e-02,  2.8408e-02,  8.9925e-02,
          6.5710e-02,  2.9536e-01,  8.7449e-02,  9.8536e-02,  2.9139e-01,
          1.6470e-01,  1.2581e-01, -3.5377e-01, -2.1015e-01,  3.4117e-03,
         -1.5888e-01],
        [ 2.4452e-01,  3.2129e-02,  8.5026e-02, -8.7748e-02,  9.8770e-04,
          1.0818e-01,  2.2536e-02, -2.2116e-01, -2.2844e-01, -2.6682e-02,
          9.2898e-03, -5.6658e-02, -1.4240e-01,  1.0486e-01, -1.3716e-01,
         -4.9092e-02],
        [ 1.5442e-01,  1.5342e-01,  3.1863e-01,  4.6630e-02, -2.4243e-01,
          2.9950e-02,  2.2142e-02, -1.6754e-02, -1.5978e-01, -1.1058e-01,
         -1.0781e-01,  5.2786e-02,  6.2692e-02,  3.0801e-02, -2.9732e-01,
          1.9259e-01],
        [-3.1820e-01, -8.9370e-02, -1.5953e-02, -1.0221e-01,  3.0057e-01,
          3.5635e-01,  3.3158e-02,  6.5096e-02, -8.8197e-02,  1.2620e-01,
          1.6161e-02, -2.5158e-01, -2.9664e-02, -8.1696e-02, -1.7346e-02,
         -1.1250e-01],
        [-1.4050e-01, -2.6352e-01,  1.3809e-01,  1.4992e-01, -1.9831e-01,
          5.4101e-02, -7.9866e-02, -2.0572e-01, -9.4044e-02,  1.6631e-02,
          3.1512e-02,  3.2646e-01,  5.4815e-02, -1.0381e-01,  1.8400e-01,
          2.4674e-02],
        [ 2.6440e-01,  7.2004e-02,  1.5230e-01, -2.9770e-01, -2.9770e-01,
          4.9429e-03, -4.3582e-02,  4.5408e-02, -3.1632e-01, -1.3998e-01,
          2.5652e-01,  2.4015e-01,  3.1171e-01,  2.6180e-01, -1.1177e-01,
         -6.8470e-02],
        [-2.5083e-01,  1.7650e-01, -2.0228e-01,  8.7957e-02,  9.2172e-02,
          2.6372e-01,  2.3979e-01,  2.4020e-01,  1.0095e-01,  2.3944e-01,
         -1.2136e-01, -2.0612e-01, -1.4208e-01, -2.0568e-01,  2.6466e-01,
         -1.3560e-01],
        [ 1.6418e-01, -8.6327e-02,  9.1125e-02, -2.3130e-01, -1.1540e-01,
         -3.1792e-01, -2.0936e-01,  9.8765e-02, -3.2663e-01, -5.8789e-02,
          7.9116e-02, -1.4786e-01,  1.4112e-01,  2.2021e-01,  8.7936e-02,
          1.3716e-01],
        [ 3.1258e-01, -8.7063e-02,  2.1620e-01, -2.9549e-02, -2.4050e-01,
         -1.7759e-01, -2.8925e-01,  8.7753e-02,  1.6631e-02, -2.1876e-01,
          2.5057e-02,  1.8523e-01, -1.0773e-01,  7.9590e-02,  6.0522e-02,
          1.4763e-01],
        [-1.2677e-01,  2.5501e-01,  3.0419e-03, -1.3127e-01,  2.0684e-01,
         -8.6025e-02,  2.4507e-01,  3.1005e-01,  1.1949e-01,  1.8354e-02,
         -1.8333e-01, -2.2017e-01, -1.4849e-01, -1.7105e-01,  3.0857e-01,
         -2.0767e-01],
        [ 6.1332e-03, -1.4965e-01,  2.5439e-02,  3.0051e-01, -1.3139e-01,
          3.8861e-02,  1.5683e-01, -1.4560e-01, -6.7781e-02,  1.8406e-01,
          2.4037e-01, -1.7607e-01, -9.8314e-02, -2.9982e-01, -2.0297e-01,
          1.2491e-01],
        [ 3.1493e-01, -1.6253e-01,  6.9856e-03, -1.0651e-01,  6.7905e-02,
         -3.5106e-01, -2.4062e-01, -1.7998e-01, -2.0078e-01, -1.0763e-01,
          2.2749e-01,  1.6082e-01, -1.2627e-01,  2.9357e-01,  1.5411e-01,
          1.7806e-01],
        [ 2.1939e-01,  1.2097e-02,  3.0314e-01, -3.2169e-01, -1.9809e-01,
         -1.3925e-01, -1.4374e-01, -2.5804e-01, -3.2454e-01, -2.8611e-01,
          3.4002e-02,  3.1528e-01,  2.6338e-01,  1.2974e-01, -2.0074e-01,
         -8.1736e-03],
        [ 1.3425e-01, -3.2610e-01,  1.0221e-01, -4.7235e-02,  1.6996e-01,
         -1.8122e-01,  1.3648e-01, -8.5577e-02, -2.7235e-01,  1.2837e-01,
          2.6514e-01, -8.4838e-02, -3.8854e-02,  1.8827e-01, -2.0544e-01,
          2.7702e-01],
        [-1.3573e-02, -1.7037e-01,  3.7566e-02,  1.4218e-01, -1.4699e-01,
         -1.5859e-01,  4.2789e-02, -2.7127e-01, -1.0602e-01, -2.9925e-01,
         -2.1172e-01,  5.1742e-02,  1.2887e-01,  2.8279e-01, -3.0254e-01,
          3.0806e-02],
        [ 1.7061e-01,  6.4587e-03,  2.5391e-01, -2.9280e-01, -1.0768e-01,
         -5.3598e-02, -3.0317e-01,  2.7324e-02, -3.3053e-01,  5.3812e-02,
          9.5803e-02,  3.6386e-02,  1.8491e-01,  2.7421e-01,  1.3950e-01,
          2.5311e-01],
        [-2.5753e-01,  1.6218e-01,  7.2732e-02,  1.4197e-01,  2.1950e-01,
         -3.7255e-02,  2.8592e-01,  9.7473e-02, -1.2613e-01,  4.4712e-02,
          1.5537e-01, -2.0140e-01, -1.5416e-01, -1.6901e-01, -8.2111e-02,
         -6.4987e-02],
        [ 2.5585e-01, -4.4308e-02,  9.2238e-02, -7.7365e-02, -2.4088e-01,
         -2.4490e-01, -9.2521e-02, -2.9611e-01,  3.0126e-02, -6.6466e-02,
          8.9488e-02,  9.3082e-02,  3.0860e-01,  2.9626e-01,  5.6434e-02,
          2.2632e-01],
        [-2.2351e-01,  1.8766e-01, -2.7419e-01,  1.9739e-01, -1.3287e-01,
          1.0610e-01,  2.8118e-01,  2.6267e-01,  3.1042e-01,  1.8369e-01,
          1.1102e-01, -3.4631e-02,  8.4462e-02,  7.2498e-02,  1.0976e-01,
         -1.8550e-01],
        [-2.3005e-01,  3.1177e-02,  7.1286e-03, -3.9543e-02,  1.2676e-01,
          3.3401e-01,  3.1966e-01, -8.2276e-02,  1.6914e-01,  2.7035e-01,
         -2.8537e-01,  4.7476e-02, -2.6063e-01, -2.4995e-01, -4.8060e-02,
         -2.0077e-01],
        [-9.3079e-04, -1.8716e-02,  2.0297e-01, -2.8917e-04,  8.7566e-02,
         -2.6736e-01, -3.3573e-01, -3.0081e-01, -2.3370e-01, -2.1950e-01,
          1.3388e-01, -7.7607e-02, -7.9120e-02,  2.2945e-01, -2.3796e-01,
          1.4871e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1526,  0.0124,  0.0753, -0.0883,  0.0271, -0.1153,  0.0984,  0.1448,
        -0.1208,  0.0233,  0.0642,  0.1284,  0.2093,  0.0747,  0.0531,  0.0357,
        -0.1063, -0.0285,  0.0299, -0.0380, -0.0536,  0.0051, -0.0651,  0.0124,
        -0.1762,  0.2016,  0.0998,  0.0959, -0.1021, -0.2120,  0.1045, -0.0323],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0805,  0.1654, -0.1036, -0.1248,  0.1610,  0.2182, -0.1669, -0.2686,
         -0.1513,  0.2050,  0.1288,  0.2531, -0.0702, -0.2626,  0.1678, -0.0820,
         -0.1863,  0.2242, -0.1014, -0.1321,  0.2733,  0.1210, -0.2576, -0.2754,
         -0.1875, -0.1984, -0.2053,  0.2066, -0.2355,  0.2740,  0.1722, -0.1137]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0110,  0.0668,  0.0894,  ...,  0.0111, -0.1713, -0.1137],
        [-0.1090, -0.0697,  0.1211,  ..., -0.0180, -0.2297,  0.0871],
        [-0.0413,  0.0340,  0.0858,  ...,  0.1382,  0.1300,  0.0345],
        ...,
        [ 0.1050, -0.1138, -0.0138,  ..., -0.0914, -0.0710, -0.1180],
        [ 0.0761, -0.1734, -0.0440,  ..., -0.1445,  0.0391,  0.1557],
        [-0.1751,  0.1118,  0.0618,  ..., -0.0562, -0.1546, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0291,  0.0351, -0.0914, -0.1468, -0.0800,  0.0533, -0.0935,  0.0485,
        -0.0071,  0.0618,  0.0197,  0.0111, -0.0448,  0.0656, -0.0447, -0.0113,
         0.0426, -0.1779, -0.0645,  0.0648, -0.0449,  0.0481,  0.1191,  0.0064,
        -0.0768,  0.1133,  0.0503, -0.0936,  0.0289,  0.1891,  0.1693, -0.1296],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1273, -0.1146, -0.1465,  ...,  0.0194, -0.1094,  0.1112],
        [-0.1355,  0.0466,  0.0288,  ...,  0.1074, -0.1032,  0.1047],
        [ 0.0593, -0.1203, -0.0923,  ..., -0.0971,  0.0872,  0.1190],
        ...,
        [ 0.0624,  0.0262,  0.1526,  ...,  0.0973, -0.1244,  0.2084],
        [ 0.0596, -0.0648, -0.0156,  ...,  0.1921,  0.1313, -0.1112],
        [ 0.0626, -0.0543,  0.1532,  ...,  0.1997,  0.0576,  0.0019]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0977,  0.1349, -0.0261, -0.0767, -0.0372, -0.0617, -0.0383, -0.0812,
         0.1340, -0.1528,  0.1253, -0.1234,  0.1781,  0.0808, -0.1375,  0.0868,
        -0.1403, -0.1699,  0.0441, -0.0204,  0.0129,  0.1098, -0.1928,  0.2070,
        -0.0659, -0.0095,  0.0851, -0.0433, -0.1214, -0.0731,  0.0994,  0.0225],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2074,  0.1257, -0.1752, -0.1553,  0.0185,  0.0240, -0.0863,  0.0132,
          0.1177, -0.1484, -0.0554,  0.0805,  0.0826,  0.0745,  0.1166,  0.0956,
         -0.2073, -0.2107,  0.0493,  0.0437, -0.1143, -0.0970, -0.1910,  0.0702,
          0.1342,  0.2152, -0.1821,  0.1471, -0.0931, -0.1967,  0.1520,  0.1894]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0220], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5961e-01,  3.2372e-01,  4.9827e-02, -7.9242e-02,  6.1530e-02,
          1.0622e-01,  2.3205e-01, -1.1046e-01,  1.1172e-01,  1.9287e-01,
          1.0728e-01, -8.1885e-02, -2.2474e-01, -3.1037e-01,  1.9574e-01,
          1.2256e-01],
        [-1.8605e-01, -1.3090e-01, -4.1175e-02, -7.5464e-02, -1.0610e-01,
          1.8342e-01,  8.6679e-02,  8.6777e-02,  3.2555e-01,  6.5747e-02,
          1.0816e-01, -1.8985e-01,  8.0855e-02,  6.5293e-03,  2.7656e-01,
         -2.0145e-02],
        [ 1.1726e-02,  2.5321e-02,  3.1766e-01, -5.6494e-02,  1.5765e-02,
         -2.7682e-01,  3.5491e-02, -3.3842e-01,  1.2137e-01, -3.6088e-03,
          7.6384e-03, -1.3604e-01,  3.2563e-01,  2.6464e-01,  1.3862e-01,
          1.9819e-01],
        [ 2.0581e-01, -1.6878e-01,  2.2367e-02, -7.0726e-03,  2.1258e-02,
         -1.3474e-01, -7.8104e-02, -2.6363e-02, -3.4766e-01, -3.3726e-01,
          1.7706e-02,  2.9402e-01,  2.3764e-01, -1.6148e-01, -1.4144e-01,
          9.4713e-02],
        [-2.5055e-02,  2.9369e-01, -1.0497e-01, -9.8928e-02,  6.8295e-02,
          1.6370e-02, -4.5983e-02,  2.4069e-01,  6.3451e-02,  2.2467e-01,
          1.4527e-01, -8.5527e-02,  3.4949e-02, -1.8460e-01,  1.8826e-01,
         -9.2549e-02],
        [ 5.8328e-02,  3.3246e-01, -2.9999e-01,  3.3435e-01,  2.4972e-01,
         -8.8451e-02,  1.8116e-01, -1.0028e-01,  1.8187e-01,  1.4655e-01,
         -2.3953e-01, -1.9281e-02, -1.7228e-01,  1.8019e-01,  3.0052e-01,
         -1.7880e-02],
        [ 3.1175e-01, -7.9783e-03,  3.5356e-01, -1.2263e-01,  6.3176e-03,
         -1.5910e-01, -1.1526e-01, -1.8316e-01, -1.9894e-01,  3.7046e-02,
          4.8490e-02,  3.8863e-03, -1.0984e-01,  1.8782e-01, -2.5622e-01,
          1.0071e-01],
        [-1.1011e-01,  1.2084e-01,  3.1192e-01, -2.9833e-01, -2.7978e-01,
         -2.5651e-01, -3.4467e-02, -2.2465e-01, -1.5278e-01, -1.6474e-01,
         -1.2431e-03, -1.1976e-02,  2.1640e-01, -1.1794e-01, -5.7159e-02,
          3.1110e-01],
        [-3.1355e-02,  1.0470e-01,  2.4079e-01, -1.7713e-01,  3.4399e-02,
         -2.8164e-01, -8.5998e-02, -3.0168e-02,  1.1904e-01, -2.4655e-01,
         -1.0036e-01, -1.5265e-02, -1.4165e-01,  1.1730e-01, -2.5594e-01,
          3.5419e-02],
        [-2.2056e-01,  1.0595e-01, -3.6757e-02, -8.3507e-02, -1.7666e-02,
          8.9686e-02, -3.5713e-02,  1.6184e-01,  1.9139e-01, -6.9445e-02,
          1.4692e-01,  6.6337e-02, -1.8324e-01, -3.1624e-02,  8.3618e-02,
         -1.3973e-01],
        [-2.8758e-01,  2.9077e-01, -9.5754e-04, -1.0065e-01, -1.2594e-01,
          3.6196e-01,  1.5496e-01,  5.0484e-02,  2.8025e-01,  1.9105e-01,
          4.0115e-03,  7.7702e-02, -1.2333e-01,  1.5774e-01, -9.0167e-02,
         -2.7188e-01],
        [-6.8015e-02,  5.3119e-02,  2.9127e-02,  2.8408e-02,  8.9925e-02,
          6.5710e-02,  2.9536e-01,  8.7449e-02,  9.8536e-02,  2.9139e-01,
          1.6470e-01,  1.2581e-01, -3.5377e-01, -2.1015e-01,  3.4117e-03,
         -1.5888e-01],
        [ 2.4452e-01,  3.2129e-02,  8.5026e-02, -8.7748e-02,  9.8770e-04,
          1.0818e-01,  2.2536e-02, -2.2116e-01, -2.2844e-01, -2.6682e-02,
          9.2898e-03, -5.6658e-02, -1.4240e-01,  1.0486e-01, -1.3716e-01,
         -4.9092e-02],
        [ 1.5442e-01,  1.5342e-01,  3.1863e-01,  4.6630e-02, -2.4243e-01,
          2.9950e-02,  2.2142e-02, -1.6754e-02, -1.5978e-01, -1.1058e-01,
         -1.0781e-01,  5.2786e-02,  6.2692e-02,  3.0801e-02, -2.9732e-01,
          1.9259e-01],
        [-3.1820e-01, -8.9370e-02, -1.5953e-02, -1.0221e-01,  3.0057e-01,
          3.5635e-01,  3.3158e-02,  6.5096e-02, -8.8197e-02,  1.2620e-01,
          1.6161e-02, -2.5158e-01, -2.9664e-02, -8.1696e-02, -1.7346e-02,
         -1.1250e-01],
        [-1.4050e-01, -2.6352e-01,  1.3809e-01,  1.4992e-01, -1.9831e-01,
          5.4101e-02, -7.9866e-02, -2.0572e-01, -9.4044e-02,  1.6631e-02,
          3.1512e-02,  3.2646e-01,  5.4815e-02, -1.0381e-01,  1.8400e-01,
          2.4674e-02],
        [ 2.6440e-01,  7.2004e-02,  1.5230e-01, -2.9770e-01, -2.9770e-01,
          4.9429e-03, -4.3582e-02,  4.5408e-02, -3.1632e-01, -1.3998e-01,
          2.5652e-01,  2.4015e-01,  3.1171e-01,  2.6180e-01, -1.1177e-01,
         -6.8470e-02],
        [-2.5083e-01,  1.7650e-01, -2.0228e-01,  8.7957e-02,  9.2172e-02,
          2.6372e-01,  2.3979e-01,  2.4020e-01,  1.0095e-01,  2.3944e-01,
         -1.2136e-01, -2.0612e-01, -1.4208e-01, -2.0568e-01,  2.6466e-01,
         -1.3560e-01],
        [ 1.6418e-01, -8.6327e-02,  9.1125e-02, -2.3130e-01, -1.1540e-01,
         -3.1792e-01, -2.0936e-01,  9.8765e-02, -3.2663e-01, -5.8789e-02,
          7.9116e-02, -1.4786e-01,  1.4112e-01,  2.2021e-01,  8.7936e-02,
          1.3716e-01],
        [ 3.1258e-01, -8.7063e-02,  2.1620e-01, -2.9549e-02, -2.4050e-01,
         -1.7759e-01, -2.8925e-01,  8.7753e-02,  1.6631e-02, -2.1876e-01,
          2.5057e-02,  1.8523e-01, -1.0773e-01,  7.9590e-02,  6.0522e-02,
          1.4763e-01],
        [-1.2677e-01,  2.5501e-01,  3.0419e-03, -1.3127e-01,  2.0684e-01,
         -8.6025e-02,  2.4507e-01,  3.1005e-01,  1.1949e-01,  1.8354e-02,
         -1.8333e-01, -2.2017e-01, -1.4849e-01, -1.7105e-01,  3.0857e-01,
         -2.0767e-01],
        [ 6.1332e-03, -1.4965e-01,  2.5439e-02,  3.0051e-01, -1.3139e-01,
          3.8861e-02,  1.5683e-01, -1.4560e-01, -6.7781e-02,  1.8406e-01,
          2.4037e-01, -1.7607e-01, -9.8314e-02, -2.9982e-01, -2.0297e-01,
          1.2491e-01],
        [ 3.1493e-01, -1.6253e-01,  6.9856e-03, -1.0651e-01,  6.7905e-02,
         -3.5106e-01, -2.4062e-01, -1.7998e-01, -2.0078e-01, -1.0763e-01,
          2.2749e-01,  1.6082e-01, -1.2627e-01,  2.9357e-01,  1.5411e-01,
          1.7806e-01],
        [ 2.1939e-01,  1.2097e-02,  3.0314e-01, -3.2169e-01, -1.9809e-01,
         -1.3925e-01, -1.4374e-01, -2.5804e-01, -3.2454e-01, -2.8611e-01,
          3.4002e-02,  3.1528e-01,  2.6338e-01,  1.2974e-01, -2.0074e-01,
         -8.1736e-03],
        [ 1.3425e-01, -3.2610e-01,  1.0221e-01, -4.7235e-02,  1.6996e-01,
         -1.8122e-01,  1.3648e-01, -8.5577e-02, -2.7235e-01,  1.2837e-01,
          2.6514e-01, -8.4838e-02, -3.8854e-02,  1.8827e-01, -2.0544e-01,
          2.7702e-01],
        [-1.3573e-02, -1.7037e-01,  3.7566e-02,  1.4218e-01, -1.4699e-01,
         -1.5859e-01,  4.2789e-02, -2.7127e-01, -1.0602e-01, -2.9925e-01,
         -2.1172e-01,  5.1742e-02,  1.2887e-01,  2.8279e-01, -3.0254e-01,
          3.0806e-02],
        [ 1.7061e-01,  6.4587e-03,  2.5391e-01, -2.9280e-01, -1.0768e-01,
         -5.3598e-02, -3.0317e-01,  2.7324e-02, -3.3053e-01,  5.3812e-02,
          9.5803e-02,  3.6386e-02,  1.8491e-01,  2.7421e-01,  1.3950e-01,
          2.5311e-01],
        [-2.5753e-01,  1.6218e-01,  7.2732e-02,  1.4197e-01,  2.1950e-01,
         -3.7255e-02,  2.8592e-01,  9.7473e-02, -1.2613e-01,  4.4712e-02,
          1.5537e-01, -2.0140e-01, -1.5416e-01, -1.6901e-01, -8.2111e-02,
         -6.4987e-02],
        [ 2.5585e-01, -4.4308e-02,  9.2238e-02, -7.7365e-02, -2.4088e-01,
         -2.4490e-01, -9.2521e-02, -2.9611e-01,  3.0126e-02, -6.6466e-02,
          8.9488e-02,  9.3082e-02,  3.0860e-01,  2.9626e-01,  5.6434e-02,
          2.2632e-01],
        [-2.2351e-01,  1.8766e-01, -2.7419e-01,  1.9739e-01, -1.3287e-01,
          1.0610e-01,  2.8118e-01,  2.6267e-01,  3.1042e-01,  1.8369e-01,
          1.1102e-01, -3.4631e-02,  8.4462e-02,  7.2498e-02,  1.0976e-01,
         -1.8550e-01],
        [-2.3005e-01,  3.1177e-02,  7.1286e-03, -3.9543e-02,  1.2676e-01,
          3.3401e-01,  3.1966e-01, -8.2276e-02,  1.6914e-01,  2.7035e-01,
         -2.8537e-01,  4.7476e-02, -2.6063e-01, -2.4995e-01, -4.8060e-02,
         -2.0077e-01],
        [-9.3079e-04, -1.8716e-02,  2.0297e-01, -2.8917e-04,  8.7566e-02,
         -2.6736e-01, -3.3573e-01, -3.0081e-01, -2.3370e-01, -2.1950e-01,
          1.3388e-01, -7.7607e-02, -7.9120e-02,  2.2945e-01, -2.3796e-01,
          1.4871e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1526,  0.0124,  0.0753, -0.0883,  0.0271, -0.1153,  0.0984,  0.1448,
        -0.1208,  0.0233,  0.0642,  0.1284,  0.2093,  0.0747,  0.0531,  0.0357,
        -0.1063, -0.0285,  0.0299, -0.0380, -0.0536,  0.0051, -0.0651,  0.0124,
        -0.1762,  0.2016,  0.0998,  0.0959, -0.1021, -0.2120,  0.1045, -0.0323],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0805,  0.1654, -0.1036, -0.1248,  0.1610,  0.2182, -0.1669, -0.2686,
         -0.1513,  0.2050,  0.1288,  0.2531, -0.0702, -0.2626,  0.1678, -0.0820,
         -0.1863,  0.2242, -0.1014, -0.1321,  0.2733,  0.1210, -0.2576, -0.2754,
         -0.1875, -0.1984, -0.2053,  0.2066, -0.2355,  0.2740,  0.1722, -0.1137]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0110,  0.0668,  0.0894,  ...,  0.0111, -0.1713, -0.1137],
        [-0.1090, -0.0697,  0.1211,  ..., -0.0180, -0.2297,  0.0871],
        [-0.0413,  0.0340,  0.0858,  ...,  0.1382,  0.1300,  0.0345],
        ...,
        [ 0.1050, -0.1138, -0.0138,  ..., -0.0914, -0.0710, -0.1180],
        [ 0.0761, -0.1734, -0.0440,  ..., -0.1445,  0.0391,  0.1557],
        [-0.1751,  0.1118,  0.0618,  ..., -0.0562, -0.1546, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0291,  0.0351, -0.0914, -0.1468, -0.0800,  0.0533, -0.0935,  0.0485,
        -0.0071,  0.0618,  0.0197,  0.0111, -0.0448,  0.0656, -0.0447, -0.0113,
         0.0426, -0.1779, -0.0645,  0.0648, -0.0449,  0.0481,  0.1191,  0.0064,
        -0.0768,  0.1133,  0.0503, -0.0936,  0.0289,  0.1891,  0.1693, -0.1296],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1273, -0.1146, -0.1465,  ...,  0.0194, -0.1094,  0.1112],
        [-0.1355,  0.0466,  0.0288,  ...,  0.1074, -0.1032,  0.1047],
        [ 0.0593, -0.1203, -0.0923,  ..., -0.0971,  0.0872,  0.1190],
        ...,
        [ 0.0624,  0.0262,  0.1526,  ...,  0.0973, -0.1244,  0.2084],
        [ 0.0596, -0.0648, -0.0156,  ...,  0.1921,  0.1313, -0.1112],
        [ 0.0626, -0.0543,  0.1532,  ...,  0.1997,  0.0576,  0.0019]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0977,  0.1349, -0.0261, -0.0767, -0.0372, -0.0617, -0.0383, -0.0812,
         0.1340, -0.1528,  0.1253, -0.1234,  0.1781,  0.0808, -0.1375,  0.0868,
        -0.1403, -0.1699,  0.0441, -0.0204,  0.0129,  0.1098, -0.1928,  0.2070,
        -0.0659, -0.0095,  0.0851, -0.0433, -0.1214, -0.0731,  0.0994,  0.0225],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2074,  0.1257, -0.1752, -0.1553,  0.0185,  0.0240, -0.0863,  0.0132,
          0.1177, -0.1484, -0.0554,  0.0805,  0.0826,  0.0745,  0.1166,  0.0956,
         -0.2073, -0.2107,  0.0493,  0.0437, -0.1143, -0.0970, -0.1910,  0.0702,
          0.1342,  0.2152, -0.1821,  0.1471, -0.0931, -0.1967,  0.1520,  0.1894]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0220], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5961e-01,  3.2372e-01,  4.9827e-02, -7.9242e-02,  6.1530e-02,
          1.0622e-01,  2.3205e-01, -1.1046e-01,  1.1172e-01,  1.9287e-01,
          1.0728e-01, -8.1885e-02, -2.2474e-01, -3.1037e-01,  1.9574e-01,
          1.2256e-01],
        [-1.8605e-01, -1.3090e-01, -4.1175e-02, -7.5464e-02, -1.0610e-01,
          1.8342e-01,  8.6679e-02,  8.6777e-02,  3.2555e-01,  6.5747e-02,
          1.0816e-01, -1.8985e-01,  8.0855e-02,  6.5293e-03,  2.7656e-01,
         -2.0145e-02],
        [ 1.1726e-02,  2.5321e-02,  3.1766e-01, -5.6494e-02,  1.5765e-02,
         -2.7682e-01,  3.5491e-02, -3.3842e-01,  1.2137e-01, -3.6088e-03,
          7.6384e-03, -1.3604e-01,  3.2563e-01,  2.6464e-01,  1.3862e-01,
          1.9819e-01],
        [ 2.0581e-01, -1.6878e-01,  2.2367e-02, -7.0726e-03,  2.1258e-02,
         -1.3474e-01, -7.8104e-02, -2.6363e-02, -3.4766e-01, -3.3726e-01,
          1.7706e-02,  2.9402e-01,  2.3764e-01, -1.6148e-01, -1.4144e-01,
          9.4713e-02],
        [-2.5055e-02,  2.9369e-01, -1.0497e-01, -9.8928e-02,  6.8295e-02,
          1.6370e-02, -4.5983e-02,  2.4069e-01,  6.3451e-02,  2.2467e-01,
          1.4527e-01, -8.5527e-02,  3.4949e-02, -1.8460e-01,  1.8826e-01,
         -9.2549e-02],
        [ 5.8328e-02,  3.3246e-01, -2.9999e-01,  3.3435e-01,  2.4972e-01,
         -8.8451e-02,  1.8116e-01, -1.0028e-01,  1.8187e-01,  1.4655e-01,
         -2.3953e-01, -1.9281e-02, -1.7228e-01,  1.8019e-01,  3.0052e-01,
         -1.7880e-02],
        [ 3.1175e-01, -7.9783e-03,  3.5356e-01, -1.2263e-01,  6.3176e-03,
         -1.5910e-01, -1.1526e-01, -1.8316e-01, -1.9894e-01,  3.7046e-02,
          4.8490e-02,  3.8863e-03, -1.0984e-01,  1.8782e-01, -2.5622e-01,
          1.0071e-01],
        [-1.1011e-01,  1.2084e-01,  3.1192e-01, -2.9833e-01, -2.7978e-01,
         -2.5651e-01, -3.4467e-02, -2.2465e-01, -1.5278e-01, -1.6474e-01,
         -1.2431e-03, -1.1976e-02,  2.1640e-01, -1.1794e-01, -5.7159e-02,
          3.1110e-01],
        [-3.1355e-02,  1.0470e-01,  2.4079e-01, -1.7713e-01,  3.4399e-02,
         -2.8164e-01, -8.5998e-02, -3.0168e-02,  1.1904e-01, -2.4655e-01,
         -1.0036e-01, -1.5265e-02, -1.4165e-01,  1.1730e-01, -2.5594e-01,
          3.5419e-02],
        [-2.2056e-01,  1.0595e-01, -3.6757e-02, -8.3507e-02, -1.7666e-02,
          8.9686e-02, -3.5713e-02,  1.6184e-01,  1.9139e-01, -6.9445e-02,
          1.4692e-01,  6.6337e-02, -1.8324e-01, -3.1624e-02,  8.3618e-02,
         -1.3973e-01],
        [-2.8758e-01,  2.9077e-01, -9.5754e-04, -1.0065e-01, -1.2594e-01,
          3.6196e-01,  1.5496e-01,  5.0484e-02,  2.8025e-01,  1.9105e-01,
          4.0115e-03,  7.7702e-02, -1.2333e-01,  1.5774e-01, -9.0167e-02,
         -2.7188e-01],
        [-6.8015e-02,  5.3119e-02,  2.9127e-02,  2.8408e-02,  8.9925e-02,
          6.5710e-02,  2.9536e-01,  8.7449e-02,  9.8536e-02,  2.9139e-01,
          1.6470e-01,  1.2581e-01, -3.5377e-01, -2.1015e-01,  3.4117e-03,
         -1.5888e-01],
        [ 2.4452e-01,  3.2129e-02,  8.5026e-02, -8.7748e-02,  9.8770e-04,
          1.0818e-01,  2.2536e-02, -2.2116e-01, -2.2844e-01, -2.6682e-02,
          9.2898e-03, -5.6658e-02, -1.4240e-01,  1.0486e-01, -1.3716e-01,
         -4.9092e-02],
        [ 1.5442e-01,  1.5342e-01,  3.1863e-01,  4.6630e-02, -2.4243e-01,
          2.9950e-02,  2.2142e-02, -1.6754e-02, -1.5978e-01, -1.1058e-01,
         -1.0781e-01,  5.2786e-02,  6.2692e-02,  3.0801e-02, -2.9732e-01,
          1.9259e-01],
        [-3.1820e-01, -8.9370e-02, -1.5953e-02, -1.0221e-01,  3.0057e-01,
          3.5635e-01,  3.3158e-02,  6.5096e-02, -8.8197e-02,  1.2620e-01,
          1.6161e-02, -2.5158e-01, -2.9664e-02, -8.1696e-02, -1.7346e-02,
         -1.1250e-01],
        [-1.4050e-01, -2.6352e-01,  1.3809e-01,  1.4992e-01, -1.9831e-01,
          5.4101e-02, -7.9866e-02, -2.0572e-01, -9.4044e-02,  1.6631e-02,
          3.1512e-02,  3.2646e-01,  5.4815e-02, -1.0381e-01,  1.8400e-01,
          2.4674e-02],
        [ 2.6440e-01,  7.2004e-02,  1.5230e-01, -2.9770e-01, -2.9770e-01,
          4.9429e-03, -4.3582e-02,  4.5408e-02, -3.1632e-01, -1.3998e-01,
          2.5652e-01,  2.4015e-01,  3.1171e-01,  2.6180e-01, -1.1177e-01,
         -6.8470e-02],
        [-2.5083e-01,  1.7650e-01, -2.0228e-01,  8.7957e-02,  9.2172e-02,
          2.6372e-01,  2.3979e-01,  2.4020e-01,  1.0095e-01,  2.3944e-01,
         -1.2136e-01, -2.0612e-01, -1.4208e-01, -2.0568e-01,  2.6466e-01,
         -1.3560e-01],
        [ 1.6418e-01, -8.6327e-02,  9.1125e-02, -2.3130e-01, -1.1540e-01,
         -3.1792e-01, -2.0936e-01,  9.8765e-02, -3.2663e-01, -5.8789e-02,
          7.9116e-02, -1.4786e-01,  1.4112e-01,  2.2021e-01,  8.7936e-02,
          1.3716e-01],
        [ 3.1258e-01, -8.7063e-02,  2.1620e-01, -2.9549e-02, -2.4050e-01,
         -1.7759e-01, -2.8925e-01,  8.7753e-02,  1.6631e-02, -2.1876e-01,
          2.5057e-02,  1.8523e-01, -1.0773e-01,  7.9590e-02,  6.0522e-02,
          1.4763e-01],
        [-1.2677e-01,  2.5501e-01,  3.0419e-03, -1.3127e-01,  2.0684e-01,
         -8.6025e-02,  2.4507e-01,  3.1005e-01,  1.1949e-01,  1.8354e-02,
         -1.8333e-01, -2.2017e-01, -1.4849e-01, -1.7105e-01,  3.0857e-01,
         -2.0767e-01],
        [ 6.1332e-03, -1.4965e-01,  2.5439e-02,  3.0051e-01, -1.3139e-01,
          3.8861e-02,  1.5683e-01, -1.4560e-01, -6.7781e-02,  1.8406e-01,
          2.4037e-01, -1.7607e-01, -9.8314e-02, -2.9982e-01, -2.0297e-01,
          1.2491e-01],
        [ 3.1493e-01, -1.6253e-01,  6.9856e-03, -1.0651e-01,  6.7905e-02,
         -3.5106e-01, -2.4062e-01, -1.7998e-01, -2.0078e-01, -1.0763e-01,
          2.2749e-01,  1.6082e-01, -1.2627e-01,  2.9357e-01,  1.5411e-01,
          1.7806e-01],
        [ 2.1939e-01,  1.2097e-02,  3.0314e-01, -3.2169e-01, -1.9809e-01,
         -1.3925e-01, -1.4374e-01, -2.5804e-01, -3.2454e-01, -2.8611e-01,
          3.4002e-02,  3.1528e-01,  2.6338e-01,  1.2974e-01, -2.0074e-01,
         -8.1736e-03],
        [ 1.3425e-01, -3.2610e-01,  1.0221e-01, -4.7235e-02,  1.6996e-01,
         -1.8122e-01,  1.3648e-01, -8.5577e-02, -2.7235e-01,  1.2837e-01,
          2.6514e-01, -8.4838e-02, -3.8854e-02,  1.8827e-01, -2.0544e-01,
          2.7702e-01],
        [-1.3573e-02, -1.7037e-01,  3.7566e-02,  1.4218e-01, -1.4699e-01,
         -1.5859e-01,  4.2789e-02, -2.7127e-01, -1.0602e-01, -2.9925e-01,
         -2.1172e-01,  5.1742e-02,  1.2887e-01,  2.8279e-01, -3.0254e-01,
          3.0806e-02],
        [ 1.7061e-01,  6.4587e-03,  2.5391e-01, -2.9280e-01, -1.0768e-01,
         -5.3598e-02, -3.0317e-01,  2.7324e-02, -3.3053e-01,  5.3812e-02,
          9.5803e-02,  3.6386e-02,  1.8491e-01,  2.7421e-01,  1.3950e-01,
          2.5311e-01],
        [-2.5753e-01,  1.6218e-01,  7.2732e-02,  1.4197e-01,  2.1950e-01,
         -3.7255e-02,  2.8592e-01,  9.7473e-02, -1.2613e-01,  4.4712e-02,
          1.5537e-01, -2.0140e-01, -1.5416e-01, -1.6901e-01, -8.2111e-02,
         -6.4987e-02],
        [ 2.5585e-01, -4.4308e-02,  9.2238e-02, -7.7365e-02, -2.4088e-01,
         -2.4490e-01, -9.2521e-02, -2.9611e-01,  3.0126e-02, -6.6466e-02,
          8.9488e-02,  9.3082e-02,  3.0860e-01,  2.9626e-01,  5.6434e-02,
          2.2632e-01],
        [-2.2351e-01,  1.8766e-01, -2.7419e-01,  1.9739e-01, -1.3287e-01,
          1.0610e-01,  2.8118e-01,  2.6267e-01,  3.1042e-01,  1.8369e-01,
          1.1102e-01, -3.4631e-02,  8.4462e-02,  7.2498e-02,  1.0976e-01,
         -1.8550e-01],
        [-2.3005e-01,  3.1177e-02,  7.1286e-03, -3.9543e-02,  1.2676e-01,
          3.3401e-01,  3.1966e-01, -8.2276e-02,  1.6914e-01,  2.7035e-01,
         -2.8537e-01,  4.7476e-02, -2.6063e-01, -2.4995e-01, -4.8060e-02,
         -2.0077e-01],
        [-9.3079e-04, -1.8716e-02,  2.0297e-01, -2.8917e-04,  8.7566e-02,
         -2.6736e-01, -3.3573e-01, -3.0081e-01, -2.3370e-01, -2.1950e-01,
          1.3388e-01, -7.7607e-02, -7.9120e-02,  2.2945e-01, -2.3796e-01,
          1.4871e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1526,  0.0124,  0.0753, -0.0883,  0.0271, -0.1153,  0.0984,  0.1448,
        -0.1208,  0.0233,  0.0642,  0.1284,  0.2093,  0.0747,  0.0531,  0.0357,
        -0.1063, -0.0285,  0.0299, -0.0380, -0.0536,  0.0051, -0.0651,  0.0124,
        -0.1762,  0.2016,  0.0998,  0.0959, -0.1021, -0.2120,  0.1045, -0.0323],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0805,  0.1654, -0.1036, -0.1248,  0.1610,  0.2182, -0.1669, -0.2686,
         -0.1513,  0.2050,  0.1288,  0.2531, -0.0702, -0.2626,  0.1678, -0.0820,
         -0.1863,  0.2242, -0.1014, -0.1321,  0.2733,  0.1210, -0.2576, -0.2754,
         -0.1875, -0.1984, -0.2053,  0.2066, -0.2355,  0.2740,  0.1722, -0.1137]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0110,  0.0668,  0.0894,  ...,  0.0111, -0.1713, -0.1137],
        [-0.1090, -0.0697,  0.1211,  ..., -0.0180, -0.2297,  0.0871],
        [-0.0413,  0.0340,  0.0858,  ...,  0.1382,  0.1300,  0.0345],
        ...,
        [ 0.1050, -0.1138, -0.0138,  ..., -0.0914, -0.0710, -0.1180],
        [ 0.0761, -0.1734, -0.0440,  ..., -0.1445,  0.0391,  0.1557],
        [-0.1751,  0.1118,  0.0618,  ..., -0.0562, -0.1546, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0291,  0.0351, -0.0914, -0.1468, -0.0800,  0.0533, -0.0935,  0.0485,
        -0.0071,  0.0618,  0.0197,  0.0111, -0.0448,  0.0656, -0.0447, -0.0113,
         0.0426, -0.1779, -0.0645,  0.0648, -0.0449,  0.0481,  0.1191,  0.0064,
        -0.0768,  0.1133,  0.0503, -0.0936,  0.0289,  0.1891,  0.1693, -0.1296],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1273, -0.1146, -0.1465,  ...,  0.0194, -0.1094,  0.1112],
        [-0.1355,  0.0466,  0.0288,  ...,  0.1074, -0.1032,  0.1047],
        [ 0.0593, -0.1203, -0.0923,  ..., -0.0971,  0.0872,  0.1190],
        ...,
        [ 0.0624,  0.0262,  0.1526,  ...,  0.0973, -0.1244,  0.2084],
        [ 0.0596, -0.0648, -0.0156,  ...,  0.1921,  0.1313, -0.1112],
        [ 0.0626, -0.0543,  0.1532,  ...,  0.1997,  0.0576,  0.0019]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0977,  0.1349, -0.0261, -0.0767, -0.0372, -0.0617, -0.0383, -0.0812,
         0.1340, -0.1528,  0.1253, -0.1234,  0.1781,  0.0808, -0.1375,  0.0868,
        -0.1403, -0.1699,  0.0441, -0.0204,  0.0129,  0.1098, -0.1928,  0.2070,
        -0.0659, -0.0095,  0.0851, -0.0433, -0.1214, -0.0731,  0.0994,  0.0225],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2074,  0.1257, -0.1752, -0.1553,  0.0185,  0.0240, -0.0863,  0.0132,
          0.1177, -0.1484, -0.0554,  0.0805,  0.0826,  0.0745,  0.1166,  0.0956,
         -0.2073, -0.2107,  0.0493,  0.0437, -0.1143, -0.0970, -0.1910,  0.0702,
          0.1342,  0.2152, -0.1821,  0.1471, -0.0931, -0.1967,  0.1520,  0.1894]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0220], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.5961e-01,  3.2372e-01,  4.9827e-02, -7.9242e-02,  6.1530e-02,
          1.0622e-01,  2.3205e-01, -1.1046e-01,  1.1172e-01,  1.9287e-01,
          1.0728e-01, -8.1885e-02, -2.2474e-01, -3.1037e-01,  1.9574e-01,
          1.2256e-01],
        [-1.8605e-01, -1.3090e-01, -4.1175e-02, -7.5464e-02, -1.0610e-01,
          1.8342e-01,  8.6679e-02,  8.6777e-02,  3.2555e-01,  6.5747e-02,
          1.0816e-01, -1.8985e-01,  8.0855e-02,  6.5293e-03,  2.7656e-01,
         -2.0145e-02],
        [ 1.1726e-02,  2.5321e-02,  3.1766e-01, -5.6494e-02,  1.5765e-02,
         -2.7682e-01,  3.5491e-02, -3.3842e-01,  1.2137e-01, -3.6088e-03,
          7.6384e-03, -1.3604e-01,  3.2563e-01,  2.6464e-01,  1.3862e-01,
          1.9819e-01],
        [ 2.0581e-01, -1.6878e-01,  2.2367e-02, -7.0726e-03,  2.1258e-02,
         -1.3474e-01, -7.8104e-02, -2.6363e-02, -3.4766e-01, -3.3726e-01,
          1.7706e-02,  2.9402e-01,  2.3764e-01, -1.6148e-01, -1.4144e-01,
          9.4713e-02],
        [-2.5055e-02,  2.9369e-01, -1.0497e-01, -9.8928e-02,  6.8295e-02,
          1.6370e-02, -4.5983e-02,  2.4069e-01,  6.3451e-02,  2.2467e-01,
          1.4527e-01, -8.5527e-02,  3.4949e-02, -1.8460e-01,  1.8826e-01,
         -9.2549e-02],
        [ 5.8328e-02,  3.3246e-01, -2.9999e-01,  3.3435e-01,  2.4972e-01,
         -8.8451e-02,  1.8116e-01, -1.0028e-01,  1.8187e-01,  1.4655e-01,
         -2.3953e-01, -1.9281e-02, -1.7228e-01,  1.8019e-01,  3.0052e-01,
         -1.7880e-02],
        [ 3.1175e-01, -7.9783e-03,  3.5356e-01, -1.2263e-01,  6.3176e-03,
         -1.5910e-01, -1.1526e-01, -1.8316e-01, -1.9894e-01,  3.7046e-02,
          4.8490e-02,  3.8863e-03, -1.0984e-01,  1.8782e-01, -2.5622e-01,
          1.0071e-01],
        [-1.1011e-01,  1.2084e-01,  3.1192e-01, -2.9833e-01, -2.7978e-01,
         -2.5651e-01, -3.4467e-02, -2.2465e-01, -1.5278e-01, -1.6474e-01,
         -1.2431e-03, -1.1976e-02,  2.1640e-01, -1.1794e-01, -5.7159e-02,
          3.1110e-01],
        [-3.1355e-02,  1.0470e-01,  2.4079e-01, -1.7713e-01,  3.4399e-02,
         -2.8164e-01, -8.5998e-02, -3.0168e-02,  1.1904e-01, -2.4655e-01,
         -1.0036e-01, -1.5265e-02, -1.4165e-01,  1.1730e-01, -2.5594e-01,
          3.5419e-02],
        [-2.2056e-01,  1.0595e-01, -3.6757e-02, -8.3507e-02, -1.7666e-02,
          8.9686e-02, -3.5713e-02,  1.6184e-01,  1.9139e-01, -6.9445e-02,
          1.4692e-01,  6.6337e-02, -1.8324e-01, -3.1624e-02,  8.3618e-02,
         -1.3973e-01],
        [-2.8758e-01,  2.9077e-01, -9.5754e-04, -1.0065e-01, -1.2594e-01,
          3.6196e-01,  1.5496e-01,  5.0484e-02,  2.8025e-01,  1.9105e-01,
          4.0115e-03,  7.7702e-02, -1.2333e-01,  1.5774e-01, -9.0167e-02,
         -2.7188e-01],
        [-6.8015e-02,  5.3119e-02,  2.9127e-02,  2.8408e-02,  8.9925e-02,
          6.5710e-02,  2.9536e-01,  8.7449e-02,  9.8536e-02,  2.9139e-01,
          1.6470e-01,  1.2581e-01, -3.5377e-01, -2.1015e-01,  3.4117e-03,
         -1.5888e-01],
        [ 2.4452e-01,  3.2129e-02,  8.5026e-02, -8.7748e-02,  9.8770e-04,
          1.0818e-01,  2.2536e-02, -2.2116e-01, -2.2844e-01, -2.6682e-02,
          9.2898e-03, -5.6658e-02, -1.4240e-01,  1.0486e-01, -1.3716e-01,
         -4.9092e-02],
        [ 1.5442e-01,  1.5342e-01,  3.1863e-01,  4.6630e-02, -2.4243e-01,
          2.9950e-02,  2.2142e-02, -1.6754e-02, -1.5978e-01, -1.1058e-01,
         -1.0781e-01,  5.2786e-02,  6.2692e-02,  3.0801e-02, -2.9732e-01,
          1.9259e-01],
        [-3.1820e-01, -8.9370e-02, -1.5953e-02, -1.0221e-01,  3.0057e-01,
          3.5635e-01,  3.3158e-02,  6.5096e-02, -8.8197e-02,  1.2620e-01,
          1.6161e-02, -2.5158e-01, -2.9664e-02, -8.1696e-02, -1.7346e-02,
         -1.1250e-01],
        [-1.4050e-01, -2.6352e-01,  1.3809e-01,  1.4992e-01, -1.9831e-01,
          5.4101e-02, -7.9866e-02, -2.0572e-01, -9.4044e-02,  1.6631e-02,
          3.1512e-02,  3.2646e-01,  5.4815e-02, -1.0381e-01,  1.8400e-01,
          2.4674e-02],
        [ 2.6440e-01,  7.2004e-02,  1.5230e-01, -2.9770e-01, -2.9770e-01,
          4.9429e-03, -4.3582e-02,  4.5408e-02, -3.1632e-01, -1.3998e-01,
          2.5652e-01,  2.4015e-01,  3.1171e-01,  2.6180e-01, -1.1177e-01,
         -6.8470e-02],
        [-2.5083e-01,  1.7650e-01, -2.0228e-01,  8.7957e-02,  9.2172e-02,
          2.6372e-01,  2.3979e-01,  2.4020e-01,  1.0095e-01,  2.3944e-01,
         -1.2136e-01, -2.0612e-01, -1.4208e-01, -2.0568e-01,  2.6466e-01,
         -1.3560e-01],
        [ 1.6418e-01, -8.6327e-02,  9.1125e-02, -2.3130e-01, -1.1540e-01,
         -3.1792e-01, -2.0936e-01,  9.8765e-02, -3.2663e-01, -5.8789e-02,
          7.9116e-02, -1.4786e-01,  1.4112e-01,  2.2021e-01,  8.7936e-02,
          1.3716e-01],
        [ 3.1258e-01, -8.7063e-02,  2.1620e-01, -2.9549e-02, -2.4050e-01,
         -1.7759e-01, -2.8925e-01,  8.7753e-02,  1.6631e-02, -2.1876e-01,
          2.5057e-02,  1.8523e-01, -1.0773e-01,  7.9590e-02,  6.0522e-02,
          1.4763e-01],
        [-1.2677e-01,  2.5501e-01,  3.0419e-03, -1.3127e-01,  2.0684e-01,
         -8.6025e-02,  2.4507e-01,  3.1005e-01,  1.1949e-01,  1.8354e-02,
         -1.8333e-01, -2.2017e-01, -1.4849e-01, -1.7105e-01,  3.0857e-01,
         -2.0767e-01],
        [ 6.1332e-03, -1.4965e-01,  2.5439e-02,  3.0051e-01, -1.3139e-01,
          3.8861e-02,  1.5683e-01, -1.4560e-01, -6.7781e-02,  1.8406e-01,
          2.4037e-01, -1.7607e-01, -9.8314e-02, -2.9982e-01, -2.0297e-01,
          1.2491e-01],
        [ 3.1493e-01, -1.6253e-01,  6.9856e-03, -1.0651e-01,  6.7905e-02,
         -3.5106e-01, -2.4062e-01, -1.7998e-01, -2.0078e-01, -1.0763e-01,
          2.2749e-01,  1.6082e-01, -1.2627e-01,  2.9357e-01,  1.5411e-01,
          1.7806e-01],
        [ 2.1939e-01,  1.2097e-02,  3.0314e-01, -3.2169e-01, -1.9809e-01,
         -1.3925e-01, -1.4374e-01, -2.5804e-01, -3.2454e-01, -2.8611e-01,
          3.4002e-02,  3.1528e-01,  2.6338e-01,  1.2974e-01, -2.0074e-01,
         -8.1736e-03],
        [ 1.3425e-01, -3.2610e-01,  1.0221e-01, -4.7235e-02,  1.6996e-01,
         -1.8122e-01,  1.3648e-01, -8.5577e-02, -2.7235e-01,  1.2837e-01,
          2.6514e-01, -8.4838e-02, -3.8854e-02,  1.8827e-01, -2.0544e-01,
          2.7702e-01],
        [-1.3573e-02, -1.7037e-01,  3.7566e-02,  1.4218e-01, -1.4699e-01,
         -1.5859e-01,  4.2789e-02, -2.7127e-01, -1.0602e-01, -2.9925e-01,
         -2.1172e-01,  5.1742e-02,  1.2887e-01,  2.8279e-01, -3.0254e-01,
          3.0806e-02],
        [ 1.7061e-01,  6.4587e-03,  2.5391e-01, -2.9280e-01, -1.0768e-01,
         -5.3598e-02, -3.0317e-01,  2.7324e-02, -3.3053e-01,  5.3812e-02,
          9.5803e-02,  3.6386e-02,  1.8491e-01,  2.7421e-01,  1.3950e-01,
          2.5311e-01],
        [-2.5753e-01,  1.6218e-01,  7.2732e-02,  1.4197e-01,  2.1950e-01,
         -3.7255e-02,  2.8592e-01,  9.7473e-02, -1.2613e-01,  4.4712e-02,
          1.5537e-01, -2.0140e-01, -1.5416e-01, -1.6901e-01, -8.2111e-02,
         -6.4987e-02],
        [ 2.5585e-01, -4.4308e-02,  9.2238e-02, -7.7365e-02, -2.4088e-01,
         -2.4490e-01, -9.2521e-02, -2.9611e-01,  3.0126e-02, -6.6466e-02,
          8.9488e-02,  9.3082e-02,  3.0860e-01,  2.9626e-01,  5.6434e-02,
          2.2632e-01],
        [-2.2351e-01,  1.8766e-01, -2.7419e-01,  1.9739e-01, -1.3287e-01,
          1.0610e-01,  2.8118e-01,  2.6267e-01,  3.1042e-01,  1.8369e-01,
          1.1102e-01, -3.4631e-02,  8.4462e-02,  7.2498e-02,  1.0976e-01,
         -1.8550e-01],
        [-2.3005e-01,  3.1177e-02,  7.1286e-03, -3.9543e-02,  1.2676e-01,
          3.3401e-01,  3.1966e-01, -8.2276e-02,  1.6914e-01,  2.7035e-01,
         -2.8537e-01,  4.7476e-02, -2.6063e-01, -2.4995e-01, -4.8060e-02,
         -2.0077e-01],
        [-9.3079e-04, -1.8716e-02,  2.0297e-01, -2.8917e-04,  8.7566e-02,
         -2.6736e-01, -3.3573e-01, -3.0081e-01, -2.3370e-01, -2.1950e-01,
          1.3388e-01, -7.7607e-02, -7.9120e-02,  2.2945e-01, -2.3796e-01,
          1.4871e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1526,  0.0124,  0.0753, -0.0883,  0.0271, -0.1153,  0.0984,  0.1448,
        -0.1208,  0.0233,  0.0642,  0.1284,  0.2093,  0.0747,  0.0531,  0.0357,
        -0.1063, -0.0285,  0.0299, -0.0380, -0.0536,  0.0051, -0.0651,  0.0124,
        -0.1762,  0.2016,  0.0998,  0.0959, -0.1021, -0.2120,  0.1045, -0.0323],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0805,  0.1654, -0.1036, -0.1248,  0.1610,  0.2182, -0.1669, -0.2686,
         -0.1513,  0.2050,  0.1288,  0.2531, -0.0702, -0.2626,  0.1678, -0.0820,
         -0.1863,  0.2242, -0.1014, -0.1321,  0.2733,  0.1210, -0.2576, -0.2754,
         -0.1875, -0.1984, -0.2053,  0.2066, -0.2355,  0.2740,  0.1722, -0.1137]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0110,  0.0668,  0.0894,  ...,  0.0111, -0.1713, -0.1137],
        [-0.1090, -0.0697,  0.1211,  ..., -0.0180, -0.2297,  0.0871],
        [-0.0413,  0.0340,  0.0858,  ...,  0.1382,  0.1300,  0.0345],
        ...,
        [ 0.1050, -0.1138, -0.0138,  ..., -0.0914, -0.0710, -0.1180],
        [ 0.0761, -0.1734, -0.0440,  ..., -0.1445,  0.0391,  0.1557],
        [-0.1751,  0.1118,  0.0618,  ..., -0.0562, -0.1546, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0291,  0.0351, -0.0914, -0.1468, -0.0800,  0.0533, -0.0935,  0.0485,
        -0.0071,  0.0618,  0.0197,  0.0111, -0.0448,  0.0656, -0.0447, -0.0113,
         0.0426, -0.1779, -0.0645,  0.0648, -0.0449,  0.0481,  0.1191,  0.0064,
        -0.0768,  0.1133,  0.0503, -0.0936,  0.0289,  0.1891,  0.1693, -0.1296],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1273, -0.1146, -0.1465,  ...,  0.0194, -0.1094,  0.1112],
        [-0.1355,  0.0466,  0.0288,  ...,  0.1074, -0.1032,  0.1047],
        [ 0.0593, -0.1203, -0.0923,  ..., -0.0971,  0.0872,  0.1190],
        ...,
        [ 0.0624,  0.0262,  0.1526,  ...,  0.0973, -0.1244,  0.2084],
        [ 0.0596, -0.0648, -0.0156,  ...,  0.1921,  0.1313, -0.1112],
        [ 0.0626, -0.0543,  0.1532,  ...,  0.1997,  0.0576,  0.0019]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0977,  0.1349, -0.0261, -0.0767, -0.0372, -0.0617, -0.0383, -0.0812,
         0.1340, -0.1528,  0.1253, -0.1234,  0.1781,  0.0808, -0.1375,  0.0868,
        -0.1403, -0.1699,  0.0441, -0.0204,  0.0129,  0.1098, -0.1928,  0.2070,
        -0.0659, -0.0095,  0.0851, -0.0433, -0.1214, -0.0731,  0.0994,  0.0225],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2074,  0.1257, -0.1752, -0.1553,  0.0185,  0.0240, -0.0863,  0.0132,
          0.1177, -0.1484, -0.0554,  0.0805,  0.0826,  0.0745,  0.1166,  0.0956,
         -0.2073, -0.2107,  0.0493,  0.0437, -0.1143, -0.0970, -0.1910,  0.0702,
          0.1342,  0.2152, -0.1821,  0.1471, -0.0931, -0.1967,  0.1520,  0.1894]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0220], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.6322e-01,  3.2597e-01,  4.6116e-02, -7.3240e-02,  6.3910e-02,
          1.0577e-01,  2.3348e-01, -1.0975e-01,  1.1527e-01,  1.9560e-01,
          1.1342e-01, -8.1441e-02, -2.2645e-01, -3.1244e-01,  1.9216e-01,
          1.1944e-01],
        [-1.9190e-01, -1.2997e-01, -4.6447e-02, -6.6701e-02, -1.0372e-01,
          1.8523e-01,  8.8712e-02,  8.8313e-02,  3.3156e-01,  7.0884e-02,
          1.0372e-01, -1.9134e-01,  7.9494e-02,  4.6257e-03,  2.7828e-01,
         -2.4769e-02],
        [ 1.7307e-02,  2.4331e-02,  3.2248e-01, -6.3415e-02,  1.6387e-02,
         -2.7903e-01,  3.3512e-02, -3.3813e-01,  1.1835e-01, -8.3941e-03,
          1.4654e-02, -1.3471e-01,  3.2586e-01,  2.6596e-01,  1.4394e-01,
          2.0286e-01],
        [ 2.1183e-01, -1.6580e-01,  2.8091e-02, -1.6810e-02,  2.2328e-02,
         -1.3522e-01, -7.9379e-02, -2.6520e-02, -3.5309e-01, -3.4243e-01,
          1.5642e-02,  2.9410e-01,  2.3650e-01, -1.6135e-01, -1.3955e-01,
          9.9957e-02],
        [-3.0972e-02,  2.9525e-01, -1.1032e-01, -8.9894e-02,  7.1193e-02,
          1.8230e-02, -4.4178e-02,  2.4252e-01,  6.9987e-02,  2.2982e-01,
          1.4228e-01, -8.7281e-02,  3.3484e-02, -1.8664e-01,  1.9109e-01,
         -9.7112e-02],
        [ 5.3043e-02,  3.3102e-01, -3.0503e-01,  3.4278e-01,  2.4806e-01,
         -8.6725e-02,  1.8161e-01, -1.0052e-01,  1.8512e-01,  1.5094e-01,
         -2.3792e-01, -1.9984e-02, -1.7260e-01,  1.8050e-01,  2.9930e-01,
         -2.2101e-02],
        [ 3.1746e-01, -8.7094e-03,  3.5922e-01, -1.3185e-01,  8.5064e-03,
         -1.6014e-01, -1.1652e-01, -1.8257e-01, -2.0316e-01,  3.2067e-02,
          4.9660e-02,  4.0973e-03, -1.0962e-01,  1.8641e-01, -2.5870e-01,
          1.0581e-01],
        [-1.0433e-01,  1.2073e-01,  3.1758e-01, -3.0792e-01, -2.7996e-01,
         -2.5794e-01, -3.5472e-02, -2.2378e-01, -1.5683e-01, -1.6974e-01,
         -2.1944e-04, -1.1824e-02,  2.1620e-01, -1.1887e-01, -5.5655e-02,
          3.1608e-01],
        [-2.4593e-02,  1.0206e-01,  2.4662e-01, -1.8651e-01,  3.1120e-02,
         -2.8534e-01, -8.7842e-02, -3.2546e-02,  1.1223e-01, -2.5257e-01,
         -9.2808e-02, -1.1982e-02, -1.3917e-01,  1.2025e-01, -2.6096e-01,
          4.0412e-02],
        [-2.2628e-01,  1.0725e-01, -4.1710e-02, -7.5183e-02, -1.6058e-02,
          9.2307e-02, -3.4479e-02,  1.6312e-01,  1.9710e-01, -6.4313e-02,
          1.4159e-01,  6.4239e-02, -1.8485e-01, -3.3261e-02,  8.5763e-02,
         -1.4390e-01],
        [-2.9384e-01,  2.9465e-01, -6.4127e-03, -9.1898e-02, -1.2706e-01,
          3.6477e-01,  1.5613e-01,  5.0802e-02,  2.8478e-01,  1.9664e-01,
          1.2852e-03,  7.5906e-02, -1.2387e-01,  1.5605e-01, -8.7148e-02,
         -2.7685e-01],
        [-7.3879e-02,  5.7939e-02,  2.4276e-02,  3.7287e-02,  9.2128e-02,
          6.8932e-02,  2.9420e-01,  8.8101e-02,  1.0302e-01,  2.9747e-01,
          1.5916e-01,  1.2298e-01, -3.5404e-01, -2.1096e-01,  7.0537e-03,
         -1.6261e-01],
        [ 2.5283e-01,  2.7623e-02,  9.2620e-02, -9.8229e-02, -3.4031e-03,
          1.0327e-01,  1.7920e-02, -2.2505e-01, -2.3662e-01, -3.3524e-02,
          1.4594e-02, -5.2343e-02, -1.3798e-01,  1.0927e-01, -1.4138e-01,
         -4.2144e-02],
        [ 1.6023e-01,  1.5068e-01,  3.2397e-01,  3.7583e-02, -2.4321e-01,
          2.8039e-02,  2.0794e-02, -1.7659e-02, -1.6493e-01, -1.1579e-01,
         -9.9282e-02,  5.4245e-02,  6.3597e-02,  3.1650e-02, -2.9846e-01,
          1.9728e-01],
        [-3.2407e-01, -9.0209e-02, -2.1466e-02, -9.3268e-02,  3.0142e-01,
          3.5711e-01,  3.5491e-02,  6.5729e-02, -8.2587e-02,  1.3100e-01,
          1.5235e-02, -2.5175e-01, -3.0329e-02, -8.2700e-02, -1.9150e-02,
         -1.1770e-01],
        [-1.3483e-01, -2.6587e-01,  1.4312e-01,  1.4154e-01, -2.0120e-01,
          5.1116e-02, -8.1492e-02, -2.0765e-01, -1.0028e-01,  1.1609e-02,
          4.4671e-02,  3.2904e-01,  5.7504e-02, -1.0158e-01,  1.7988e-01,
          2.8700e-02],
        [ 2.6967e-01,  7.4895e-02,  1.5766e-01, -3.0730e-01, -2.9485e-01,
          3.8685e-03, -4.3288e-02,  4.5919e-02, -3.1922e-01, -1.4488e-01,
          2.5859e-01,  2.4069e-01,  3.1110e-01,  2.6034e-01, -1.1098e-01,
         -6.4328e-02],
        [-2.5591e-01,  1.7309e-01, -2.0825e-01,  9.8415e-02,  8.9308e-02,
          2.6246e-01,  2.4102e-01,  2.3961e-01,  1.0511e-01,  2.4353e-01,
         -1.1591e-01, -2.0439e-01, -1.4042e-01, -2.0382e-01,  2.6086e-01,
         -1.4042e-01],
        [ 1.7042e-01, -8.6663e-02,  9.7024e-02, -2.3806e-01, -1.1248e-01,
         -3.2221e-01, -2.1020e-01,  9.8368e-02, -3.2731e-01, -6.4313e-02,
          8.5553e-02, -1.4495e-01,  1.4116e-01,  2.1973e-01,  9.1888e-02,
          1.4198e-01],
        [ 3.1944e-01, -8.8386e-02,  2.2207e-01, -3.9110e-02, -2.4188e-01,
         -1.8109e-01, -2.8970e-01,  8.7246e-02,  1.1808e-02, -2.2510e-01,
          2.8192e-02,  1.8792e-01, -1.0704e-01,  8.0367e-02,  5.9622e-02,
          1.5287e-01],
        [-1.3149e-01,  2.5500e-01, -1.4443e-03, -1.2332e-01,  2.0826e-01,
         -8.5174e-02,  2.4571e-01,  3.1169e-01,  1.2427e-01,  2.2496e-02,
         -1.8442e-01, -2.2103e-01, -1.4864e-01, -1.7197e-01,  3.0902e-01,
         -2.1102e-01],
        [ 1.2878e-04, -1.4708e-01,  2.0280e-02,  3.0931e-01, -1.2802e-01,
          4.2564e-02,  1.5819e-01, -1.4354e-01, -6.1705e-02,  1.8965e-01,
          2.2892e-01, -1.7926e-01, -1.0076e-01, -3.0249e-01, -1.9675e-01,
          1.2077e-01],
        [ 3.2060e-01, -1.6213e-01,  1.2629e-02, -1.1637e-01,  6.8595e-02,
         -3.5273e-01, -2.4061e-01, -1.7915e-01, -2.0428e-01, -1.1283e-01,
          2.2565e-01,  1.6132e-01, -1.2714e-01,  2.9264e-01,  1.5570e-01,
          1.8263e-01],
        [ 2.2430e-01,  1.5242e-02,  3.0909e-01, -3.3286e-01, -1.9616e-01,
         -1.3849e-01, -1.4325e-01, -2.5641e-01, -3.2738e-01, -2.9061e-01,
          2.8741e-02,  3.1387e-01,  2.6025e-01,  1.2708e-01, -1.9707e-01,
         -3.8156e-03],
        [ 1.4035e-01, -3.2629e-01,  1.0754e-01, -5.6153e-02,  1.6888e-01,
         -1.8397e-01,  1.3553e-01, -8.6725e-02, -2.7780e-01,  1.2283e-01,
          2.7107e-01, -8.2636e-02, -3.7537e-02,  1.8946e-01, -2.0781e-01,
          2.8159e-01],
        [-9.4840e-03, -1.7098e-01,  4.1617e-02,  1.3489e-01, -1.4970e-01,
         -1.5700e-01,  4.0517e-02, -2.7231e-01, -1.1124e-01, -3.0217e-01,
         -2.1729e-01,  5.0554e-02,  1.2933e-01,  2.8399e-01, -3.0031e-01,
          3.4463e-02],
        [ 1.7664e-01,  6.1503e-03,  2.5907e-01, -3.0163e-01, -1.0613e-01,
         -5.8045e-02, -3.0129e-01,  2.8151e-02, -3.3265e-01,  4.7689e-02,
          1.0246e-01,  3.9441e-02,  1.8503e-01,  2.7329e-01,  1.3808e-01,
          2.5694e-01],
        [-2.6335e-01,  1.6589e-01,  6.7774e-02,  1.5071e-01,  2.2022e-01,
         -3.4164e-02,  2.8561e-01,  9.8366e-02, -1.2109e-01,  5.0503e-02,
          1.5195e-01, -2.0398e-01, -1.5508e-01, -1.7019e-01, -7.9067e-02,
         -6.8996e-02],
        [ 2.6148e-01, -4.7689e-02,  9.7864e-02, -8.7441e-02, -2.4017e-01,
         -2.4600e-01, -9.2249e-02, -2.9560e-01,  2.6508e-02, -7.1658e-02,
          8.9334e-02,  9.3421e-02,  3.0715e-01,  2.9624e-01,  5.4655e-02,
          2.3087e-01],
        [-2.2911e-01,  1.8671e-01, -2.7991e-01,  2.0725e-01, -1.3412e-01,
          1.0758e-01,  2.8127e-01,  2.6116e-01,  3.1362e-01,  1.8872e-01,
          1.0927e-01, -3.7713e-02,  8.2686e-02,  7.3945e-02,  1.0792e-01,
         -1.9025e-01],
        [-2.3597e-01,  3.0094e-02,  1.4888e-03, -3.0068e-02,  1.2325e-01,
          3.3620e-01,  3.1953e-01, -8.2834e-02,  1.7245e-01,  2.7569e-01,
         -2.8673e-01,  4.6566e-02, -2.5994e-01, -2.4926e-01, -4.9377e-02,
         -2.0543e-01],
        [ 5.8619e-03, -1.8367e-02,  2.0925e-01, -9.9948e-03,  9.0462e-02,
         -2.6939e-01, -3.3682e-01, -3.0111e-01, -2.3826e-01, -2.2573e-01,
          1.4305e-01, -7.5807e-02, -7.9116e-02,  2.2851e-01, -2.3510e-01,
          1.5457e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1479,  0.0299,  0.0673, -0.0997,  0.0395, -0.1057,  0.0918,  0.1410,
        -0.1204,  0.0298,  0.0640,  0.1266,  0.1957,  0.0674,  0.0754,  0.0375,
        -0.1130, -0.0155,  0.0336, -0.0362, -0.0482, -0.0093, -0.0725,  0.0025,
        -0.1755,  0.1957,  0.1083,  0.0929, -0.1061, -0.2094,  0.1106, -0.0352],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0837,  0.1679, -0.1078, -0.1287,  0.1644,  0.2243, -0.1715, -0.2729,
         -0.1558,  0.2065,  0.1325,  0.2558, -0.0786, -0.2675,  0.1721, -0.0833,
         -0.1913,  0.2272, -0.1065, -0.1369,  0.2755,  0.1290, -0.2617, -0.2792,
         -0.1939, -0.1998, -0.2100,  0.2116, -0.2387,  0.2781,  0.1760, -0.1170]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0272,  0.0837,  0.0977,  ...,  0.0040, -0.1794, -0.1137],
        [-0.1127, -0.0681,  0.1285,  ..., -0.0148, -0.2404,  0.0871],
        [-0.0374,  0.0331,  0.0770,  ...,  0.1338,  0.1374,  0.0345],
        ...,
        [ 0.1081, -0.1224, -0.0211,  ..., -0.0867, -0.0708, -0.1180],
        [ 0.0815, -0.1769, -0.0539,  ..., -0.1483,  0.0518,  0.1557],
        [-0.1795,  0.1174,  0.0695,  ..., -0.0593, -0.1551, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0211,  0.0294, -0.0878, -0.1510, -0.0846,  0.0745, -0.0896,  0.0489,
        -0.0063,  0.0567,  0.0113,  0.0133, -0.0474,  0.0907, -0.0411, -0.0116,
         0.0392, -0.1802, -0.0647,  0.0683, -0.0394,  0.0110,  0.1256,  0.0102,
        -0.1122,  0.1257,  0.0555, -0.0982,  0.0257,  0.1927,  0.1770, -0.1330],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1175, -0.1253, -0.1480,  ...,  0.0256, -0.0940,  0.1057],
        [-0.1490,  0.0322,  0.0320,  ...,  0.1174, -0.0835,  0.0953],
        [ 0.0707, -0.1077, -0.0928,  ..., -0.1049,  0.0693,  0.1262],
        ...,
        [ 0.0710,  0.0355,  0.1548,  ...,  0.0926, -0.1390,  0.2123],
        [ 0.0478, -0.0775, -0.0148,  ...,  0.2003,  0.1495, -0.1187],
        [ 0.0539, -0.0630,  0.1505,  ...,  0.2044,  0.0716, -0.0015]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1032,  0.1438, -0.0333, -0.0857, -0.0321, -0.0383, -0.0494, -0.0603,
         0.1402, -0.1599,  0.1162, -0.1169,  0.1844,  0.0840, -0.1323,  0.0983,
        -0.1460, -0.1731,  0.0517, -0.0081,  0.0011,  0.1002, -0.2011,  0.2113,
        -0.0546, -0.0053,  0.0782, -0.0351, -0.1323, -0.0778,  0.1068,  0.0273],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2254,  0.1403, -0.1950, -0.1952,  0.0232,  0.0552, -0.1083,  0.0654,
          0.1375, -0.1607, -0.0871,  0.1030,  0.1058,  0.0909,  0.1407,  0.1174,
         -0.2234, -0.2287,  0.0740,  0.0680, -0.1381, -0.1193, -0.2115,  0.0873,
          0.1560,  0.2308, -0.1993,  0.1837, -0.1193, -0.2151,  0.1728,  0.2090]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0358], device='cuda:0', requires_grad=True)

