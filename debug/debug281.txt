Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-8.5332e-04,  3.9427e-01,  3.0691e-01, -3.2584e-01, -1.9325e-01,
         -1.5454e-01, -7.8165e-02, -3.9394e-01, -2.5879e-01, -7.8347e-02,
         -2.9577e-02,  1.9821e-01, -3.1009e-01, -7.0176e-02, -3.6359e-02,
          3.8577e-01],
        [-2.4816e-01, -3.8791e-01, -9.9508e-02, -1.1396e-02, -2.4758e-02,
          2.4763e-01,  1.6440e-01,  1.6217e-01,  4.3421e-01,  1.3753e-01,
          2.9843e-01, -2.6290e-01,  3.6420e-01, -2.8189e-02,  3.4437e-01,
         -9.0948e-02],
        [ 9.3758e-02,  2.9491e-01,  3.9009e-01, -1.3075e-01, -1.0390e-01,
         -3.4875e-01, -9.2729e-02, -4.5072e-01, -6.5355e-02, -9.0512e-02,
         -1.5858e-01, -3.1815e-02,  1.5967e-02,  3.4971e-01, -2.1425e-02,
          2.8798e-01],
        [ 2.8424e-01,  1.1836e-01,  9.6288e-02, -8.7486e-02, -7.0361e-02,
         -2.1625e-01, -1.7827e-01, -1.2349e-01, -4.7806e-01, -4.2994e-01,
         -2.1837e-01,  3.8807e-01, -8.0988e-02, -1.1524e-01, -2.1528e-01,
          1.8088e-01],
        [-9.6324e-02,  3.4511e-02, -1.7191e-01, -2.3352e-02,  1.6802e-01,
          8.9375e-02,  4.8479e-02,  3.3010e-01,  1.8694e-01,  3.0552e-01,
          3.4834e-01, -1.6897e-01,  3.2722e-01, -2.3267e-01,  2.9684e-01,
         -1.7426e-01],
        [-2.0577e-02,  6.0605e-02, -3.7419e-01,  4.1682e-01,  3.5965e-01,
         -7.8027e-03,  2.8896e-01, -1.0930e-03,  3.1732e-01,  2.3539e-01,
         -7.4473e-02, -1.1207e-01,  1.3015e-01,  1.1790e-01,  4.3384e-01,
         -1.0603e-01],
        [ 3.6678e-01,  2.4642e-01,  4.0640e-01, -1.8366e-01, -5.9570e-02,
         -2.0996e-01, -1.8751e-01, -2.4187e-01, -2.9926e-01, -3.2929e-02,
         -4.6139e-02,  6.6515e-02, -3.6135e-01,  2.0473e-01, -3.0104e-01,
          1.6339e-01],
        [-5.7955e-02,  3.6327e-01,  3.6208e-01, -3.6101e-01, -3.4915e-01,
         -3.0067e-01, -1.0489e-01, -2.7593e-01, -2.4655e-01, -2.2945e-01,
         -9.4642e-02,  4.2024e-02, -4.2561e-02, -9.5156e-02, -1.2640e-01,
          3.7222e-01],
        [ 3.2834e-02,  3.5658e-01,  3.0260e-01, -2.4496e-01, -5.1859e-02,
         -3.4644e-01, -1.5924e-01, -1.0223e-01,  9.5800e-03, -3.2012e-01,
         -2.8471e-01,  5.5607e-02, -4.2039e-01,  1.5876e-01, -2.9647e-01,
          1.0874e-01],
        [-3.0084e-01, -1.6624e-01, -1.1168e-01,  5.9598e-04,  9.3443e-02,
          1.7087e-01,  7.5889e-02,  2.6002e-01,  3.2371e-01,  1.9444e-02,
          3.6585e-01, -2.5669e-02,  1.2071e-01, -9.4293e-02,  2.0560e-01,
         -2.2887e-01],
        [-3.7017e-01,  1.4853e-02, -7.7881e-02, -1.8903e-02, -2.7308e-02,
          4.4420e-01,  2.6456e-01,  1.5235e-01,  4.1363e-01,  2.8168e-01,
          2.2828e-01, -1.9313e-02,  1.9893e-01,  1.0057e-01,  2.6670e-02,
         -3.6290e-01],
        [-1.3984e-01, -2.0364e-01, -3.9034e-02,  1.0099e-01,  1.8990e-01,
          1.3825e-01,  3.8981e-01,  1.7117e-01,  2.1544e-01,  3.7182e-01,
          4.1033e-01,  4.5432e-02, -5.6141e-02, -2.6405e-01,  4.1638e-02,
         -2.3643e-01],
        [ 3.3516e-01,  2.9119e-01,  1.6755e-01, -1.7290e-01, -1.0613e-01,
          2.1856e-02, -8.8103e-02, -3.3017e-01, -3.6593e-01, -1.1743e-01,
         -1.7788e-01,  4.1700e-02, -4.3880e-01,  1.5627e-01, -2.4908e-01,
          5.3230e-02],
        [ 2.0935e-01,  4.0192e-01,  3.7115e-01, -1.2921e-02, -3.1454e-01,
         -2.4003e-02, -4.0949e-02, -7.7620e-02, -2.5116e-01, -1.7509e-01,
         -2.8212e-01,  1.1360e-01, -2.0380e-01,  5.8990e-02, -3.3183e-01,
          2.5405e-01],
        [-3.7869e-01, -3.5483e-01, -7.3182e-02, -3.3012e-02,  3.7449e-01,
          4.0695e-01,  1.1438e-01,  1.2836e-01,  1.7593e-02,  1.9796e-01,
          1.9357e-01, -3.1783e-01,  2.5747e-01, -1.1474e-01,  7.1958e-02,
         -1.8289e-01],
        [-5.0220e-02,  9.0031e-03,  2.1618e-01,  5.7227e-02, -3.7340e-01,
         -4.5042e-02, -2.3204e-01, -3.5456e-01, -3.1092e-01, -1.0236e-01,
         -1.5332e-01,  4.6100e-01, -3.0219e-01, -1.6516e-02,  6.9034e-03,
          1.2951e-01],
        [ 3.2983e-01,  3.2985e-01,  2.1618e-01, -3.6693e-01, -3.8512e-01,
         -6.1205e-02, -1.2115e-01, -3.1342e-02, -4.2495e-01, -2.1472e-01,
          6.6301e-02,  3.1429e-01,  3.0894e-02,  3.0200e-01, -1.4557e-01,
          4.4811e-03],
        [-3.0059e-01, -6.2532e-02, -2.5283e-01,  1.4819e-01,  1.4651e-01,
          3.0980e-01,  3.0249e-01,  2.9026e-01,  1.9097e-01,  3.0274e-01,
          1.2921e-02, -2.5863e-01,  1.1578e-01, -2.1753e-01,  2.9944e-01,
         -1.9512e-01],
        [ 2.2556e-01,  1.5228e-01,  1.4332e-01, -2.8133e-01, -2.1895e-01,
         -3.7502e-01, -3.2457e-01,  3.2708e-03, -5.0707e-01, -1.2487e-01,
         -1.1716e-01, -5.8978e-02, -1.4789e-01,  2.9260e-01, -5.5887e-02,
          2.0959e-01],
        [ 3.7478e-01,  1.8105e-01,  2.7629e-01, -9.7143e-02, -3.1520e-01,
         -2.3359e-01, -3.6528e-01,  2.0881e-02, -9.3173e-02, -2.9368e-01,
         -1.7450e-01,  2.5207e-01, -4.0562e-01,  1.0888e-01,  3.0656e-02,
          2.1871e-01],
        [-1.9032e-01,  3.9317e-04, -5.9251e-02, -5.9824e-02,  2.9057e-01,
         -2.0118e-02,  3.2245e-01,  3.8757e-01,  2.3459e-01,  9.3723e-02,
          1.1618e-02, -2.9331e-01,  1.3042e-01, -2.1058e-01,  3.9965e-01,
         -2.8013e-01],
        [-7.8730e-02, -4.0789e-01, -5.5680e-02,  3.9480e-01, -1.6952e-02,
          1.1712e-01,  2.6853e-01, -5.0302e-02,  6.9795e-02,  2.7863e-01,
          4.0099e-01, -2.6556e-01,  1.8532e-01, -3.6920e-01, -6.7905e-02,
          2.8789e-02],
        [ 3.6890e-01,  8.0113e-02,  5.9888e-02, -1.7105e-01, -2.2666e-03,
         -3.9965e-01, -3.0739e-01, -2.3538e-01, -2.9810e-01, -1.7261e-01,
          5.3346e-02,  2.1721e-01, -3.9362e-01,  3.1856e-01,  8.8689e-02,
          2.4199e-01],
        [ 2.6239e-01,  2.3568e-01,  3.4920e-01, -3.7609e-01, -2.4536e-01,
         -1.7686e-01, -1.8837e-01, -2.9622e-01, -3.9852e-01, -3.4180e-01,
         -1.3987e-01,  3.5410e-01,  1.1706e-02,  1.3252e-01, -1.9142e-01,
          4.5100e-02],
        [ 2.2469e-01, -4.3743e-02,  1.8513e-01, -1.3759e-01,  3.5361e-02,
         -2.8455e-01,  1.1660e-02, -2.1199e-01, -4.3546e-01,  2.3021e-02,
          3.9847e-02,  3.0718e-02, -3.6231e-01,  2.6345e-01, -3.4072e-01,
          3.7583e-01],
        [ 5.1082e-02,  8.7523e-02,  9.8499e-02,  6.9451e-02, -2.3109e-01,
         -2.1694e-01, -4.0595e-02, -3.4956e-01, -2.1918e-01, -3.7362e-01,
         -3.6656e-01,  1.2446e-01, -1.5608e-01,  3.2170e-01, -4.0467e-01,
          1.0762e-01],
        [ 2.3057e-01,  2.5483e-01,  3.1212e-01, -3.5947e-01, -1.8779e-01,
         -1.0833e-01, -3.7378e-01, -3.6668e-02, -4.3742e-01, -1.7270e-02,
         -6.0166e-02,  9.9968e-02, -8.7973e-02,  3.0613e-01,  9.6042e-02,
          3.2161e-01],
        [-3.2659e-01, -1.0233e-01,  6.6489e-03,  2.1596e-01,  3.1408e-01,
          3.0103e-02,  3.8091e-01,  1.7586e-01, -1.1119e-02,  1.2268e-01,
          3.8095e-01, -2.7688e-01,  1.4310e-01, -2.2057e-01, -6.3100e-03,
         -1.4245e-01],
        [ 3.1763e-01,  1.9551e-01,  1.5286e-01, -1.4683e-01, -3.1606e-01,
         -3.0108e-01, -1.6825e-01, -3.6240e-01, -7.2794e-02, -1.3610e-01,
         -1.0765e-01,  1.5676e-01,  2.8611e-02,  3.3136e-01, -6.4441e-03,
          2.9728e-01],
        [-2.6980e-01, -4.2647e-02, -3.1954e-01,  2.5344e-01, -7.3459e-02,
          1.4734e-01,  3.4137e-01,  3.0874e-01,  3.9771e-01,  2.4371e-01,
          2.2816e-01, -8.5745e-02,  3.2910e-01,  6.1827e-02,  1.4516e-01,
         -2.4052e-01],
        [-3.0234e-01, -2.3499e-01, -6.2312e-02,  3.6794e-02,  2.1514e-01,
          4.0622e-01,  4.0763e-01,  1.6518e-03,  2.8882e-01,  3.5307e-01,
         -8.3012e-02, -3.4196e-02,  3.4903e-02, -2.9761e-01,  3.2864e-02,
         -2.8133e-01],
        [ 4.7979e-02,  2.3106e-01,  2.4725e-01, -4.6393e-02,  4.7037e-03,
         -3.1574e-01, -4.1423e-01, -3.7554e-01, -3.8010e-01, -2.7978e-01,
         -3.9247e-02, -7.3560e-03, -3.5853e-01,  2.6969e-01, -2.5962e-01,
          2.0395e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0672, -0.0199, -0.0125, -0.0327,  0.0109, -0.2362,  0.0976,  0.1231,
        -0.0562, -0.0067,  0.0432,  0.0770,  0.1339,  0.0742,  0.0641, -0.0193,
        -0.0179, -0.0400,  0.0842, -0.0319, -0.1058, -0.0704, -0.0307,  0.0370,
        -0.0360,  0.1330,  0.1589,  0.0468, -0.0991, -0.1820,  0.0229,  0.0238],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2193,  0.3130, -0.2296, -0.2610,  0.3045,  0.3604, -0.2828, -0.3752,
         -0.3232,  0.3422,  0.2664,  0.3780, -0.2658, -0.3979,  0.2859, -0.2404,
         -0.3215,  0.3338, -0.2322, -0.2381,  0.4039,  0.3186, -0.3734, -0.3769,
         -0.2891, -0.3324, -0.3206,  0.3446, -0.3518,  0.3824,  0.3035, -0.2375]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0057,  0.1144,  0.0700,  ...,  0.1970, -0.3100, -0.1137],
        [-0.0742, -0.0660,  0.1200,  ...,  0.1015, -0.2866,  0.0871],
        [-0.1073,  0.1582,  0.0931,  ...,  0.1983,  0.0275,  0.0345],
        ...,
        [ 0.0973, -0.1202, -0.0376,  ..., -0.1699, -0.0246, -0.1180],
        [ 0.0392, -0.1838, -0.0414,  ..., -0.2609,  0.0922,  0.1557],
        [-0.1847,  0.1345,  0.0515,  ...,  0.0701, -0.2440, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0531,  0.0302, -0.0954, -0.1556, -0.0818, -0.0083, -0.1014,  0.0403,
        -0.0323,  0.0572,  0.0276, -0.0026,  0.0081,  0.1025, -0.0435, -0.0120,
         0.0475, -0.1669,  0.0048,  0.0827, -0.0619,  0.0174,  0.1116,  0.0239,
        -0.1110,  0.0990,  0.0447, -0.0981,  0.0455,  0.2043,  0.1694, -0.1289],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0532, -0.1641, -0.1859,  ...,  0.0362, -0.0449,  0.0658],
        [-0.2165, -0.0156, -0.0164,  ...,  0.1394, -0.0284,  0.0490],
        [ 0.1470, -0.0495, -0.0409,  ..., -0.1421,  0.0027,  0.1864],
        ...,
        [ 0.1412,  0.0583,  0.2067,  ...,  0.1041, -0.1763,  0.2450],
        [-0.0136, -0.1372, -0.0438,  ...,  0.2402,  0.2148, -0.1728],
        [-0.0017, -0.1102,  0.1298,  ...,  0.2230,  0.1274, -0.0443]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1014,  0.1488, -0.0472, -0.1008, -0.1077, -0.1770, -0.0644, -0.0262,
         0.1416, -0.1705,  0.1327, -0.1273,  0.1989,  0.0934, -0.1088,  0.1240,
        -0.1372, -0.1796,  0.0778,  0.0114, -0.0159,  0.0804, -0.2084,  0.2186,
        -0.0448, -0.0098,  0.0755, -0.0414, -0.1514, -0.0595,  0.1241,  0.0312],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3780,  0.3018, -0.3410, -0.3720, -0.2255, -0.2204, -0.2862,  0.2529,
          0.2793, -0.2961, -0.2485,  0.2638,  0.2733,  0.2296,  0.2894,  0.2723,
         -0.3699, -0.3760,  0.2222,  0.2673, -0.3279, -0.2782, -0.3797,  0.2251,
          0.3423,  0.3943, -0.3500,  0.3666, -0.2866, -0.3745,  0.3394,  0.3793]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1335], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.2837e-02,  3.5308e-01,  3.2341e-01, -3.4684e-01, -2.6856e-02,
         -1.7868e-01, -6.8003e-02, -3.9038e-01, -1.7687e-01, -8.5116e-02,
          2.8972e-02,  1.7550e-01,  6.0130e-02, -5.2333e-02,  3.1773e-01,
          3.6419e-01],
        [-2.7686e-01, -3.3785e-01, -1.2839e-01,  1.4391e-02, -1.5917e-01,
          2.8614e-01,  1.8970e-01,  1.6987e-01,  4.0124e-01,  1.3555e-01,
          2.2110e-01, -2.7405e-01, -2.7751e-04, -4.5484e-02, -6.2325e-04,
         -8.4333e-02],
        [ 9.9966e-02,  2.4703e-01,  4.0274e-01, -1.4026e-01,  1.4071e-01,
         -3.7504e-01, -6.5056e-02, -4.1343e-01,  5.3457e-02, -8.2151e-02,
         -9.5221e-02, -6.0940e-02,  3.9568e-01,  3.0973e-01,  4.3414e-01,
          2.6557e-01],
        [ 2.9266e-01,  6.7947e-02,  1.0725e-01, -9.2522e-02,  9.9199e-02,
         -2.3099e-01, -1.7190e-01, -9.7953e-02, -4.0797e-01, -4.0328e-01,
         -1.0668e-01,  3.6678e-01,  2.8491e-01, -1.2743e-01,  1.4206e-01,
          1.6000e-01],
        [-1.1743e-01,  1.2208e-01, -1.9039e-01, -2.7779e-03,  5.5443e-02,
          1.2436e-01,  6.7523e-02,  3.4879e-01,  1.6102e-01,  2.9264e-01,
          2.3014e-01, -1.9141e-01, -5.4640e-02, -2.2688e-01, -8.4787e-02,
         -1.3722e-01],
        [-2.2184e-02,  1.4687e-01, -3.7612e-01,  4.1318e-01,  1.6181e-01,
          4.7284e-03,  2.7609e-01, -1.9767e-02,  2.5283e-01,  2.0577e-01,
         -1.3867e-01, -9.8718e-02, -2.4863e-01,  1.3185e-01,  3.2001e-02,
         -7.0276e-02],
        [ 3.9409e-01,  2.0136e-01,  4.3328e-01, -2.0367e-01,  1.2820e-01,
         -2.5119e-01, -2.1176e-01, -2.3976e-01, -2.5147e-01, -2.8529e-02,
         -1.9755e-02,  6.6949e-02, -3.2868e-02,  2.2935e-01, -1.1020e-02,
          1.6245e-01],
        [-4.4259e-02,  3.1498e-01,  3.7528e-01, -3.6301e-01, -1.4707e-01,
         -3.3140e-01, -1.0929e-01, -2.4723e-01, -1.7926e-01, -2.1482e-01,
         -7.2338e-02,  2.1752e-02,  2.5444e-01, -8.4061e-02,  1.6175e-01,
          3.6522e-01],
        [ 5.7118e-02,  3.0439e-01,  3.2655e-01, -2.6982e-01,  3.0450e-02,
         -3.8330e-01, -1.8421e-01, -1.1284e-01,  4.0476e-02, -3.1497e-01,
         -1.1266e-01,  7.6962e-02, -8.0955e-02,  1.4160e-01,  1.4828e-02,
          9.5895e-02],
        [-3.0653e-01, -8.3707e-02, -1.1731e-01,  3.1109e-03, -4.1272e-02,
          1.8986e-01,  6.7518e-02,  2.5299e-01,  2.7297e-01, -6.7721e-03,
          2.3742e-01, -2.5608e-02, -2.6230e-01, -6.8246e-02, -1.8778e-01,
         -1.8898e-01],
        [-3.6923e-01,  7.1909e-02, -8.0024e-02, -2.6353e-02, -1.7524e-01,
          4.5521e-01,  2.4556e-01,  1.2018e-01,  3.3787e-01,  2.4894e-01,
          6.7649e-02,  7.1482e-03, -1.6118e-01,  1.3464e-01, -3.8889e-01,
         -3.3069e-01],
        [-1.4530e-01, -1.4459e-01, -4.4234e-02,  1.0621e-01,  1.1339e-01,
          1.5312e-01,  3.8924e-01,  1.6260e-01,  1.7064e-01,  3.4463e-01,
          1.5459e-01,  4.6467e-02, -4.0177e-01, -2.0217e-01, -2.5958e-01,
         -2.0012e-01],
        [ 3.6821e-01,  2.2012e-01,  2.0288e-01, -2.0456e-01,  7.3880e-02,
         -2.8211e-02, -1.1481e-01, -3.3911e-01, -3.4160e-01, -1.2244e-01,
         -1.2166e-01,  4.6175e-02, -2.3185e-02,  1.9575e-01,  1.7233e-01,
          3.5886e-02],
        [ 2.3768e-01,  3.5408e-01,  3.9791e-01, -3.5374e-02, -1.7959e-01,
         -6.4073e-02, -7.3823e-02, -8.8023e-02, -2.2383e-01, -1.7359e-01,
         -2.1553e-01,  1.2880e-01,  1.3324e-01,  7.2952e-02, -3.3281e-02,
          2.5133e-01],
        [-3.9600e-01, -3.0314e-01, -9.1079e-02, -2.6513e-02,  2.0493e-01,
          4.4609e-01,  1.2040e-01,  1.2174e-01, -3.6686e-02,  1.8543e-01,
          1.2821e-01, -3.1643e-01, -8.6075e-02, -1.1838e-01, -2.8308e-01,
         -1.7068e-01],
        [-8.7470e-02, -1.5675e-01,  1.7963e-01,  8.9071e-02, -2.0096e-01,
         -1.7374e-02, -1.5628e-01, -2.9410e-01, -1.6904e-01, -8.9671e-03,
          1.0714e-02,  4.3174e-01,  1.1833e-01, -9.3545e-02,  4.1608e-01,
          2.8600e-02],
        [ 3.3326e-01,  2.7315e-01,  2.2017e-01, -3.6796e-01, -2.0731e-01,
         -7.1422e-02, -1.2174e-01, -2.8028e-03, -3.5770e-01, -1.8815e-01,
          1.3784e-01,  2.8951e-01,  3.4654e-01,  2.8652e-01,  1.2837e-01,
         -1.6834e-02],
        [-3.1652e-01, -2.0911e-02, -2.6785e-01,  1.5585e-01, -1.1629e-02,
          3.3762e-01,  3.1267e-01,  2.7761e-01,  1.3480e-01,  2.8712e-01,
         -3.6229e-02, -2.4891e-01, -1.6779e-01, -2.2372e-01,  4.1233e-02,
         -1.8718e-01],
        [ 2.5213e-01,  1.3155e-01,  1.7769e-01, -3.1369e-01, -7.7939e-03,
         -4.1347e-01, -3.0929e-01,  2.8673e-02, -3.8955e-01, -1.3745e-01,
         -4.4038e-02, -7.9008e-02,  1.9575e-01,  2.5867e-01,  3.7206e-01,
          2.0919e-01],
        [ 3.9037e-01,  1.3897e-01,  2.9330e-01, -1.0766e-01, -1.7166e-01,
         -2.6615e-01, -3.7436e-01,  3.1907e-02, -3.6619e-02, -2.7967e-01,
         -6.8536e-02,  2.4770e-01, -7.6041e-02,  1.0669e-01,  3.2897e-01,
          2.0773e-01],
        [-2.0221e-01,  7.7152e-02, -6.9858e-02, -5.0086e-02,  1.5252e-01,
          2.2754e-03,  3.3170e-01,  3.9592e-01,  1.9362e-01,  7.4991e-02,
         -7.1032e-02, -3.0435e-01, -2.0422e-01, -2.0676e-01,  4.3292e-02,
         -2.5392e-01],
        [-8.0773e-02, -3.3970e-01, -5.9575e-02,  3.9036e-01, -1.5278e-01,
          1.3896e-01,  2.5254e-01, -6.9618e-02,  7.1455e-03,  2.5341e-01,
          2.5223e-01, -2.5700e-01, -1.5189e-01, -3.3924e-01, -4.4867e-01,
          6.0244e-02],
        [ 3.7682e-01,  3.3712e-02,  6.8365e-02, -1.6936e-01,  1.5994e-01,
         -4.2212e-01, -3.0864e-01, -2.0965e-01, -2.3043e-01, -1.5201e-01,
          1.1815e-01,  1.9968e-01, -1.1117e-01,  3.1154e-01,  3.7917e-01,
          2.2729e-01],
        [ 2.7631e-01,  2.0221e-01,  3.6177e-01, -3.8250e-01, -8.7536e-02,
         -2.0106e-01, -2.0326e-01, -2.6971e-01, -3.4263e-01, -3.2573e-01,
         -1.0497e-01,  3.3547e-01,  2.5461e-01,  1.4753e-01,  6.8912e-03,
          4.3110e-02],
        [ 2.2875e-01, -1.3571e-01,  1.9127e-01, -1.4501e-01,  1.9072e-01,
         -2.9055e-01,  2.2139e-02, -1.9259e-01, -3.6699e-01,  5.5979e-02,
          1.6960e-01,  1.7462e-02,  5.0865e-02,  2.3588e-01,  7.7672e-02,
          3.2969e-01],
        [ 7.3568e-02,  1.4857e-02,  1.2129e-01,  5.4396e-02, -8.0818e-02,
         -2.6316e-01, -5.6544e-02, -3.6454e-01, -1.8448e-01, -3.6532e-01,
         -2.9448e-01,  1.4238e-01,  1.9881e-01,  3.3354e-01, -1.8959e-02,
          8.6164e-02],
        [ 2.3443e-01,  2.0859e-01,  3.1752e-01, -3.5741e-01, -2.9213e-03,
         -1.2563e-01, -3.7497e-01,  1.1501e-03, -3.5939e-01,  6.5643e-03,
          1.2886e-03,  7.1464e-02,  1.9965e-01,  2.9866e-01,  3.6593e-01,
          3.0646e-01],
        [-3.3455e-01, -3.9582e-02, -5.7390e-04,  2.1797e-01,  2.0098e-01,
          5.0279e-02,  3.7914e-01,  1.6983e-01, -5.8683e-02,  9.7970e-02,
          2.1852e-01, -2.7498e-01, -2.0889e-01, -1.8828e-01, -3.4267e-01,
         -1.1085e-01],
        [ 3.2264e-01,  1.4613e-01,  1.5814e-01, -1.4218e-01, -1.8222e-01,
         -3.1988e-01, -1.6300e-01, -3.4222e-01, -1.1582e-02, -1.1135e-01,
          1.1446e-03,  1.4184e-01,  3.1338e-01,  3.0880e-01,  2.9951e-01,
          2.7603e-01],
        [-2.8714e-01, -1.2170e-03, -3.3619e-01,  2.6190e-01, -2.3669e-01,
          1.7902e-01,  3.5341e-01,  2.9306e-01,  3.4158e-01,  2.3146e-01,
          1.8720e-01, -7.6554e-02,  5.0552e-02,  4.9343e-02, -1.0486e-01,
         -2.3528e-01],
        [-3.0279e-01, -1.8145e-01, -6.5049e-02,  3.3348e-02,  5.2625e-02,
          4.1668e-01,  3.9963e-01, -3.0696e-02,  2.1450e-01,  3.2416e-01,
         -1.8985e-01, -9.4156e-03, -2.8724e-01, -2.6909e-01, -3.0217e-01,
         -2.5669e-01],
        [ 8.6810e-02,  2.0838e-01,  2.8808e-01, -9.1212e-02,  1.7852e-01,
         -3.6125e-01, -4.3818e-01, -3.7909e-01, -3.0184e-01, -2.9703e-01,
          2.8522e-02, -3.9246e-04, -1.1166e-02,  2.6532e-01,  5.2252e-02,
          2.1428e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0960, -0.0586,  0.1840, -0.0280, -0.0848, -0.0390,  0.0727,  0.0625,
        -0.0260, -0.0572, -0.0309,  0.0552,  0.1272,  0.0998, -0.0159,  0.0005,
        -0.1418,  0.0228,  0.1165,  0.0183, -0.0224, -0.1762, -0.0124, -0.0492,
        -0.0394,  0.2269,  0.1235,  0.0185, -0.0493, -0.1486,  0.0151,  0.0301],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1944,  0.2856, -0.2112, -0.2427,  0.2656,  0.3159, -0.2628, -0.3652,
         -0.2882,  0.3063,  0.2482,  0.3600, -0.2223, -0.3640,  0.2853, -0.1538,
         -0.2836,  0.3241, -0.2154, -0.2298,  0.3426,  0.3413, -0.3608, -0.3665,
         -0.2614, -0.2923, -0.3067,  0.3273, -0.3503,  0.3720,  0.2851, -0.2239]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0112, -0.0034,  0.0258,  ...,  0.2090, -0.3528, -0.1137],
        [-0.0821, -0.1901,  0.0829,  ...,  0.1453, -0.3294,  0.0871],
        [-0.0539,  0.1579,  0.0910,  ...,  0.0107,  0.2360,  0.0345],
        ...,
        [ 0.0417, -0.1562,  0.0128,  ...,  0.0671, -0.2804, -0.1180],
        [ 0.0348, -0.0700,  0.0061,  ..., -0.3029,  0.1279,  0.1557],
        [-0.0849,  0.1616,  0.0123,  ..., -0.1725,  0.0634, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0510,  0.0541, -0.0929, -0.1204, -0.0576,  0.0458, -0.1290,  0.0620,
        -0.0463,  0.0922,  0.0330,  0.0081,  0.0095,  0.0630, -0.0784, -0.0203,
         0.0465, -0.1421, -0.0323, -0.0152, -0.1094,  0.0478,  0.0820, -0.0065,
        -0.0850,  0.0666,  0.0242, -0.0960,  0.0640,  0.1473,  0.1369, -0.0659],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0378, -0.1969, -0.0800,  ..., -0.1407, -0.0149,  0.2633],
        [-0.2367, -0.0456,  0.1054,  ..., -0.0713, -0.0017,  0.2718],
        [ 0.1654, -0.0188, -0.1770,  ...,  0.0836, -0.0246, -0.0693],
        ...,
        [ 0.1525,  0.1124,  0.0808,  ...,  0.2641, -0.2232,  0.0545],
        [-0.0535, -0.1744,  0.0772,  ...,  0.0019,  0.2500,  0.0870],
        [-0.0189, -0.1224,  0.2119,  ...,  0.0503,  0.1406,  0.1322]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0870,  0.1225, -0.0354, -0.0549, -0.0312, -0.0352, -0.0325, -0.0624,
         0.1100, -0.1752,  0.1224, -0.1328,  0.1651, -0.0186, -0.1429,  0.1054,
        -0.1273, -0.1539,  0.0135, -0.0295,  0.0086,  0.1085, -0.1892,  0.2025,
        -0.0698, -0.0287,  0.0880, -0.0373, -0.1122, -0.0601,  0.1110,  0.0010],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5178,  0.4421, -0.5202, -0.5235,  0.3684,  0.3765, -0.4247,  0.4334,
          0.4333, -0.4561, -0.4462,  0.4071,  0.4293, -0.3702,  0.4502,  0.3986,
         -0.5281, -0.5193,  0.3962,  0.4134, -0.4812, -0.4542, -0.5177,  0.3533,
          0.4925,  0.5189, -0.4928,  0.5608, -0.4284, -0.5102,  0.4950,  0.5100]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2395], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.2837e-02,  3.5307e-01,  3.2341e-01, -3.4684e-01, -2.6857e-02,
         -1.7868e-01, -6.8002e-02, -3.9038e-01, -1.7687e-01, -8.5116e-02,
          2.8972e-02,  1.7550e-01,  6.0131e-02, -5.2334e-02,  3.1773e-01,
          3.6419e-01],
        [-2.7686e-01, -3.3785e-01, -1.2839e-01,  1.4391e-02, -1.5917e-01,
          2.8614e-01,  1.8970e-01,  1.6987e-01,  4.0124e-01,  1.3555e-01,
          2.2109e-01, -2.7405e-01, -2.7807e-04, -4.5484e-02, -6.2320e-04,
         -8.4332e-02],
        [ 9.9966e-02,  2.4703e-01,  4.0273e-01, -1.4026e-01,  1.4071e-01,
         -3.7504e-01, -6.5055e-02, -4.1343e-01,  5.3457e-02, -8.2150e-02,
         -9.5221e-02, -6.0939e-02,  3.9568e-01,  3.0973e-01,  4.3414e-01,
          2.6557e-01],
        [ 2.9266e-01,  6.7946e-02,  1.0725e-01, -9.2522e-02,  9.9198e-02,
         -2.3099e-01, -1.7190e-01, -9.7953e-02, -4.0797e-01, -4.0328e-01,
         -1.0668e-01,  3.6678e-01,  2.8491e-01, -1.2743e-01,  1.4206e-01,
          1.6000e-01],
        [-1.1743e-01,  1.2208e-01, -1.9039e-01, -2.7782e-03,  5.5444e-02,
          1.2436e-01,  6.7522e-02,  3.4879e-01,  1.6102e-01,  2.9264e-01,
          2.3014e-01, -1.9141e-01, -5.4640e-02, -2.2688e-01, -8.4787e-02,
         -1.3722e-01],
        [-2.2184e-02,  1.4688e-01, -3.7612e-01,  4.1318e-01,  1.6181e-01,
          4.7283e-03,  2.7609e-01, -1.9766e-02,  2.5283e-01,  2.0576e-01,
         -1.3867e-01, -9.8718e-02, -2.4863e-01,  1.3185e-01,  3.2001e-02,
         -7.0275e-02],
        [ 3.9409e-01,  2.0136e-01,  4.3328e-01, -2.0367e-01,  1.2820e-01,
         -2.5119e-01, -2.1176e-01, -2.3976e-01, -2.5147e-01, -2.8529e-02,
         -1.9754e-02,  6.6949e-02, -3.2868e-02,  2.2934e-01, -1.1020e-02,
          1.6245e-01],
        [-4.4259e-02,  3.1498e-01,  3.7528e-01, -3.6301e-01, -1.4707e-01,
         -3.3140e-01, -1.0929e-01, -2.4723e-01, -1.7926e-01, -2.1481e-01,
         -7.2338e-02,  2.1752e-02,  2.5444e-01, -8.4062e-02,  1.6175e-01,
          3.6522e-01],
        [ 5.7117e-02,  3.0439e-01,  3.2655e-01, -2.6982e-01,  3.0449e-02,
         -3.8330e-01, -1.8421e-01, -1.1284e-01,  4.0476e-02, -3.1497e-01,
         -1.1265e-01,  7.6962e-02, -8.0955e-02,  1.4160e-01,  1.4828e-02,
          9.5894e-02],
        [-3.0653e-01, -8.3706e-02, -1.1731e-01,  3.1106e-03, -4.1271e-02,
          1.8986e-01,  6.7517e-02,  2.5299e-01,  2.7297e-01, -6.7726e-03,
          2.3742e-01, -2.5608e-02, -2.6230e-01, -6.8245e-02, -1.8778e-01,
         -1.8898e-01],
        [-3.6923e-01,  7.1910e-02, -8.0023e-02, -2.6353e-02, -1.7524e-01,
          4.5521e-01,  2.4556e-01,  1.2018e-01,  3.3787e-01,  2.4894e-01,
          6.7648e-02,  7.1478e-03, -1.6118e-01,  1.3464e-01, -3.8889e-01,
         -3.3069e-01],
        [-1.4530e-01, -1.4459e-01, -4.4234e-02,  1.0621e-01,  1.1339e-01,
          1.5312e-01,  3.8924e-01,  1.6260e-01,  1.7064e-01,  3.4463e-01,
          1.5459e-01,  4.6466e-02, -4.0177e-01, -2.0217e-01, -2.5958e-01,
         -2.0012e-01],
        [ 3.6821e-01,  2.2012e-01,  2.0288e-01, -2.0456e-01,  7.3879e-02,
         -2.8210e-02, -1.1481e-01, -3.3912e-01, -3.4160e-01, -1.2244e-01,
         -1.2166e-01,  4.6176e-02, -2.3184e-02,  1.9575e-01,  1.7233e-01,
          3.5885e-02],
        [ 2.3768e-01,  3.5408e-01,  3.9791e-01, -3.5373e-02, -1.7960e-01,
         -6.4073e-02, -7.3823e-02, -8.8024e-02, -2.2383e-01, -1.7359e-01,
         -2.1552e-01,  1.2880e-01,  1.3324e-01,  7.2952e-02, -3.3281e-02,
          2.5133e-01],
        [-3.9600e-01, -3.0314e-01, -9.1078e-02, -2.6513e-02,  2.0493e-01,
          4.4609e-01,  1.2040e-01,  1.2174e-01, -3.6686e-02,  1.8543e-01,
          1.2821e-01, -3.1643e-01, -8.6075e-02, -1.1838e-01, -2.8308e-01,
         -1.7068e-01],
        [-8.7470e-02, -1.5675e-01,  1.7962e-01,  8.9072e-02, -2.0096e-01,
         -1.7374e-02, -1.5628e-01, -2.9410e-01, -1.6904e-01, -8.9665e-03,
          1.0714e-02,  4.3174e-01,  1.1833e-01, -9.3545e-02,  4.1608e-01,
          2.8599e-02],
        [ 3.3326e-01,  2.7315e-01,  2.2017e-01, -3.6796e-01, -2.0732e-01,
         -7.1422e-02, -1.2174e-01, -2.8033e-03, -3.5770e-01, -1.8815e-01,
          1.3784e-01,  2.8951e-01,  3.4655e-01,  2.8652e-01,  1.2837e-01,
         -1.6834e-02],
        [-3.1652e-01, -2.0910e-02, -2.6785e-01,  1.5585e-01, -1.1628e-02,
          3.3762e-01,  3.1267e-01,  2.7761e-01,  1.3480e-01,  2.8712e-01,
         -3.6230e-02, -2.4891e-01, -1.6779e-01, -2.2372e-01,  4.1233e-02,
         -1.8718e-01],
        [ 2.5213e-01,  1.3155e-01,  1.7769e-01, -3.1369e-01, -7.7944e-03,
         -4.1347e-01, -3.0929e-01,  2.8672e-02, -3.8955e-01, -1.3745e-01,
         -4.4038e-02, -7.9007e-02,  1.9576e-01,  2.5867e-01,  3.7206e-01,
          2.0919e-01],
        [ 3.9037e-01,  1.3897e-01,  2.9330e-01, -1.0766e-01, -1.7166e-01,
         -2.6615e-01, -3.7436e-01,  3.1906e-02, -3.6619e-02, -2.7967e-01,
         -6.8536e-02,  2.4770e-01, -7.6041e-02,  1.0669e-01,  3.2897e-01,
          2.0773e-01],
        [-2.0221e-01,  7.7153e-02, -6.9857e-02, -5.0086e-02,  1.5252e-01,
          2.2753e-03,  3.3170e-01,  3.9592e-01,  1.9362e-01,  7.4990e-02,
         -7.1033e-02, -3.0436e-01, -2.0422e-01, -2.0675e-01,  4.3292e-02,
         -2.5392e-01],
        [-8.0773e-02, -3.3970e-01, -5.9575e-02,  3.9036e-01, -1.5278e-01,
          1.3896e-01,  2.5254e-01, -6.9618e-02,  7.1456e-03,  2.5341e-01,
          2.5223e-01, -2.5700e-01, -1.5189e-01, -3.3924e-01, -4.4867e-01,
          6.0245e-02],
        [ 3.7682e-01,  3.3711e-02,  6.8365e-02, -1.6936e-01,  1.5994e-01,
         -4.2212e-01, -3.0864e-01, -2.0965e-01, -2.3043e-01, -1.5201e-01,
          1.1815e-01,  1.9968e-01, -1.1117e-01,  3.1154e-01,  3.7917e-01,
          2.2729e-01],
        [ 2.7631e-01,  2.0220e-01,  3.6177e-01, -3.8250e-01, -8.7537e-02,
         -2.0106e-01, -2.0326e-01, -2.6971e-01, -3.4263e-01, -3.2573e-01,
         -1.0497e-01,  3.3547e-01,  2.5461e-01,  1.4753e-01,  6.8911e-03,
          4.3110e-02],
        [ 2.2875e-01, -1.3571e-01,  1.9127e-01, -1.4501e-01,  1.9072e-01,
         -2.9055e-01,  2.2140e-02, -1.9259e-01, -3.6699e-01,  5.5980e-02,
          1.6960e-01,  1.7462e-02,  5.0866e-02,  2.3588e-01,  7.7672e-02,
          3.2969e-01],
        [ 7.3568e-02,  1.4856e-02,  1.2129e-01,  5.4396e-02, -8.0819e-02,
         -2.6316e-01, -5.6544e-02, -3.6454e-01, -1.8448e-01, -3.6532e-01,
         -2.9447e-01,  1.4238e-01,  1.9881e-01,  3.3354e-01, -1.8959e-02,
          8.6163e-02],
        [ 2.3443e-01,  2.0859e-01,  3.1752e-01, -3.5741e-01, -2.9218e-03,
         -1.2563e-01, -3.7497e-01,  1.1497e-03, -3.5939e-01,  6.5646e-03,
          1.2889e-03,  7.1465e-02,  1.9966e-01,  2.9866e-01,  3.6593e-01,
          3.0646e-01],
        [-3.3455e-01, -3.9581e-02, -5.7350e-04,  2.1797e-01,  2.0098e-01,
          5.0279e-02,  3.7914e-01,  1.6983e-01, -5.8683e-02,  9.7970e-02,
          2.1851e-01, -2.7498e-01, -2.0889e-01, -1.8828e-01, -3.4267e-01,
         -1.1085e-01],
        [ 3.2264e-01,  1.4613e-01,  1.5814e-01, -1.4218e-01, -1.8222e-01,
         -3.1988e-01, -1.6299e-01, -3.4222e-01, -1.1583e-02, -1.1135e-01,
          1.1450e-03,  1.4184e-01,  3.1338e-01,  3.0880e-01,  2.9951e-01,
          2.7603e-01],
        [-2.8714e-01, -1.2163e-03, -3.3619e-01,  2.6190e-01, -2.3668e-01,
          1.7902e-01,  3.5341e-01,  2.9306e-01,  3.4158e-01,  2.3146e-01,
          1.8719e-01, -7.6554e-02,  5.0552e-02,  4.9343e-02, -1.0486e-01,
         -2.3528e-01],
        [-3.0279e-01, -1.8145e-01, -6.5048e-02,  3.3348e-02,  5.2626e-02,
          4.1667e-01,  3.9963e-01, -3.0696e-02,  2.1450e-01,  3.2416e-01,
         -1.8985e-01, -9.4159e-03, -2.8724e-01, -2.6909e-01, -3.0217e-01,
         -2.5669e-01],
        [ 8.6810e-02,  2.0838e-01,  2.8808e-01, -9.1211e-02,  1.7852e-01,
         -3.6124e-01, -4.3818e-01, -3.7909e-01, -3.0184e-01, -2.9703e-01,
          2.8522e-02, -3.9211e-04, -1.1166e-02,  2.6532e-01,  5.2252e-02,
          2.1428e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0960, -0.0586,  0.1840, -0.0280, -0.0848, -0.0390,  0.0727,  0.0625,
        -0.0260, -0.0572, -0.0309,  0.0552,  0.1272,  0.0998, -0.0159,  0.0005,
        -0.1418,  0.0228,  0.1165,  0.0183, -0.0224, -0.1762, -0.0124, -0.0492,
        -0.0394,  0.2269,  0.1235,  0.0185, -0.0493, -0.1486,  0.0151,  0.0301],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1944,  0.2856, -0.2112, -0.2427,  0.2656,  0.3159, -0.2628, -0.3652,
         -0.2882,  0.3063,  0.2482,  0.3600, -0.2223, -0.3640,  0.2853, -0.1538,
         -0.2836,  0.3241, -0.2154, -0.2298,  0.3426,  0.3413, -0.3608, -0.3665,
         -0.2614, -0.2923, -0.3067,  0.3273, -0.3503,  0.3720,  0.2851, -0.2239]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0112, -0.0034,  0.0258,  ...,  0.2090, -0.3528, -0.1137],
        [-0.0821, -0.1901,  0.0829,  ...,  0.1453, -0.3294,  0.0871],
        [-0.0539,  0.1579,  0.0910,  ...,  0.0107,  0.2360,  0.0345],
        ...,
        [ 0.0417, -0.1562,  0.0128,  ...,  0.0671, -0.2804, -0.1180],
        [ 0.0348, -0.0700,  0.0061,  ..., -0.3029,  0.1279,  0.1557],
        [-0.0849,  0.1616,  0.0123,  ..., -0.1725,  0.0634, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0510,  0.0541, -0.0929, -0.1204, -0.0576,  0.0458, -0.1290,  0.0620,
        -0.0463,  0.0922,  0.0330,  0.0081,  0.0095,  0.0630, -0.0784, -0.0203,
         0.0465, -0.1421, -0.0323, -0.0152, -0.1094,  0.0478,  0.0820, -0.0065,
        -0.0850,  0.0666,  0.0242, -0.0960,  0.0640,  0.1473,  0.1369, -0.0659],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0378, -0.1969, -0.0800,  ..., -0.1407, -0.0149,  0.2633],
        [-0.2367, -0.0456,  0.1054,  ..., -0.0713, -0.0017,  0.2718],
        [ 0.1654, -0.0188, -0.1770,  ...,  0.0836, -0.0246, -0.0693],
        ...,
        [ 0.1525,  0.1124,  0.0808,  ...,  0.2641, -0.2232,  0.0545],
        [-0.0535, -0.1744,  0.0772,  ...,  0.0019,  0.2500,  0.0870],
        [-0.0189, -0.1224,  0.2119,  ...,  0.0503,  0.1406,  0.1322]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0870,  0.1225, -0.0354, -0.0549, -0.0312, -0.0352, -0.0325, -0.0624,
         0.1100, -0.1752,  0.1224, -0.1328,  0.1651, -0.0186, -0.1429,  0.1054,
        -0.1273, -0.1539,  0.0135, -0.0295,  0.0086,  0.1085, -0.1892,  0.2025,
        -0.0698, -0.0287,  0.0880, -0.0373, -0.1122, -0.0601,  0.1110,  0.0010],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5178,  0.4421, -0.5202, -0.5235,  0.3684,  0.3765, -0.4247,  0.4334,
          0.4333, -0.4561, -0.4462,  0.4071,  0.4293, -0.3702,  0.4502,  0.3986,
         -0.5281, -0.5193,  0.3962,  0.4134, -0.4812, -0.4542, -0.5177,  0.3533,
          0.4925,  0.5189, -0.4928,  0.5608, -0.4284, -0.5102,  0.4950,  0.5100]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2395], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 9.4516e-03,  3.6203e-01,  3.2259e-01, -3.1640e-01, -3.1728e-01,
         -2.0293e-01, -9.1679e-02, -4.7872e-01, -2.5514e-01, -8.8372e-02,
         -2.7269e-02,  2.5019e-01,  1.0675e-01, -2.8574e-02,  3.0574e-02,
          3.7114e-01],
        [-2.6134e-01, -3.3872e-01, -1.1595e-01, -1.0418e-02,  6.2464e-02,
          2.8557e-01,  1.9719e-01,  2.2928e-01,  4.5534e-01,  1.5337e-01,
          2.8621e-01, -3.1273e-01, -2.1087e-02, -8.0051e-02,  2.5868e-01,
         -8.3682e-02],
        [ 9.0854e-02,  2.4961e-01,  3.9428e-01, -1.1075e-01, -1.7541e-01,
         -3.8257e-01, -8.2186e-02, -4.9871e-01, -3.3464e-02, -8.6531e-02,
         -1.3939e-01, -3.9851e-03,  4.3564e-01,  3.6843e-01,  1.4182e-01,
          2.6696e-01],
        [ 2.8613e-01,  7.4441e-02,  1.0294e-01, -7.3219e-02, -1.4795e-01,
         -2.4012e-01, -1.9155e-01, -1.7669e-01, -4.9148e-01, -4.2842e-01,
         -1.2149e-01,  4.2621e-01,  3.0999e-01, -7.2492e-02, -1.2557e-01,
          1.6373e-01],
        [-1.0431e-01,  8.4135e-02, -1.8429e-01, -2.9570e-02,  2.5565e-01,
          1.2553e-01,  7.6645e-02,  3.9771e-01,  2.0740e-01,  3.1808e-01,
          3.2169e-01, -2.1566e-01, -7.4191e-02, -2.8070e-01,  1.9303e-01,
         -1.6028e-01],
        [-1.8893e-02,  1.2282e-01, -3.7669e-01,  4.0295e-01,  4.2972e-01,
          1.5885e-02,  2.9676e-01,  4.3131e-02,  3.1661e-01,  2.3713e-01,
         -9.1606e-02, -1.4166e-01, -2.7263e-01,  8.6994e-02,  3.0913e-01,
         -8.4662e-02],
        [ 3.8537e-01,  1.1851e-01,  4.2549e-01, -1.8721e-01, -1.4048e-01,
         -2.5342e-01, -2.1629e-01, -3.1297e-01, -3.2189e-01, -5.0253e-02,
         -5.6305e-02,  1.1862e-01, -3.3484e-02,  2.7104e-01, -1.8679e-01,
          1.6345e-01],
        [-5.0472e-02,  2.6895e-01,  3.6979e-01, -3.5475e-01, -4.0169e-01,
         -3.3083e-01, -1.1479e-01, -3.2297e-01, -2.5053e-01, -2.3597e-01,
         -1.0291e-01,  7.4844e-02,  2.7156e-01, -4.6899e-02,  4.7517e-03,
          3.6397e-01],
        [ 4.7337e-02,  3.0571e-01,  3.1928e-01, -2.4381e-01, -1.3906e-01,
         -3.8946e-01, -2.0151e-01, -1.7698e-01, -1.8693e-02, -3.3790e-01,
         -2.5759e-01,  1.1314e-01, -3.5418e-02,  2.0655e-01, -2.4414e-01,
          1.0075e-01],
        [-3.0079e-01, -1.0805e-01, -1.1615e-01, -1.3968e-02,  1.6927e-01,
          2.0073e-01,  8.8418e-02,  3.1879e-01,  3.3655e-01,  2.5166e-02,
          3.3199e-01, -6.4673e-02, -2.9973e-01, -1.2883e-01,  9.2665e-02,
         -2.0651e-01],
        [-3.7222e-01,  4.5503e-02, -8.4985e-02, -3.1978e-02,  5.7959e-02,
          4.7440e-01,  2.7299e-01,  2.0704e-01,  4.2386e-01,  2.8434e-01,
          1.3481e-01, -5.8733e-02, -1.8761e-01,  6.4721e-02, -7.7118e-02,
         -3.4468e-01],
        [-1.3919e-01, -1.6166e-01, -4.2945e-02,  9.0711e-02,  2.5942e-01,
          1.6433e-01,  4.0739e-01,  2.3120e-01,  2.3005e-01,  3.7668e-01,
          2.4951e-01,  4.5937e-03, -4.0657e-01, -2.8712e-01, -1.4033e-02,
         -2.1472e-01],
        [ 3.5337e-01,  2.5172e-01,  1.9207e-01, -1.7508e-01, -2.4317e-01,
         -3.9595e-02, -1.3799e-01, -4.3792e-01, -4.1078e-01, -1.4471e-01,
         -1.6369e-01,  1.1167e-01, -8.8102e-03,  2.2679e-01, -1.7201e-01,
          4.7385e-02],
        [ 2.2153e-01,  3.3524e-01,  3.8458e-01, -1.3905e-02, -3.8827e-01,
         -5.9714e-02, -7.4507e-02, -1.3938e-01, -2.7313e-01, -1.8973e-01,
         -2.7343e-01,  1.5959e-01,  1.4841e-01,  1.0657e-01, -2.5029e-01,
          2.4812e-01],
        [-3.8779e-01, -2.9879e-01, -8.4353e-02, -4.2250e-02,  4.5086e-01,
          4.4893e-01,  1.3248e-01,  1.9135e-01,  3.0930e-02,  2.0719e-01,
          1.8635e-01, -3.6394e-01, -1.1380e-01, -1.6174e-01, -4.9589e-02,
         -1.7232e-01],
        [-5.8451e-02, -6.8728e-02,  2.1974e-01,  8.7862e-02, -4.4286e-01,
         -8.8480e-02, -2.4122e-01, -4.1912e-01, -2.9268e-01, -9.5392e-02,
         -1.2719e-01,  4.8582e-01,  2.0658e-01,  3.0926e-02,  1.5568e-01,
          8.4029e-02],
        [ 3.2913e-01,  2.7106e-01,  2.1822e-01, -3.5650e-01, -4.4610e-01,
         -8.0855e-02, -1.3944e-01, -7.6560e-02, -4.3132e-01, -2.1563e-01,
          9.8396e-02,  3.4643e-01,  3.8979e-01,  3.3445e-01, -6.8380e-02,
         -1.4156e-02],
        [-3.0738e-01, -9.2311e-03, -2.6084e-01,  1.4399e-01,  2.0559e-01,
          3.3421e-01,  3.1746e-01,  3.3627e-01,  1.9764e-01,  3.0762e-01,
          4.9812e-05, -2.9092e-01, -1.8452e-01, -2.7045e-01,  2.0759e-01,
         -1.8659e-01],
        [ 2.2934e-01,  1.1884e-01,  1.5434e-01, -2.6888e-01, -3.1966e-01,
         -4.1191e-01, -3.1928e-01, -5.6994e-02, -4.8060e-01, -1.2510e-01,
         -1.0959e-01, -2.3702e-02,  2.6025e-01,  3.1964e-01,  9.5202e-02,
          1.9095e-01],
        [ 3.8759e-01,  1.3689e-01,  2.9057e-01, -9.1536e-02, -4.0820e-01,
         -2.7674e-01, -3.9588e-01, -5.3660e-02, -1.1846e-01, -3.0477e-01,
         -1.4962e-01,  3.0900e-01, -3.0178e-02,  1.6272e-01,  9.6416e-02,
          2.1087e-01],
        [-1.9138e-01,  5.1847e-02, -6.3571e-02, -6.6903e-02,  3.4874e-01,
         -2.1213e-03,  3.3675e-01,  4.2366e-01,  2.2864e-01,  9.6167e-02,
         -7.5407e-03, -3.1745e-01, -2.1570e-01, -2.4809e-01,  2.9520e-01,
         -2.6559e-01],
        [-8.2855e-02, -3.3536e-01, -6.2639e-02,  3.7908e-01,  6.4032e-02,
          1.5769e-01,  2.8859e-01,  1.7899e-02,  8.6670e-02,  2.8920e-01,
          3.8171e-01, -3.1260e-01, -2.2194e-01, -4.0884e-01, -1.7660e-01,
          4.8721e-02],
        [ 3.7829e-01,  3.3942e-02,  7.0591e-02, -1.6657e-01, -7.2464e-02,
         -4.3370e-01, -3.3012e-01, -2.9074e-01, -3.0993e-01, -1.8256e-01,
          6.5441e-02,  2.5922e-01, -6.5617e-02,  3.6757e-01,  1.8978e-01,
          2.3335e-01],
        [ 2.6873e-01,  2.0301e-01,  3.5601e-01, -3.7466e-01, -2.9571e-01,
         -1.9733e-01, -2.1074e-01, -3.3863e-01, -4.0993e-01, -3.4534e-01,
         -9.7561e-02,  3.8502e-01,  2.7038e-01,  1.8668e-01, -1.4689e-01,
          3.7836e-02],
        [ 2.2314e-01, -1.0869e-01,  1.9029e-01, -1.2276e-01, -2.9476e-02,
         -3.0391e-01,  2.3106e-03, -2.5427e-01, -4.3204e-01,  2.3738e-02,
          7.2151e-02,  6.0561e-02,  8.8984e-02,  2.9370e-01, -2.2461e-01,
          3.5054e-01],
        [ 5.3233e-02,  3.1980e-02,  1.0494e-01,  7.9994e-02, -2.9887e-01,
         -2.4855e-01, -4.9841e-02, -3.9398e-01, -2.1545e-01, -3.7755e-01,
         -3.5861e-01,  1.5506e-01,  1.9941e-01,  3.6343e-01, -2.8428e-01,
          9.1321e-02],
        [ 2.3487e-01,  1.9808e-01,  3.1823e-01, -3.5273e-01, -2.5040e-01,
         -1.3610e-01, -3.9427e-01, -8.6236e-02, -4.4327e-01, -2.1415e-02,
         -4.2007e-02,  1.3629e-01,  2.4497e-01,  3.4839e-01,  1.8602e-01,
          3.0929e-01],
        [-3.3168e-01, -5.5847e-02, -1.8395e-03,  2.0667e-01,  3.9512e-01,
          6.5220e-02,  4.0228e-01,  2.4747e-01,  1.0796e-02,  1.3263e-01,
          2.9530e-01, -3.2619e-01, -2.4381e-01, -2.5422e-01, -9.3247e-02,
         -1.2602e-01],
        [ 3.1751e-01,  1.6621e-01,  1.5583e-01, -1.3520e-01, -3.7857e-01,
         -3.2652e-01, -1.8012e-01, -4.1049e-01, -7.8121e-02, -1.3728e-01,
         -5.0012e-03,  1.9295e-01,  3.1651e-01,  3.6413e-01,  7.4042e-02,
          2.7955e-01],
        [-2.8435e-01,  2.0595e-02, -3.3419e-01,  2.5669e-01, -7.2908e-03,
          1.8144e-01,  3.6468e-01,  3.6427e-01,  4.1203e-01,  2.5693e-01,
          2.3834e-01, -1.2662e-01,  2.4310e-02,  3.1468e-04,  5.9817e-02,
         -2.3951e-01],
        [-3.0043e-01, -1.8721e-01, -6.4023e-02,  2.2482e-02,  2.7984e-01,
          4.2777e-01,  4.1887e-01,  4.7045e-02,  2.9158e-01,  3.5176e-01,
         -1.2744e-01, -6.6901e-02, -3.3172e-01, -3.2743e-01, -7.9718e-02,
         -2.6103e-01],
        [ 6.9389e-02,  1.7906e-01,  2.7154e-01, -5.0189e-02, -7.8136e-02,
         -3.5985e-01, -4.4184e-01, -4.5047e-01, -3.7764e-01, -2.9450e-01,
         -3.4376e-02,  4.5659e-02,  1.2598e-02,  3.1952e-01, -1.7090e-01,
          2.0568e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0532, -0.0123,  0.1083, -0.0356, -0.0591, -0.0912,  0.0745,  0.0824,
        -0.0189, -0.0585, -0.0064,  0.0584,  0.1476,  0.0799,  0.0189, -0.0494,
        -0.0506, -0.0051,  0.0917,  0.0068, -0.0429, -0.1394, -0.0285,  0.0012,
        -0.0048,  0.1615,  0.1192,  0.0187, -0.0648, -0.1416,  0.0303, -0.0430],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2339,  0.3246, -0.2309, -0.2648,  0.3261,  0.3642, -0.2851, -0.3873,
         -0.3176,  0.3496,  0.2669,  0.3773, -0.2671, -0.4016,  0.3069, -0.2876,
         -0.3238,  0.3348, -0.2315, -0.2533,  0.4033,  0.3155, -0.3747, -0.3818,
         -0.3327, -0.3426, -0.3167,  0.3545, -0.3628,  0.3861,  0.2930, -0.2404]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0134, -0.0089,  0.0434,  ...,  0.2365, -0.3687, -0.1137],
        [-0.0864, -0.1923,  0.0876,  ...,  0.1480, -0.3490,  0.0871],
        [-0.0403,  0.1763,  0.0731,  ..., -0.0053,  0.2689,  0.0345],
        ...,
        [ 0.0259, -0.1909,  0.0423,  ...,  0.0663, -0.2946, -0.1180],
        [ 0.0510, -0.0490, -0.0194,  ..., -0.3045,  0.1544,  0.1557],
        [-0.2047,  0.0495,  0.0020,  ...,  0.0418, -0.2397, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0571,  0.0575, -0.0881, -0.1189, -0.0573,  0.0527, -0.1279,  0.0611,
        -0.0491,  0.0819,  0.0313,  0.0092,  0.0257,  0.0732, -0.0782, -0.0173,
         0.0498, -0.1497, -0.0285, -0.0239, -0.0750,  0.0448,  0.0885, -0.0072,
        -0.0870,  0.0867,  0.0328, -0.0876,  0.0488,  0.1386,  0.1476, -0.1051],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0177, -0.1903, -0.0800,  ..., -0.1161, -0.0287,  0.0707],
        [-0.2658, -0.0443,  0.1158,  ..., -0.0481, -0.0080,  0.0586],
        [ 0.1843, -0.0294, -0.1767,  ...,  0.0539, -0.0077,  0.1673],
        ...,
        [ 0.1664,  0.0965,  0.0895,  ...,  0.2277, -0.1993,  0.2422],
        [-0.0792, -0.1642,  0.0782,  ...,  0.0326,  0.2357, -0.1657],
        [-0.0492, -0.1251,  0.2158,  ...,  0.0715,  0.1333, -0.0321]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0831,  0.1209, -0.0225, -0.0583, -0.0348, -0.0633, -0.0254, -0.0603,
         0.0939, -0.1343,  0.1356, -0.1274,  0.1511,  0.0570, -0.1348,  0.0868,
        -0.1173, -0.1450,  0.0024, -0.0145,  0.0077,  0.1102, -0.1829,  0.1723,
        -0.0646, -0.0316,  0.0914, -0.0429, -0.1086, -0.0529,  0.0944,  0.0027],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5226,  0.4447, -0.5217, -0.5245,  0.3893,  0.3803, -0.4362,  0.4307,
          0.4556, -0.4599, -0.4196,  0.4160,  0.4148,  0.4251,  0.4536,  0.4073,
         -0.5230, -0.5285,  0.3926,  0.4183, -0.4781, -0.4563, -0.5225,  0.3832,
          0.5066,  0.5306, -0.5063,  0.5554, -0.4347, -0.5198,  0.5013,  0.5225]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2411], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 0.0113,  0.0649,  0.2968, -0.3337, -0.2828, -0.1496, -0.0566, -0.4470,
         -0.2038, -0.0574,  0.1776,  0.1986,  0.0615, -0.0545, -0.1786,  0.3691],
        [-0.2629, -0.0725, -0.1016,  0.0166,  0.0413,  0.2474,  0.1662,  0.2025,
          0.4369,  0.1401,  0.0687, -0.2755, -0.0102, -0.0616,  0.4606, -0.0841],
        [ 0.0896,  0.0054,  0.3725, -0.1283, -0.1344, -0.3401, -0.0390, -0.4556,
          0.0125, -0.0634, -0.0834, -0.0489,  0.4030,  0.3259, -0.0534,  0.2621],
        [ 0.2724, -0.0571,  0.0722, -0.0856, -0.1050, -0.1811, -0.1379, -0.1256,
         -0.4426, -0.3957,  0.0299,  0.3630,  0.2958, -0.1132, -0.2860,  0.1455],
        [-0.1014,  0.3395, -0.1634, -0.0047,  0.2247,  0.0800,  0.0365,  0.3612,
          0.1750,  0.2998,  0.0666, -0.1704, -0.0552, -0.2510,  0.3761, -0.1572],
        [-0.0046,  0.3176, -0.3495,  0.4157,  0.3725, -0.0428,  0.2476, -0.0061,
          0.2756,  0.2102, -0.1121, -0.0907, -0.2337,  0.1185,  0.4440, -0.0742],
        [ 0.3743, -0.0105,  0.3995, -0.2012, -0.1097, -0.2048, -0.1682, -0.2703,
         -0.2776, -0.0264,  0.0029,  0.0696, -0.0609,  0.1864, -0.3549,  0.1511],
        [-0.0594,  0.1343,  0.3497, -0.3703, -0.3810, -0.2947, -0.0805, -0.2958,
         -0.2259, -0.2214, -0.0596,  0.0436,  0.2534, -0.0944, -0.1391,  0.3547],
        [ 0.0510,  0.0191,  0.3067, -0.2753, -0.1228, -0.3509, -0.1719, -0.1518,
          0.0033, -0.3270,  0.0128,  0.0771, -0.0449,  0.1919, -0.4376,  0.1056],
        [-0.3012,  0.1687, -0.1013,  0.0144,  0.1401,  0.1583,  0.0518,  0.2836,
          0.3068,  0.0108,  0.1075, -0.0253, -0.2801, -0.1096,  0.2786, -0.2090],
        [-0.3648,  0.2169, -0.0599, -0.0148,  0.0247,  0.4240,  0.2323,  0.1665,
          0.3871,  0.2591,  0.0043, -0.0085, -0.2141,  0.0809,  0.0880, -0.3353],
        [-0.1289,  0.0217, -0.0179,  0.1098,  0.2139,  0.1170,  0.3529,  0.1793,
          0.1847,  0.3510,  0.0887,  0.0575, -0.4210, -0.2421,  0.1345, -0.2038],
        [ 0.3473, -0.0061,  0.1612, -0.1967, -0.1922,  0.0226, -0.0892, -0.3869,
         -0.3708, -0.1136, -0.0947,  0.0531, -0.0143,  0.2066, -0.3945,  0.0380],
        [ 0.2167,  0.1075,  0.3670, -0.0349, -0.3614, -0.0224, -0.0370, -0.1072,
         -0.2512, -0.1742, -0.1080,  0.1228,  0.1321,  0.0689, -0.4309,  0.2431],
        [-0.3866, -0.0606, -0.0677, -0.0183,  0.4345,  0.4141,  0.1013,  0.1671,
          0.0079,  0.1945,  0.0342, -0.3295, -0.1074, -0.1381,  0.1543, -0.1695],
        [-0.0357, -0.4047,  0.2004,  0.0348, -0.4430, -0.0227, -0.1988, -0.4017,
         -0.2714, -0.0723, -0.0515,  0.4442,  0.1874, -0.0210, -0.0954,  0.0997],
        [ 0.3177,  0.0984,  0.1934, -0.3697, -0.3871, -0.0303, -0.0853, -0.0249,
         -0.3977, -0.1887,  0.1942,  0.2937,  0.3507,  0.2710, -0.1938, -0.0291],
        [-0.2905,  0.1192, -0.2311,  0.1518,  0.1495,  0.2852,  0.2645,  0.2879,
          0.1519,  0.2819, -0.0524, -0.2415, -0.1474, -0.1948,  0.2860, -0.1684],
        [ 0.2382, -0.0896,  0.1440, -0.2965, -0.2469, -0.3745, -0.2742, -0.0080,
         -0.4306, -0.1112,  0.0167, -0.0688,  0.2032,  0.2575, -0.0643,  0.1953],
        [ 0.3798, -0.0642,  0.2635, -0.1098, -0.3785, -0.2309, -0.3515, -0.0170,
         -0.0830, -0.2803,  0.0928,  0.2591, -0.0375,  0.1196, -0.1018,  0.1986],
        [-0.1775,  0.2412, -0.0361, -0.0564,  0.3012, -0.0481,  0.2926,  0.3828,
          0.1948,  0.0725, -0.1090, -0.2730, -0.1946, -0.2045,  0.4188, -0.2523],
        [-0.0956,  0.0125, -0.0577,  0.4188,  0.0628,  0.1259,  0.2654,  0.0026,
          0.0784,  0.2873,  0.2141, -0.2944, -0.2205, -0.3962,  0.0022,  0.0409],
        [ 0.3722, -0.1517,  0.0504, -0.1858, -0.0451, -0.3971, -0.2920, -0.2628,
         -0.2837, -0.1673,  0.2073,  0.2247, -0.0686,  0.3244,  0.0299,  0.2242],
        [ 0.2519,  0.1152,  0.3287, -0.3821, -0.2276, -0.1523, -0.1588, -0.2908,
         -0.3702, -0.3184,  0.0181,  0.3405,  0.2630,  0.1225, -0.2229,  0.0149],
        [ 0.2172, -0.3694,  0.1698, -0.1475,  0.0106, -0.2500,  0.0495, -0.2050,
         -0.3882,  0.0454,  0.1959,  0.0092,  0.0590,  0.2704, -0.4059,  0.3494],
        [ 0.0466, -0.1803,  0.0829,  0.0632, -0.2597, -0.2098, -0.0189, -0.3606,
         -0.1880, -0.3602, -0.2667,  0.1172,  0.1960,  0.3376, -0.4649,  0.0833],
        [ 0.2241, -0.0081,  0.2904, -0.3653, -0.2126, -0.0961, -0.3446, -0.0510,
         -0.4071,  0.0009,  0.0480,  0.0924,  0.2320,  0.2717,  0.0397,  0.2918],
        [-0.3296,  0.1686,  0.0175,  0.2313,  0.3607,  0.0225,  0.3562,  0.2067,
         -0.0276,  0.1141,  0.0730, -0.2804, -0.2320, -0.2133,  0.0705, -0.1221],
        [ 0.3037,  0.0470,  0.1274, -0.1470, -0.3282, -0.2822, -0.1335, -0.3658,
         -0.0398, -0.1114,  0.1119,  0.1437,  0.3551,  0.3230, -0.0467,  0.2622],
        [-0.2731,  0.1566, -0.3113,  0.2703, -0.0354,  0.1435,  0.3243,  0.3316,
          0.3805,  0.2390,  0.1472, -0.0917,  0.0440,  0.0521,  0.2025, -0.2271],
        [-0.2886,  0.0148, -0.0360,  0.0362,  0.2372,  0.3784,  0.3704,  0.0057,
          0.2540,  0.3267, -0.2305, -0.0151, -0.3141, -0.2793,  0.0750, -0.2460],
        [ 0.0631, -0.0136,  0.2456, -0.0688, -0.0369, -0.3115, -0.3876, -0.3931,
         -0.3261, -0.2677,  0.0946, -0.0133, -0.0335,  0.2289, -0.3384,  0.1968]],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0653, -0.0583,  0.1148, -0.0781, -0.0503, -0.0257,  0.0829,  0.1350,
        -0.0482, -0.0631,  0.0274,  0.0705,  0.1902,  0.1065, -0.0553,  0.0980,
        -0.1538, -0.0036,  0.0208, -0.0006, -0.0186, -0.1074, -0.0613, -0.0268,
        -0.1620,  0.2577,  0.1027,  0.0274, -0.0860, -0.2264,  0.1637, -0.0312],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2534,  0.3404, -0.2471, -0.2616,  0.3431,  0.3838, -0.2993, -0.3841,
         -0.3339,  0.3872,  0.2660,  0.3933, -0.2870, -0.4249,  0.3229, -0.3158,
         -0.3290,  0.3298, -0.2392, -0.2588,  0.4215,  0.3422, -0.3751, -0.3769,
         -0.3837, -0.3602, -0.3212,  0.3678, -0.3493,  0.3875,  0.2911, -0.2410]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0537,  0.1286,  0.0572,  ...,  0.2205, -0.3302, -0.1137],
        [-0.1226, -0.0297,  0.1170,  ...,  0.1554, -0.3303,  0.0871],
        [ 0.0124, -0.0594,  0.0186,  ...,  0.0278,  0.2331,  0.0345],
        ...,
        [-0.0045,  0.0344,  0.0578,  ...,  0.0851, -0.3199, -0.1180],
        [ 0.0990, -0.2294, -0.0534,  ..., -0.3284,  0.1528,  0.1557],
        [-0.2184,  0.1713,  0.0376,  ...,  0.0980, -0.2789, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0413,  0.0406, -0.0664, -0.1340, -0.0722,  0.0600, -0.1103,  0.0455,
        -0.0385,  0.0799,  0.0173,  0.0117,  0.0300,  0.0790, -0.0525, -0.0185,
         0.0585, -0.1552,  0.0024,  0.0282, -0.0500,  0.0326,  0.1092,  0.0058,
        -0.0936,  0.1045,  0.0472, -0.0943,  0.0537,  0.1393,  0.1671, -0.1230],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0772, -0.1816, -0.1166,  ..., -0.1311, -0.0162,  0.0747],
        [-0.2033, -0.0375,  0.0839,  ..., -0.0641,  0.0074,  0.0492],
        [ 0.1351, -0.0259, -0.1587,  ...,  0.0830, -0.0265,  0.1877],
        ...,
        [ 0.1153,  0.0946,  0.1213,  ...,  0.2528, -0.2250,  0.2458],
        [-0.0038, -0.1490,  0.0381,  ...,  0.0173,  0.2361, -0.1675],
        [-0.0009, -0.1345,  0.1982,  ...,  0.0358,  0.1637, -0.0505]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1030,  0.1473, -0.0584, -0.0832, -0.0005, -0.0437, -0.0576, -0.0441,
         0.1237, -0.1691,  0.1277, -0.1174,  0.1719,  0.0868, -0.1231,  0.1249,
        -0.1388, -0.1725, -0.0580, -0.0035, -0.0024,  0.0853, -0.2101,  0.2131,
        -0.0461, -0.0047,  0.0748, -0.0290, -0.1357, -0.0727,  0.1203,  0.0419],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4624,  0.3824, -0.4672, -0.4569,  0.3347,  0.3168, -0.3803,  0.3527,
          0.3818, -0.4046, -0.3513,  0.3679,  0.3513,  0.3310,  0.3951,  0.3898,
         -0.4582, -0.4713, -0.3256,  0.3713, -0.4158, -0.3942, -0.4681,  0.3145,
          0.4380,  0.4724, -0.4560,  0.4612, -0.3821, -0.4595,  0.4439,  0.4692]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2241], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-8.3719e-03,  3.5409e-01,  2.8648e-01, -3.0186e-01, -2.8021e-01,
         -1.3018e-01, -3.9767e-02, -4.4057e-01, -2.0312e-01, -3.8192e-02,
          1.5038e-01,  1.7763e-01,  4.5910e-02, -6.2760e-02, -1.7007e-01,
          3.4683e-01],
        [-2.4478e-01, -3.4530e-01, -8.6814e-02, -8.9883e-03,  3.3038e-02,
          2.3320e-01,  1.5639e-01,  1.9215e-01,  4.2464e-01,  1.2420e-01,
          7.6532e-02, -2.5658e-01,  1.5798e-03, -5.3688e-02,  4.5174e-01,
         -6.4247e-02],
        [ 7.0166e-02,  2.4241e-01,  3.5793e-01, -1.0215e-01, -1.3651e-01,
         -3.2796e-01, -3.0995e-02, -4.5453e-01,  1.3549e-02, -4.6745e-02,
         -8.9718e-02, -6.5711e-02,  3.9599e-01,  3.2449e-01, -4.8211e-02,
          2.4234e-01],
        [ 2.5708e-01,  6.8366e-02,  6.3289e-02, -6.5356e-02, -1.0661e-01,
         -1.7243e-01, -1.3512e-01, -1.2042e-01, -4.4084e-01, -3.8443e-01,
          2.2324e-02,  3.5090e-01,  2.9154e-01, -1.1198e-01, -2.8883e-01,
          1.2816e-01],
        [-9.6393e-02,  8.5692e-02, -1.5991e-01, -2.2090e-02,  2.4335e-01,
          7.5042e-02,  4.3118e-02,  3.7546e-01,  1.8736e-01,  2.9338e-01,
          9.4076e-02, -1.6564e-01, -6.5920e-02, -2.6358e-01,  4.0006e-01,
         -1.4631e-01],
        [-3.2920e-05,  1.2508e-01, -3.4794e-01,  4.0271e-01,  3.8644e-01,
         -4.0555e-02,  2.5169e-01, -2.9184e-03,  2.8003e-01,  2.0633e-01,
         -1.1342e-01, -8.6718e-02, -2.4729e-01,  1.1052e-01,  4.9094e-01,
         -6.6597e-02],
        [ 3.5728e-01,  1.2237e-01,  3.8736e-01, -1.7895e-01, -1.0714e-01,
         -1.9669e-01, -1.6351e-01, -2.6185e-01, -2.6409e-01, -1.3784e-02,
          2.6828e-04,  5.5577e-02, -6.6574e-02,  1.8508e-01, -3.5795e-01,
          1.3405e-01],
        [-7.6673e-02,  2.7408e-01,  3.3660e-01, -3.4726e-01, -3.6532e-01,
         -2.8514e-01, -7.1107e-02, -2.8123e-01, -2.1029e-01, -2.0806e-01,
         -7.3067e-02,  2.6317e-02,  2.4372e-01, -9.9122e-02, -1.3022e-01,
          3.3880e-01],
        [ 3.4655e-02,  3.1869e-01,  2.9367e-01, -2.5202e-01, -1.1102e-01,
         -3.3876e-01, -1.6310e-01, -1.4003e-01,  1.2420e-02, -3.1254e-01,
          5.0648e-03,  6.0390e-02, -5.3930e-02,  1.8632e-01, -4.3155e-01,
          8.6242e-02],
        [-2.9273e-01, -1.1206e-01, -9.4404e-02, -4.5561e-03,  1.4766e-01,
          1.5136e-01,  5.1970e-02,  2.8853e-01,  3.1049e-01,  2.0779e-03,
          1.3294e-01, -1.5992e-02, -2.8283e-01, -1.1294e-01,  2.8963e-01,
         -1.9638e-01],
        [-3.5610e-01,  4.5749e-02, -5.5769e-02, -2.8316e-02,  3.3565e-02,
          4.1945e-01,  2.3245e-01,  1.6961e-01,  3.9238e-01,  2.5242e-01,
         -3.5281e-03, -2.4840e-03, -2.1202e-01,  7.2019e-02,  1.0578e-01,
         -3.2332e-01],
        [-1.1702e-01, -1.5260e-01, -9.5551e-03,  9.1159e-02,  2.1113e-01,
          1.0673e-01,  3.5250e-01,  1.7904e-01,  1.8122e-01,  3.4174e-01,
          1.1121e-01,  6.8007e-02, -4.1449e-01, -2.4955e-01,  1.3402e-01,
         -1.8980e-01],
        [ 3.2918e-01,  2.4717e-01,  1.4780e-01, -1.6810e-01, -2.0411e-01,
          3.9323e-02, -8.3076e-02, -3.9146e-01, -3.7113e-01, -9.6483e-02,
         -1.0146e-01,  3.4063e-02, -2.1397e-02,  2.0427e-01, -3.9505e-01,
          1.8470e-02],
        [ 1.9951e-01,  3.3965e-01,  3.5208e-01, -1.2050e-02, -3.5082e-01,
         -1.0131e-02, -2.9620e-02, -9.5974e-02, -2.3581e-01, -1.5960e-01,
         -1.1325e-01,  1.0609e-01,  1.2180e-01,  6.3968e-02, -4.2348e-01,
          2.2533e-01],
        [-3.7036e-01, -3.0658e-01, -5.5191e-02, -4.0835e-02,  4.2654e-01,
          4.0259e-01,  9.3802e-02,  1.5721e-01, -1.0919e-03,  1.8077e-01,
          4.0093e-02, -3.1351e-01, -9.8401e-02, -1.3401e-01,  1.4506e-01,
         -1.5203e-01],
        [-3.0341e-01, -2.2738e-01,  1.2124e-02,  2.6037e-01,  1.4759e-01,
          1.7961e-01,  1.0403e-01,  8.2148e-02,  1.7255e-01,  1.3474e-01,
          4.7779e-02,  1.4252e-01, -1.5367e-01, -3.0214e-01,  5.9399e-01,
         -9.2508e-02],
        [ 2.9973e-01,  2.3939e-01,  1.8283e-01, -3.4789e-01, -3.8007e-01,
         -1.9306e-02, -8.0780e-02, -9.4841e-03, -3.8607e-01, -1.7629e-01,
          1.7289e-01,  2.7891e-01,  3.3844e-01,  2.7373e-01, -1.7496e-01,
         -4.6445e-02],
        [-2.7528e-01,  4.0652e-02, -2.2133e-01,  1.3044e-01,  1.4699e-01,
          2.7992e-01,  2.6174e-01,  2.7980e-01,  1.4390e-01,  2.7140e-01,
         -4.7417e-02, -2.2880e-01, -1.4795e-01, -1.9171e-01,  2.8869e-01,
         -1.5258e-01],
        [ 2.2101e-01,  1.1566e-01,  1.3454e-01, -2.7349e-01, -2.5000e-01,
         -3.6443e-01, -2.7084e-01, -5.7856e-03, -4.3397e-01, -9.7756e-02,
          1.9680e-02, -8.1965e-02,  1.9788e-01,  2.6031e-01, -5.7417e-02,
          1.7493e-01],
        [ 3.6546e-01,  1.4108e-01,  2.5563e-01, -9.1005e-02, -3.7704e-01,
         -2.2092e-01, -3.5118e-01, -1.0515e-02, -8.1107e-02, -2.6945e-01,
          8.5900e-02,  2.4820e-01, -4.2925e-02,  1.2821e-01, -9.9726e-02,
          1.8126e-01],
        [-1.6839e-01,  6.3605e-02, -2.9244e-02, -7.3513e-02,  3.0799e-01,
         -5.2452e-02,  2.9508e-01,  3.8414e-01,  1.9370e-01,  6.5200e-02,
         -8.8461e-02, -2.6469e-01, -2.0052e-01, -2.1338e-01,  4.5306e-01,
         -2.4150e-01],
        [-8.4618e-02, -3.3908e-01, -5.1892e-02,  3.9869e-01,  5.1272e-02,
          1.1838e-01,  2.6259e-01, -4.5846e-03,  7.4553e-02,  2.7745e-01,
          2.2980e-01, -2.8025e-01, -2.1725e-01, -3.9828e-01,  8.1175e-04,
          5.4005e-02],
        [ 3.6249e-01,  2.3168e-02,  4.5145e-02, -1.7000e-01, -4.5214e-02,
         -3.9216e-01, -2.9425e-01, -2.5883e-01, -2.8183e-01, -1.6081e-01,
          1.8594e-01,  2.1745e-01, -6.8300e-02,  3.3010e-01,  3.2106e-02,
          2.1251e-01],
        [ 2.3111e-01,  1.7853e-01,  3.1556e-01, -3.5685e-01, -2.1322e-01,
         -1.4060e-01, -1.5079e-01, -2.6940e-01, -3.5389e-01, -3.0445e-01,
          5.5791e-03,  3.2113e-01,  2.4995e-01,  1.1783e-01, -1.9740e-01,
         -3.0734e-03],
        [ 2.1498e-01, -9.5107e-02,  1.6959e-01, -1.3561e-01, -3.1579e-03,
         -2.4995e-01,  4.3210e-02, -2.1392e-01, -3.9718e-01,  4.7765e-02,
          1.9769e-01,  7.9181e-03,  6.9141e-02,  2.8279e-01, -4.2541e-01,
          3.4360e-01],
        [ 3.4760e-02,  4.0415e-02,  7.2910e-02,  8.2303e-02, -2.6459e-01,
         -2.0251e-01, -1.3502e-02, -3.6160e-01, -1.8563e-01, -3.4999e-01,
         -2.8010e-01,  1.0539e-01,  1.9539e-01,  3.4042e-01, -4.8465e-01,
          7.0447e-02],
        [ 2.0818e-01,  1.6692e-01,  2.8080e-01, -3.4555e-01, -2.0615e-01,
         -8.5660e-02, -3.4433e-01, -3.9934e-02, -3.9873e-01,  1.1657e-02,
          2.9733e-02,  8.0584e-02,  2.2333e-01,  2.8411e-01,  4.6895e-02,
          2.7673e-01],
        [-3.2218e-01, -5.2630e-02,  2.0778e-02,  2.1496e-01,  3.6724e-01,
          1.5785e-02,  3.6039e-01,  2.1153e-01, -2.3608e-02,  1.0841e-01,
          9.6941e-02, -2.7408e-01, -2.3405e-01, -2.2870e-01,  8.5130e-02,
         -1.1133e-01],
        [ 2.8739e-01,  1.5771e-01,  1.1633e-01, -1.2686e-01, -3.2141e-01,
         -2.6980e-01, -1.3029e-01, -3.5544e-01, -3.0424e-02, -9.9660e-02,
          9.2960e-02,  1.2991e-01,  3.4445e-01,  3.2564e-01, -3.7754e-02,
          2.4666e-01],
        [-2.6160e-01,  1.8496e-02, -3.0340e-01,  2.5226e-01, -3.6761e-02,
          1.3894e-01,  3.2401e-01,  3.2746e-01,  3.7517e-01,  2.3107e-01,
          1.5356e-01, -8.1826e-02,  4.2822e-02,  4.6837e-02,  2.1317e-01,
         -2.1505e-01],
        [-2.7389e-01, -1.6461e-01, -2.7545e-02,  1.6930e-02,  2.3261e-01,
          3.7007e-01,  3.6839e-01, -4.7496e-03,  2.4913e-01,  3.1596e-01,
         -2.1708e-01, -3.8948e-03, -3.0925e-01, -2.8093e-01,  6.3076e-02,
         -2.2932e-01],
        [ 4.2056e-02,  1.3677e-01,  2.3196e-01, -4.1393e-02, -3.3876e-02,
         -2.9846e-01, -3.8248e-01, -3.9160e-01, -3.2347e-01, -2.5210e-01,
          8.7634e-02, -2.8933e-02, -4.3319e-02,  2.2592e-01, -3.2413e-01,
          1.7437e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0903, -0.0279,  0.1118, -0.0823, -0.0451, -0.0228,  0.0826,  0.1324,
        -0.0593, -0.0436,  0.0116,  0.0937,  0.1566,  0.0874, -0.0335, -0.0500,
        -0.1794,  0.0033,  0.0073, -0.0156, -0.0118, -0.0842, -0.0732, -0.0408,
        -0.1358,  0.2594,  0.0825,  0.0469, -0.1047, -0.2240,  0.1869, -0.0476],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2577,  0.3423, -0.2501, -0.2693,  0.3696,  0.4025, -0.3049, -0.3837,
         -0.3500,  0.3961,  0.2763,  0.3940, -0.2989, -0.4311,  0.3239,  0.3084,
         -0.3301,  0.3346, -0.2429, -0.2616,  0.4291,  0.3409, -0.3791, -0.3779,
         -0.4154, -0.3713, -0.3227,  0.3712, -0.3531,  0.3914,  0.2955, -0.2467]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0153,  0.1011,  0.0773,  ...,  0.1582, -0.2610, -0.1137],
        [-0.1126, -0.0421,  0.1175,  ...,  0.1307, -0.3110,  0.0871],
        [-0.0036, -0.0380,  0.0318,  ...,  0.0274,  0.2304,  0.0345],
        ...,
        [ 0.0084,  0.0197,  0.0540,  ...,  0.0663, -0.3101, -0.1180],
        [ 0.0922, -0.2186, -0.0534,  ..., -0.3024,  0.1380,  0.1557],
        [-0.1963,  0.1607,  0.0395,  ...,  0.0654, -0.2695, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0469,  0.0412, -0.0707, -0.1353, -0.0728,  0.0513, -0.1112,  0.0503,
        -0.0404,  0.0782,  0.0236,  0.0118,  0.0250,  0.0747, -0.0518, -0.0202,
         0.0575, -0.1576, -0.0616,  0.0362, -0.0557,  0.0303,  0.1054,  0.0066,
        -0.0886,  0.0535,  0.0428, -0.1134,  0.0545,  0.1432,  0.1668, -0.1268],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0654, -0.1795, -0.1088,  ..., -0.1211, -0.0269,  0.0758],
        [-0.2134, -0.0355,  0.1042,  ..., -0.0504, -0.0104,  0.0491],
        [ 0.1390, -0.0300, -0.1652,  ...,  0.0664, -0.0092,  0.1819],
        ...,
        [ 0.1117,  0.0776,  0.1253,  ...,  0.2329, -0.2007,  0.2298],
        [-0.0092, -0.1480,  0.0497,  ...,  0.0376,  0.2170, -0.1664],
        [-0.0003, -0.1225,  0.1945,  ...,  0.0587,  0.1401, -0.0365]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1057,  0.1588, -0.0590, -0.0816, -0.0069, -0.0427, -0.0564, -0.0435,
         0.1333, -0.1767,  0.1148, -0.1300,  0.1912,  0.1024, -0.1270,  0.1327,
        -0.1372, -0.1713,  0.0433, -0.0123, -0.0049,  0.0877, -0.1987,  0.2347,
        -0.0443, -0.0081,  0.0776, -0.0281, -0.1340, -0.0678,  0.1266,  0.0352],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4821,  0.4074, -0.4840, -0.4611,  0.3461,  0.3494, -0.3942,  0.3607,
          0.3825, -0.4267, -0.3741,  0.3708,  0.3673,  0.3564,  0.4021,  0.4135,
         -0.4681, -0.4807,  0.3311,  0.3788, -0.4293, -0.4092, -0.4773,  0.3258,
          0.4535,  0.4808, -0.4631,  0.4723, -0.3938, -0.4677,  0.4581,  0.4735]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2321], device='cuda:0', requires_grad=True)

