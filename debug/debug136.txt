Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 6.0250e-03,  1.9893e-02,  3.1742e-01, -3.4504e-01, -2.0449e-01,
         -1.7393e-01, -4.9293e-02, -3.8067e-01, -1.9776e-01, -8.2258e-02,
         -8.1027e-02,  1.9674e-01,  7.1751e-02, -3.9991e-02, -7.9900e-02,
          3.8811e-01],
        [-2.5187e-01,  8.3306e-03, -1.0435e-01,  1.4464e-02,  1.0746e-04,
          2.5440e-01,  1.5553e-01,  1.6003e-01,  4.2033e-01,  1.4442e-01,
          3.0805e-01, -2.6473e-01, -1.3107e-02, -6.5562e-02,  3.8307e-01,
         -9.3322e-02],
        [ 8.2128e-02, -1.1522e-01,  3.8326e-01, -1.3072e-01, -8.0417e-02,
         -3.5498e-01, -3.5792e-02, -4.0568e-01,  1.3383e-02, -7.6125e-02,
         -1.8027e-01, -5.3929e-02,  4.1568e-01,  3.5052e-01,  2.7211e-02,
          2.7451e-01],
        [ 2.6921e-01, -2.7485e-01,  8.4086e-02, -9.2994e-02, -7.7977e-02,
         -2.0133e-01, -1.4190e-01, -9.2427e-02, -4.4065e-01, -4.1547e-01,
         -1.5884e-01,  3.6628e-01,  3.1440e-01, -9.3914e-02, -2.3546e-01,
          1.6649e-01],
        [-8.6863e-02,  4.2288e-01, -1.6497e-01, -1.0757e-02,  1.7066e-01,
          8.2387e-02,  1.6891e-02,  3.0630e-01,  1.5507e-01,  2.9976e-01,
          3.4200e-01, -1.5481e-01, -5.1270e-02, -2.5196e-01,  2.8933e-01,
         -1.6329e-01],
        [ 5.0249e-03,  4.3988e-01, -3.5204e-01,  4.1280e-01,  3.3611e-01,
         -3.1383e-02,  2.3216e-01, -4.7062e-02,  2.5709e-01,  2.1215e-01,
         -8.3317e-02, -7.9293e-02, -2.4948e-01,  1.2249e-01,  3.8494e-01,
         -7.9296e-02],
        [ 3.6797e-01, -9.7826e-02,  4.0786e-01, -2.0409e-01, -8.5472e-02,
         -2.1895e-01, -1.6744e-01, -2.3719e-01, -2.7937e-01, -3.7243e-02,
         -7.9831e-02,  6.8382e-02, -3.7367e-02,  2.5284e-01, -3.5615e-01,
          1.6422e-01],
        [-6.1988e-02,  6.0834e-02,  3.5804e-01, -3.7317e-01, -3.6460e-01,
         -3.0768e-01, -7.5809e-02, -2.6687e-01, -2.2180e-01, -2.2949e-01,
         -1.2593e-01,  4.2023e-02,  2.8148e-01, -6.3095e-02, -1.3615e-01,
          3.6633e-01],
        [ 3.5438e-02, -3.6279e-02,  3.0464e-01, -2.6771e-01, -7.4012e-02,
         -3.5312e-01, -1.5485e-01, -1.0375e-01,  2.2022e-02, -3.2521e-01,
         -2.8940e-01,  5.9776e-02, -4.7251e-02,  1.9114e-01, -3.6469e-01,
          1.1057e-01],
        [-2.8404e-01,  2.4043e-01, -9.7609e-02,  6.2508e-03,  8.8833e-02,
          1.5949e-01,  3.0432e-02,  2.3189e-01,  2.8730e-01,  7.6254e-03,
          3.6234e-01, -6.5023e-03, -2.7499e-01, -1.0232e-01,  1.8635e-01,
         -2.1012e-01],
        [-3.5449e-01,  4.2478e-01, -6.5375e-02, -1.4126e-02, -2.2399e-02,
          4.3333e-01,  2.2790e-01,  1.2524e-01,  3.7202e-01,  2.6832e-01,
          1.9914e-01,  8.9052e-04, -1.9852e-01,  8.7499e-02,  3.8229e-03,
         -3.4619e-01],
        [-1.2177e-01,  1.6536e-01, -2.2831e-02,  1.0835e-01,  1.8547e-01,
          1.2258e-01,  3.4679e-01,  1.4623e-01,  1.8553e-01,  3.5892e-01,
          3.2587e-01,  6.3241e-02, -4.3032e-01, -2.7192e-01,  8.6155e-02,
         -2.2037e-01],
        [ 3.4106e-01, -1.4196e-01,  1.7709e-01, -2.0598e-01, -1.3897e-01,
          5.8094e-03, -7.9570e-02, -3.3071e-01, -3.5197e-01, -1.3025e-01,
         -1.8042e-01,  4.8448e-02, -3.3199e-02,  1.9606e-01, -2.7011e-01,
          5.6348e-02],
        [ 2.0692e-01,  3.9778e-02,  3.6890e-01, -3.1495e-02, -3.3197e-01,
         -2.6284e-02, -2.7349e-02, -7.1992e-02, -2.3657e-01, -1.7636e-01,
         -2.9681e-01,  1.1305e-01,  1.3910e-01,  9.0916e-02, -3.8541e-01,
          2.5242e-01],
        [-3.7808e-01,  3.6319e-02, -7.2415e-02, -2.0106e-02,  3.9614e-01,
          4.2317e-01,  9.1111e-02,  1.2644e-01, -3.7558e-03,  1.9998e-01,
          2.0655e-01, -3.2109e-01, -1.1405e-01, -1.4717e-01,  7.9768e-02,
         -1.7892e-01],
        [-5.3734e-02, -4.2258e-01,  2.2249e-01,  3.1028e-02, -3.4049e-01,
         -4.4666e-02, -1.7329e-01, -3.0419e-01, -2.2322e-01, -8.6715e-02,
         -1.6007e-01,  4.2598e-01,  1.8143e-01, -8.4513e-03,  4.0520e-02,
          1.2025e-01],
        [ 3.1720e-01, -2.5020e-02,  2.0439e-01, -3.7803e-01, -3.8666e-01,
         -5.0269e-02, -9.0001e-02, -8.1820e-03, -3.9517e-01, -2.0566e-01,
          8.7537e-02,  3.0064e-01,  3.8577e-01,  3.1935e-01, -1.9235e-01,
         -6.8349e-03],
        [-2.9550e-01,  1.7413e-01, -2.4861e-01,  1.6408e-01,  1.6058e-01,
          3.0927e-01,  2.7276e-01,  2.7299e-01,  1.6455e-01,  3.0196e-01,
          2.5403e-02, -2.5454e-01, -1.9999e-01, -2.5183e-01,  3.1990e-01,
         -1.9021e-01],
        [ 2.2997e-01, -2.1660e-01,  1.5453e-01, -2.9932e-01, -2.0220e-01,
         -3.8799e-01, -2.7634e-01,  3.9783e-02, -4.2944e-01, -1.2550e-01,
         -1.5188e-01, -7.1577e-02,  2.2445e-01,  3.0356e-01, -1.0654e-02,
          2.1133e-01],
        [ 3.7543e-01, -2.1036e-01,  2.7669e-01, -1.1575e-01, -3.4637e-01,
         -2.4365e-01, -3.5237e-01,  2.0091e-02, -7.6466e-02, -2.9629e-01,
         -1.6427e-01,  2.5794e-01, -2.9093e-02,  1.5005e-01, -4.0047e-02,
          2.1873e-01],
        [-1.7474e-01,  3.4244e-01, -4.6048e-02, -5.3534e-02,  2.8180e-01,
         -3.6491e-02,  2.8792e-01,  3.5482e-01,  1.8792e-01,  8.0914e-02,
          3.3694e-03, -2.7207e-01, -2.1767e-01, -2.2233e-01,  3.7803e-01,
         -2.6484e-01],
        [-6.6120e-02, -9.2259e-03, -4.4108e-02,  4.0050e-01, -1.5497e-02,
          1.1776e-01,  2.3046e-01, -6.7760e-02,  3.6880e-02,  2.7161e-01,
          4.2237e-01, -2.5714e-01, -2.0246e-01, -3.8434e-01, -8.2161e-02,
          4.4698e-02],
        [ 3.6722e-01, -2.6350e-01,  5.8566e-02, -1.8738e-01, -2.3713e-02,
         -4.0580e-01, -2.8985e-01, -2.3074e-01, -2.7809e-01, -1.7461e-01,
          4.2725e-02,  2.1949e-01, -5.2158e-02,  3.5402e-01,  6.5819e-02,
          2.3888e-01],
        [ 2.6094e-01,  7.1264e-02,  3.4740e-01, -3.9872e-01, -2.6896e-01,
         -1.8029e-01, -1.7201e-01, -2.8805e-01, -3.8663e-01, -3.4449e-01,
         -1.0006e-01,  3.6036e-01,  3.1963e-01,  1.6999e-01, -2.4289e-01,
          4.4852e-02],
        [ 2.0669e-01, -4.6997e-01,  1.7179e-01, -1.4774e-01,  4.7986e-02,
         -2.6244e-01,  5.6838e-02, -1.6994e-01, -3.8266e-01,  3.9499e-02,
          4.8187e-02, -1.2749e-03,  6.8049e-02,  2.6857e-01, -3.2432e-01,
          3.5516e-01],
        [ 4.0443e-02, -2.6957e-01,  9.0861e-02,  6.1625e-02, -2.2977e-01,
         -2.1696e-01, -8.7362e-03, -3.2458e-01, -1.7622e-01, -3.6626e-01,
         -3.7366e-01,  1.1107e-01,  1.9606e-01,  3.3791e-01, -3.8517e-01,
          9.3961e-02],
        [ 2.2270e-01, -7.9081e-02,  3.0514e-01, -3.7308e-01, -1.9940e-01,
         -1.0653e-01, -3.5023e-01, -2.2398e-02, -4.0856e-01, -1.3384e-02,
         -7.3440e-02,  9.4672e-02,  2.5377e-01,  3.3372e-01,  5.5282e-02,
          3.1438e-01],
        [-3.1325e-01,  2.8566e-01,  1.8535e-02,  2.2436e-01,  3.1593e-01,
          2.2327e-02,  3.4081e-01,  1.5752e-01, -3.9201e-02,  1.1435e-01,
          3.2489e-01, -2.6608e-01, -2.3164e-01, -2.3461e-01,  1.1261e-02,
         -1.2935e-01],
        [ 3.0618e-01, -1.0527e-01,  1.4224e-01, -1.5602e-01, -3.2614e-01,
         -2.9836e-01, -1.3758e-01, -3.4815e-01, -4.6584e-02, -1.2914e-01,
         -6.6979e-02,  1.5101e-01,  3.6219e-01,  3.4970e-01, -1.5955e-02,
          2.8591e-01],
        [-2.7016e-01,  2.3480e-01, -3.2033e-01,  2.7305e-01, -5.1029e-02,
          1.5289e-01,  3.2124e-01,  3.0250e-01,  3.7903e-01,  2.4786e-01,
          2.6697e-01, -8.8919e-02,  1.8554e-02,  1.8482e-02,  1.8211e-01,
         -2.4030e-01],
        [-2.8775e-01,  1.4650e-01, -4.9240e-02,  4.3340e-02,  2.1806e-01,
          3.9544e-01,  3.7439e-01, -2.2503e-02,  2.5324e-01,  3.4182e-01,
         -1.0583e-01, -1.8020e-02, -3.3842e-01, -3.1280e-01,  4.1299e-02,
         -2.6698e-01],
        [ 6.5212e-02, -1.3499e-01,  2.6662e-01, -7.9709e-02, -6.1119e-03,
         -3.3304e-01, -4.0103e-01, -3.6266e-01, -3.3837e-01, -2.9320e-01,
         -7.4960e-02, -1.8615e-03,  2.0238e-04,  3.0258e-01, -3.3380e-01,
          2.2293e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0573,  0.0379, -0.0090, -0.0827,  0.0244, -0.0493,  0.0282,  0.0573,
        -0.0440,  0.0412,  0.0875,  0.0920,  0.0630,  0.0403,  0.0943, -0.0552,
        -0.0482,  0.0022,  0.0102, -0.0267, -0.0408, -0.0562, -0.0447,  0.0081,
        -0.1094,  0.0927,  0.1195,  0.0496, -0.0912, -0.1034,  0.0528, -0.0132],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1927,  0.2752, -0.2023, -0.2186,  0.2798,  0.3309, -0.2530, -0.3440,
         -0.2786,  0.2871,  0.2265,  0.3439, -0.2188, -0.3625,  0.2677, -0.2189,
         -0.2853,  0.2942, -0.2020, -0.2147,  0.3674,  0.2630, -0.3374, -0.3442,
         -0.2462, -0.3047, -0.2884,  0.3176, -0.3137,  0.3483,  0.2590, -0.2004]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0020,  0.1009,  0.0869,  ...,  0.1889, -0.3033, -0.1137],
        [-0.0755, -0.0844,  0.1270,  ...,  0.1017, -0.2959,  0.0871],
        [-0.0409,  0.0062,  0.0449,  ...,  0.0506,  0.2118,  0.0345],
        ...,
        [ 0.0871, -0.1162,  0.0104,  ..., -0.1243, -0.0591, -0.1180],
        [ 0.0466, -0.1685, -0.0601,  ..., -0.2625,  0.1060,  0.1557],
        [-0.1723,  0.1134,  0.0418,  ...,  0.0505, -0.2301, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0553,  0.0364, -0.0541, -0.1401, -0.0793,  0.0553, -0.1097,  0.0322,
        -0.0600,  0.0558,  0.0171,  0.0190,  0.0739,  0.0890, -0.0584,  0.0107,
         0.0388, -0.1521,  0.0047, -0.0244, -0.0785,  0.0229,  0.1044,  0.0178,
        -0.1150,  0.1088,  0.0524, -0.0753,  0.0418,  0.1958,  0.1705, -0.1252],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0408, -0.1703, -0.1032,  ...,  0.0138, -0.0409,  0.0645],
        [-0.2263, -0.0161,  0.0886,  ...,  0.1192, -0.0284,  0.0516],
        [ 0.1493, -0.0505, -0.1697,  ..., -0.1354,  0.0062,  0.1793],
        ...,
        [ 0.1533,  0.0787,  0.1187,  ...,  0.1188, -0.1935,  0.2548],
        [-0.0250, -0.1357,  0.0650,  ...,  0.2330,  0.2116, -0.1695],
        [-0.0175, -0.1085,  0.1981,  ...,  0.1856,  0.1237, -0.0381]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0970,  0.1440, -0.0540, -0.0888,  0.0164, -0.0223, -0.0550, -0.0212,
         0.1090, -0.1643,  0.1483, -0.0975,  0.1864,  0.0669, -0.1135,  0.1200,
        -0.1264, -0.1671,  0.0723,  0.0203, -0.0168,  0.0868, -0.2282,  0.2330,
        -0.0436, -0.0289,  0.0625, -0.0292, -0.1423, -0.0612,  0.1275,  0.0174],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3423,  0.2537, -0.3026, -0.3255,  0.1805,  0.1802, -0.2370,  0.2050,
          0.2528, -0.2557, -0.2208,  0.2192,  0.2218,  0.1943,  0.2600,  0.2185,
         -0.3330, -0.3436,  0.1936,  0.2217, -0.2810, -0.2445, -0.3163,  0.1840,
          0.3053,  0.3430, -0.3141,  0.3290, -0.2477, -0.3333,  0.2936,  0.3294]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1171], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-0.0113,  0.4016,  0.3036, -0.3300, -0.1713, -0.1433, -0.0332, -0.3563,
         -0.1861, -0.0632, -0.0347,  0.1648, -0.2827, -0.0715,  0.0400,  0.3702],
        [-0.2432, -0.3969, -0.0998, -0.0047, -0.0397,  0.2384,  0.1358,  0.1339,
          0.3774,  0.1279,  0.3055, -0.2364,  0.3447, -0.0307,  0.2790, -0.0829],
        [ 0.0775,  0.2973,  0.3818, -0.1284, -0.0724, -0.3326, -0.0455, -0.4021,
          0.0125, -0.0689, -0.1586, -0.0754,  0.0504,  0.3388,  0.0619,  0.2675],
        [ 0.2786,  0.1289,  0.0969, -0.0962, -0.0534, -0.2044, -0.1449, -0.0892,
         -0.4150, -0.4189, -0.2265,  0.3568, -0.0591, -0.1121, -0.1458,  0.1717],
        [-0.0872,  0.0286, -0.1686, -0.0205,  0.1458,  0.0750,  0.0147,  0.2937,
          0.1254,  0.2912,  0.3515, -0.1349,  0.3020, -0.2289,  0.2257, -0.1623],
        [-0.0059,  0.0596, -0.3656,  0.4136,  0.3299, -0.0258,  0.2455, -0.0418,
          0.2466,  0.2153, -0.0775, -0.0732,  0.0988,  0.1307,  0.3457, -0.0881],
        [ 0.3648,  0.2576,  0.4094, -0.1926, -0.0498, -0.2057, -0.1632, -0.2186,
         -0.2445, -0.0267, -0.0565,  0.0450, -0.3453,  0.2125, -0.2396,  0.1580],
        [-0.0619,  0.3705,  0.3625, -0.3656, -0.3361, -0.2962, -0.0810, -0.2533,
         -0.1947, -0.2213, -0.1012,  0.0201, -0.0251, -0.0929, -0.0658,  0.3652],
        [ 0.0253,  0.3600,  0.2992, -0.2454, -0.0355, -0.3409, -0.1255, -0.0800,
          0.0656, -0.3094, -0.2872,  0.0340, -0.4006,  0.1562, -0.2268,  0.0974],
        [-0.2853, -0.1653, -0.1020, -0.0043,  0.0635,  0.1528,  0.0323,  0.2200,
          0.2550, -0.0008,  0.3613,  0.0123,  0.0896, -0.0803,  0.1221, -0.2102],
        [-0.3598,  0.0095, -0.0738, -0.0167, -0.0505,  0.4296,  0.2267,  0.1143,
          0.3472,  0.2662,  0.2310,  0.0160,  0.1726,  0.1056, -0.0493, -0.3491],
        [-0.1283, -0.2035, -0.0319,  0.0974,  0.1680,  0.1272,  0.3494,  0.1434,
          0.1561,  0.3574,  0.4077,  0.0720, -0.0795, -0.2559, -0.0343, -0.2214],
        [ 0.3269,  0.2998,  0.1661, -0.1781, -0.0855,  0.0345, -0.0523, -0.2917,
         -0.2999, -0.1037, -0.1841,  0.0071, -0.4134,  0.1559, -0.1768,  0.0413],
        [ 0.2036,  0.4067,  0.3694, -0.0152, -0.3003, -0.0185, -0.0137, -0.0566,
         -0.1999, -0.1661, -0.2858,  0.0930, -0.1861,  0.0584, -0.2665,  0.2454],
        [-0.3730, -0.3616, -0.0726, -0.0290,  0.3579,  0.4003,  0.0873,  0.0994,
         -0.0375,  0.1876,  0.1996, -0.2902,  0.2366, -0.1155,  0.0104, -0.1740],
        [-0.0885,  0.0056,  0.1924,  0.0686, -0.3020,  0.0034, -0.1472, -0.2595,
         -0.1713, -0.0490, -0.1411,  0.3712, -0.2198, -0.0479,  0.1255,  0.0865],
        [ 0.3222,  0.3344,  0.2130, -0.3688, -0.3682, -0.0527, -0.0885, -0.0063,
         -0.3672, -0.2036,  0.0637,  0.2900,  0.0513,  0.2995, -0.0745, -0.0066],
        [-0.3010, -0.0753, -0.2578,  0.1593,  0.1398,  0.3056,  0.2837,  0.2689,
          0.1418,  0.2986,  0.0255, -0.2385,  0.1027, -0.2283,  0.2457, -0.1926],
        [ 0.2141,  0.1614,  0.1404, -0.2863, -0.1946, -0.3610, -0.2785,  0.0474,
         -0.4282, -0.1078, -0.1236, -0.0977, -0.1178,  0.2909,  0.0266,  0.1929],
        [ 0.3721,  0.1905,  0.2784, -0.1046, -0.3050, -0.2327, -0.3353,  0.0423,
         -0.0375, -0.2872, -0.1844,  0.2327, -0.3891,  0.1161,  0.0935,  0.2117],
        [-0.1834, -0.0064, -0.0574, -0.0557,  0.2719, -0.0330,  0.2937,  0.3569,
          0.1779,  0.0818,  0.0154, -0.2638,  0.1087, -0.2080,  0.3278, -0.2708],
        [-0.0635, -0.4045, -0.0454,  0.3869, -0.0451,  0.1055,  0.2256, -0.0832,
          0.0044,  0.2596,  0.3956, -0.2335,  0.1557, -0.3544, -0.1495,  0.0478],
        [ 0.3660,  0.0888,  0.0614, -0.1776,  0.0089, -0.3934, -0.2859, -0.2125,
         -0.2480, -0.1656,  0.0453,  0.1950, -0.3774,  0.3225,  0.1451,  0.2363],
        [ 0.2647,  0.2489,  0.3554, -0.3884, -0.2432, -0.1769, -0.1714, -0.2812,
         -0.3531, -0.3403, -0.1546,  0.3400,  0.0212,  0.1466, -0.1458,  0.0443],
        [ 0.2027, -0.0442,  0.1714, -0.1323,  0.0747, -0.2540,  0.0661, -0.1561,
         -0.3470,  0.0513,  0.0462, -0.0222, -0.3197,  0.2451, -0.2472,  0.3503],
        [ 0.0439,  0.0952,  0.0972,  0.0652, -0.2104, -0.2047, -0.0121, -0.3136,
         -0.1596, -0.3604, -0.3721,  0.0902, -0.1314,  0.3197, -0.3405,  0.0975],
        [ 0.2256,  0.2616,  0.3116, -0.3633, -0.1749, -0.1044, -0.3450, -0.0154,
         -0.3812, -0.0088, -0.0661,  0.0799, -0.0704,  0.3074,  0.1645,  0.3130],
        [-0.3164, -0.1038,  0.0123,  0.2141,  0.2930,  0.0210,  0.3426,  0.1480,
         -0.0694,  0.1092,  0.3803, -0.2507,  0.1204, -0.2141, -0.0835, -0.1288],
        [ 0.3119,  0.2008,  0.1514, -0.1498, -0.3011, -0.2950, -0.1392, -0.3385,
         -0.0189, -0.1268, -0.1121,  0.1338,  0.0467,  0.3310,  0.0599,  0.2884],
        [-0.2698, -0.0544, -0.3238,  0.2632, -0.0805,  0.1440,  0.3227,  0.2887,
          0.3494,  0.2394,  0.2397, -0.0670,  0.3158,  0.0523,  0.0932, -0.2376],
        [-0.2939, -0.2399, -0.0590,  0.0388,  0.1963,  0.3955,  0.3740, -0.0276,
          0.2284,  0.3406, -0.0804, -0.0062,  0.0127, -0.2942, -0.0422, -0.2696],
        [ 0.0481,  0.2476,  0.2536, -0.0618,  0.0133, -0.3086, -0.3879, -0.3467,
         -0.3199, -0.2742, -0.0541, -0.0326, -0.3420,  0.2827, -0.1987,  0.2004]],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0612, -0.0157,  0.0072, -0.0419,  0.0178, -0.2335,  0.1026,  0.1335,
        -0.0449, -0.0042,  0.0461,  0.0771,  0.1368,  0.0825,  0.0541, -0.0169,
        -0.0166, -0.0381,  0.0919, -0.0169, -0.0899, -0.1002, -0.0300,  0.0410,
        -0.0697,  0.1353,  0.1717,  0.0385, -0.0915, -0.1839,  0.0237,  0.0173],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1770,  0.2702, -0.1861, -0.2156,  0.2535,  0.2913, -0.2495, -0.3447,
         -0.2901,  0.2841,  0.2203,  0.3326, -0.2189, -0.3630,  0.2518, -0.1225,
         -0.2801,  0.3001, -0.1832, -0.2079,  0.3414,  0.2779, -0.3379, -0.3483,
         -0.2109, -0.2817, -0.2874,  0.3008, -0.3172,  0.3506,  0.2615, -0.1981]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0067,  0.0763,  0.0807,  ...,  0.1863, -0.2953, -0.1137],
        [-0.0871, -0.0686,  0.1206,  ...,  0.1029, -0.2746,  0.0871],
        [-0.1035,  0.1097,  0.1041,  ...,  0.1824,  0.0704,  0.0345],
        ...,
        [ 0.1202, -0.1402, -0.0330,  ..., -0.1787, -0.0424, -0.1180],
        [ 0.0521, -0.1751, -0.0450,  ..., -0.2594,  0.0801,  0.1557],
        [-0.2017,  0.1290,  0.0587,  ...,  0.0652, -0.2247, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0470,  0.0362, -0.1024, -0.1522, -0.0785,  0.0177, -0.1054,  0.0365,
        -0.0295,  0.0592,  0.0237,  0.0026, -0.0024,  0.0987, -0.0500, -0.0063,
         0.0434, -0.1647, -0.0008,  0.0764, -0.0601,  0.0217,  0.1097,  0.0167,
        -0.1120,  0.0975,  0.0435, -0.0889,  0.0407,  0.1912,  0.1662, -0.1289],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0554, -0.1612, -0.1854,  ...,  0.0349, -0.0483,  0.0647],
        [-0.2165, -0.0091, -0.0207,  ...,  0.1343, -0.0344,  0.0488],
        [ 0.1428, -0.0580, -0.0422,  ..., -0.1354,  0.0108,  0.1822],
        ...,
        [ 0.1296,  0.0661,  0.1900,  ...,  0.0933, -0.1801,  0.2486],
        [-0.0175, -0.1215, -0.0573,  ...,  0.2240,  0.2022, -0.1680],
        [-0.0061, -0.1007,  0.1197,  ...,  0.2134,  0.1194, -0.0439]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0998,  0.1436, -0.0418, -0.0900, -0.1127, -0.1684, -0.0516, -0.0390,
         0.1289, -0.1562,  0.1211, -0.1228,  0.1870,  0.0773, -0.1225,  0.1062,
        -0.1399, -0.1698,  0.0680,  0.0054, -0.0062,  0.0929, -0.2054,  0.2058,
        -0.0517, -0.0061,  0.0778, -0.0354, -0.1366, -0.0677,  0.1107,  0.0229],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3173,  0.2380, -0.2727, -0.3063, -0.1522, -0.1487, -0.2215,  0.1744,
          0.2225, -0.2377, -0.1846,  0.2013,  0.2112,  0.1693,  0.2234,  0.2056,
         -0.3107, -0.3164,  0.1552,  0.1937, -0.2583, -0.2105, -0.3126,  0.1679,
          0.2746,  0.3342, -0.2877,  0.2997, -0.2204, -0.3143,  0.2742,  0.3184]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0840], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 7.6454e-03,  4.0238e-01,  3.2108e-01, -3.4134e-01,  1.4992e-02,
         -1.7281e-01, -4.8216e-02, -3.4981e-01, -1.4857e-01, -8.3864e-02,
          1.1618e-02,  1.3800e-01, -5.2801e-03, -7.8459e-02,  2.9917e-01,
          3.7730e-01],
        [-2.6270e-01, -3.8032e-01, -1.1788e-01,  8.0871e-05, -2.1165e-01,
          2.7048e-01,  1.6160e-01,  1.2024e-01,  3.6273e-01,  1.2628e-01,
          2.4041e-01, -2.2825e-01,  7.2088e-02, -1.5589e-02,  2.9647e-02,
         -9.0068e-02],
        [ 1.0035e-01,  2.9416e-01,  4.0482e-01, -1.4062e-01,  1.8060e-01,
         -3.7474e-01, -5.0503e-02, -3.7784e-01,  7.6301e-02, -8.6886e-02,
         -1.1714e-01, -9.1555e-02,  3.3911e-01,  2.9408e-01,  4.2278e-01,
          2.8120e-01],
        [ 2.9334e-01,  1.1695e-01,  1.1088e-01, -9.3590e-02,  1.4690e-01,
         -2.3095e-01, -1.5881e-01, -5.8112e-02, -3.8572e-01, -4.0938e-01,
         -1.3260e-01,  3.3274e-01,  2.2628e-01, -1.3881e-01,  1.3183e-01,
          1.7884e-01],
        [-9.1949e-02,  6.1244e-02, -1.7202e-01, -2.8222e-02, -3.1880e-02,
          9.5760e-02,  2.4073e-02,  2.6684e-01,  9.8113e-02,  2.7767e-01,
          2.7265e-01, -1.1405e-01,  3.8233e-02, -1.9549e-01, -3.9417e-02,
         -1.4801e-01],
        [-7.8787e-03,  9.5284e-02, -3.6683e-01,  3.9896e-01,  9.3017e-02,
         -1.2261e-02,  2.4798e-01, -8.8210e-02,  2.0528e-01,  1.9823e-01,
         -1.1150e-01, -3.6486e-02, -1.7171e-01,  1.5405e-01,  6.2139e-02,
         -8.0308e-02],
        [ 3.8941e-01,  2.4126e-01,  4.3056e-01, -1.9890e-01,  1.6685e-01,
         -2.4543e-01, -1.9410e-01, -2.0243e-01, -2.2552e-01, -2.7338e-02,
         -3.6791e-02,  3.4652e-02, -8.7511e-02,  2.1020e-01, -2.8109e-02,
          1.7194e-01],
        [-4.5389e-02,  3.4944e-01,  3.7558e-01, -3.6199e-01, -1.1809e-01,
         -3.2971e-01, -9.7866e-02, -2.1798e-01, -1.6066e-01, -2.1623e-01,
         -8.5430e-02, -2.6416e-03,  2.1310e-01, -9.8664e-02,  1.5196e-01,
          3.7381e-01],
        [ 4.1535e-02,  3.3960e-01,  3.1398e-01, -2.5248e-01,  7.6451e-02,
         -3.6642e-01, -1.5644e-01, -7.4588e-02,  7.6122e-02, -3.0276e-01,
         -1.2895e-01,  3.5758e-02, -1.4423e-01,  1.1119e-01, -2.0102e-02,
          9.7348e-02],
        [-2.8826e-01, -1.3238e-01, -1.0400e-01, -1.5095e-02, -1.1198e-01,
          1.6948e-01,  3.3650e-02,  1.9121e-01,  2.2526e-01, -1.7591e-02,
          2.6961e-01,  3.1990e-02, -1.8263e-01, -3.9757e-02, -1.5183e-01,
         -1.9659e-01],
        [-3.6833e-01,  2.6601e-02, -8.1395e-02, -2.7037e-02, -2.1768e-01,
          4.5369e-01,  2.3062e-01,  8.6810e-02,  3.1639e-01,  2.5240e-01,
          9.1419e-02,  3.7071e-02, -1.0419e-01,  1.5090e-01, -3.7651e-01,
         -3.4631e-01],
        [-1.3820e-01, -1.8654e-01, -3.9967e-02,  9.8920e-02,  6.4021e-02,
          1.4505e-01,  3.6778e-01,  1.2612e-01,  1.4249e-01,  3.4311e-01,
          1.8310e-01,  8.2033e-02, -3.4055e-01, -1.8763e-01, -2.3799e-01,
         -2.1258e-01],
        [ 3.4708e-01,  2.8478e-01,  1.8721e-01, -1.8373e-01,  1.3963e-01,
         -4.4738e-03, -7.4449e-02, -2.6497e-01, -2.8534e-01, -1.0986e-01,
         -1.4538e-01, -2.1921e-02, -1.1510e-01,  1.5758e-01,  1.3312e-01,
          4.7781e-02],
        [ 2.2308e-01,  3.8947e-01,  3.8656e-01, -2.0285e-02, -1.3137e-01,
         -4.7790e-02, -4.6665e-02, -4.2512e-02, -1.8647e-01, -1.6276e-01,
         -2.3134e-01,  8.6126e-02,  6.6696e-02,  4.3463e-02, -6.4250e-02,
          2.5372e-01],
        [-3.9107e-01, -3.4388e-01, -8.8566e-02, -3.1493e-02,  1.6333e-01,
          4.4040e-01,  1.0350e-01,  8.4648e-02, -6.2481e-02,  1.8422e-01,
          1.4711e-01, -2.8259e-01, -2.9476e-02, -9.8388e-02, -2.6670e-01,
         -1.8053e-01],
        [-1.1944e-01, -8.2886e-02,  1.5938e-01,  1.2430e-01, -9.9678e-02,
          2.0753e-02, -1.0358e-01, -1.8721e-01, -8.0120e-02,  9.2029e-03,
         -3.5021e-02,  3.2121e-01,  1.2283e-02, -1.2885e-01,  3.5110e-01,
          3.9381e-02],
        [ 3.3373e-01,  3.1405e-01,  2.2272e-01, -3.6855e-01, -1.6653e-01,
         -7.1281e-02, -1.1074e-01,  3.1322e-02, -3.3882e-01, -1.9266e-01,
          1.1712e-01,  2.6054e-01,  3.0051e-01,  2.7667e-01,  1.1888e-01,
         -3.0737e-03],
        [-3.1961e-01, -5.9726e-02, -2.7258e-01,  1.5939e-01, -4.8671e-02,
          3.4032e-01,  3.0487e-01,  2.4814e-01,  1.2028e-01,  2.9399e-01,
         -1.5099e-02, -2.2508e-01, -1.2760e-01, -2.1664e-01,  4.5959e-02,
         -2.0137e-01],
        [ 2.5595e-01,  1.7493e-01,  1.8264e-01, -3.1723e-01,  2.4677e-02,
         -4.1699e-01, -2.9938e-01,  5.5027e-02, -3.7413e-01, -1.4402e-01,
         -6.2713e-02, -1.0186e-01,  1.4799e-01,  2.4529e-01,  3.6511e-01,
          2.2488e-01],
        [ 3.9074e-01,  1.7974e-01,  2.9510e-01, -1.0757e-01, -1.3904e-01,
         -2.6620e-01, -3.6227e-01,  5.7728e-02, -1.9160e-02, -2.8236e-01,
         -8.5521e-02,  2.2277e-01, -1.2527e-01,  8.8852e-02,  3.1839e-01,
          2.2046e-01],
        [-1.8744e-01,  2.7198e-02, -6.0406e-02, -6.5154e-02,  7.8431e-02,
         -1.5252e-02,  3.0346e-01,  3.2805e-01,  1.4522e-01,  6.7481e-02,
         -3.8730e-02, -2.4095e-01, -1.2981e-01, -1.8664e-01,  7.5084e-02,
         -2.6405e-01],
        [-7.1289e-02, -3.7562e-01, -5.2134e-02,  3.7959e-01, -1.9329e-01,
          1.2847e-01,  2.3142e-01, -1.0282e-01, -2.1700e-02,  2.4686e-01,
          2.6839e-01, -2.2270e-01, -9.7034e-02, -3.1360e-01, -4.2383e-01,
          5.5394e-02],
        [ 3.7904e-01,  6.7916e-02,  7.1699e-02, -1.7167e-01,  1.9001e-01,
         -4.2411e-01, -3.0096e-01, -1.8699e-01, -2.1783e-01, -1.5672e-01,
          1.0113e-01,  1.7995e-01, -1.4783e-01,  3.0017e-01,  3.7366e-01,
          2.3862e-01],
        [ 2.8377e-01,  2.3702e-01,  3.7038e-01, -3.9055e-01, -6.1304e-02,
         -2.0896e-01, -2.0204e-01, -2.5082e-01, -3.3724e-01, -3.3588e-01,
         -1.2021e-01,  3.2054e-01,  2.2567e-01,  1.4199e-01,  9.2679e-03,
          5.7178e-02],
        [ 2.0538e-01, -8.1549e-02,  1.7370e-01, -1.2141e-01,  2.7259e-01,
         -2.6421e-01,  6.2772e-02, -1.1853e-01, -3.1058e-01,  7.0519e-02,
          1.3507e-01, -5.0446e-02, -3.6240e-02,  2.0515e-01,  3.3423e-02,
          3.3778e-01],
        [ 5.4215e-02,  6.6833e-02,  1.0733e-01,  7.3880e-02, -9.6009e-03,
         -2.4101e-01, -2.1378e-02, -2.9234e-01, -1.3109e-01, -3.5354e-01,
         -3.2283e-01,  7.6598e-02,  1.1640e-01,  3.0490e-01, -5.6248e-02,
          9.4178e-02],
        [ 2.3760e-01,  2.4311e-01,  3.2139e-01, -3.6060e-01,  2.4186e-02,
         -1.2859e-01, -3.6739e-01,  2.2503e-02, -3.4759e-01,  1.2837e-03,
         -1.4185e-02,  5.3707e-02,  1.6286e-01,  2.8654e-01,  3.6084e-01,
          3.1794e-01],
        [-3.2896e-01, -8.6055e-02,  1.7369e-03,  2.1278e-01,  1.4605e-01,
          4.3690e-02,  3.5961e-01,  1.2664e-01, -8.8318e-02,  9.8559e-02,
          2.5188e-01, -2.3536e-01, -1.4486e-01, -1.7299e-01, -3.2505e-01,
         -1.2601e-01],
        [ 3.2488e-01,  1.8373e-01,  1.6209e-01, -1.4479e-01, -1.4473e-01,
         -3.2182e-01, -1.5438e-01, -3.1503e-01,  3.0695e-03, -1.1736e-01,
         -2.1181e-02,  1.1833e-01,  2.7007e-01,  2.9973e-01,  2.9383e-01,
          2.9039e-01],
        [-2.8768e-01, -3.6298e-02, -3.3799e-01,  2.6279e-01, -2.6824e-01,
          1.7898e-01,  3.4313e-01,  2.6579e-01,  3.2524e-01,  2.3493e-01,
          2.0406e-01, -5.4083e-02,  9.1066e-02,  6.1849e-02, -9.7112e-02,
         -2.4581e-01],
        [-3.0304e-01, -2.1980e-01, -6.6761e-02,  3.3450e-02,  1.6446e-02,
          4.1640e-01,  3.8764e-01, -5.8689e-02,  1.9683e-01,  3.2765e-01,
         -1.6954e-01,  1.5430e-02, -2.4120e-01, -2.5706e-01, -2.9191e-01,
         -2.6930e-01],
        [ 8.5389e-02,  2.5296e-01,  2.8858e-01, -8.9751e-02,  2.1934e-01,
         -3.5899e-01, -4.2176e-01, -3.4436e-01, -2.7877e-01, -2.9972e-01,
          6.3315e-03, -3.0966e-02, -6.8624e-02,  2.4989e-01,  3.8223e-02,
          2.2884e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0896, -0.0599,  0.1792, -0.0357, -0.0454, -0.0322,  0.0711,  0.0637,
        -0.0240, -0.0391, -0.0270,  0.0644,  0.1313,  0.1038, -0.0175,  0.0064,
        -0.1500,  0.0313,  0.1144,  0.0212, -0.0041, -0.1797, -0.0149, -0.0504,
        -0.0734,  0.2164,  0.1216,  0.0322, -0.0552, -0.1453,  0.0206,  0.0250],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1675,  0.2548, -0.1872, -0.2106,  0.1939,  0.2566, -0.2404, -0.3451,
         -0.2660,  0.2562,  0.2205,  0.3227, -0.1752, -0.3388,  0.2579, -0.0528,
         -0.2519,  0.2986, -0.1926, -0.2078,  0.2640,  0.3129, -0.3372, -0.3457,
         -0.2035, -0.2331, -0.2858,  0.2826, -0.3220,  0.3517,  0.2594, -0.2000]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0090, -0.0031,  0.0264,  ...,  0.1993, -0.3050, -0.1137],
        [-0.0844, -0.1944,  0.0871,  ...,  0.1337, -0.2983,  0.0871],
        [-0.0562,  0.1574,  0.0898,  ...,  0.0243,  0.1959,  0.0345],
        ...,
        [ 0.0444, -0.1554,  0.0131,  ...,  0.0565, -0.2300, -0.1180],
        [ 0.0374, -0.0656,  0.0005,  ..., -0.2890,  0.0981,  0.1557],
        [-0.0870,  0.1614,  0.0112,  ..., -0.1604,  0.0056, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0511,  0.0509, -0.0921, -0.1202, -0.0599,  0.0447, -0.1262,  0.0617,
        -0.0490,  0.0910,  0.0305,  0.0075,  0.0089,  0.0622, -0.0782, -0.0220,
         0.0490, -0.1434, -0.0301, -0.0173, -0.1132,  0.0451,  0.0837, -0.0054,
        -0.0835,  0.0642,  0.0243, -0.1002,  0.0636,  0.1475,  0.1418, -0.0654],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0636, -0.1710, -0.1035,  ..., -0.1082, -0.0411,  0.2296],
        [-0.2074, -0.0215,  0.0817,  ..., -0.0376, -0.0267,  0.2430],
        [ 0.1410, -0.0447, -0.1495,  ...,  0.0546, -0.0005, -0.0349],
        ...,
        [ 0.1250,  0.0847,  0.1062,  ...,  0.2289, -0.1940,  0.0888],
        [-0.0250, -0.1447,  0.0458,  ...,  0.0353,  0.2223,  0.0487],
        [ 0.0067, -0.1000,  0.1925,  ...,  0.0815,  0.1160,  0.1039]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0811,  0.1184, -0.0282, -0.0497, -0.0301, -0.0367, -0.0286, -0.0663,
         0.1073, -0.1658,  0.1281, -0.1352,  0.1631, -0.0181, -0.1464,  0.0984,
        -0.1225, -0.1500,  0.0139, -0.0313,  0.0150,  0.1142, -0.1818,  0.2012,
        -0.0761, -0.0321,  0.0923, -0.0478, -0.1090, -0.0543,  0.1019, -0.0026],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3649,  0.2872, -0.3591, -0.3711,  0.2106,  0.2161, -0.2686,  0.2727,
          0.2816, -0.2942, -0.2901,  0.2539,  0.2747, -0.2119,  0.2952,  0.2368,
         -0.3746, -0.3672,  0.2442,  0.2592, -0.3229, -0.2963, -0.3607,  0.1989,
          0.3361,  0.3681, -0.3379,  0.4031, -0.2731, -0.3580,  0.3342,  0.3589]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1029], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 7.6454e-03,  4.0238e-01,  3.2108e-01, -3.4134e-01,  1.4992e-02,
         -1.7281e-01, -4.8216e-02, -3.4981e-01, -1.4857e-01, -8.3864e-02,
          1.1618e-02,  1.3800e-01, -5.2801e-03, -7.8459e-02,  2.9917e-01,
          3.7730e-01],
        [-2.6270e-01, -3.8032e-01, -1.1788e-01,  8.0873e-05, -2.1165e-01,
          2.7048e-01,  1.6160e-01,  1.2024e-01,  3.6273e-01,  1.2628e-01,
          2.4041e-01, -2.2825e-01,  7.2088e-02, -1.5589e-02,  2.9647e-02,
         -9.0068e-02],
        [ 1.0035e-01,  2.9416e-01,  4.0482e-01, -1.4062e-01,  1.8060e-01,
         -3.7474e-01, -5.0503e-02, -3.7784e-01,  7.6301e-02, -8.6886e-02,
         -1.1714e-01, -9.1555e-02,  3.3911e-01,  2.9408e-01,  4.2278e-01,
          2.8120e-01],
        [ 2.9334e-01,  1.1695e-01,  1.1088e-01, -9.3590e-02,  1.4690e-01,
         -2.3095e-01, -1.5881e-01, -5.8112e-02, -3.8572e-01, -4.0938e-01,
         -1.3260e-01,  3.3274e-01,  2.2628e-01, -1.3881e-01,  1.3183e-01,
          1.7884e-01],
        [-9.1949e-02,  6.1244e-02, -1.7202e-01, -2.8222e-02, -3.1880e-02,
          9.5760e-02,  2.4073e-02,  2.6684e-01,  9.8113e-02,  2.7767e-01,
          2.7265e-01, -1.1405e-01,  3.8233e-02, -1.9549e-01, -3.9417e-02,
         -1.4801e-01],
        [-7.8787e-03,  9.5284e-02, -3.6683e-01,  3.9896e-01,  9.3017e-02,
         -1.2261e-02,  2.4798e-01, -8.8210e-02,  2.0528e-01,  1.9823e-01,
         -1.1150e-01, -3.6486e-02, -1.7171e-01,  1.5405e-01,  6.2139e-02,
         -8.0308e-02],
        [ 3.8941e-01,  2.4126e-01,  4.3056e-01, -1.9890e-01,  1.6685e-01,
         -2.4543e-01, -1.9410e-01, -2.0243e-01, -2.2552e-01, -2.7338e-02,
         -3.6791e-02,  3.4652e-02, -8.7511e-02,  2.1020e-01, -2.8109e-02,
          1.7194e-01],
        [-4.5389e-02,  3.4944e-01,  3.7558e-01, -3.6199e-01, -1.1809e-01,
         -3.2971e-01, -9.7866e-02, -2.1798e-01, -1.6066e-01, -2.1623e-01,
         -8.5430e-02, -2.6416e-03,  2.1310e-01, -9.8664e-02,  1.5196e-01,
          3.7381e-01],
        [ 4.1535e-02,  3.3960e-01,  3.1398e-01, -2.5248e-01,  7.6451e-02,
         -3.6642e-01, -1.5644e-01, -7.4588e-02,  7.6122e-02, -3.0276e-01,
         -1.2895e-01,  3.5758e-02, -1.4423e-01,  1.1119e-01, -2.0102e-02,
          9.7348e-02],
        [-2.8826e-01, -1.3238e-01, -1.0400e-01, -1.5095e-02, -1.1198e-01,
          1.6948e-01,  3.3650e-02,  1.9121e-01,  2.2526e-01, -1.7591e-02,
          2.6961e-01,  3.1990e-02, -1.8263e-01, -3.9757e-02, -1.5183e-01,
         -1.9659e-01],
        [-3.6833e-01,  2.6601e-02, -8.1395e-02, -2.7037e-02, -2.1768e-01,
          4.5369e-01,  2.3062e-01,  8.6811e-02,  3.1639e-01,  2.5240e-01,
          9.1419e-02,  3.7071e-02, -1.0419e-01,  1.5090e-01, -3.7651e-01,
         -3.4631e-01],
        [-1.3820e-01, -1.8654e-01, -3.9967e-02,  9.8920e-02,  6.4021e-02,
          1.4505e-01,  3.6778e-01,  1.2612e-01,  1.4249e-01,  3.4311e-01,
          1.8310e-01,  8.2033e-02, -3.4055e-01, -1.8763e-01, -2.3799e-01,
         -2.1258e-01],
        [ 3.4708e-01,  2.8478e-01,  1.8721e-01, -1.8373e-01,  1.3963e-01,
         -4.4738e-03, -7.4449e-02, -2.6497e-01, -2.8534e-01, -1.0986e-01,
         -1.4538e-01, -2.1921e-02, -1.1510e-01,  1.5758e-01,  1.3312e-01,
          4.7781e-02],
        [ 2.2308e-01,  3.8947e-01,  3.8656e-01, -2.0285e-02, -1.3138e-01,
         -4.7790e-02, -4.6665e-02, -4.2512e-02, -1.8647e-01, -1.6276e-01,
         -2.3134e-01,  8.6126e-02,  6.6696e-02,  4.3463e-02, -6.4250e-02,
          2.5372e-01],
        [-3.9107e-01, -3.4388e-01, -8.8566e-02, -3.1493e-02,  1.6333e-01,
          4.4040e-01,  1.0350e-01,  8.4648e-02, -6.2481e-02,  1.8422e-01,
          1.4711e-01, -2.8259e-01, -2.9476e-02, -9.8388e-02, -2.6670e-01,
         -1.8053e-01],
        [-1.1944e-01, -8.2886e-02,  1.5938e-01,  1.2430e-01, -9.9678e-02,
          2.0753e-02, -1.0358e-01, -1.8721e-01, -8.0120e-02,  9.2030e-03,
         -3.5021e-02,  3.2121e-01,  1.2283e-02, -1.2885e-01,  3.5110e-01,
          3.9381e-02],
        [ 3.3373e-01,  3.1405e-01,  2.2272e-01, -3.6855e-01, -1.6653e-01,
         -7.1281e-02, -1.1074e-01,  3.1322e-02, -3.3882e-01, -1.9266e-01,
          1.1712e-01,  2.6054e-01,  3.0051e-01,  2.7667e-01,  1.1888e-01,
         -3.0737e-03],
        [-3.1961e-01, -5.9726e-02, -2.7258e-01,  1.5939e-01, -4.8671e-02,
          3.4032e-01,  3.0487e-01,  2.4814e-01,  1.2028e-01,  2.9399e-01,
         -1.5099e-02, -2.2508e-01, -1.2760e-01, -2.1664e-01,  4.5959e-02,
         -2.0137e-01],
        [ 2.5595e-01,  1.7493e-01,  1.8264e-01, -3.1723e-01,  2.4676e-02,
         -4.1699e-01, -2.9938e-01,  5.5027e-02, -3.7413e-01, -1.4402e-01,
         -6.2713e-02, -1.0186e-01,  1.4799e-01,  2.4529e-01,  3.6511e-01,
          2.2488e-01],
        [ 3.9074e-01,  1.7974e-01,  2.9510e-01, -1.0757e-01, -1.3904e-01,
         -2.6620e-01, -3.6227e-01,  5.7728e-02, -1.9160e-02, -2.8236e-01,
         -8.5521e-02,  2.2277e-01, -1.2527e-01,  8.8852e-02,  3.1839e-01,
          2.2046e-01],
        [-1.8744e-01,  2.7198e-02, -6.0406e-02, -6.5154e-02,  7.8431e-02,
         -1.5252e-02,  3.0346e-01,  3.2805e-01,  1.4522e-01,  6.7481e-02,
         -3.8730e-02, -2.4095e-01, -1.2981e-01, -1.8664e-01,  7.5084e-02,
         -2.6405e-01],
        [-7.1289e-02, -3.7562e-01, -5.2134e-02,  3.7959e-01, -1.9329e-01,
          1.2847e-01,  2.3142e-01, -1.0282e-01, -2.1701e-02,  2.4686e-01,
          2.6839e-01, -2.2270e-01, -9.7034e-02, -3.1360e-01, -4.2383e-01,
          5.5394e-02],
        [ 3.7904e-01,  6.7916e-02,  7.1699e-02, -1.7167e-01,  1.9001e-01,
         -4.2411e-01, -3.0096e-01, -1.8699e-01, -2.1783e-01, -1.5672e-01,
          1.0113e-01,  1.7995e-01, -1.4783e-01,  3.0017e-01,  3.7366e-01,
          2.3862e-01],
        [ 2.8377e-01,  2.3702e-01,  3.7038e-01, -3.9055e-01, -6.1304e-02,
         -2.0896e-01, -2.0204e-01, -2.5082e-01, -3.3724e-01, -3.3588e-01,
         -1.2021e-01,  3.2054e-01,  2.2567e-01,  1.4199e-01,  9.2679e-03,
          5.7178e-02],
        [ 2.0538e-01, -8.1549e-02,  1.7370e-01, -1.2141e-01,  2.7259e-01,
         -2.6421e-01,  6.2772e-02, -1.1853e-01, -3.1058e-01,  7.0519e-02,
          1.3507e-01, -5.0446e-02, -3.6240e-02,  2.0515e-01,  3.3423e-02,
          3.3778e-01],
        [ 5.4215e-02,  6.6833e-02,  1.0733e-01,  7.3880e-02, -9.6009e-03,
         -2.4101e-01, -2.1378e-02, -2.9234e-01, -1.3109e-01, -3.5354e-01,
         -3.2283e-01,  7.6598e-02,  1.1640e-01,  3.0490e-01, -5.6248e-02,
          9.4178e-02],
        [ 2.3760e-01,  2.4311e-01,  3.2139e-01, -3.6060e-01,  2.4186e-02,
         -1.2859e-01, -3.6739e-01,  2.2503e-02, -3.4759e-01,  1.2836e-03,
         -1.4185e-02,  5.3707e-02,  1.6286e-01,  2.8654e-01,  3.6084e-01,
          3.1794e-01],
        [-3.2896e-01, -8.6055e-02,  1.7370e-03,  2.1278e-01,  1.4605e-01,
          4.3690e-02,  3.5961e-01,  1.2664e-01, -8.8318e-02,  9.8559e-02,
          2.5188e-01, -2.3536e-01, -1.4486e-01, -1.7299e-01, -3.2505e-01,
         -1.2601e-01],
        [ 3.2488e-01,  1.8373e-01,  1.6209e-01, -1.4479e-01, -1.4473e-01,
         -3.2182e-01, -1.5438e-01, -3.1503e-01,  3.0696e-03, -1.1736e-01,
         -2.1181e-02,  1.1833e-01,  2.7007e-01,  2.9973e-01,  2.9383e-01,
          2.9039e-01],
        [-2.8768e-01, -3.6298e-02, -3.3799e-01,  2.6279e-01, -2.6824e-01,
          1.7898e-01,  3.4313e-01,  2.6579e-01,  3.2524e-01,  2.3493e-01,
          2.0406e-01, -5.4083e-02,  9.1066e-02,  6.1849e-02, -9.7112e-02,
         -2.4581e-01],
        [-3.0304e-01, -2.1980e-01, -6.6761e-02,  3.3450e-02,  1.6446e-02,
          4.1640e-01,  3.8764e-01, -5.8689e-02,  1.9683e-01,  3.2765e-01,
         -1.6954e-01,  1.5430e-02, -2.4120e-01, -2.5706e-01, -2.9191e-01,
         -2.6930e-01],
        [ 8.5389e-02,  2.5296e-01,  2.8858e-01, -8.9751e-02,  2.1934e-01,
         -3.5899e-01, -4.2176e-01, -3.4436e-01, -2.7877e-01, -2.9972e-01,
          6.3315e-03, -3.0966e-02, -6.8623e-02,  2.4989e-01,  3.8223e-02,
          2.2884e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0896, -0.0599,  0.1792, -0.0357, -0.0454, -0.0322,  0.0711,  0.0637,
        -0.0240, -0.0391, -0.0270,  0.0644,  0.1313,  0.1038, -0.0175,  0.0064,
        -0.1500,  0.0313,  0.1144,  0.0212, -0.0041, -0.1797, -0.0149, -0.0504,
        -0.0734,  0.2164,  0.1216,  0.0322, -0.0552, -0.1453,  0.0206,  0.0250],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1675,  0.2548, -0.1872, -0.2106,  0.1939,  0.2566, -0.2404, -0.3451,
         -0.2660,  0.2562,  0.2205,  0.3227, -0.1752, -0.3388,  0.2579, -0.0528,
         -0.2519,  0.2986, -0.1926, -0.2078,  0.2640,  0.3129, -0.3372, -0.3457,
         -0.2035, -0.2331, -0.2858,  0.2826, -0.3220,  0.3517,  0.2594, -0.2000]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0090, -0.0031,  0.0264,  ...,  0.1993, -0.3050, -0.1137],
        [-0.0844, -0.1944,  0.0871,  ...,  0.1337, -0.2983,  0.0871],
        [-0.0562,  0.1574,  0.0898,  ...,  0.0243,  0.1959,  0.0345],
        ...,
        [ 0.0444, -0.1554,  0.0131,  ...,  0.0565, -0.2300, -0.1180],
        [ 0.0374, -0.0656,  0.0005,  ..., -0.2890,  0.0981,  0.1557],
        [-0.0870,  0.1614,  0.0112,  ..., -0.1604,  0.0056, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0511,  0.0509, -0.0921, -0.1202, -0.0599,  0.0447, -0.1262,  0.0617,
        -0.0490,  0.0910,  0.0305,  0.0075,  0.0089,  0.0622, -0.0782, -0.0220,
         0.0490, -0.1434, -0.0301, -0.0173, -0.1132,  0.0451,  0.0837, -0.0054,
        -0.0835,  0.0642,  0.0243, -0.1002,  0.0636,  0.1475,  0.1418, -0.0654],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0636, -0.1710, -0.1035,  ..., -0.1082, -0.0411,  0.2296],
        [-0.2074, -0.0215,  0.0817,  ..., -0.0376, -0.0267,  0.2430],
        [ 0.1410, -0.0447, -0.1495,  ...,  0.0546, -0.0005, -0.0349],
        ...,
        [ 0.1250,  0.0847,  0.1062,  ...,  0.2289, -0.1940,  0.0888],
        [-0.0250, -0.1447,  0.0458,  ...,  0.0353,  0.2223,  0.0487],
        [ 0.0067, -0.1000,  0.1925,  ...,  0.0815,  0.1160,  0.1039]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0811,  0.1184, -0.0282, -0.0497, -0.0301, -0.0367, -0.0286, -0.0663,
         0.1073, -0.1658,  0.1281, -0.1352,  0.1631, -0.0181, -0.1464,  0.0984,
        -0.1225, -0.1500,  0.0139, -0.0313,  0.0150,  0.1142, -0.1818,  0.2012,
        -0.0761, -0.0321,  0.0923, -0.0478, -0.1090, -0.0543,  0.1019, -0.0026],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3649,  0.2872, -0.3591, -0.3711,  0.2106,  0.2161, -0.2686,  0.2727,
          0.2816, -0.2942, -0.2901,  0.2539,  0.2747, -0.2119,  0.2952,  0.2368,
         -0.3746, -0.3672,  0.2442,  0.2592, -0.3229, -0.2963, -0.3607,  0.1989,
          0.3361,  0.3681, -0.3379,  0.4031, -0.2731, -0.3580,  0.3342,  0.3589]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1029], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 5.6008e-03,  3.9741e-01,  3.1813e-01, -3.3693e-01, -1.9506e-01,
         -1.6878e-01, -5.3495e-02, -3.9045e-01, -1.8410e-01, -7.9445e-02,
         -4.5926e-02,  1.8948e-01,  4.6806e-02, -4.2588e-02,  1.6858e-02,
          3.7853e-01],
        [-2.5735e-01, -3.6560e-01, -1.1157e-01,  3.0843e-03, -3.9651e-02,
          2.6069e-01,  1.6773e-01,  1.6366e-01,  4.0003e-01,  1.4540e-01,
          3.0149e-01, -2.6540e-01,  2.9654e-02, -6.7636e-02,  2.6865e-01,
         -8.7433e-02],
        [ 9.0278e-02,  2.8252e-01,  3.9307e-01, -1.2960e-01, -5.6109e-02,
         -3.5598e-01, -5.0193e-02, -4.1918e-01,  2.7010e-02, -8.1970e-02,
         -1.5640e-01, -5.5713e-02,  3.8469e-01,  3.5839e-01,  1.2243e-01,
          2.7445e-01],
        [ 2.8761e-01,  1.0519e-01,  1.0363e-01, -9.3263e-02, -4.3125e-02,
         -2.1858e-01, -1.6560e-01, -1.0798e-01, -4.3755e-01, -4.2593e-01,
         -1.4266e-01,  3.7932e-01,  2.6052e-01, -7.9790e-02, -1.4312e-01,
          1.7314e-01],
        [-1.0081e-01,  5.4161e-02, -1.8037e-01, -1.3655e-02,  1.4340e-01,
          9.7040e-02,  4.3187e-02,  3.2175e-01,  1.4693e-01,  3.0996e-01,
          3.3899e-01, -1.6296e-01, -1.8177e-02, -2.6828e-01,  2.0392e-01,
         -1.6537e-01],
        [-1.3936e-02,  9.5068e-02, -3.7168e-01,  4.1553e-01,  3.1683e-01,
         -1.2211e-02,  2.6490e-01, -2.7269e-02,  2.5932e-01,  2.2801e-01,
         -7.8663e-02, -9.1054e-02, -2.2208e-01,  1.0065e-01,  3.1309e-01,
         -8.7239e-02],
        [ 3.8431e-01,  1.4638e-01,  4.2389e-01, -2.0261e-01, -3.4961e-02,
         -2.3221e-01, -1.9143e-01, -2.5100e-01, -2.6987e-01, -4.5837e-02,
         -7.1399e-02,  7.5848e-02, -6.8707e-02,  2.6200e-01, -2.0261e-01,
          1.6932e-01],
        [-4.9051e-02,  2.9457e-01,  3.7073e-01, -3.6922e-01, -3.0897e-01,
         -3.1640e-01, -9.7176e-02, -2.7497e-01, -2.1102e-01, -2.3513e-01,
         -1.1729e-01,  4.2239e-02,  2.4546e-01, -5.2128e-02, -1.1285e-02,
          3.6995e-01],
        [ 3.8799e-02,  3.2801e-01,  3.1011e-01, -2.5310e-01, -3.9204e-02,
         -3.6076e-01, -1.6810e-01, -1.1169e-01,  4.0617e-02, -3.2461e-01,
         -2.6752e-01,  6.2626e-02, -9.2897e-02,  1.8814e-01, -2.4746e-01,
          1.0052e-01],
        [-2.9423e-01, -1.3599e-01, -1.0940e-01, -1.2327e-03,  5.7546e-02,
          1.6973e-01,  5.2159e-02,  2.4251e-01,  2.7345e-01,  1.3983e-02,
          3.4566e-01, -1.0322e-02, -2.3977e-01, -1.1302e-01,  9.9028e-02,
         -2.0874e-01],
        [-3.6990e-01,  1.6856e-02, -8.2160e-02, -1.5782e-02, -5.0089e-02,
          4.4838e-01,  2.4178e-01,  1.3452e-01,  3.6657e-01,  2.7795e-01,
          1.5202e-01, -8.4508e-03, -1.3253e-01,  7.5249e-02, -6.2402e-02,
         -3.5055e-01],
        [-1.3658e-01, -1.8569e-01, -3.9421e-02,  1.0520e-01,  1.6715e-01,
          1.4064e-01,  3.7922e-01,  1.6783e-01,  1.7701e-01,  3.6991e-01,
          2.6861e-01,  5.1135e-02, -3.5187e-01, -2.7767e-01,  1.8751e-03,
         -2.2035e-01],
        [ 3.4819e-01,  2.9006e-01,  1.8656e-01, -1.9553e-01, -1.0629e-01,
          6.0204e-04, -9.3129e-02, -3.3446e-01, -3.3278e-01, -1.3417e-01,
         -1.8036e-01,  4.4301e-02, -7.3921e-02,  2.1029e-01, -1.8300e-01,
          5.3465e-02],
        [ 2.1785e-01,  3.5895e-01,  3.8055e-01, -2.5102e-02, -2.9528e-01,
         -3.8611e-02, -4.9518e-02, -8.4094e-02, -2.2442e-01, -1.8264e-01,
         -2.8690e-01,  1.1880e-01,  1.0625e-01,  9.5018e-02, -2.5997e-01,
          2.5086e-01],
        [-3.8760e-01, -3.2622e-01, -8.3587e-02, -2.6401e-02,  3.5013e-01,
          4.2900e-01,  1.0842e-01,  1.3078e-01, -1.7248e-02,  2.0357e-01,
          2.0318e-01, -3.2193e-01, -7.1964e-02, -1.5375e-01, -3.4049e-02,
         -1.7860e-01],
        [-6.7344e-02, -1.8758e-02,  2.0970e-01,  6.0214e-02, -2.7960e-01,
         -2.7431e-02, -1.7782e-01, -2.8896e-01, -1.8871e-01, -7.3432e-02,
         -1.4525e-01,  3.9887e-01,  1.2158e-01,  6.3353e-04,  1.5676e-01,
          9.1260e-02],
        [ 3.2961e-01,  2.9790e-01,  2.1794e-01, -3.7280e-01, -3.5319e-01,
         -6.2423e-02, -1.1820e-01, -2.1583e-02, -3.8415e-01, -2.1273e-01,
          7.8947e-02,  3.0609e-01,  3.4740e-01,  3.2746e-01, -8.3969e-02,
         -6.9944e-03],
        [-3.1168e-01, -3.6086e-02, -2.6419e-01,  1.6194e-01,  1.1711e-01,
          3.2250e-01,  3.0235e-01,  2.8869e-01,  1.5944e-01,  3.0945e-01,
          1.9826e-02, -2.5882e-01, -1.5526e-01, -2.6774e-01,  2.2791e-01,
         -1.9558e-01],
        [ 2.2997e-01,  1.5445e-01,  1.5409e-01, -2.9035e-01, -2.0268e-01,
         -3.8468e-01, -2.8778e-01,  2.3180e-02, -4.1724e-01, -1.2147e-01,
         -1.3084e-01, -7.6921e-02,  2.0687e-01,  3.1104e-01,  7.1062e-02,
          2.0081e-01],
        [ 3.8740e-01,  1.6565e-01,  2.8949e-01, -1.0909e-01, -3.0491e-01,
         -2.5530e-01, -3.6948e-01,  1.1198e-02, -6.5880e-02, -3.0080e-01,
         -1.6797e-01,  2.6409e-01, -7.6315e-02,  1.5419e-01,  7.5935e-02,
          2.1818e-01],
        [-1.9229e-01,  2.4769e-02, -6.4077e-02, -5.1821e-02,  2.5499e-01,
         -1.9642e-02,  3.1603e-01,  3.7002e-01,  1.8669e-01,  9.3798e-02,
          1.0591e-02, -2.8020e-01, -1.7913e-01, -2.4198e-01,  3.0755e-01,
         -2.7199e-01],
        [-7.0771e-02, -3.5913e-01, -5.0505e-02,  3.8648e-01, -5.1099e-02,
          1.2290e-01,  2.4753e-01, -5.8997e-02,  1.8534e-02,  2.7226e-01,
          3.8632e-01, -2.5528e-01, -1.5697e-01, -3.8508e-01, -1.8032e-01,
          5.2157e-02],
        [ 3.7804e-01,  5.8551e-02,  6.9848e-02, -1.8045e-01,  2.0051e-02,
         -4.1610e-01, -3.0900e-01, -2.3830e-01, -2.6649e-01, -1.7940e-01,
          4.9651e-02,  2.2170e-01, -1.0237e-01,  3.6084e-01,  1.7445e-01,
          2.3878e-01],
        [ 2.7453e-01,  2.2799e-01,  3.6073e-01, -3.9304e-01, -2.2066e-01,
         -1.9018e-01, -1.9985e-01, -2.9971e-01, -3.7757e-01, -3.4921e-01,
         -1.1697e-01,  3.5931e-01,  2.4575e-01,  1.8459e-01, -1.6505e-01,
          4.7217e-02],
        [ 2.1278e-01, -8.1547e-02,  1.7995e-01, -1.3342e-01,  8.8215e-02,
         -2.6697e-01,  4.3371e-02, -1.7290e-01, -3.6186e-01,  3.9340e-02,
          6.0651e-02, -6.5916e-04,  2.1578e-02,  2.7420e-01, -2.2390e-01,
          3.5047e-01],
        [ 5.3914e-02,  6.1530e-02,  1.0519e-01,  6.3745e-02, -1.9455e-01,
         -2.2913e-01, -2.5951e-02, -3.3249e-01, -1.6838e-01, -3.7486e-01,
         -3.7543e-01,  1.1423e-01,  1.6048e-01,  3.5615e-01, -2.9901e-01,
          9.7876e-02],
        [ 2.3536e-01,  2.2472e-01,  3.1813e-01, -3.6779e-01, -1.5625e-01,
         -1.1874e-01, -3.7297e-01, -3.2658e-02, -3.9758e-01, -1.9321e-02,
         -5.8865e-02,  9.8818e-02,  2.0804e-01,  3.4167e-01,  1.6620e-01,
          3.1544e-01],
        [-3.2951e-01, -8.2912e-02,  9.1184e-04,  2.2249e-01,  2.9314e-01,
          4.0265e-02,  3.7253e-01,  1.7823e-01, -4.4320e-02,  1.2648e-01,
          3.1419e-01, -2.7776e-01, -1.9042e-01, -2.4485e-01, -7.7014e-02,
         -1.3206e-01],
        [ 3.1958e-01,  1.9028e-01,  1.5718e-01, -1.5150e-01, -2.9257e-01,
         -3.1114e-01, -1.6083e-01, -3.5832e-01, -3.6592e-02, -1.3651e-01,
         -2.4633e-02,  1.5592e-01,  2.7558e-01,  3.5991e-01,  5.7059e-02,
          2.8736e-01],
        [-2.8468e-01, -3.6611e-03, -3.3414e-01,  2.7022e-01, -9.9031e-02,
          1.6607e-01,  3.4488e-01,  3.1442e-01,  3.7146e-01,  2.5492e-01,
          2.5229e-01, -9.2774e-02,  5.5153e-02,  6.3744e-03,  7.5940e-02,
         -2.4469e-01],
        [-3.0070e-01, -2.1485e-01, -6.3449e-02,  3.8870e-02,  1.8221e-01,
          4.0769e-01,  3.9535e-01, -1.2480e-02,  2.4248e-01,  3.4841e-01,
         -1.0809e-01, -2.4203e-02, -2.8695e-01, -3.2057e-01, -6.0390e-02,
         -2.6828e-01],
        [ 7.1056e-02,  2.1069e-01,  2.7202e-01, -7.0287e-02,  2.6566e-02,
         -3.3844e-01, -4.1620e-01, -3.8263e-01, -3.2319e-01, -2.9184e-01,
         -5.6666e-02, -4.1596e-04, -3.2992e-02,  3.1294e-01, -1.9458e-01,
          2.1571e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0712,  0.0008,  0.1046, -0.0391, -0.0357, -0.0657,  0.0690,  0.0820,
        -0.0357, -0.0298,  0.0111,  0.0783,  0.1382,  0.0690,  0.0237, -0.0610,
        -0.0585, -0.0122,  0.0795,  0.0016, -0.0324, -0.1255, -0.0393,  0.0174,
        -0.0608,  0.1606,  0.1131,  0.0427, -0.0697, -0.1396,  0.0430, -0.0486],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1861,  0.2819, -0.1920, -0.2222,  0.2659,  0.3042, -0.2531, -0.3554,
         -0.2862,  0.2900,  0.2248,  0.3334, -0.2069, -0.3658,  0.2671, -0.1541,
         -0.2857,  0.3040, -0.1906, -0.2209,  0.3441,  0.2769, -0.3410, -0.3540,
         -0.2714, -0.2908, -0.2869,  0.3026, -0.3266,  0.3573,  0.2574, -0.2046]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0039,  0.0018,  0.0379,  ...,  0.2338, -0.3555, -0.1137],
        [-0.0769, -0.1819,  0.0823,  ...,  0.1448, -0.3344,  0.0871],
        [-0.0521,  0.1635,  0.0805,  ..., -0.0025,  0.2489,  0.0345],
        ...,
        [ 0.0375, -0.1782,  0.0351,  ...,  0.0636, -0.2729, -0.1180],
        [ 0.0411, -0.0599, -0.0137,  ..., -0.3013,  0.1403,  0.1557],
        [-0.1930,  0.0620, -0.0047,  ...,  0.0388, -0.2132, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0570,  0.0575, -0.0898, -0.1179, -0.0570,  0.0521, -0.1282,  0.0621,
        -0.0492,  0.0818,  0.0318,  0.0077,  0.0246,  0.0729, -0.0788, -0.0158,
         0.0511, -0.1491, -0.0277, -0.0235, -0.0733,  0.0428,  0.0885, -0.0079,
        -0.0865,  0.0867,  0.0340, -0.0877,  0.0491,  0.1398,  0.1474, -0.1043],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0194, -0.1797, -0.0867,  ..., -0.1080, -0.0374,  0.0740],
        [-0.2636, -0.0316,  0.1065,  ..., -0.0385, -0.0190,  0.0636],
        [ 0.1802, -0.0425, -0.1660,  ...,  0.0437,  0.0034,  0.1602],
        ...,
        [ 0.1666,  0.0874,  0.0940,  ...,  0.2221, -0.1928,  0.2402],
        [-0.0720, -0.1472,  0.0634,  ...,  0.0462,  0.2202, -0.1546],
        [-0.0488, -0.1157,  0.2114,  ...,  0.0772,  0.1265, -0.0298]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0811,  0.1182, -0.0182, -0.0548, -0.0373, -0.0636, -0.0222, -0.0639,
         0.0917, -0.1307,  0.1370, -0.1285,  0.1485,  0.0557, -0.1381,  0.0834,
        -0.1147, -0.1427,  0.0009, -0.0174,  0.0120,  0.1137, -0.1789,  0.1709,
        -0.0679, -0.0332,  0.0937, -0.0470, -0.1058, -0.0508,  0.0888,  0.0007],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3624,  0.2804, -0.3568, -0.3630,  0.2229,  0.2146, -0.2727,  0.2645,
          0.2967, -0.2947, -0.2612,  0.2572,  0.2536,  0.2633,  0.2909,  0.2374,
         -0.3628, -0.3684,  0.2335,  0.2558, -0.3131, -0.2927, -0.3569,  0.2216,
          0.3414,  0.3730, -0.3448,  0.3903, -0.2714, -0.3609,  0.3331,  0.3631]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0933], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.0832e-02,  3.7566e-01,  2.9073e-01, -3.0045e-01,  1.0184e-01,
         -1.4385e-01, -4.2022e-02, -4.1205e-01, -1.7745e-01, -5.3512e-02,
          5.8042e-02,  1.8339e-01,  3.8762e-02, -5.7292e-02,  2.5323e-01,
          3.5147e-01],
        [-2.3547e-01, -3.8231e-01, -8.9892e-02, -2.0553e-02, -2.8611e-01,
          2.4200e-01,  1.5907e-01,  1.5809e-01,  3.7915e-01,  1.2800e-01,
          2.6951e-01, -2.6979e-01,  1.2457e-03, -4.0594e-02,  5.2306e-02,
         -6.4768e-02],
        [ 6.8184e-02,  2.8171e-01,  3.6951e-01, -1.0755e-01,  2.6015e-01,
         -3.3814e-01, -3.1380e-02, -4.2897e-01,  3.2569e-02, -6.4470e-02,
         -8.6585e-02, -6.1984e-02,  3.4379e-01,  3.4262e-01,  3.5075e-01,
          2.5293e-01],
        [ 2.6300e-01,  1.1215e-01,  7.8328e-02, -7.2289e-02,  2.5125e-01,
         -1.9698e-01, -1.5203e-01, -9.7399e-02, -4.0790e-01, -4.0675e-01,
         -4.8148e-02,  3.7229e-01,  2.4113e-01, -1.0122e-01,  3.7849e-02,
          1.4844e-01],
        [-8.8127e-02,  3.2498e-02, -1.6245e-01, -3.0277e-02, -1.1013e-01,
          8.4836e-02,  4.5955e-02,  3.3687e-01,  1.3569e-01,  3.0393e-01,
          3.8192e-01, -1.7949e-01, -5.7339e-02, -2.5112e-01, -1.1929e-02,
         -1.4805e-01],
        [-8.9846e-03,  5.7750e-02, -3.6297e-01,  4.1064e-01,  4.5851e-02,
         -1.6414e-02,  2.6786e-01, -2.1869e-02,  2.6098e-01,  2.2882e-01,
         -7.6043e-02, -1.1120e-01, -2.4606e-01,  9.8387e-02,  8.4608e-02,
         -8.0999e-02],
        [ 3.6444e-01,  1.8471e-01,  4.0666e-01, -1.8201e-01,  1.8320e-01,
         -2.2047e-01, -1.8495e-01, -2.6214e-01, -2.0669e-01, -2.6264e-02,
         -4.8161e-02,  8.2194e-02, -4.6847e-02,  1.3772e-01, -6.9949e-02,
          1.5032e-01],
        [-6.5201e-02,  3.4252e-01,  3.5321e-01, -3.5295e-01, -1.0712e-01,
         -3.0485e-01, -9.0426e-02, -2.8591e-01, -1.7578e-01, -2.2536e-01,
         -1.0012e-01,  4.9705e-02,  2.5587e-01, -9.7020e-02,  1.0494e-01,
          3.5201e-01],
        [ 2.1188e-02,  3.4800e-01,  2.9247e-01, -2.3457e-01,  2.0823e-01,
         -3.4387e-01, -1.6449e-01, -1.1006e-01,  6.2881e-02, -3.1115e-01,
         -1.9443e-01,  7.1089e-02, -4.4789e-02,  1.6783e-01, -3.1615e-02,
          8.3459e-02],
        [-2.8155e-01, -1.5784e-01, -9.2593e-02, -1.6236e-02, -2.0468e-01,
          1.5562e-01,  5.0083e-02,  2.4916e-01,  2.5706e-01,  6.3115e-03,
          3.0831e-01, -2.1313e-02, -2.6396e-01, -9.2643e-02, -1.1077e-01,
         -1.9387e-01],
        [-3.4528e-01,  2.3788e-02, -5.6993e-02, -3.7196e-02, -3.5464e-01,
          4.2683e-01,  2.1615e-01,  1.1616e-01,  3.5068e-01,  2.5816e-01,
          5.3123e-02, -5.9317e-03, -7.8506e-02,  8.0798e-02, -2.3667e-01,
         -3.2569e-01],
        [-1.2020e-01, -1.9067e-01, -2.1429e-02,  8.9068e-02, -9.2425e-02,
          1.2163e-01,  3.6886e-01,  1.6806e-01,  1.5094e-01,  3.5756e-01,
          2.1427e-01,  4.8068e-02, -3.3902e-01, -2.5772e-01, -1.2214e-01,
         -2.0538e-01],
        [ 3.2998e-01,  3.0142e-01,  1.6365e-01, -1.7360e-01,  1.9004e-01,
          1.7983e-02, -7.8380e-02, -3.1790e-01, -3.2860e-01, -1.1830e-01,
         -1.4039e-01,  5.5839e-02, -9.1467e-02,  2.0951e-01,  8.0946e-02,
          3.1759e-02],
        [ 2.0488e-01,  3.9847e-01,  3.6710e-01, -1.1958e-02, -6.1041e-02,
         -2.6909e-02, -4.9865e-02, -8.6577e-02, -2.0525e-01, -1.7542e-01,
         -2.9566e-01,  1.2971e-01,  1.4489e-01,  6.5733e-02, -8.6621e-02,
          2.3827e-01],
        [-3.7181e-01, -3.5565e-01, -6.5832e-02, -4.1160e-02,  9.1959e-02,
          4.1503e-01,  1.0267e-01,  1.3093e-01, -3.6030e-02,  1.9429e-01,
          1.5564e-01, -3.2562e-01, -8.2461e-02, -1.3704e-01, -2.2155e-01,
         -1.6202e-01],
        [-2.8536e-01, -2.8264e-01,  1.1386e-03,  2.7370e-01, -1.8025e-01,
          2.1608e-01,  9.7518e-02,  8.9006e-03,  1.5265e-01,  1.8367e-01,
          7.3207e-02,  1.3315e-01, -1.4896e-01, -3.3780e-01,  1.9018e-01,
         -1.0397e-01],
        [ 3.1367e-01,  3.1620e-01,  2.0260e-01, -3.5697e-01, -1.2145e-01,
         -4.8916e-02, -1.1081e-01, -1.8780e-02, -3.6458e-01, -2.0220e-01,
          9.3117e-02,  3.1322e-01,  3.7801e-01,  2.8991e-01,  1.0041e-01,
         -2.1886e-02],
        [-2.9481e-01, -3.7902e-02, -2.4678e-01,  1.4244e-01, -7.5854e-02,
          3.1065e-01,  2.9283e-01,  2.9883e-01,  1.2220e-01,  2.9795e-01,
          2.6871e-02, -2.6579e-01, -1.8216e-01, -2.0004e-01,  8.2654e-02,
         -1.7642e-01],
        [ 2.2224e-01,  1.5247e-01,  1.4876e-01, -2.7904e-01,  1.1565e-01,
         -3.8291e-01, -2.8387e-01, -4.1730e-05, -4.1076e-01, -1.1913e-01,
         -5.9188e-02, -6.6990e-02,  2.0836e-01,  2.7340e-01,  3.2616e-01,
          1.9325e-01],
        [ 3.6688e-01,  1.8156e-01,  2.6888e-01, -9.1023e-02, -3.3012e-02,
         -2.3767e-01, -3.6044e-01,  1.9037e-02, -4.4427e-02, -2.8651e-01,
         -7.0095e-02,  2.6342e-01, -7.4573e-02,  1.4126e-01,  2.7603e-01,
          1.9769e-01],
        [-1.8326e-01, -7.8737e-03, -5.0814e-02, -6.3410e-02,  1.8915e-02,
         -2.7282e-02,  3.1877e-01,  3.7629e-01,  1.8936e-01,  9.1058e-02,
         -5.6338e-04, -2.9595e-01, -1.9528e-01, -2.4454e-01,  1.0689e-01,
         -2.5945e-01],
        [-5.4160e-02, -3.8830e-01, -3.0469e-02,  3.6849e-01, -3.0386e-01,
          1.0308e-01,  2.3263e-01, -6.9502e-02, -3.4214e-04,  2.5829e-01,
          3.2448e-01, -2.5675e-01, -1.5310e-01, -3.6334e-01, -3.7548e-01,
          6.8430e-02],
        [ 3.5648e-01,  5.8685e-02,  4.7587e-02, -1.5618e-01,  2.2973e-01,
         -3.9696e-01, -2.9731e-01, -2.3980e-01, -2.2867e-01, -1.6260e-01,
          6.1500e-02,  2.2282e-01, -7.4222e-02,  3.1090e-01,  3.3983e-01,
          2.1484e-01],
        [ 2.5665e-01,  2.2234e-01,  3.4242e-01, -3.7198e-01, -4.4629e-02,
         -1.7689e-01, -1.9301e-01, -3.0930e-01, -3.4544e-01, -3.3712e-01,
         -6.7333e-02,  3.6742e-01,  2.6395e-01,  1.3994e-01, -6.0721e-02,
          2.5893e-02],
        [ 1.9504e-01, -6.5108e-02,  1.6102e-01, -1.1415e-01,  3.6317e-01,
         -2.5089e-01,  4.9974e-02, -1.7435e-01, -3.4126e-01,  5.3670e-02,
          2.8492e-03,  9.5106e-03,  6.5196e-02,  2.5353e-01,  3.4591e-02,
          3.3275e-01],
        [ 4.3855e-02,  9.5401e-02,  9.0637e-02,  7.6354e-02,  4.5030e-02,
         -2.2151e-01, -2.7027e-02, -3.3529e-01, -1.7969e-01, -3.7133e-01,
         -3.3592e-01,  1.3019e-01,  1.5333e-01,  3.7030e-01, -1.0590e-01,
          8.3476e-02],
        [ 2.1413e-01,  2.3498e-01,  2.9508e-01, -3.4571e-01,  6.2182e-02,
         -9.8721e-02, -3.5667e-01, -3.1704e-02, -3.5933e-01, -3.9034e-03,
         -4.8937e-02,  9.5997e-02,  2.1897e-01,  2.9589e-01,  3.1563e-01,
          2.9259e-01],
        [-3.1951e-01, -9.3733e-02,  1.4497e-02,  2.1116e-01,  2.7989e-02,
          2.7579e-02,  3.6851e-01,  1.8835e-01, -6.7735e-02,  1.1992e-01,
          2.6408e-01, -2.8782e-01, -1.9913e-01, -2.2231e-01, -2.4675e-01,
         -1.2114e-01],
        [ 3.0229e-01,  1.9115e-01,  1.3758e-01, -1.3397e-01, -5.5298e-02,
         -2.9308e-01, -1.4943e-01, -3.4743e-01, -2.4778e-02, -1.2457e-01,
          3.9324e-02,  1.5831e-01,  2.6202e-01,  3.5344e-01,  1.8831e-01,
          2.6892e-01],
        [-2.6416e-01, -2.2897e-02, -3.1271e-01,  2.4756e-01, -2.9114e-01,
          1.5010e-01,  3.3190e-01,  3.2137e-01,  3.3062e-01,  2.3993e-01,
          2.3662e-01, -9.5567e-02,  4.2107e-02,  6.7081e-02, -5.8546e-02,
         -2.2181e-01],
        [-2.7898e-01, -2.2135e-01, -4.0637e-02,  1.7008e-02, -6.5148e-02,
          3.8753e-01,  3.8435e-01, -1.9110e-02,  2.1675e-01,  3.3266e-01,
         -1.3836e-01, -2.2294e-02, -3.0834e-01, -2.9541e-01, -2.5385e-01,
         -2.4548e-01],
        [ 5.2901e-02,  2.1938e-01,  2.5618e-01, -5.3480e-02,  2.9988e-01,
         -3.2611e-01, -4.0708e-01, -3.8964e-01, -3.0157e-01, -2.8118e-01,
         -2.6873e-02,  1.6659e-03, -1.0036e-02,  2.0196e-01,  6.8503e-03,
          1.9807e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0444,  0.0050,  0.1201, -0.0265, -0.0152, -0.0790,  0.0776,  0.1674,
        -0.0768, -0.0095, -0.0114,  0.0972,  0.2112,  0.0989, -0.0570, -0.1270,
        -0.1027,  0.0175,  0.0621,  0.0100,  0.0082, -0.1327, -0.0793, -0.0288,
        -0.1473,  0.1948,  0.0944,  0.0830, -0.0693, -0.1885,  0.0974, -0.0699],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1754,  0.2694, -0.1924, -0.2206,  0.2406,  0.3158, -0.2578, -0.3447,
         -0.2882,  0.2853,  0.2174,  0.3269, -0.2037, -0.3688,  0.2684,  0.1424,
         -0.2842,  0.3049, -0.1921, -0.2110,  0.3237,  0.2985, -0.3371, -0.3530,
         -0.3101, -0.2701, -0.2855,  0.2812, -0.3210,  0.3517,  0.2577, -0.2003]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0140,  0.0570,  0.0193,  ..., -0.0343, -0.0441, -0.1137],
        [-0.0763, -0.0627,  0.0197,  ...,  0.1002, -0.3292,  0.0871],
        [-0.0606,  0.0178,  0.1476,  ...,  0.0354,  0.2420,  0.0345],
        ...,
        [ 0.0519, -0.0182, -0.0414,  ...,  0.0221, -0.2639, -0.1180],
        [ 0.0405, -0.1765,  0.0544,  ..., -0.2582,  0.1282,  0.1557],
        [-0.1975,  0.1374, -0.0474,  ...,  0.0093, -0.2358, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0545,  0.0552, -0.0892, -0.1273, -0.0590,  0.0599, -0.1263,  0.0677,
        -0.0410,  0.0826,  0.0369,  0.0080,  0.0133,  0.0750, -0.0598, -0.0208,
         0.0550, -0.1577, -0.0229, -0.0195, -0.0557,  0.0301,  0.0964, -0.0078,
        -0.0881,  0.0678,  0.0370, -0.0886,  0.0277,  0.1452,  0.1490, -0.1138],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1492, -0.1672, -0.0902,  ..., -0.1061, -0.0577,  0.0830],
        [-0.1036, -0.0174,  0.1069,  ..., -0.0318, -0.0410,  0.0608],
        [ 0.0287, -0.0569, -0.1643,  ...,  0.0397,  0.0257,  0.1557],
        ...,
        [ 0.0298,  0.0642,  0.1058,  ...,  0.2160, -0.1625,  0.2163],
        [ 0.0927, -0.1301,  0.0599,  ...,  0.0547,  0.1960, -0.1571],
        [ 0.0900, -0.0963,  0.2019,  ...,  0.0821,  0.0999, -0.0151]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0853,  0.1197, -0.0120, -0.0563, -0.0429, -0.0613, -0.0199, -0.0736,
         0.1034, -0.1400,  0.1375, -0.1438,  0.1573,  0.0804, -0.1446,  0.0810,
        -0.1134, -0.1433,  0.0102, -0.0319,  0.0225,  0.1173, -0.1717,  0.1985,
        -0.0751, -0.0319,  0.1020, -0.0508, -0.1004, -0.0460,  0.0852,  0.0028],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3292,  0.2371, -0.3252, -0.3239,  0.1791,  0.1665, -0.2300,  0.2309,
          0.2653, -0.2533, -0.2176,  0.2244,  0.2145,  0.1797,  0.2531,  0.2085,
         -0.3218, -0.3281,  0.1916,  0.2203, -0.2739, -0.2569, -0.3287,  0.1459,
          0.2913,  0.3378, -0.3100,  0.3241, -0.2319, -0.3193,  0.3022,  0.3162]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.0624], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 4.3433e-04,  2.2987e-01,  3.1443e-01, -3.4968e-01, -1.9977e-01,
         -1.6502e-01, -4.4619e-02, -3.7972e-01, -1.6297e-01, -8.0046e-02,
          1.8538e-01,  1.9201e-01,  5.0202e-02, -2.9523e-02, -6.1466e-02,
          3.8401e-01],
        [-2.5489e-01, -1.9478e-01, -1.0838e-01,  2.4146e-02, -1.4072e-02,
          2.5506e-01,  1.5809e-01,  1.6302e-01,  4.1010e-01,  1.5107e-01,
          6.0284e-02, -2.6897e-01, -1.6760e-03, -7.2661e-02,  3.7524e-01,
         -9.1489e-02],
        [ 8.4360e-02,  1.2331e-01,  3.8556e-01, -1.4094e-01, -7.0646e-02,
         -3.5092e-01, -3.1414e-02, -4.0819e-01,  3.7334e-02, -7.8633e-02,
         -8.3844e-02, -5.1525e-02,  3.9445e-01,  3.4391e-01,  5.3018e-02,
          2.7202e-01],
        [ 2.7435e-01,  3.0371e-02,  8.9749e-02, -1.0549e-01, -6.0307e-02,
         -2.0156e-01, -1.4421e-01, -9.2943e-02, -4.2529e-01, -4.2041e-01,
          3.2687e-02,  3.7041e-01,  3.0538e-01, -8.4931e-02, -2.1024e-01,
          1.6577e-01],
        [-9.4560e-02,  2.0562e-01, -1.7367e-01,  4.5985e-03,  1.6441e-01,
          8.8641e-02,  2.7928e-02,  3.1869e-01,  1.4952e-01,  3.1275e-01,
          7.0366e-02, -1.6576e-01, -4.6372e-02, -2.6558e-01,  2.8490e-01,
         -1.6547e-01],
        [-7.6843e-04,  2.3479e-01, -3.5955e-01,  4.2548e-01,  3.2499e-01,
         -3.3107e-02,  2.4282e-01, -3.8789e-02,  2.5765e-01,  2.2202e-01,
         -1.0656e-01, -8.9204e-02, -2.2708e-01,  1.0688e-01,  3.4361e-01,
         -8.1314e-02],
        [ 3.7561e-01,  6.4946e-02,  4.1502e-01, -2.1755e-01, -6.8070e-02,
         -2.2052e-01, -1.7120e-01, -2.4110e-01, -2.6345e-01, -4.6012e-02,
          3.3973e-03,  7.5253e-02, -5.5971e-02,  2.1174e-01, -2.7947e-01,
          1.6606e-01],
        [-5.8073e-02,  1.9839e-01,  3.6309e-01, -3.8423e-01, -3.4163e-01,
         -3.0662e-01, -8.1586e-02, -2.7023e-01, -2.1575e-01, -2.3699e-01,
         -6.8353e-02,  4.8482e-02,  2.5578e-01, -7.5117e-02, -6.7687e-02,
          3.6518e-01],
        [ 3.9740e-02,  1.4738e-01,  3.1009e-01, -2.7971e-01, -6.2952e-02,
         -3.5418e-01, -1.5846e-01, -1.0852e-01,  3.3492e-02, -3.3400e-01,
          1.7664e-02,  6.5606e-02, -5.8293e-02,  1.9661e-01, -3.5757e-01,
          1.0907e-01],
        [-2.8920e-01,  3.2362e-02, -1.0419e-01,  1.7172e-02,  7.7707e-02,
          1.6125e-01,  3.7599e-02,  2.3918e-01,  2.7586e-01,  1.6520e-02,
          1.0208e-01, -1.3290e-02, -2.6373e-01, -1.1240e-01,  1.8247e-01,
         -2.1101e-01],
        [-3.5898e-01,  1.0608e-01, -7.0446e-02, -3.6134e-03, -3.5632e-02,
          4.3418e-01,  2.2611e-01,  1.2299e-01,  3.6177e-01,  2.7363e-01,
          5.7696e-03, -4.9539e-03, -2.0739e-01,  6.5646e-02, -6.4650e-03,
         -3.4537e-01],
        [-1.2580e-01, -7.0774e-02, -2.7771e-02,  1.2156e-01,  1.6972e-01,
          1.2573e-01,  3.5022e-01,  1.4860e-01,  1.6571e-01,  3.6586e-01,
          9.0706e-02,  5.8579e-02, -4.1910e-01, -2.5974e-01,  8.2731e-02,
         -2.1597e-01],
        [ 3.4034e-01,  1.4148e-01,  1.7783e-01, -2.1146e-01, -1.2136e-01,
          6.2705e-03, -8.1306e-02, -3.3145e-01, -3.3867e-01, -1.3365e-01,
         -8.5326e-02,  5.0254e-02, -2.2994e-02,  2.2937e-01, -2.7407e-01,
          5.1277e-02],
        [ 2.1278e-01,  2.0698e-01,  3.7522e-01, -4.3898e-02, -3.1894e-01,
         -3.0230e-02, -3.3205e-02, -7.8260e-02, -2.3289e-01, -1.8578e-01,
         -1.0526e-01,  1.2068e-01,  1.2846e-01,  8.3100e-02, -3.6514e-01,
          2.5131e-01],
        [-3.8098e-01, -1.7152e-01, -7.6640e-02, -9.4117e-03,  3.8088e-01,
          4.2170e-01,  9.4306e-02,  1.2954e-01, -1.4105e-02,  2.0570e-01,
          3.2588e-02, -3.2552e-01, -9.9854e-02, -1.5112e-01,  6.7245e-02,
         -1.7644e-01],
        [-5.1198e-02, -2.1361e-01,  2.2611e-01,  1.6433e-02, -3.3593e-01,
         -4.4212e-02, -1.7990e-01, -3.1432e-01, -2.1542e-01, -1.0242e-01,
         -4.1987e-02,  4.3512e-01,  1.6865e-01,  9.0345e-03,  6.1288e-02,
          1.1521e-01],
        [ 3.2175e-01,  1.6310e-01,  2.0964e-01, -3.8950e-01, -3.5830e-01,
         -4.9562e-02, -9.4141e-02, -3.5164e-03, -3.8567e-01, -2.1240e-01,
          2.0403e-01,  3.0307e-01,  3.6274e-01,  3.0094e-01, -1.4004e-01,
         -9.1864e-03],
        [-3.0126e-01,  6.6924e-02, -2.5431e-01,  1.7660e-01,  1.2657e-01,
          3.0732e-01,  2.7782e-01,  2.7262e-01,  1.5403e-01,  3.0963e-01,
         -4.1930e-02, -2.6031e-01, -1.6600e-01, -2.2887e-01,  2.4247e-01,
         -1.8906e-01],
        [ 2.3847e-01,  1.3682e-02,  1.6216e-01, -3.1535e-01, -1.9286e-01,
         -3.9132e-01, -2.7547e-01,  3.2304e-02, -4.1104e-01, -1.3384e-01,
          1.7719e-02, -6.4069e-02,  2.0584e-01,  2.8663e-01,  2.1736e-02,
          2.1293e-01],
        [ 3.7897e-01,  4.0012e-02,  2.7993e-01, -1.2634e-01, -3.2775e-01,
         -2.4376e-01, -3.5097e-01,  2.0069e-02, -6.4651e-02, -3.0022e-01,
          9.1135e-02,  2.6203e-01, -3.7071e-02,  1.4768e-01, -3.2630e-02,
          2.1387e-01],
        [-1.7974e-01,  1.5894e-01, -5.1262e-02, -4.2159e-02,  2.6667e-01,
         -3.5379e-02,  2.9461e-01,  3.6114e-01,  1.8713e-01,  8.9284e-02,
         -9.4027e-02, -2.7964e-01, -1.9805e-01, -2.2585e-01,  3.5104e-01,
         -2.6373e-01],
        [-7.0542e-02, -1.2689e-01, -4.9470e-02,  4.1307e-01, -1.9968e-02,
          1.2049e-01,  2.3586e-01, -5.9612e-02,  2.7002e-02,  2.8352e-01,
          1.9669e-01, -2.6543e-01, -1.9095e-01, -3.8048e-01, -9.8477e-02,
          4.7887e-02],
        [ 3.7028e-01, -7.0926e-02,  6.1238e-02, -1.9730e-01, -8.4639e-04,
         -4.0635e-01, -2.8981e-01, -2.3305e-01, -2.6763e-01, -1.8094e-01,
          2.0604e-01,  2.2523e-01, -7.0227e-02,  3.4226e-01,  9.6725e-02,
          2.3351e-01],
        [ 2.6545e-01,  1.5289e-01,  3.5246e-01, -4.1054e-01, -2.2386e-01,
         -1.7879e-01, -1.7913e-01, -2.8472e-01, -3.7412e-01, -3.5065e-01,
          2.1000e-02,  3.6432e-01,  2.8998e-01,  1.6132e-01, -2.0167e-01,
          4.0659e-02],
        [ 2.0479e-01, -2.4548e-01,  1.7153e-01, -1.4929e-01,  7.2165e-02,
         -2.5211e-01,  6.3520e-02, -1.6172e-01, -3.5747e-01,  4.0619e-02,
          1.9872e-01, -3.3737e-03,  4.1866e-02,  2.7160e-01, -3.0527e-01,
          3.5079e-01],
        [ 4.5991e-02, -7.8905e-02,  9.6748e-02,  5.0729e-02, -2.1550e-01,
         -2.2117e-01, -1.6894e-02, -3.3110e-01, -1.7510e-01, -3.7497e-01,
         -2.7930e-01,  1.2013e-01,  1.9430e-01,  3.5603e-01, -3.7778e-01,
          9.2826e-02],
        [ 2.2646e-01,  7.0051e-02,  3.0683e-01, -3.8250e-01, -1.7477e-01,
         -1.0910e-01, -3.4781e-01, -2.4624e-02, -3.9597e-01, -1.8929e-02,
          4.4801e-02,  9.9128e-02,  2.3615e-01,  3.0104e-01,  9.6258e-02,
          3.0679e-01],
        [-3.2426e-01,  5.4143e-02,  7.2136e-03,  2.4227e-01,  3.0753e-01,
          3.0879e-02,  3.5039e-01,  1.6901e-01, -5.0823e-02,  1.2850e-01,
          7.6021e-02, -2.7709e-01, -2.2710e-01, -2.3069e-01,  5.5023e-03,
         -1.3291e-01],
        [ 3.0805e-01,  1.1926e-01,  1.4461e-01, -1.6549e-01, -2.9516e-01,
         -2.9741e-01, -1.3991e-01, -3.4320e-01, -3.2133e-02, -1.3271e-01,
          1.0658e-01,  1.5356e-01,  3.6375e-01,  3.5137e-01,  5.0899e-03,
          2.7866e-01],
        [-2.7595e-01,  9.0658e-02, -3.2640e-01,  2.8601e-01, -7.1088e-02,
          1.5686e-01,  3.2773e-01,  3.0836e-01,  3.7210e-01,  2.5688e-01,
          1.5471e-01, -9.8917e-02,  3.8701e-02,  2.8750e-02,  1.4146e-01,
         -2.3975e-01],
        [-2.8897e-01, -6.8620e-02, -5.0382e-02,  5.2008e-02,  1.9150e-01,
          3.9157e-01,  3.7139e-01, -2.5776e-02,  2.3865e-01,  3.4523e-01,
         -2.2708e-01, -1.9182e-02, -3.1631e-01, -3.0263e-01,  2.3432e-03,
         -2.6006e-01],
        [ 6.8279e-02,  7.9084e-02,  2.6846e-01, -9.1462e-02,  8.7793e-03,
         -3.3177e-01, -3.9543e-01, -3.6053e-01, -3.1453e-01, -2.9524e-01,
          8.8470e-02, -1.5857e-03, -2.3050e-02,  2.6672e-01, -2.6592e-01,
          2.1882e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0581, -0.0653,  0.1175, -0.0685, -0.0454, -0.0214,  0.0903,  0.1301,
        -0.0458, -0.0612,  0.0279,  0.0700,  0.2025,  0.1115, -0.0582,  0.1032,
        -0.1348,  0.0004,  0.0276,  0.0024, -0.0070, -0.1172, -0.0590, -0.0135,
        -0.1671,  0.2476,  0.1049,  0.0287, -0.0854, -0.2240,  0.1623, -0.0308],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1850,  0.2759, -0.2008, -0.2151,  0.2668,  0.3214, -0.2566, -0.3481,
         -0.2801,  0.3077,  0.2184,  0.3422, -0.2076, -0.3716,  0.2733, -0.1873,
         -0.2883,  0.2963, -0.1977, -0.2187,  0.3612,  0.2706, -0.3375, -0.3477,
         -0.3114, -0.2972, -0.2869,  0.3057, -0.3122,  0.3505,  0.2535, -0.1983]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0362,  0.0944,  0.0586,  ...,  0.2091, -0.2954, -0.1137],
        [-0.1094, -0.0556,  0.1146,  ...,  0.1485, -0.3039,  0.0871],
        [-0.0054, -0.0261,  0.0237,  ...,  0.0377,  0.2007,  0.0345],
        ...,
        [ 0.0124,  0.0026,  0.0560,  ...,  0.0769, -0.2771, -0.1180],
        [ 0.0841, -0.2002, -0.0524,  ..., -0.3186,  0.1198,  0.1557],
        [-0.2066,  0.1460,  0.0384,  ...,  0.0885, -0.2344, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0353,  0.0405, -0.0681, -0.1361, -0.0729,  0.0659, -0.1096,  0.0426,
        -0.0348,  0.0789,  0.0129,  0.0143,  0.0326,  0.0792, -0.0529, -0.0172,
         0.0549, -0.1611,  0.0060,  0.0271, -0.0429,  0.0267,  0.1103,  0.0070,
        -0.0976,  0.1077,  0.0494, -0.0924,  0.0504,  0.1373,  0.1693, -0.1263],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0816, -0.1658, -0.1343,  ..., -0.1237, -0.0413,  0.0858],
        [-0.1959, -0.0199,  0.0589,  ..., -0.0535, -0.0192,  0.0625],
        [ 0.1222, -0.0464, -0.1283,  ...,  0.0628,  0.0021,  0.1713],
        ...,
        [ 0.1084,  0.0791,  0.1374,  ...,  0.2445, -0.1958,  0.2346],
        [ 0.0034, -0.1302,  0.0108,  ...,  0.0329,  0.2125, -0.1539],
        [ 0.0061, -0.1177,  0.1759,  ...,  0.0483,  0.1387, -0.0380]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0971,  0.1411, -0.0480, -0.0783, -0.0029, -0.0380, -0.0523, -0.0463,
         0.1208, -0.1629,  0.1196, -0.1194,  0.1706,  0.0883, -0.1262,  0.1123,
        -0.1387, -0.1698, -0.0636, -0.0058,  0.0028,  0.0906, -0.2013,  0.2077,
        -0.0506, -0.0050,  0.0791, -0.0308, -0.1324, -0.0700,  0.1087,  0.0338],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3261,  0.2398, -0.3121, -0.3158,  0.1817,  0.1690, -0.2329,  0.1949,
          0.2484, -0.2622, -0.2107,  0.2257,  0.2131,  0.1896,  0.2483,  0.2350,
         -0.3215, -0.3324, -0.1783,  0.2237, -0.2699, -0.2435, -0.3202,  0.1770,
          0.2905,  0.3359, -0.3160,  0.3154, -0.2342, -0.3233,  0.2976,  0.3248]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1032], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-6.7870e-03,  4.2810e-01,  3.0841e-01, -3.3436e-01, -1.8436e-01,
         -1.5515e-01, -3.0633e-02, -3.6674e-01, -1.5713e-01, -7.3358e-02,
          1.4582e-01,  1.8216e-01,  3.5578e-02, -4.1741e-02, -3.9834e-02,
          3.7501e-01],
        [-2.4580e-01, -3.9837e-01, -9.9868e-02,  1.1972e-02, -3.1521e-02,
          2.4903e-01,  1.5147e-01,  1.4885e-01,  3.9572e-01,  1.4703e-01,
          7.8792e-02, -2.5991e-01,  6.9926e-03, -6.7773e-02,  3.5082e-01,
         -8.1227e-02],
        [ 7.3162e-02,  3.0159e-01,  3.7717e-01, -1.2843e-01, -5.7893e-02,
         -3.4690e-01, -2.3948e-02, -3.9597e-01,  4.3231e-02, -7.3545e-02,
         -1.0383e-01, -5.9371e-02,  3.8497e-01,  3.4144e-01,  7.5417e-02,
          2.6079e-01],
        [ 2.6733e-01,  1.3172e-01,  8.4595e-02, -9.7337e-02, -4.4950e-02,
         -2.0012e-01, -1.4112e-01, -8.2037e-02, -4.1653e-01, -4.1946e-01,
          2.2326e-02,  3.6534e-01,  3.0185e-01, -8.2848e-02, -1.9947e-01,
          1.5866e-01],
        [-9.1977e-02,  2.8564e-02, -1.7111e-01, -2.2354e-03,  1.5840e-01,
          8.8854e-02,  3.0458e-02,  3.1523e-01,  1.4565e-01,  3.1547e-01,
          1.0032e-01, -1.6286e-01, -5.0186e-02, -2.7091e-01,  2.7647e-01,
         -1.6127e-01],
        [ 2.2148e-03,  7.5931e-02, -3.5700e-01,  4.1945e-01,  3.1925e-01,
         -2.7530e-02,  2.4361e-01, -4.6768e-02,  2.5085e-01,  2.2371e-01,
         -1.1226e-01, -8.6226e-02, -2.3511e-01,  1.0384e-01,  3.6392e-01,
         -7.7437e-02],
        [ 3.6647e-01,  1.8015e-01,  4.0805e-01, -2.0692e-01, -5.3084e-02,
         -2.1953e-01, -1.6723e-01, -2.2733e-01, -2.4671e-01, -4.3506e-02,
         -8.0949e-03,  6.9207e-02, -6.1654e-02,  2.1184e-01, -2.6628e-01,
          1.5706e-01],
        [-6.7792e-02,  3.2217e-01,  3.5525e-01, -3.7231e-01, -3.2018e-01,
         -3.0491e-01, -7.4924e-02, -2.5266e-01, -2.0021e-01, -2.3328e-01,
         -8.9889e-02,  4.0382e-02,  2.4769e-01, -7.6754e-02, -4.7043e-02,
          3.5609e-01],
        [ 2.9799e-02,  3.6633e-01,  3.0001e-01, -2.6655e-01, -4.7252e-02,
         -3.4773e-01, -1.5213e-01, -9.5790e-02,  4.6023e-02, -3.2864e-01,
          7.9637e-03,  5.5924e-02, -6.5555e-02,  1.9049e-01, -3.4039e-01,
          9.7090e-02],
        [-2.8436e-01, -1.5886e-01, -9.9307e-02,  8.2923e-03,  6.7488e-02,
          1.5919e-01,  3.6328e-02,  2.3213e-01,  2.6930e-01,  1.6571e-02,
          1.3380e-01, -7.9370e-03, -2.6294e-01, -1.1223e-01,  1.6837e-01,
         -2.0449e-01],
        [-3.5348e-01, -5.9879e-03, -6.6195e-02, -8.9794e-03, -4.4486e-02,
          4.3327e-01,  2.2257e-01,  1.1554e-01,  3.5553e-01,  2.7362e-01,
         -3.2014e-04, -1.0904e-03, -2.0033e-01,  6.3199e-02, -7.7186e-03,
         -3.3888e-01],
        [-1.1927e-01, -2.0134e-01, -2.1412e-02,  1.1140e-01,  1.5798e-01,
          1.2105e-01,  3.4986e-01,  1.4420e-01,  1.5616e-01,  3.6466e-01,
          1.1246e-01,  6.4150e-02, -4.1300e-01, -2.6446e-01,  6.3614e-02,
         -2.0895e-01],
        [ 3.3356e-01,  3.2289e-01,  1.7294e-01, -2.0259e-01, -1.0820e-01,
          1.1390e-02, -7.6149e-02, -3.1777e-01, -3.3090e-01, -1.3214e-01,
         -1.1036e-01,  4.2964e-02, -3.2333e-02,  2.2682e-01, -2.5048e-01,
          4.4604e-02],
        [ 2.0310e-01,  3.8853e-01,  3.6597e-01, -3.2043e-02, -3.0305e-01,
         -2.4751e-02, -2.8503e-02, -6.4979e-02, -2.1718e-01, -1.8123e-01,
         -1.2084e-01,  1.1265e-01,  1.2046e-01,  8.0824e-02, -3.4339e-01,
          2.4090e-01],
        [-3.7189e-01, -3.5630e-01, -6.8472e-02, -2.0548e-02,  3.6407e-01,
          4.1732e-01,  8.8852e-02,  1.1524e-01, -2.6284e-02,  2.0199e-01,
          4.7237e-02, -3.1759e-01, -9.2211e-02, -1.4756e-01,  4.3784e-02,
         -1.6673e-01],
        [-2.8647e-01, -3.4395e-01, -1.0803e-02,  3.0390e-01, -2.2669e-02,
          2.1046e-01,  6.4940e-02, -6.1449e-02,  7.0787e-02,  1.8048e-01,
          5.8944e-02,  1.5445e-01, -1.0282e-01, -3.0806e-01,  3.8668e-01,
         -1.1678e-01],
        [ 3.1215e-01,  2.9976e-01,  2.0241e-01, -3.7845e-01, -3.4126e-01,
         -4.6139e-02, -9.0759e-02,  1.1263e-02, -3.7115e-01, -2.0960e-01,
          1.8263e-01,  2.9609e-01,  3.5489e-01,  3.0659e-01, -1.1509e-01,
         -1.7529e-02],
        [-2.9379e-01, -2.0097e-02, -2.4904e-01,  1.6688e-01,  1.1502e-01,
          3.1036e-01,  2.7663e-01,  2.6099e-01,  1.4233e-01,  3.0948e-01,
         -3.3634e-02, -2.5556e-01, -1.6700e-01, -2.3078e-01,  2.3035e-01,
         -1.8223e-01],
        [ 2.2911e-01,  1.8079e-01,  1.5575e-01, -3.0454e-01, -1.8223e-01,
         -3.8937e-01, -2.7201e-01,  4.0152e-02, -4.0568e-01, -1.3120e-01,
          2.0098e-02, -7.0518e-02,  2.0154e-01,  2.8848e-01,  3.8837e-02,
          2.0357e-01],
        [ 3.7110e-01,  2.0195e-01,  2.7386e-01, -1.1801e-01, -3.1558e-01,
         -2.4126e-01, -3.5044e-01,  3.0909e-02, -5.4235e-02, -2.9893e-01,
          8.7167e-02,  2.5670e-01, -4.1633e-02,  1.5290e-01, -1.4546e-02,
          2.0586e-01],
        [-1.7425e-01,  1.0002e-02, -4.6535e-02, -5.0339e-02,  2.6025e-01,
         -3.4784e-02,  2.9553e-01,  3.5350e-01,  1.7893e-01,  8.9144e-02,
         -7.0202e-02, -2.7500e-01, -2.0002e-01, -2.3117e-01,  3.5546e-01,
         -2.5756e-01],
        [-6.4165e-02, -3.8146e-01, -4.2080e-02,  4.0086e-01, -3.3927e-02,
          1.1612e-01,  2.3488e-01, -6.5959e-02,  1.7925e-02,  2.8017e-01,
          2.0243e-01, -2.5684e-01, -1.8840e-01, -3.7898e-01, -1.1014e-01,
          5.6116e-02],
        [ 3.6415e-01,  6.9869e-02,  5.5987e-02, -1.8859e-01,  9.0966e-03,
         -4.0562e-01, -2.9078e-01, -2.2447e-01, -2.5821e-01, -1.8074e-01,
          1.8741e-01,  2.2105e-01, -7.0930e-02,  3.4393e-01,  1.1481e-01,
          2.2713e-01],
        [ 2.5511e-01,  2.4191e-01,  3.4542e-01, -3.9869e-01, -2.0299e-01,
         -1.7645e-01, -1.7474e-01, -2.6581e-01, -3.5936e-01, -3.4801e-01,
          4.6606e-03,  3.5705e-01,  2.8209e-01,  1.6494e-01, -1.7459e-01,
          3.2880e-02],
        [ 2.0269e-01, -5.4504e-02,  1.6948e-01, -1.4328e-01,  7.8132e-02,
         -2.5344e-01,  6.2083e-02, -1.5735e-01, -3.5335e-01,  3.8444e-02,
          2.0190e-01, -5.2021e-03,  4.4847e-02,  2.7545e-01, -3.0041e-01,
          3.4715e-01],
        [ 3.9388e-02,  9.3539e-02,  9.0922e-02,  5.8903e-02, -2.0557e-01,
         -2.1990e-01, -1.0997e-02, -3.2116e-01, -1.6682e-01, -3.7365e-01,
         -3.0209e-01,  1.1444e-01,  1.8996e-01,  3.5691e-01, -3.7128e-01,
          8.5564e-02],
        [ 2.1750e-01,  2.2289e-01,  3.0026e-01, -3.7254e-01, -1.6106e-01,
         -1.0633e-01, -3.4862e-01, -1.1370e-02, -3.8382e-01, -1.7086e-02,
          2.5803e-02,  9.4155e-02,  2.2962e-01,  3.1299e-01,  1.1850e-01,
          2.9930e-01],
        [-3.1936e-01, -1.0267e-01,  1.1889e-02,  2.3268e-01,  2.9807e-01,
          2.8095e-02,  3.5153e-01,  1.6436e-01, -5.8778e-02,  1.2878e-01,
          9.6559e-02, -2.7202e-01, -2.2510e-01, -2.3731e-01, -8.9734e-03,
         -1.2716e-01],
        [ 2.9930e-01,  2.1219e-01,  1.3800e-01, -1.5629e-01, -2.8059e-01,
         -2.9290e-01, -1.3818e-01, -3.2987e-01, -2.0509e-02, -1.3068e-01,
          8.2687e-02,  1.4790e-01,  3.5501e-01,  3.5505e-01,  2.7667e-02,
          2.7112e-01],
        [-2.6931e-01, -3.1140e-02, -3.2097e-01,  2.7648e-01, -8.2613e-02,
          1.5759e-01,  3.2698e-01,  2.9874e-01,  3.6189e-01,  2.5619e-01,
          1.6529e-01, -9.4229e-02,  3.9110e-02,  2.4492e-02,  1.3341e-01,
         -2.3308e-01],
        [-2.8062e-01, -2.1904e-01, -4.3858e-02,  4.2477e-02,  1.7786e-01,
          3.9003e-01,  3.6980e-01, -3.8960e-02,  2.2751e-01,  3.4340e-01,
         -2.1587e-01, -1.3694e-02, -3.1306e-01, -3.0364e-01, -1.8732e-02,
         -2.5182e-01],
        [ 5.8228e-02,  2.0538e-01,  2.6197e-01, -7.9416e-02,  2.6115e-02,
         -3.2939e-01, -3.9232e-01, -3.5153e-01, -3.0668e-01, -2.9315e-01,
          7.3931e-02, -7.0605e-03, -3.1022e-02,  2.6571e-01, -2.3424e-01,
          2.0932e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0840, -0.0361,  0.1056, -0.0648, -0.0435, -0.0289,  0.0881,  0.1234,
        -0.0498, -0.0429,  0.0073,  0.0854,  0.1589,  0.0907, -0.0358, -0.0377,
        -0.1493,  0.0025,  0.0239, -0.0006, -0.0027, -0.1137, -0.0610, -0.0233,
        -0.1372,  0.2442,  0.0923,  0.0384, -0.1013, -0.2238,  0.1741, -0.0457],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1874,  0.2733, -0.1972, -0.2137,  0.2660,  0.3184, -0.2538, -0.3438,
         -0.2927,  0.2983,  0.2170,  0.3352, -0.2072, -0.3717,  0.2705,  0.1660,
         -0.2835,  0.2939, -0.1947, -0.2159,  0.3509,  0.2732, -0.3349, -0.3445,
         -0.3164, -0.2935, -0.2838,  0.2973, -0.3100,  0.3472,  0.2525, -0.1965]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0172,  0.0858,  0.0828,  ...,  0.1477, -0.2136, -0.1137],
        [-0.1163, -0.0511,  0.1187,  ...,  0.1257, -0.2876,  0.0871],
        [-0.0036, -0.0221,  0.0318,  ...,  0.0365,  0.1952,  0.0345],
        ...,
        [ 0.0074,  0.0017,  0.0611,  ...,  0.0529, -0.2620, -0.1180],
        [ 0.0937, -0.2039, -0.0574,  ..., -0.2917,  0.1060,  0.1557],
        [-0.2018,  0.1536,  0.0416,  ...,  0.0606, -0.2237, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0433,  0.0433, -0.0732, -0.1359, -0.0722,  0.0626, -0.1114,  0.0483,
        -0.0325,  0.0776,  0.0143,  0.0142,  0.0328,  0.0779, -0.0538, -0.0150,
         0.0550, -0.1635, -0.0553,  0.0334, -0.0453,  0.0248,  0.1088,  0.0035,
        -0.0984,  0.0546,  0.0478, -0.1037,  0.0504,  0.1374,  0.1689, -0.1249],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0765, -0.1696, -0.1239,  ..., -0.1188, -0.0413,  0.0842],
        [-0.2017, -0.0228,  0.0781,  ..., -0.0478, -0.0231,  0.0600],
        [ 0.1225, -0.0469, -0.1366,  ...,  0.0570,  0.0075,  0.1675],
        ...,
        [ 0.1030,  0.0723,  0.1352,  ...,  0.2345, -0.1874,  0.2248],
        [ 0.0004, -0.1318,  0.0221,  ...,  0.0399,  0.2070, -0.1532],
        [ 0.0085, -0.1118,  0.1776,  ...,  0.0588,  0.1283, -0.0278]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 1.0088e-01,  1.4944e-01, -4.6179e-02, -7.9337e-02, -1.1830e-02,
        -3.1736e-02, -5.0157e-02, -4.8022e-02,  1.2659e-01, -1.6723e-01,
         1.0647e-01, -1.2760e-01,  1.8108e-01,  9.6512e-02, -1.3392e-01,
         1.1359e-01, -1.3647e-01, -1.6648e-01,  3.5341e-02, -1.0230e-02,
         8.5703e-05,  9.2434e-02, -1.9136e-01,  2.1645e-01, -4.8212e-02,
        -9.2870e-03,  8.5124e-02, -2.5719e-02, -1.2861e-01, -6.7064e-02,
         1.1098e-01,  2.8519e-02], device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3345,  0.2481, -0.3181, -0.3100,  0.1851,  0.1784, -0.2372,  0.1908,
          0.2386, -0.2697, -0.2179,  0.2237,  0.2151,  0.2026,  0.2493,  0.2457,
         -0.3223, -0.3346,  0.1857,  0.2254, -0.2701, -0.2478, -0.3266,  0.1767,
          0.2912,  0.3366, -0.3157,  0.3129, -0.2385, -0.3244,  0.2999,  0.3235]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1026], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-6.7870e-03,  4.2810e-01,  3.0841e-01, -3.3436e-01, -1.8436e-01,
         -1.5515e-01, -3.0633e-02, -3.6674e-01, -1.5713e-01, -7.3358e-02,
          1.4582e-01,  1.8216e-01,  3.5578e-02, -4.1741e-02, -3.9834e-02,
          3.7500e-01],
        [-2.4580e-01, -3.9837e-01, -9.9868e-02,  1.1972e-02, -3.1521e-02,
          2.4903e-01,  1.5147e-01,  1.4885e-01,  3.9572e-01,  1.4703e-01,
          7.8792e-02, -2.5991e-01,  6.9926e-03, -6.7773e-02,  3.5082e-01,
         -8.1227e-02],
        [ 7.3162e-02,  3.0159e-01,  3.7717e-01, -1.2843e-01, -5.7893e-02,
         -3.4690e-01, -2.3948e-02, -3.9597e-01,  4.3231e-02, -7.3545e-02,
         -1.0383e-01, -5.9371e-02,  3.8497e-01,  3.4144e-01,  7.5417e-02,
          2.6079e-01],
        [ 2.6733e-01,  1.3172e-01,  8.4595e-02, -9.7337e-02, -4.4950e-02,
         -2.0012e-01, -1.4112e-01, -8.2037e-02, -4.1653e-01, -4.1946e-01,
          2.2326e-02,  3.6534e-01,  3.0185e-01, -8.2848e-02, -1.9947e-01,
          1.5866e-01],
        [-9.1977e-02,  2.8564e-02, -1.7111e-01, -2.2354e-03,  1.5840e-01,
          8.8854e-02,  3.0458e-02,  3.1523e-01,  1.4565e-01,  3.1547e-01,
          1.0032e-01, -1.6286e-01, -5.0186e-02, -2.7091e-01,  2.7647e-01,
         -1.6127e-01],
        [ 2.2148e-03,  7.5931e-02, -3.5700e-01,  4.1945e-01,  3.1925e-01,
         -2.7530e-02,  2.4361e-01, -4.6768e-02,  2.5085e-01,  2.2371e-01,
         -1.1226e-01, -8.6226e-02, -2.3511e-01,  1.0384e-01,  3.6392e-01,
         -7.7437e-02],
        [ 3.6647e-01,  1.8015e-01,  4.0805e-01, -2.0692e-01, -5.3084e-02,
         -2.1953e-01, -1.6723e-01, -2.2733e-01, -2.4671e-01, -4.3506e-02,
         -8.0949e-03,  6.9207e-02, -6.1654e-02,  2.1184e-01, -2.6628e-01,
          1.5706e-01],
        [-6.7792e-02,  3.2217e-01,  3.5525e-01, -3.7231e-01, -3.2018e-01,
         -3.0491e-01, -7.4924e-02, -2.5266e-01, -2.0021e-01, -2.3328e-01,
         -8.9889e-02,  4.0382e-02,  2.4769e-01, -7.6754e-02, -4.7043e-02,
          3.5609e-01],
        [ 2.9799e-02,  3.6633e-01,  3.0001e-01, -2.6655e-01, -4.7253e-02,
         -3.4773e-01, -1.5213e-01, -9.5790e-02,  4.6023e-02, -3.2864e-01,
          7.9637e-03,  5.5924e-02, -6.5555e-02,  1.9049e-01, -3.4039e-01,
          9.7090e-02],
        [-2.8436e-01, -1.5886e-01, -9.9307e-02,  8.2923e-03,  6.7488e-02,
          1.5919e-01,  3.6328e-02,  2.3213e-01,  2.6930e-01,  1.6571e-02,
          1.3380e-01, -7.9370e-03, -2.6294e-01, -1.1223e-01,  1.6837e-01,
         -2.0449e-01],
        [-3.5348e-01, -5.9879e-03, -6.6195e-02, -8.9794e-03, -4.4486e-02,
          4.3327e-01,  2.2257e-01,  1.1554e-01,  3.5553e-01,  2.7362e-01,
         -3.2014e-04, -1.0904e-03, -2.0033e-01,  6.3199e-02, -7.7186e-03,
         -3.3888e-01],
        [-1.1927e-01, -2.0134e-01, -2.1412e-02,  1.1140e-01,  1.5798e-01,
          1.2105e-01,  3.4986e-01,  1.4420e-01,  1.5616e-01,  3.6466e-01,
          1.1246e-01,  6.4150e-02, -4.1300e-01, -2.6446e-01,  6.3614e-02,
         -2.0895e-01],
        [ 3.3356e-01,  3.2289e-01,  1.7294e-01, -2.0259e-01, -1.0820e-01,
          1.1390e-02, -7.6149e-02, -3.1777e-01, -3.3089e-01, -1.3214e-01,
         -1.1036e-01,  4.2964e-02, -3.2333e-02,  2.2682e-01, -2.5048e-01,
          4.4604e-02],
        [ 2.0310e-01,  3.8853e-01,  3.6597e-01, -3.2043e-02, -3.0305e-01,
         -2.4751e-02, -2.8503e-02, -6.4979e-02, -2.1718e-01, -1.8123e-01,
         -1.2084e-01,  1.1265e-01,  1.2046e-01,  8.0824e-02, -3.4339e-01,
          2.4090e-01],
        [-3.7189e-01, -3.5630e-01, -6.8472e-02, -2.0548e-02,  3.6407e-01,
          4.1732e-01,  8.8852e-02,  1.1524e-01, -2.6284e-02,  2.0199e-01,
          4.7237e-02, -3.1759e-01, -9.2211e-02, -1.4756e-01,  4.3784e-02,
         -1.6673e-01],
        [-2.8647e-01, -3.4395e-01, -1.0803e-02,  3.0390e-01, -2.2669e-02,
          2.1046e-01,  6.4939e-02, -6.1449e-02,  7.0787e-02,  1.8048e-01,
          5.8944e-02,  1.5445e-01, -1.0282e-01, -3.0806e-01,  3.8668e-01,
         -1.1678e-01],
        [ 3.1215e-01,  2.9976e-01,  2.0241e-01, -3.7845e-01, -3.4126e-01,
         -4.6139e-02, -9.0759e-02,  1.1263e-02, -3.7115e-01, -2.0960e-01,
          1.8263e-01,  2.9609e-01,  3.5489e-01,  3.0659e-01, -1.1509e-01,
         -1.7529e-02],
        [-2.9379e-01, -2.0097e-02, -2.4904e-01,  1.6688e-01,  1.1502e-01,
          3.1036e-01,  2.7663e-01,  2.6099e-01,  1.4233e-01,  3.0948e-01,
         -3.3634e-02, -2.5556e-01, -1.6700e-01, -2.3078e-01,  2.3035e-01,
         -1.8223e-01],
        [ 2.2911e-01,  1.8079e-01,  1.5575e-01, -3.0454e-01, -1.8223e-01,
         -3.8937e-01, -2.7201e-01,  4.0152e-02, -4.0568e-01, -1.3120e-01,
          2.0098e-02, -7.0518e-02,  2.0154e-01,  2.8848e-01,  3.8837e-02,
          2.0357e-01],
        [ 3.7110e-01,  2.0195e-01,  2.7386e-01, -1.1801e-01, -3.1558e-01,
         -2.4126e-01, -3.5044e-01,  3.0909e-02, -5.4235e-02, -2.9893e-01,
          8.7167e-02,  2.5670e-01, -4.1633e-02,  1.5290e-01, -1.4546e-02,
          2.0586e-01],
        [-1.7425e-01,  1.0002e-02, -4.6535e-02, -5.0339e-02,  2.6025e-01,
         -3.4784e-02,  2.9553e-01,  3.5350e-01,  1.7893e-01,  8.9144e-02,
         -7.0202e-02, -2.7500e-01, -2.0002e-01, -2.3117e-01,  3.5546e-01,
         -2.5756e-01],
        [-6.4165e-02, -3.8146e-01, -4.2080e-02,  4.0086e-01, -3.3927e-02,
          1.1612e-01,  2.3488e-01, -6.5959e-02,  1.7925e-02,  2.8017e-01,
          2.0243e-01, -2.5684e-01, -1.8840e-01, -3.7898e-01, -1.1014e-01,
          5.6116e-02],
        [ 3.6415e-01,  6.9869e-02,  5.5987e-02, -1.8859e-01,  9.0966e-03,
         -4.0562e-01, -2.9078e-01, -2.2447e-01, -2.5821e-01, -1.8074e-01,
          1.8741e-01,  2.2105e-01, -7.0930e-02,  3.4393e-01,  1.1481e-01,
          2.2713e-01],
        [ 2.5511e-01,  2.4191e-01,  3.4542e-01, -3.9869e-01, -2.0299e-01,
         -1.7645e-01, -1.7474e-01, -2.6581e-01, -3.5936e-01, -3.4801e-01,
          4.6606e-03,  3.5705e-01,  2.8209e-01,  1.6494e-01, -1.7459e-01,
          3.2880e-02],
        [ 2.0269e-01, -5.4504e-02,  1.6948e-01, -1.4328e-01,  7.8132e-02,
         -2.5344e-01,  6.2083e-02, -1.5735e-01, -3.5335e-01,  3.8444e-02,
          2.0190e-01, -5.2021e-03,  4.4847e-02,  2.7545e-01, -3.0041e-01,
          3.4715e-01],
        [ 3.9388e-02,  9.3539e-02,  9.0922e-02,  5.8903e-02, -2.0557e-01,
         -2.1990e-01, -1.0997e-02, -3.2116e-01, -1.6682e-01, -3.7365e-01,
         -3.0209e-01,  1.1444e-01,  1.8996e-01,  3.5691e-01, -3.7128e-01,
          8.5564e-02],
        [ 2.1750e-01,  2.2289e-01,  3.0026e-01, -3.7254e-01, -1.6106e-01,
         -1.0633e-01, -3.4862e-01, -1.1370e-02, -3.8382e-01, -1.7086e-02,
          2.5803e-02,  9.4154e-02,  2.2962e-01,  3.1299e-01,  1.1850e-01,
          2.9930e-01],
        [-3.1936e-01, -1.0267e-01,  1.1889e-02,  2.3268e-01,  2.9807e-01,
          2.8095e-02,  3.5153e-01,  1.6436e-01, -5.8778e-02,  1.2878e-01,
          9.6559e-02, -2.7202e-01, -2.2510e-01, -2.3731e-01, -8.9734e-03,
         -1.2716e-01],
        [ 2.9930e-01,  2.1219e-01,  1.3800e-01, -1.5629e-01, -2.8059e-01,
         -2.9290e-01, -1.3818e-01, -3.2987e-01, -2.0509e-02, -1.3068e-01,
          8.2687e-02,  1.4790e-01,  3.5501e-01,  3.5505e-01,  2.7667e-02,
          2.7112e-01],
        [-2.6931e-01, -3.1140e-02, -3.2097e-01,  2.7648e-01, -8.2613e-02,
          1.5759e-01,  3.2698e-01,  2.9874e-01,  3.6189e-01,  2.5619e-01,
          1.6529e-01, -9.4229e-02,  3.9110e-02,  2.4492e-02,  1.3341e-01,
         -2.3308e-01],
        [-2.8062e-01, -2.1904e-01, -4.3858e-02,  4.2477e-02,  1.7786e-01,
          3.9003e-01,  3.6980e-01, -3.8960e-02,  2.2751e-01,  3.4340e-01,
         -2.1587e-01, -1.3694e-02, -3.1306e-01, -3.0364e-01, -1.8732e-02,
         -2.5182e-01],
        [ 5.8228e-02,  2.0538e-01,  2.6197e-01, -7.9416e-02,  2.6115e-02,
         -3.2939e-01, -3.9232e-01, -3.5153e-01, -3.0668e-01, -2.9315e-01,
          7.3931e-02, -7.0606e-03, -3.1023e-02,  2.6571e-01, -2.3424e-01,
          2.0932e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0840, -0.0361,  0.1056, -0.0648, -0.0435, -0.0289,  0.0881,  0.1234,
        -0.0498, -0.0429,  0.0073,  0.0854,  0.1589,  0.0907, -0.0358, -0.0377,
        -0.1493,  0.0025,  0.0239, -0.0006, -0.0027, -0.1137, -0.0610, -0.0233,
        -0.1372,  0.2442,  0.0923,  0.0384, -0.1013, -0.2238,  0.1741, -0.0457],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1874,  0.2733, -0.1972, -0.2137,  0.2660,  0.3184, -0.2538, -0.3438,
         -0.2927,  0.2983,  0.2170,  0.3352, -0.2072, -0.3717,  0.2705,  0.1660,
         -0.2835,  0.2939, -0.1947, -0.2159,  0.3509,  0.2732, -0.3349, -0.3445,
         -0.3164, -0.2935, -0.2838,  0.2973, -0.3100,  0.3472,  0.2525, -0.1965]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0172,  0.0858,  0.0828,  ...,  0.1477, -0.2136, -0.1137],
        [-0.1163, -0.0511,  0.1187,  ...,  0.1257, -0.2876,  0.0871],
        [-0.0036, -0.0221,  0.0318,  ...,  0.0365,  0.1952,  0.0345],
        ...,
        [ 0.0074,  0.0017,  0.0611,  ...,  0.0529, -0.2620, -0.1180],
        [ 0.0937, -0.2039, -0.0574,  ..., -0.2917,  0.1060,  0.1557],
        [-0.2018,  0.1536,  0.0416,  ...,  0.0606, -0.2237, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0433,  0.0433, -0.0732, -0.1359, -0.0722,  0.0626, -0.1114,  0.0483,
        -0.0325,  0.0776,  0.0143,  0.0142,  0.0328,  0.0779, -0.0538, -0.0150,
         0.0550, -0.1635, -0.0553,  0.0334, -0.0453,  0.0248,  0.1088,  0.0035,
        -0.0984,  0.0546,  0.0478, -0.1037,  0.0504,  0.1374,  0.1689, -0.1249],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0765, -0.1696, -0.1239,  ..., -0.1188, -0.0413,  0.0842],
        [-0.2017, -0.0228,  0.0781,  ..., -0.0478, -0.0231,  0.0600],
        [ 0.1225, -0.0469, -0.1366,  ...,  0.0570,  0.0075,  0.1675],
        ...,
        [ 0.1030,  0.0723,  0.1352,  ...,  0.2345, -0.1874,  0.2248],
        [ 0.0004, -0.1318,  0.0221,  ...,  0.0399,  0.2070, -0.1532],
        [ 0.0085, -0.1118,  0.1776,  ...,  0.0588,  0.1283, -0.0278]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 1.0088e-01,  1.4944e-01, -4.6179e-02, -7.9337e-02, -1.1830e-02,
        -3.1736e-02, -5.0157e-02, -4.8022e-02,  1.2659e-01, -1.6723e-01,
         1.0647e-01, -1.2760e-01,  1.8108e-01,  9.6512e-02, -1.3392e-01,
         1.1359e-01, -1.3647e-01, -1.6648e-01,  3.5341e-02, -1.0230e-02,
         8.5700e-05,  9.2434e-02, -1.9136e-01,  2.1645e-01, -4.8212e-02,
        -9.2870e-03,  8.5124e-02, -2.5719e-02, -1.2861e-01, -6.7064e-02,
         1.1098e-01,  2.8519e-02], device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3345,  0.2481, -0.3181, -0.3100,  0.1851,  0.1784, -0.2372,  0.1908,
          0.2386, -0.2697, -0.2179,  0.2237,  0.2151,  0.2026,  0.2493,  0.2457,
         -0.3223, -0.3346,  0.1857,  0.2254, -0.2701, -0.2478, -0.3266,  0.1767,
          0.2912,  0.3366, -0.3157,  0.3129, -0.2385, -0.3244,  0.2999,  0.3235]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1026], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 3.9812e-02,  4.2037e-01,  3.5144e-01, -3.6891e-01,  1.8256e-01,
         -1.9399e-01, -8.6050e-02, -1.4255e-02,  1.9977e-01, -1.1213e-01,
          8.7937e-02, -2.1148e-01, -2.8098e-01,  2.5377e-03,  3.2373e-01,
          4.1836e-01],
        [-3.0054e-01, -4.3951e-01, -1.5166e-01,  4.8987e-02, -3.6594e-01,
          2.9318e-01,  1.5847e-01, -2.5421e-01,  3.2373e-02,  1.5134e-01,
          2.1661e-01,  1.7817e-01,  2.8560e-01, -1.2395e-01,  1.9478e-02,
         -1.3564e-01],
        [ 1.4709e-01,  3.4417e-01,  4.3464e-01, -1.8191e-01,  3.5053e-01,
         -4.0798e-01,  1.8296e-02, -2.8805e-03,  4.5731e-01, -1.5058e-01,
          4.5138e-02, -4.8457e-01,  5.1384e-02,  3.9989e-01,  4.5751e-01,
          3.3048e-01],
        [-1.6528e-01, -3.1567e-01, -3.3483e-01,  3.3955e-01, -1.6161e-01,
          2.3672e-01,  2.0444e-01, -1.5929e-01, -4.9721e-01,  4.9027e-02,
          5.6866e-02,  4.2427e-01,  2.5357e-01, -4.6870e-01, -3.2826e-01,
         -2.7118e-01],
        [-1.4816e-01, -1.6875e-02, -2.1553e-01,  2.7839e-02, -1.9215e-01,
          1.3082e-01,  6.0761e-02, -9.9573e-02, -2.2276e-01,  3.5011e-01,
          1.9912e-01,  2.7977e-01,  3.3783e-01, -3.1576e-01, -5.2024e-02,
         -2.1369e-01],
        [-6.7973e-02,  1.4263e-02, -4.1340e-01,  4.6468e-01, -3.0152e-02,
          3.0588e-02,  2.8178e-01, -4.3941e-01, -1.4192e-01,  2.7196e-01,
         -2.8287e-02,  3.3976e-01, -3.6892e-03,  5.0517e-02,  2.2685e-02,
         -1.4326e-01],
        [ 3.5483e-01,  2.3323e-01,  4.7011e-01, -2.5224e-01,  2.4722e-01,
         -2.3715e-01, -2.5522e-01,  1.7242e-01,  1.1914e-01,  6.1745e-02,
         -5.9855e-02, -3.5417e-01, -1.7210e-01,  2.9874e-01, -1.5059e-03,
          2.1658e-01],
        [-1.4930e-02,  3.9123e-01,  4.2120e-01, -4.2215e-01, -3.0955e-02,
         -3.5755e-01, -1.1818e-01,  1.0851e-01,  1.1039e-01, -2.0997e-01,
         -5.9647e-02, -3.5581e-01,  6.5823e-02, -5.2766e-03,  1.5314e-01,
          4.2794e-01],
        [ 7.7385e-02,  4.0046e-01,  3.4155e-01, -2.9789e-01,  2.9108e-01,
         -3.8399e-01, -1.1415e-01,  2.9856e-01,  3.7000e-01, -3.4836e-01,
         -9.3570e-02, -3.6808e-01, -4.1406e-01,  2.2849e-01, -2.5558e-02,
          1.4837e-01],
        [-3.4159e-01, -2.0753e-01, -1.4587e-01,  4.0724e-02, -2.8633e-01,
          2.0255e-01, -1.8181e-02, -1.7894e-01, -9.1553e-02,  5.8764e-02,
          1.4656e-01,  4.2897e-01,  1.3891e-01, -1.5759e-01, -1.5450e-01,
         -2.5868e-01],
        [-4.1815e-01, -4.2924e-02, -1.1717e-01,  3.7878e-02, -4.3865e-01,
          4.8619e-01,  1.8505e-01, -3.1098e-01, -7.8996e-02,  3.3476e-01,
          2.5989e-02,  4.6166e-01,  2.0508e-01,  2.7757e-02, -4.2896e-01,
         -3.9992e-01],
        [-1.8952e-01, -2.5619e-01, -8.2053e-02,  1.5759e-01, -1.7674e-01,
          1.7654e-01,  1.3047e-01, -2.5718e-01,  2.4580e-02,  4.1772e-01,
          1.0526e-01,  4.9264e-01, -9.9045e-03, -3.3249e-01, -7.1172e-02,
         -2.7887e-01],
        [ 3.7801e-01,  3.3645e-01,  2.1853e-01, -2.3191e-01,  2.6517e-01,
         -2.0296e-02, -6.3381e-02,  1.1937e-01,  9.5903e-02, -7.4640e-02,
         -2.0209e-01, -4.2245e-01, -2.3006e-01,  2.5074e-01,  1.5148e-01,
          9.0864e-02],
        [ 2.7026e-01,  4.5331e-01,  4.2520e-01, -7.7954e-02,  2.1234e-02,
         -7.8279e-02, -7.3698e-02,  3.1684e-01,  1.1893e-01, -1.9472e-01,
         -1.8102e-01, -2.9902e-01, -1.5699e-01,  1.4731e-01, -5.0684e-02,
          3.1077e-01],
        [-4.4091e-01, -4.1762e-01, -1.2680e-01,  2.7142e-02,  1.5014e-02,
          4.7360e-01,  2.7122e-02, -2.8653e-01, -3.6406e-01,  2.5315e-01,
          5.6573e-02,  1.1765e-01,  2.6199e-01, -2.0603e-01, -2.5681e-01,
         -2.3434e-01],
        [-3.8912e-01, -3.2856e-01, -4.7128e-02,  3.4857e-01, -2.4720e-01,
          2.8629e-01,  1.0889e-01, -2.0333e-01, -7.4707e-02,  2.6474e-01,
          3.3408e-02,  3.3041e-01,  3.4158e-03, -3.1682e-01,  1.3779e-01,
         -1.8592e-01],
        [ 3.8391e-01,  3.7836e-01,  2.6857e-01, -4.3142e-01, -2.8273e-02,
         -1.0692e-01, -1.2158e-01,  3.8205e-01, -1.6463e-02, -2.4093e-01,
          1.5905e-01, -1.1793e-01,  6.3358e-02,  3.9000e-01,  1.5353e-01,
          5.7254e-02],
        [-3.6213e-01, -1.1201e-01, -3.2112e-01,  2.2354e-01, -1.6647e-01,
          3.7261e-01,  3.3548e-01, -9.2804e-02, -1.8273e-01,  3.0181e-01,
         -2.1506e-02,  1.4375e-01,  3.9038e-02, -3.2894e-01,  1.5831e-02,
         -2.6110e-01],
        [ 2.9949e-01,  2.1745e-01,  2.1098e-01, -3.5639e-01,  2.0748e-01,
         -4.4633e-01, -2.8423e-01,  4.2124e-01, -3.9058e-02, -1.9600e-01,
          1.8889e-02, -4.8602e-01, -1.0463e-01,  3.4620e-01,  3.7452e-01,
          2.7090e-01],
        [ 4.4072e-01,  2.5531e-01,  3.2877e-01, -1.6784e-01,  5.3081e-02,
         -2.9723e-01, -2.8389e-01,  4.4243e-01,  3.6355e-01, -3.6812e-01,
         -2.0296e-02, -1.9077e-01, -4.1953e-01,  2.0471e-01,  3.5983e-01,
          2.7305e-01],
        [-2.3426e-01, -4.4479e-02, -9.2358e-02, -1.7559e-02, -4.0693e-02,
          1.7768e-02,  2.6329e-01, -5.2351e-03, -1.7231e-01,  1.2942e-01,
         -5.3335e-02,  1.3255e-01,  6.9013e-02, -2.9917e-01,  6.7610e-02,
         -3.1314e-01],
        [-1.1815e-01, -4.5209e-01, -8.5869e-02,  4.3069e-01, -3.8921e-01,
          1.5851e-01,  1.1831e-01, -4.6498e-01, -3.3000e-01,  3.1911e-01,
          1.3379e-01,  1.6812e-01,  1.7264e-01, -4.3385e-01, -4.1296e-01,
         -4.6997e-04],
        [ 4.2021e-01,  1.2055e-01,  1.1261e-01, -2.2945e-01,  3.0991e-01,
         -4.5114e-01, -3.0965e-01,  1.4548e-01,  6.7134e-02, -1.7872e-01,
          9.5645e-02, -1.8548e-01, -2.9522e-01,  4.0564e-01,  3.8412e-01,
          2.9121e-01],
        [ 3.3146e-01,  2.8678e-01,  4.2123e-01, -4.5717e-01,  4.5800e-02,
         -2.4492e-01, -1.9253e-01,  6.5853e-02, -9.8250e-02, -3.5593e-01,
         -4.5152e-02, -3.0038e-02,  4.6881e-02,  2.5227e-01,  1.4464e-02,
          1.1701e-01],
        [ 2.5213e-01, -1.7419e-02,  2.1507e-01, -1.7760e-01,  4.4526e-01,
         -2.9286e-01,  1.7019e-02,  2.5905e-01,  4.0631e-02,  4.3431e-02,
          1.3020e-01, -4.4691e-01, -2.4018e-01,  3.1151e-01,  7.5608e-02,
          3.9957e-01],
        [ 1.0294e-01,  1.3913e-01,  1.4731e-01,  1.6176e-02,  1.1650e-01,
         -2.7727e-01,  6.9247e-03,  5.8228e-02,  2.0022e-01, -3.9708e-01,
         -2.9920e-01, -3.1443e-01, -4.7428e-02,  4.3066e-01, -3.6931e-02,
          1.4905e-01],
        [ 2.9049e-01,  3.1298e-01,  3.6140e-01, -4.2080e-01,  1.4858e-01,
         -1.6367e-01, -3.2243e-01,  3.5831e-01, -7.9880e-02, -6.1955e-02,
          1.0175e-02, -3.1395e-01, -1.3613e-02,  3.8947e-01,  3.4350e-01,
          3.7290e-01],
        [-3.7953e-01, -1.5388e-01, -4.3138e-02,  2.7400e-01, -4.4386e-02,
          7.5205e-02,  2.5345e-01, -2.6109e-01, -2.5312e-01,  1.5604e-01,
          1.2831e-01,  1.8295e-01,  1.5946e-01, -3.0437e-01, -2.2460e-01,
         -1.8527e-01],
        [ 3.8264e-01,  2.5743e-01,  2.0496e-01, -2.1020e-01,  3.1128e-02,
         -3.6180e-01,  2.2001e-02,  3.6353e-02,  2.1082e-01, -2.0011e-01,
          1.1696e-01, -2.6720e-01,  6.4689e-03,  4.2387e-01,  2.3149e-01,
          3.5083e-01],
        [-3.2021e-01, -7.7333e-02, -3.8515e-01,  3.2322e-01, -3.6866e-01,
          2.0570e-01,  4.0599e-01, -6.5265e-02,  2.6562e-02,  2.0903e-01,
          2.4285e-01,  3.0379e-01,  1.8334e-01, -4.1960e-02, -1.2806e-01,
         -3.0244e-01],
        [-3.5184e-01, -2.9000e-01, -1.0160e-01,  9.0755e-02, -1.5086e-01,
          4.4644e-01,  2.9734e-01, -4.2093e-01, -9.9702e-02,  4.0234e-01,
         -2.3744e-01,  4.0823e-01,  3.0437e-02, -3.6697e-01, -2.8439e-01,
         -3.2094e-01],
        [ 1.1797e-01,  2.8577e-01,  3.0513e-01, -1.2017e-01,  3.9285e-01,
         -3.7481e-01, -4.8645e-01,  2.0873e-02,  7.4535e-02, -2.4929e-01,
          2.3432e-02, -4.2027e-01, -2.2722e-01,  3.6821e-01,  7.2783e-02,
          2.6691e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1443,  0.0600,  0.2194, -0.1481,  0.0053,  0.0052,  0.0165,  0.1450,
        -0.1081, -0.0362,  0.0281,  0.0489,  0.0796,  0.0434, -0.0008,  0.0136,
        -0.1138, -0.0008,  0.0111, -0.0442,  0.0148, -0.1484, -0.1514, -0.0385,
        -0.2643,  0.2169,  0.0772,  0.0506, -0.0350, -0.1236,  0.1369, -0.0966],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2072,  0.2731, -0.2369,  0.2582,  0.2583,  0.3622, -0.3092, -0.3938,
         -0.3406,  0.3099,  0.2745,  0.3607, -0.2637, -0.4350,  0.3106,  0.1690,
         -0.3342,  0.3672, -0.2432, -0.2657,  0.2256,  0.4051, -0.3970, -0.4151,
         -0.3299, -0.2761, -0.3409,  0.2878, -0.3831,  0.4126,  0.3225, -0.2582]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0022,  0.1059,  0.0584,  ..., -0.0264,  0.0070, -0.1137],
        [-0.0235, -0.1637,  0.0695,  ...,  0.0518, -0.3385,  0.0871],
        [-0.1134,  0.1238,  0.1275,  ...,  0.0834,  0.2255,  0.0345],
        ...,
        [ 0.0991, -0.1343, -0.0066,  ..., -0.0394, -0.2655, -0.1180],
        [ 0.0097, -0.0935,  0.0218,  ..., -0.1944,  0.1109,  0.1557],
        [-0.1796,  0.1252,  0.0375,  ..., -0.1034,  0.0457, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0320,  0.0711, -0.1196, -0.1104, -0.0469,  0.0261, -0.1487,  0.0875,
        -0.0325,  0.0941,  0.0398, -0.0152, -0.0102,  0.0920, -0.0872, -0.0355,
         0.0549, -0.1242, -0.0233,  0.0119, -0.0866,  0.0597,  0.0837, -0.0275,
        -0.0760,  0.0874,  0.0224, -0.1204,  0.0638,  0.1619,  0.1510, -0.1069],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1886, -0.1270, -0.1019,  ..., -0.0818, -0.0957,  0.1742],
        [-0.0197, -0.0038,  0.1214,  ..., -0.0379, -0.0508,  0.2244],
        [-0.0469, -0.0813, -0.1740,  ...,  0.0331,  0.0439,  0.0166],
        ...,
        [ 0.0033,  0.0387,  0.1079,  ...,  0.2032, -0.1368,  0.1444],
        [ 0.1738, -0.1154,  0.0748,  ...,  0.0481,  0.1865,  0.0090],
        [ 0.1348, -0.0760,  0.2086,  ...,  0.0885,  0.0785,  0.0740]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0583,  0.0480,  0.0532, -0.0127, -0.1098, -0.1592,  0.0317, -0.1730,
         0.0564, -0.0682,  0.2117, -0.1683,  0.1076,  0.0783, -0.1948, -0.0139,
        -0.0864, -0.1031, -0.0216, -0.0777,  0.0658,  0.1722, -0.1333,  0.1638,
        -0.1393, -0.0591,  0.1505, -0.1216, -0.0410, -0.0363,  0.0121, -0.0247],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2991,  0.1961, -0.3112, -0.2780,  0.1660,  0.1526, -0.2024,  0.2284,
          0.2114, -0.2078, -0.1874,  0.1985,  0.1899, -0.1601,  0.2313,  0.1741,
         -0.2928, -0.2989,  0.1636,  0.1976, -0.2554, -0.2356, -0.3036, -0.1077,
          0.2694,  0.3012, -0.2825,  0.3027, -0.2081, -0.2896,  0.2844,  0.2824]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.1222], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.7450e-01,  9.7950e-02,  7.3173e-03, -4.9696e-02, -1.4564e-01,
          1.4525e-01,  8.9479e-02, -3.6176e-01, -1.3349e-01,  2.1146e-01,
          2.1119e-01,  1.7548e-01, -8.2226e-02, -3.9212e-01, -3.1803e-03,
          8.0077e-02],
        [-1.8790e-01, -3.4959e-01, -9.2097e-02, -5.7473e-02, -3.0078e-01,
          2.2354e-01, -2.3809e-02, -1.7934e-01,  7.9185e-02,  7.2728e-02,
          2.8631e-01,  9.3611e-02,  2.0354e-01, -9.8377e-02,  8.3929e-02,
         -5.6250e-02],
        [ 3.2962e-02,  2.6935e-01,  3.7966e-01, -9.7546e-02,  2.6540e-01,
         -3.4294e-01,  1.7682e-01, -7.7237e-02,  3.6474e-01, -7.8770e-03,
         -3.2428e-02, -3.9907e-01,  1.6724e-01,  3.3963e-01,  3.8073e-01,
          2.5913e-01],
        [-3.3893e-02, -2.4473e-01, -2.8404e-01,  2.5855e-01, -7.8961e-02,
          1.6949e-01,  4.9105e-03, -8.8964e-02, -4.0510e-01, -1.0960e-01,
          3.9678e-02,  3.4630e-01,  1.8557e-01, -4.1692e-01, -2.4637e-01,
         -1.9963e-01],
        [-5.3453e-02,  5.8965e-02, -1.6568e-01, -6.0956e-02, -1.3818e-01,
          6.6722e-02, -1.9832e-01, -2.9896e-02, -1.8488e-01,  2.5702e-01,
          3.1910e-01,  1.9811e-01,  1.9438e-01, -2.8105e-01, -6.0610e-03,
         -1.4611e-01],
        [ 2.9900e-02,  9.2167e-02, -3.6379e-01,  3.7710e-01,  2.9815e-02,
         -3.9123e-02,  4.6774e-02, -3.7503e-01, -8.9397e-02,  1.7670e-01,
         -6.2862e-02,  2.6802e-01, -1.5121e-02,  7.9812e-02,  7.7761e-02,
         -7.3811e-02],
        [ 2.1163e-01,  1.6277e-01,  4.2255e-01, -1.4486e-01,  1.9610e-01,
         -1.1894e-01, -9.4397e-02,  1.0787e-01,  8.2213e-02,  1.4679e-01,
         -6.5498e-02, -2.9518e-01, -1.6469e-01,  2.7225e-01, -4.6710e-02,
          9.6310e-02],
        [-1.4956e-01,  3.2053e-01,  3.7285e-01, -3.2888e-01, -9.3313e-02,
         -2.6476e-01,  4.1187e-02,  4.1753e-02,  9.6439e-02, -1.1322e-01,
         -9.7047e-02, -2.8849e-01,  1.0064e-01, -3.3850e-02,  1.3410e-01,
          3.4211e-01],
        [-3.3966e-02,  3.2623e-01,  2.9776e-01, -2.1189e-01,  2.3224e-01,
         -3.1257e-01,  7.5464e-02,  2.3351e-01,  3.6674e-01, -2.3753e-01,
         -2.4360e-01, -2.9277e-01, -3.1660e-01,  2.1236e-01, -5.2805e-02,
          7.6092e-02],
        [-2.5513e-01, -1.3319e-01, -9.4451e-02, -4.7186e-02, -2.2777e-01,
          1.3944e-01, -2.2952e-01, -1.0959e-01, -5.5539e-02, -3.1777e-02,
          3.0332e-01,  3.4947e-01,  1.0596e-02, -1.2315e-01, -1.1291e-01,
         -1.9063e-01],
        [-3.2121e-01,  2.6065e-02, -6.8070e-02, -4.6209e-02, -3.7477e-01,
          4.1833e-01, -2.7220e-02, -2.4324e-01, -8.0997e-03,  2.2218e-01,
          2.3935e-01,  3.8469e-01,  7.3421e-02,  6.3262e-02, -3.5607e-01,
         -3.3231e-01],
        [-1.2904e-01, -1.9248e-01, -3.0334e-02,  7.7971e-02, -1.2555e-01,
          1.2439e-01,  2.2768e-02, -1.8528e-01, -5.9213e-02,  3.5543e-01,
          1.8630e-01,  4.0974e-01, -8.4474e-02, -2.9932e-01, -1.3511e-01,
         -2.1797e-01],
        [ 1.9692e-01,  2.5544e-01,  1.6567e-01, -1.4061e-01,  2.2039e-01,
          6.9797e-02,  4.8788e-02,  5.6067e-02,  5.5398e-02,  6.1793e-02,
         -2.1423e-01, -3.4697e-01, -1.8370e-01,  2.1042e-01,  1.0862e-01,
          1.7255e-02],
        [ 1.4832e-01,  3.7975e-01,  3.7919e-01,  9.7048e-03, -3.5630e-02,
          1.9557e-03,  1.1572e-01,  2.5254e-01,  1.0041e-01, -9.3592e-02,
         -2.9478e-01, -2.2842e-01, -7.0268e-02,  1.1938e-01, -8.6922e-02,
          2.3597e-01],
        [-3.2808e-01, -3.4084e-01, -7.6764e-02, -6.1711e-02,  7.8749e-02,
          4.0190e-01, -1.0806e-01, -2.1790e-01, -3.5732e-01,  1.3100e-01,
          2.0676e-01,  4.1239e-02,  1.2842e-01, -1.7467e-01, -2.3861e-01,
         -1.6189e-01],
        [-3.0347e-01, -2.2134e-01,  5.3322e-02,  2.5270e-01, -1.8381e-01,
          2.2946e-01,  1.9628e-03, -1.0155e-01,  4.4692e-03,  1.8952e-01,
          2.5382e-02,  2.1434e-01, -4.8437e-02, -1.8276e-01,  2.2582e-01,
         -1.2014e-01],
        [ 2.7551e-01,  3.0222e-01,  2.1983e-01, -3.4239e-01, -8.7149e-02,
         -2.4673e-02,  9.9141e-02,  3.1701e-01, -5.1586e-02, -1.4195e-01,
          6.4069e-02, -4.4780e-02,  1.3792e-01,  3.6114e-01,  1.0709e-01,
         -1.8176e-02],
        [-2.3949e-01, -3.4098e-02, -2.7208e-01,  1.2981e-01, -1.0368e-01,
          2.8509e-01,  1.4412e-01, -2.4625e-02, -1.5792e-01,  2.1475e-01,
          5.9434e-02,  7.4442e-02, -1.5755e-02, -3.1238e-01,  5.7339e-02,
         -1.8002e-01],
        [ 1.8445e-01,  1.4405e-01,  1.6369e-01, -2.7345e-01,  1.3750e-01,
         -3.7289e-01, -6.8219e-02,  3.5139e-01, -8.5336e-02, -6.2700e-02,
         -5.2766e-02, -4.0393e-01, -2.9151e-02,  2.9569e-01,  3.3945e-01,
          2.0088e-01],
        [ 3.2959e-01,  1.8524e-01,  2.8181e-01, -8.5641e-02, -1.4192e-02,
         -2.3505e-01, -1.1519e-01,  3.7585e-01,  2.9062e-01, -2.3546e-01,
         -1.6752e-01, -1.1627e-01, -2.9887e-01,  1.8062e-01,  2.9355e-01,
          2.0684e-01],
        [-1.2590e-01,  4.6399e-02, -4.3845e-02, -1.0835e-01,  1.8099e-02,
         -5.1478e-02,  1.1246e-01,  6.1022e-02, -1.3154e-01,  2.6870e-02,
          1.4138e-02,  4.9261e-02, -8.5851e-03, -2.7223e-01,  1.0090e-01,
         -2.4028e-01],
        [-9.3404e-03, -3.6914e-01, -3.6177e-02,  3.4370e-01, -3.1477e-01,
          9.6472e-02, -1.0143e-02, -3.9686e-01, -2.9693e-01,  1.9732e-01,
          2.1455e-01,  8.9929e-02,  6.9678e-02, -4.1378e-01, -3.7729e-01,
          7.2442e-02],
        [ 2.9491e-01,  4.3867e-02,  6.9025e-02, -1.4040e-01,  2.5580e-01,
         -3.7005e-01, -1.5201e-01,  8.2374e-02,  4.9203e-02, -7.0478e-02,
          2.7034e-02, -1.1536e-01, -2.4496e-01,  3.8573e-01,  3.5770e-01,
          2.1659e-01],
        [ 2.2570e-01,  2.1541e-01,  3.7394e-01, -3.6759e-01, -1.1632e-02,
         -1.6632e-01, -1.5626e-02, -6.1819e-05, -7.9022e-02, -2.8177e-01,
         -1.9091e-01,  4.0533e-02,  1.0679e-01,  2.3106e-01,  5.0228e-03,
          4.1182e-02],
        [ 1.3243e-01, -9.5901e-02,  1.6549e-01, -8.6335e-02,  3.8547e-01,
         -2.0556e-01,  2.5455e-01,  1.9113e-01, -1.1637e-03,  1.4268e-01,
          5.0505e-02, -3.7460e-01, -1.9160e-01,  2.8689e-01,  1.7876e-02,
          3.2130e-01],
        [-2.5345e-02,  5.0444e-02,  9.6224e-02,  1.1061e-01,  5.7276e-02,
         -1.9992e-01,  1.3032e-01, -8.8727e-03,  1.6581e-01, -2.8223e-01,
         -3.5193e-01, -2.3021e-01,  2.8824e-02,  3.9967e-01, -7.6398e-02,
          7.2519e-02],
        [ 1.7549e-01,  2.3770e-01,  3.1611e-01, -3.3587e-01,  8.9898e-02,
         -9.2057e-02, -1.4554e-01,  2.9326e-01, -9.3585e-02,  5.2747e-02,
         -1.5776e-02, -2.3987e-01,  3.0038e-03,  3.5956e-01,  3.3076e-01,
          3.0155e-01],
        [-2.8915e-01, -6.9374e-02,  1.5397e-02,  1.7585e-01,  1.3684e-02,
          1.1226e-03,  3.2459e-02, -1.7572e-01, -3.2079e-01,  7.9208e-02,
          2.2404e-01,  8.2312e-02,  8.9256e-02, -2.6227e-01, -2.5020e-01,
         -1.0828e-01],
        [ 3.0235e-01,  1.8861e-01,  1.5761e-01, -1.2949e-01, -2.6385e-02,
         -3.0377e-01,  1.3545e-01, -2.9939e-02,  2.6995e-01, -1.1529e-01,
         -1.1500e-02, -1.8859e-01,  9.1391e-02,  3.9060e-01,  2.6782e-01,
          2.8701e-01],
        [-1.7424e-01, -7.8634e-03, -3.3981e-01,  2.3210e-01, -3.1358e-01,
          1.1937e-01,  2.5100e-01, -2.1102e-03,  5.6866e-02,  1.1536e-01,
          2.6902e-01,  2.4032e-01,  1.4504e-01, -2.3141e-02, -8.6443e-02,
         -2.2326e-01],
        [-2.6172e-01, -2.2034e-01, -5.6371e-02,  8.6006e-03, -9.6532e-02,
          3.8324e-01,  1.1458e-01, -3.5563e-01, -8.6131e-02,  3.0203e-01,
         -1.1268e-01,  3.3347e-01, -4.5073e-02, -3.4158e-01, -2.6621e-01,
         -2.5665e-01],
        [-2.4563e-01, -1.1358e-01, -1.0442e-01,  2.6636e-01, -1.3369e-02,
          2.5957e-02, -3.0215e-01, -3.9494e-01, -3.1256e-01,  2.6743e-02,
          1.8358e-01,  1.2962e-02, -9.9931e-02, -4.9921e-02, -3.3552e-01,
         -1.3939e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.2250,  0.0961,  0.1959, -0.2019,  0.0773, -0.1047,  0.0540,  0.1644,
        -0.1959,  0.0269,  0.1518,  0.0771,  0.0573, -0.0283,  0.0964, -0.0079,
        -0.1429, -0.0046,  0.0129, -0.1164, -0.0386, -0.1137, -0.1702, -0.0972,
        -0.2764,  0.1952,  0.1161,  0.0776, -0.0714, -0.1216,  0.1581, -0.0908],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1277,  0.1718, -0.1803,  0.1932,  0.2235,  0.2871, -0.2490, -0.3315,
         -0.2768,  0.2654,  0.2101,  0.3195, -0.2548, -0.3721,  0.2429,  0.0819,
         -0.2689,  0.2708, -0.1792, -0.2027,  0.1390,  0.3351, -0.3338, -0.3236,
         -0.2596, -0.2402, -0.2807,  0.2366, -0.3134,  0.3492,  0.2603,  0.1723]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0356,  0.1262,  0.2031,  ...,  0.0049,  0.1319, -0.1137],
        [-0.0298, -0.1611, -0.0079,  ...,  0.0540, -0.4809,  0.0871],
        [-0.1014,  0.1422,  0.2352,  ...,  0.1066,  0.3859,  0.0345],
        ...,
        [ 0.0939, -0.1595, -0.1162,  ..., -0.0623, -0.3947, -0.1180],
        [ 0.0094, -0.0721,  0.0639,  ..., -0.1726,  0.2802,  0.1557],
        [-0.1703,  0.1133,  0.1275,  ..., -0.0855,  0.1725, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0534,  0.0947, -0.1237, -0.0844, -0.0231,  0.0151, -0.1592,  0.0869,
        -0.0594,  0.1227,  0.0569, -0.0325, -0.0094,  0.0786, -0.0923, -0.0534,
         0.0918, -0.1227, -0.0194,  0.0013, -0.1030,  0.0640,  0.0804, -0.0389,
        -0.0625,  0.0968,  0.0028, -0.1176,  0.0631,  0.1716,  0.1296, -0.1160],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.2243, -0.1603, -0.0836,  ..., -0.0622, -0.0985,  0.1639],
        [-0.0018, -0.0214,  0.1248,  ..., -0.0194, -0.0627,  0.2055],
        [-0.0554, -0.0732, -0.1694,  ...,  0.0076,  0.0619,  0.0439],
        ...,
        [-0.0298,  0.0592,  0.0904,  ...,  0.1780, -0.1330,  0.1570],
        [ 0.1844, -0.1168,  0.0713,  ...,  0.0737,  0.1684, -0.0178],
        [ 0.1642, -0.0988,  0.2212,  ...,  0.1130,  0.0706,  0.0588]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0435,  0.0493,  0.0428, -0.0059, -0.1009, -0.1338,  0.0324, -0.1587,
         0.0588, -0.0736,  0.2043, -0.1769,  0.1045,  0.0678, -0.1955,  0.0014,
        -0.0802, -0.1086, -0.0268, -0.0825,  0.0752,  0.1724, -0.1268,  0.1643,
        -0.1327, -0.0652,  0.1528, -0.1217, -0.0517, -0.0197,  0.0178, -0.0324],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2725,  0.1727, -0.2825, -0.2530,  0.1408,  0.1332, -0.1719,  0.2041,
          0.1868, -0.1705, -0.1527,  0.1639,  0.1621, -0.1409,  0.1993,  0.1416,
         -0.2604, -0.2688,  0.1363,  0.1600, -0.2219, -0.2040, -0.2713, -0.0637,
          0.2426,  0.2723, -0.2569,  0.2712, -0.1793, -0.2514,  0.2593,  0.2473]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0803], device='cuda:0', requires_grad=True)

