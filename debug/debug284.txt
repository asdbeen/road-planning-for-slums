Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.1132e-03,  3.9315e-01,  3.0611e-01, -3.2476e-01, -1.9260e-01,
         -1.5441e-01, -7.7930e-02, -3.9413e-01, -2.6087e-01, -7.7884e-02,
         -2.8009e-02,  1.9861e-01, -3.1033e-01, -7.0611e-02, -3.7512e-02,
          3.8555e-01],
        [-2.4799e-01, -3.8697e-01, -9.8917e-02, -1.2291e-02, -2.5182e-02,
          2.4777e-01,  1.6413e-01,  1.6255e-01,  4.3595e-01,  1.3725e-01,
          2.9721e-01, -2.6345e-01,  3.6447e-01, -2.7739e-02,  3.4536e-01,
         -9.0738e-02],
        [ 9.3736e-02,  2.9403e-01,  3.8951e-01, -1.3000e-01, -1.0362e-01,
         -3.4868e-01, -9.2916e-02, -4.5126e-01, -6.7615e-02, -9.0289e-02,
         -1.5732e-01, -3.1118e-02,  1.5434e-02,  3.4951e-01, -2.2922e-02,
          2.8799e-01],
        [ 2.8402e-01,  1.1727e-01,  9.5566e-02, -8.6408e-02, -6.9847e-02,
         -2.1643e-01, -1.7793e-01, -1.2395e-01, -4.8003e-01, -4.2958e-01,
         -2.1695e-01,  3.8872e-01, -8.1281e-02, -1.1573e-01, -2.1635e-01,
          1.8062e-01],
        [-9.6263e-02,  3.5380e-02, -1.7138e-01, -2.4136e-02,  1.6770e-01,
          8.9659e-02,  4.8314e-02,  3.3064e-01,  1.8886e-01,  3.0531e-01,
          3.4714e-01, -1.6973e-01,  3.2764e-01, -2.3241e-01,  2.9798e-01,
         -1.7417e-01],
        [-2.0558e-02,  6.1436e-02, -3.7372e-01,  4.1612e-01,  3.5941e-01,
         -7.7068e-03,  2.8898e-01, -6.3970e-04,  3.1933e-01,  2.3521e-01,
         -7.5602e-02, -1.1271e-01,  1.3059e-01,  1.1808e-01,  4.3531e-01,
         -1.0600e-01],
        [ 3.6655e-01,  2.4547e-01,  4.0578e-01, -1.8278e-01, -5.9101e-02,
         -2.0999e-01, -1.8730e-01, -2.4219e-01, -3.0098e-01, -3.2609e-02,
         -4.4958e-02,  6.6960e-02, -3.6157e-01,  2.0417e-01, -3.0205e-01,
          1.6315e-01],
        [-5.8018e-02,  3.6258e-01,  3.6168e-01, -3.6041e-01, -3.4894e-01,
         -3.0070e-01, -1.0494e-01, -2.7632e-01, -2.4823e-01, -2.2929e-01,
         -9.3747e-02,  4.2531e-02, -4.2900e-02, -9.5445e-02, -1.2760e-01,
          3.7215e-01],
        [ 3.2757e-02,  3.5592e-01,  3.0219e-01, -2.4437e-01, -5.1484e-02,
         -3.4633e-01, -1.5922e-01, -1.0232e-01,  7.9179e-03, -3.1988e-01,
         -2.8364e-01,  5.5852e-02, -4.2061e-01,  1.5860e-01, -2.9760e-01,
          1.0872e-01],
        [-3.0084e-01, -1.6550e-01, -1.1125e-01, -3.3228e-05,  9.3178e-02,
          1.7098e-01,  7.5872e-02,  2.6041e-01,  3.2561e-01,  1.9278e-02,
          3.6476e-01, -2.6258e-02,  1.2113e-01, -9.4169e-02,  2.0691e-01,
         -2.2887e-01],
        [-3.7005e-01,  1.5777e-02, -7.7293e-02, -1.9759e-02, -2.7688e-02,
          4.4434e-01,  2.6441e-01,  1.5282e-01,  4.1559e-01,  2.8142e-01,
          2.2702e-01, -1.9959e-02,  1.9930e-01,  1.0090e-01,  2.7893e-02,
         -3.6277e-01],
        [-1.3984e-01, -2.0310e-01, -3.8702e-02,  1.0057e-01,  1.8952e-01,
          1.3819e-01,  3.8973e-01,  1.7119e-01,  2.1711e-01,  3.7161e-01,
          4.0927e-01,  4.5184e-02, -5.5915e-02, -2.6408e-01,  4.2752e-02,
         -2.3651e-01],
        [ 3.3497e-01,  2.9013e-01,  1.6685e-01, -1.7192e-01, -1.0568e-01,
          2.1712e-02, -8.7904e-02, -3.3069e-01, -3.6790e-01, -1.1711e-01,
         -1.7652e-01,  4.2384e-02, -4.3916e-01,  1.5578e-01, -2.5022e-01,
          5.3011e-02],
        [ 2.0925e-01,  4.0124e-01,  3.7074e-01, -1.2325e-02, -3.1417e-01,
         -2.3967e-02, -4.0847e-02, -7.7767e-02, -2.5268e-01, -1.7486e-01,
         -2.8113e-01,  1.1390e-01, -2.0400e-01,  5.8733e-02, -3.3286e-01,
          2.5396e-01],
        [-3.7862e-01, -3.5406e-01, -7.2705e-02, -3.3690e-02,  3.7421e-01,
          4.0708e-01,  1.1436e-01,  1.2886e-01,  1.9377e-02,  1.9777e-01,
          1.9251e-01, -3.1850e-01,  2.5786e-01, -1.1443e-01,  7.3079e-02,
         -1.8280e-01],
        [-5.0212e-02,  6.9336e-03,  2.1492e-01,  5.9119e-02, -3.7288e-01,
         -4.6090e-02, -2.3179e-01, -3.5606e-01, -3.1485e-01, -1.0197e-01,
         -1.5057e-01,  4.6294e-01, -3.0354e-01, -1.6876e-02,  5.1651e-03,
          1.2938e-01],
        [ 3.2963e-01,  3.2902e-01,  2.1564e-01, -3.6619e-01, -3.8458e-01,
         -6.0997e-02, -1.2098e-01, -3.1319e-02, -4.2652e-01, -2.1435e-01,
          6.7488e-02,  3.1443e-01,  3.0794e-02,  3.0164e-01, -1.4666e-01,
          4.3320e-03],
        [-3.0042e-01, -6.1638e-02, -2.5228e-01,  1.4735e-01,  1.4614e-01,
          3.0996e-01,  3.0228e-01,  2.9072e-01,  1.9267e-01,  3.0248e-01,
          1.1796e-02, -2.5922e-01,  1.1604e-01, -2.1701e-01,  3.0040e-01,
         -1.9490e-01],
        [ 2.2529e-01,  1.5106e-01,  1.4245e-01, -2.8019e-01, -2.1834e-01,
         -3.7487e-01, -3.2443e-01,  2.9494e-03, -5.0932e-01, -1.2441e-01,
         -1.1556e-01, -5.8475e-02, -1.4822e-01,  2.9209e-01, -5.7231e-02,
          2.0935e-01],
        [ 3.7458e-01,  1.8015e-01,  2.7567e-01, -9.6280e-02, -3.1465e-01,
         -2.3357e-01, -3.6505e-01,  2.0676e-02, -9.4964e-02, -2.9333e-01,
         -1.7317e-01,  2.5245e-01, -4.0583e-01,  1.0848e-01,  2.9704e-02,
          2.1852e-01],
        [-1.9025e-01,  1.2334e-03, -5.8779e-02, -6.0572e-02,  2.9029e-01,
         -1.9851e-02,  3.2225e-01,  3.8807e-01,  2.3634e-01,  9.3545e-02,
          1.0540e-02, -2.9399e-01,  1.3078e-01, -2.1026e-01,  4.0076e-01,
         -2.8001e-01],
        [-7.8778e-02, -4.0737e-01, -5.5385e-02,  3.9442e-01, -1.7158e-02,
          1.1693e-01,  2.6879e-01, -5.0139e-02,  7.1580e-02,  2.7849e-01,
          4.0008e-01, -2.6589e-01,  1.8570e-01, -3.6924e-01, -6.6461e-02,
          2.8667e-02],
        [ 3.6874e-01,  7.9321e-02,  5.9393e-02, -1.7034e-01, -1.9001e-03,
         -3.9968e-01, -3.0726e-01, -2.3570e-01, -2.9964e-01, -1.7236e-01,
          5.4373e-02,  2.1765e-01, -3.9385e-01,  3.1812e-01,  8.7699e-02,
          2.4181e-01],
        [ 2.6219e-01,  2.3480e-01,  3.4864e-01, -3.7522e-01, -2.4494e-01,
         -1.7696e-01, -1.8813e-01, -2.9658e-01, -4.0015e-01, -3.4152e-01,
         -1.3870e-01,  3.5459e-01,  1.1518e-02,  1.3199e-01, -1.9220e-01,
          4.4857e-02],
        [ 2.2448e-01, -4.4962e-02,  1.8432e-01, -1.3651e-01,  3.5930e-02,
         -2.8446e-01,  1.1817e-02, -2.1228e-01, -4.3771e-01,  2.3451e-02,
          4.1446e-02,  3.1236e-02, -3.6268e-01,  2.6302e-01, -3.4213e-01,
          3.7565e-01],
        [ 5.1064e-02,  8.6672e-02,  9.8023e-02,  7.0197e-02, -2.3097e-01,
         -2.1732e-01, -4.0604e-02, -3.5037e-01, -2.2111e-01, -3.7351e-01,
         -3.6553e-01,  1.2542e-01, -1.5664e-01,  3.2138e-01, -4.0586e-01,
          1.0753e-01],
        [ 2.3041e-01,  2.5406e-01,  3.1163e-01, -3.5879e-01, -1.8737e-01,
         -1.0815e-01, -3.7374e-01, -3.6756e-02, -4.3903e-01, -1.6983e-02,
         -5.9108e-02,  1.0017e-01, -8.8139e-02,  3.0577e-01,  9.4880e-02,
          3.2149e-01],
        [-3.2659e-01, -1.0173e-01,  7.0078e-03,  2.1547e-01,  3.1375e-01,
          3.0120e-02,  3.8084e-01,  1.7603e-01, -9.3815e-03,  1.2249e-01,
          3.7988e-01, -2.7727e-01,  1.4338e-01, -2.2054e-01, -5.1161e-03,
         -1.4249e-01],
        [ 3.1754e-01,  1.9483e-01,  1.5243e-01, -1.4622e-01, -3.1570e-01,
         -3.0106e-01, -1.6819e-01, -3.6262e-01, -7.4446e-02, -1.3587e-01,
         -1.0662e-01,  1.5714e-01,  2.8373e-02,  3.3112e-01, -7.5737e-03,
          2.9721e-01],
        [-2.6966e-01, -4.1806e-02, -3.1904e-01,  2.5266e-01, -7.3770e-02,
          1.4751e-01,  3.4120e-01,  3.0920e-01,  3.9935e-01,  2.4350e-01,
          2.2713e-01, -8.6331e-02,  3.2938e-01,  6.2301e-02,  1.4610e-01,
         -2.4033e-01],
        [-3.0221e-01, -2.3420e-01, -6.1806e-02,  3.6094e-02,  2.1471e-01,
          4.0614e-01,  4.0753e-01,  1.8118e-03,  2.9055e-01,  3.5279e-01,
         -8.4144e-02, -3.4523e-02,  3.5131e-02, -2.9732e-01,  3.4085e-02,
         -2.8123e-01],
        [ 4.7671e-02,  2.2984e-01,  2.4643e-01, -4.5180e-02,  5.3298e-03,
         -3.1595e-01, -4.1372e-01, -3.7600e-01, -3.8208e-01, -2.7937e-01,
         -3.7723e-02, -6.7236e-03, -3.5877e-01,  2.6902e-01, -2.6050e-01,
          2.0358e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0671, -0.0208, -0.0127, -0.0318,  0.0098, -0.2366,  0.0980,  0.1233,
        -0.0564, -0.0071,  0.0425,  0.0772,  0.1346,  0.0743,  0.0637, -0.0171,
        -0.0182, -0.0407,  0.0843, -0.0317, -0.1071, -0.0694, -0.0302,  0.0376,
        -0.0358,  0.1338,  0.1586,  0.0467, -0.0990, -0.1826,  0.0229,  0.0248],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2197,  0.3135, -0.2299, -0.2616,  0.3051,  0.3613, -0.2832, -0.3754,
         -0.3234,  0.3428,  0.2669,  0.3783, -0.2663, -0.3982,  0.2862, -0.2419,
         -0.3219,  0.3341, -0.2327, -0.2384,  0.4047,  0.3188, -0.3738, -0.3772,
         -0.2903, -0.3330, -0.3209,  0.3449, -0.3520,  0.3828,  0.3040, -0.2379]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0051,  0.1149,  0.0691,  ...,  0.1978, -0.3101, -0.1137],
        [-0.0733, -0.0662,  0.1193,  ...,  0.1022, -0.2867,  0.0871],
        [-0.1068,  0.1589,  0.0922,  ...,  0.1992,  0.0272,  0.0345],
        ...,
        [ 0.0966, -0.1201, -0.0371,  ..., -0.1704, -0.0246, -0.1180],
        [ 0.0384, -0.1838, -0.0406,  ..., -0.2616,  0.0923,  0.1557],
        [-0.1838,  0.1344,  0.0506,  ...,  0.0709, -0.2441, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0540,  0.0308, -0.0945, -0.1548, -0.0811, -0.0082, -0.1022,  0.0412,
        -0.0331,  0.0581,  0.0284, -0.0035,  0.0090,  0.1018, -0.0441, -0.0129,
         0.0484, -0.1662,  0.0042,  0.0820, -0.0627,  0.0181,  0.1109,  0.0233,
        -0.1102,  0.0983,  0.0440, -0.0990,  0.0463,  0.2038,  0.1687, -0.1281],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0522, -0.1633, -0.1869,  ...,  0.0353, -0.0456,  0.0664],
        [-0.2174, -0.0149, -0.0173,  ...,  0.1386, -0.0290,  0.0495],
        [ 0.1479, -0.0502, -0.0398,  ..., -0.1413,  0.0033,  0.1860],
        ...,
        [ 0.1427,  0.0573,  0.2083,  ...,  0.1052, -0.1754,  0.2444],
        [-0.0142, -0.1368, -0.0444,  ...,  0.2398,  0.2144, -0.1725],
        [-0.0024, -0.1096,  0.1291,  ...,  0.2224,  0.1269, -0.0438]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1007,  0.1481, -0.0466, -0.1004, -0.1067, -0.1763, -0.0640, -0.0267,
         0.1412, -0.1701,  0.1336, -0.1283,  0.1985,  0.0930, -0.1092,  0.1237,
        -0.1364, -0.1792,  0.0771,  0.0107, -0.0154,  0.0808, -0.2077,  0.2180,
        -0.0454, -0.0106,  0.0762, -0.0422, -0.1510, -0.0586,  0.1237,  0.0307],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3787,  0.3024, -0.3416, -0.3725, -0.2264, -0.2211, -0.2867,  0.2535,
          0.2797, -0.2965, -0.2494,  0.2647,  0.2737,  0.2300,  0.2899,  0.2727,
         -0.3706, -0.3764,  0.2228,  0.2681, -0.3285, -0.2787, -0.3804,  0.2256,
          0.3429,  0.3951, -0.3507,  0.3676, -0.2870, -0.3753,  0.3398,  0.3799]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1338], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.1924e-02,  3.4905e-01,  3.2227e-01, -3.4565e-01, -3.0831e-02,
         -1.7870e-01, -6.9095e-02, -3.9379e-01, -1.7857e-01, -8.2661e-02,
          3.1410e-02,  1.7747e-01,  6.3801e-02, -5.4719e-02,  3.1869e-01,
          3.6089e-01],
        [-2.7635e-01, -3.3454e-01, -1.2773e-01,  1.3662e-02, -1.5537e-01,
          2.8634e-01,  1.9081e-01,  1.7281e-01,  4.0282e-01,  1.3386e-01,
          2.1877e-01, -2.7570e-01, -3.7296e-03, -4.3659e-02, -1.6806e-03,
         -8.1921e-02],
        [ 9.8781e-02,  2.4300e-01,  4.0138e-01, -1.3879e-01,  1.3695e-01,
         -3.7474e-01, -6.5854e-02, -4.1665e-01,  5.1865e-02, -7.9501e-02,
         -9.2711e-02, -5.9082e-02,  3.9937e-01,  3.0718e-01,  4.3461e-01,
          2.6232e-01],
        [ 2.9203e-01,  6.4554e-02,  1.0641e-01, -9.1679e-02,  9.5517e-02,
         -2.3115e-01, -1.7301e-01, -1.0104e-01, -4.0961e-01, -4.0135e-01,
         -1.0441e-01,  3.6856e-01,  2.8844e-01, -1.2944e-01,  1.4310e-01,
          1.5728e-01],
        [-1.1717e-01,  1.2534e-01, -1.8994e-01, -3.2456e-03,  5.9170e-02,
          1.2500e-01,  6.9212e-02,  3.5181e-01,  1.6285e-01,  2.9110e-01,
          2.2789e-01, -1.9307e-01, -5.8218e-02, -2.2610e-01, -8.6582e-02,
         -1.3472e-01],
        [-2.2209e-02,  1.4913e-01, -3.7599e-01,  4.1311e-01,  1.6453e-01,
          5.3611e-03,  2.7737e-01, -1.7611e-02,  2.5438e-01,  2.0497e-01,
         -1.4015e-01, -1.0002e-01, -2.5162e-01,  1.3191e-01,  3.0412e-02,
         -6.8861e-02],
        [ 3.9330e-01,  1.9784e-01,  4.3235e-01, -2.0264e-01,  1.2450e-01,
         -2.5112e-01, -2.1260e-01, -2.4291e-01, -2.5309e-01, -2.6449e-02,
         -1.7384e-02,  6.8778e-02, -2.9420e-02,  2.2702e-01, -1.0387e-02,
          1.5991e-01],
        [-4.4872e-02,  3.1199e-01,  3.7455e-01, -3.6220e-01, -1.5026e-01,
         -3.3137e-01, -1.0998e-01, -2.5007e-01, -1.8074e-01, -2.1314e-01,
         -7.0398e-02,  2.3414e-02,  2.5746e-01, -8.5960e-02,  1.6229e-01,
          3.6329e-01],
        [ 5.6361e-02,  3.0087e-01,  3.2568e-01, -2.6879e-01,  2.6924e-02,
         -3.8317e-01, -1.8502e-01, -1.1537e-01,  3.9301e-02, -3.1307e-01,
         -1.1066e-01,  7.8337e-02, -7.7639e-02,  1.3948e-01,  1.5626e-02,
          9.3379e-02],
        [-3.0612e-01, -8.0533e-02, -1.1675e-01,  2.4976e-03, -3.7579e-02,
          1.9019e-01,  6.8801e-02,  2.5572e-01,  2.7451e-01, -8.2995e-03,
          2.3518e-01, -2.7073e-02, -2.6570e-01, -6.7018e-02, -1.8906e-01,
         -1.8666e-01],
        [-3.6832e-01,  7.5653e-02, -7.8930e-02, -2.7519e-02, -1.7148e-01,
          4.5508e-01,  2.4646e-01,  1.2318e-01,  3.3939e-01,  2.4667e-01,
          6.5192e-02,  5.3825e-03, -1.6482e-01,  1.3710e-01, -3.8958e-01,
         -3.2762e-01],
        [-1.4437e-01, -1.4088e-01, -4.3180e-02,  1.0500e-01,  1.1703e-01,
          1.5294e-01,  3.9015e-01,  1.6532e-01,  1.7197e-01,  3.4244e-01,
          1.5231e-01,  4.4982e-02, -4.0548e-01, -1.9976e-01, -2.6023e-01,
         -1.9710e-01],
        [ 3.6746e-01,  2.1595e-01,  2.0188e-01, -2.0355e-01,  6.9497e-02,
         -2.8596e-02, -1.1635e-01, -3.4292e-01, -3.4366e-01, -1.1995e-01,
         -1.1890e-01,  4.8387e-02, -1.9420e-02,  1.9362e-01,  1.7380e-01,
          3.2290e-02],
        [ 2.3726e-01,  3.5113e-01,  3.9738e-01, -3.4762e-02, -1.8323e-01,
         -6.4242e-02, -7.4780e-02, -9.0710e-02, -2.2529e-01, -1.7216e-01,
         -2.1331e-01,  1.3032e-01,  1.3647e-01,  7.1257e-02, -3.2349e-02,
          2.4938e-01],
        [-3.9536e-01, -2.9986e-01, -9.0289e-02, -2.7370e-02,  2.0862e-01,
          4.4612e-01,  1.2128e-01,  1.2470e-01, -3.5181e-02,  1.8362e-01,
          1.2594e-01, -3.1813e-01, -8.9437e-02, -1.1630e-01, -2.8388e-01,
         -1.6831e-01],
        [-8.7528e-02, -1.5958e-01,  1.7927e-01,  8.9218e-02, -2.0309e-01,
         -1.8079e-02, -1.5790e-01, -2.9596e-01, -1.7043e-01, -7.9814e-03,
          1.1146e-02,  4.3277e-01,  1.2192e-01, -9.2536e-02,  4.1867e-01,
          2.6930e-02],
        [ 3.3259e-01,  2.6986e-01,  2.1933e-01, -3.6707e-01, -2.1094e-01,
         -7.1434e-02, -1.2261e-01, -5.8398e-03, -3.5928e-01, -1.8626e-01,
          1.4006e-01,  2.9129e-01,  3.4989e-01,  2.8439e-01,  1.2913e-01,
         -1.9189e-02],
        [-3.1589e-01, -1.7910e-02, -2.6707e-01,  1.5500e-01, -8.3360e-03,
          3.3759e-01,  3.1345e-01,  2.8040e-01,  1.3625e-01,  2.8538e-01,
         -3.8286e-02, -2.5053e-01, -1.7098e-01, -2.2177e-01,  4.0595e-02,
         -1.8507e-01],
        [ 2.5082e-01,  1.2740e-01,  1.7618e-01, -3.1205e-01, -1.1501e-02,
         -4.1304e-01, -3.0998e-01,  2.5451e-02, -3.9118e-01, -1.3461e-01,
         -4.1524e-02, -7.7045e-02,  1.9955e-01,  2.5598e-01,  3.7238e-01,
          2.0581e-01],
        [ 3.8936e-01,  1.3517e-01,  2.9211e-01, -1.0636e-01, -1.7532e-01,
         -2.6591e-01, -3.7515e-01,  2.8840e-02, -3.8143e-02, -2.7723e-01,
         -6.6166e-02,  2.4956e-01, -7.2398e-02,  1.0414e-01,  3.2954e-01,
          2.0471e-01],
        [-2.0229e-01,  7.8992e-02, -6.9790e-02, -5.0083e-02,  1.5430e-01,
          2.8569e-03,  3.3291e-01,  3.9725e-01,  1.9475e-01,  7.4480e-02,
         -7.1700e-02, -3.0505e-01, -2.0696e-01, -2.0740e-01,  4.1677e-02,
         -2.5288e-01],
        [-7.9939e-02, -3.3614e-01, -5.8633e-02,  3.8925e-01, -1.4905e-01,
          1.3876e-01,  2.5325e-01, -6.6898e-02,  8.4342e-03,  2.5139e-01,
          2.4987e-01, -2.5854e-01, -1.5520e-01, -3.3687e-01, -4.4927e-01,
          6.2816e-02],
        [ 3.7606e-01,  3.0543e-02,  6.7471e-02, -1.6837e-01,  1.5655e-01,
         -4.2195e-01, -3.0926e-01, -2.1243e-01, -2.3181e-01, -1.5013e-01,
          1.2035e-01,  2.0136e-01, -1.0797e-01,  3.0930e-01,  3.7961e-01,
          2.2505e-01],
        [ 2.7566e-01,  1.9931e-01,  3.6095e-01, -3.8163e-01, -9.0597e-02,
         -2.0099e-01, -2.0394e-01, -2.7245e-01, -3.4406e-01, -3.2398e-01,
         -1.0309e-01,  3.3715e-01,  2.5770e-01,  1.4557e-01,  7.4320e-03,
          4.1095e-02],
        [ 2.2826e-01, -1.3940e-01,  1.9060e-01, -1.4428e-01,  1.8638e-01,
         -2.9096e-01,  2.0676e-02, -1.9596e-01, -3.6884e-01,  5.7868e-02,
          1.7219e-01,  1.9304e-02,  5.4532e-02,  2.3416e-01,  7.9144e-02,
          3.2687e-01],
        [ 7.3424e-02,  1.2124e-02,  1.2099e-01,  5.4701e-02, -8.4073e-02,
         -2.6375e-01, -5.7982e-02, -3.6717e-01, -1.8615e-01, -3.6416e-01,
         -2.9261e-01,  1.4384e-01,  2.0209e-01,  3.3302e-01, -1.7389e-02,
          8.4274e-02],
        [ 2.3350e-01,  2.0518e-01,  3.1645e-01, -3.5622e-01, -6.3283e-03,
         -1.2534e-01, -3.7552e-01, -1.7186e-03, -3.6085e-01,  8.7120e-03,
          3.5952e-03,  7.3215e-02,  2.0298e-01,  2.9628e-01,  3.6620e-01,
          3.0398e-01],
        [-3.3393e-01, -3.6317e-02,  2.0604e-04,  2.1714e-01,  2.0460e-01,
          5.0375e-02,  3.8020e-01,  1.7257e-01, -5.7241e-02,  9.6177e-02,
          2.1616e-01, -2.7649e-01, -2.1235e-01, -1.8643e-01, -3.4363e-01,
         -1.0826e-01],
        [ 3.2197e-01,  1.4312e-01,  1.5732e-01, -1.4130e-01, -1.8558e-01,
         -3.1981e-01, -1.6376e-01, -3.4484e-01, -1.2910e-02, -1.0961e-01,
          3.2929e-03,  1.4336e-01,  3.1666e-01,  3.0676e-01,  3.0012e-01,
          2.7375e-01],
        [-2.8652e-01,  1.7382e-03, -3.3544e-01,  2.6108e-01, -2.3342e-01,
          1.7896e-01,  3.5410e-01,  2.9578e-01,  3.4300e-01,  2.2977e-01,
          1.8507e-01, -7.8178e-02,  4.7509e-02,  5.1344e-02, -1.0538e-01,
         -2.3327e-01],
        [-3.0181e-01, -1.7784e-01, -6.3924e-02,  3.2079e-02,  5.6195e-02,
          4.1640e-01,  4.0033e-01, -2.7763e-02,  2.1596e-01,  3.2189e-01,
         -1.9220e-01, -1.1136e-02, -2.9084e-01, -2.6664e-01, -3.0258e-01,
         -2.5393e-01],
        [ 8.5730e-02,  2.0450e-01,  2.8684e-01, -8.9840e-02,  1.7486e-01,
         -3.6101e-01, -4.3906e-01, -3.8220e-01, -3.0341e-01, -2.9453e-01,
          3.0949e-02,  1.3966e-03, -7.4129e-03,  2.6286e-01,  5.2804e-02,
          2.1114e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0941, -0.0606,  0.1860, -0.0263, -0.0867, -0.0402,  0.0748,  0.0644,
        -0.0250, -0.0589, -0.0326,  0.0539,  0.1297,  0.1019, -0.0179, -0.0042,
        -0.1399,  0.0210,  0.1185,  0.0200, -0.0211, -0.1778, -0.0106, -0.0476,
        -0.0370,  0.2287,  0.1256,  0.0169, -0.0478, -0.1506,  0.0133,  0.0320],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1944,  0.2856, -0.2113, -0.2431,  0.2666,  0.3170, -0.2627, -0.3652,
         -0.2876,  0.3071,  0.2485,  0.3604, -0.2227, -0.3637,  0.2854, -0.1567,
         -0.2840,  0.3243, -0.2154, -0.2297,  0.3443,  0.3411, -0.3609, -0.3667,
         -0.2621, -0.2932, -0.3067,  0.3281, -0.3507,  0.3720,  0.2853, -0.2239]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0116, -0.0039,  0.0256,  ...,  0.2092, -0.3533, -0.1137],
        [-0.0825, -0.1905,  0.0827,  ...,  0.1456, -0.3298,  0.0871],
        [-0.0535,  0.1583,  0.0912,  ...,  0.0104,  0.2364,  0.0345],
        ...,
        [ 0.0412, -0.1567,  0.0127,  ...,  0.0674, -0.2809, -0.1180],
        [ 0.0352, -0.0696,  0.0063,  ..., -0.3032,  0.1282,  0.1557],
        [-0.0845,  0.1620,  0.0125,  ..., -0.1728,  0.0640, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0512,  0.0543, -0.0931, -0.1202, -0.0574,  0.0456, -0.1293,  0.0622,
        -0.0465,  0.0924,  0.0332,  0.0079,  0.0093,  0.0628, -0.0786, -0.0205,
         0.0467, -0.1419, -0.0321, -0.0149, -0.1092,  0.0480,  0.0818, -0.0067,
        -0.0848,  0.0669,  0.0240, -0.0961,  0.0642,  0.1475,  0.1366, -0.0661],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0373, -0.1976, -0.0794,  ..., -0.1415, -0.0144,  0.2638],
        [-0.2373, -0.0463,  0.1060,  ..., -0.0721, -0.0012,  0.2723],
        [ 0.1658, -0.0182, -0.1776,  ...,  0.0842, -0.0250, -0.0698],
        ...,
        [ 0.1530,  0.1132,  0.0802,  ...,  0.2649, -0.2238,  0.0539],
        [-0.0540, -0.1751,  0.0778,  ...,  0.0012,  0.2504,  0.0875],
        [-0.0194, -0.1231,  0.2125,  ...,  0.0495,  0.1411,  0.1327]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0869,  0.1224, -0.0353, -0.0548, -0.0314, -0.0354, -0.0324, -0.0626,
         0.1099, -0.1751,  0.1225, -0.1330,  0.1649, -0.0183, -0.1430,  0.1053,
        -0.1272, -0.1538,  0.0133, -0.0297,  0.0087,  0.1087, -0.1891,  0.2023,
        -0.0698, -0.0288,  0.0881, -0.0373, -0.1120, -0.0600,  0.1109,  0.0008],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5196,  0.4439, -0.5221, -0.5253,  0.3703,  0.3785, -0.4265,  0.4352,
          0.4351, -0.4580, -0.4481,  0.4090,  0.4311, -0.3721,  0.4521,  0.4005,
         -0.5299, -0.5211,  0.3981,  0.4153, -0.4831, -0.4561, -0.5196,  0.3551,
          0.4943,  0.5207, -0.4947,  0.5627, -0.4303, -0.5120,  0.4968,  0.5118]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2411], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.1923e-02,  3.4905e-01,  3.2227e-01, -3.4565e-01, -3.0832e-02,
         -1.7870e-01, -6.9095e-02, -3.9379e-01, -1.7857e-01, -8.2661e-02,
          3.1410e-02,  1.7747e-01,  6.3802e-02, -5.4720e-02,  3.1869e-01,
          3.6089e-01],
        [-2.7635e-01, -3.3454e-01, -1.2773e-01,  1.3662e-02, -1.5537e-01,
          2.8634e-01,  1.9081e-01,  1.7281e-01,  4.0282e-01,  1.3386e-01,
          2.1877e-01, -2.7570e-01, -3.7302e-03, -4.3658e-02, -1.6806e-03,
         -8.1920e-02],
        [ 9.8780e-02,  2.4300e-01,  4.0138e-01, -1.3879e-01,  1.3695e-01,
         -3.7474e-01, -6.5854e-02, -4.1665e-01,  5.1865e-02, -7.9501e-02,
         -9.2710e-02, -5.9082e-02,  3.9937e-01,  3.0718e-01,  4.3461e-01,
          2.6232e-01],
        [ 2.9203e-01,  6.4553e-02,  1.0641e-01, -9.1678e-02,  9.5516e-02,
         -2.3115e-01, -1.7301e-01, -1.0104e-01, -4.0961e-01, -4.0135e-01,
         -1.0441e-01,  3.6856e-01,  2.8844e-01, -1.2944e-01,  1.4310e-01,
          1.5728e-01],
        [-1.1717e-01,  1.2534e-01, -1.8994e-01, -3.2460e-03,  5.9171e-02,
          1.2500e-01,  6.9212e-02,  3.5181e-01,  1.6285e-01,  2.9110e-01,
          2.2789e-01, -1.9307e-01, -5.8219e-02, -2.2610e-01, -8.6582e-02,
         -1.3472e-01],
        [-2.2209e-02,  1.4913e-01, -3.7599e-01,  4.1311e-01,  1.6453e-01,
          5.3609e-03,  2.7737e-01, -1.7611e-02,  2.5438e-01,  2.0496e-01,
         -1.4015e-01, -1.0002e-01, -2.5162e-01,  1.3191e-01,  3.0412e-02,
         -6.8861e-02],
        [ 3.9330e-01,  1.9784e-01,  4.3235e-01, -2.0264e-01,  1.2450e-01,
         -2.5112e-01, -2.1260e-01, -2.4291e-01, -2.5309e-01, -2.6449e-02,
         -1.7384e-02,  6.8779e-02, -2.9420e-02,  2.2702e-01, -1.0387e-02,
          1.5991e-01],
        [-4.4872e-02,  3.1199e-01,  3.7455e-01, -3.6220e-01, -1.5027e-01,
         -3.3137e-01, -1.0998e-01, -2.5007e-01, -1.8074e-01, -2.1314e-01,
         -7.0397e-02,  2.3414e-02,  2.5746e-01, -8.5961e-02,  1.6229e-01,
          3.6329e-01],
        [ 5.6361e-02,  3.0087e-01,  3.2568e-01, -2.6879e-01,  2.6924e-02,
         -3.8317e-01, -1.8502e-01, -1.1537e-01,  3.9301e-02, -3.1306e-01,
         -1.1066e-01,  7.8338e-02, -7.7638e-02,  1.3948e-01,  1.5626e-02,
          9.3379e-02],
        [-3.0612e-01, -8.0532e-02, -1.1675e-01,  2.4972e-03, -3.7578e-02,
          1.9019e-01,  6.8801e-02,  2.5572e-01,  2.7451e-01, -8.3001e-03,
          2.3518e-01, -2.7074e-02, -2.6571e-01, -6.7017e-02, -1.8906e-01,
         -1.8666e-01],
        [-3.6832e-01,  7.5654e-02, -7.8930e-02, -2.7519e-02, -1.7148e-01,
          4.5508e-01,  2.4646e-01,  1.2318e-01,  3.3939e-01,  2.4667e-01,
          6.5192e-02,  5.3820e-03, -1.6482e-01,  1.3710e-01, -3.8958e-01,
         -3.2762e-01],
        [-1.4437e-01, -1.4088e-01, -4.3179e-02,  1.0500e-01,  1.1703e-01,
          1.5294e-01,  3.9015e-01,  1.6532e-01,  1.7197e-01,  3.4244e-01,
          1.5231e-01,  4.4981e-02, -4.0548e-01, -1.9976e-01, -2.6023e-01,
         -1.9709e-01],
        [ 3.6746e-01,  2.1595e-01,  2.0188e-01, -2.0355e-01,  6.9496e-02,
         -2.8595e-02, -1.1635e-01, -3.4292e-01, -3.4366e-01, -1.1995e-01,
         -1.1889e-01,  4.8388e-02, -1.9419e-02,  1.9362e-01,  1.7380e-01,
          3.2289e-02],
        [ 2.3726e-01,  3.5113e-01,  3.9738e-01, -3.4761e-02, -1.8323e-01,
         -6.4242e-02, -7.4780e-02, -9.0710e-02, -2.2529e-01, -1.7216e-01,
         -2.1331e-01,  1.3032e-01,  1.3647e-01,  7.1256e-02, -3.2349e-02,
          2.4938e-01],
        [-3.9536e-01, -2.9986e-01, -9.0289e-02, -2.7371e-02,  2.0862e-01,
          4.4612e-01,  1.2128e-01,  1.2470e-01, -3.5180e-02,  1.8362e-01,
          1.2594e-01, -3.1813e-01, -8.9438e-02, -1.1630e-01, -2.8388e-01,
         -1.6831e-01],
        [-8.7529e-02, -1.5958e-01,  1.7927e-01,  8.9219e-02, -2.0309e-01,
         -1.8079e-02, -1.5790e-01, -2.9596e-01, -1.7043e-01, -7.9807e-03,
          1.1147e-02,  4.3277e-01,  1.2192e-01, -9.2537e-02,  4.1867e-01,
          2.6929e-02],
        [ 3.3259e-01,  2.6986e-01,  2.1933e-01, -3.6707e-01, -2.1094e-01,
         -7.1434e-02, -1.2261e-01, -5.8404e-03, -3.5928e-01, -1.8626e-01,
          1.4006e-01,  2.9129e-01,  3.4989e-01,  2.8439e-01,  1.2913e-01,
         -1.9190e-02],
        [-3.1589e-01, -1.7909e-02, -2.6707e-01,  1.5500e-01, -8.3352e-03,
          3.3759e-01,  3.1345e-01,  2.8040e-01,  1.3625e-01,  2.8538e-01,
         -3.8286e-02, -2.5053e-01, -1.7098e-01, -2.2177e-01,  4.0595e-02,
         -1.8507e-01],
        [ 2.5082e-01,  1.2740e-01,  1.7618e-01, -3.1205e-01, -1.1502e-02,
         -4.1304e-01, -3.0998e-01,  2.5450e-02, -3.9118e-01, -1.3461e-01,
         -4.1524e-02, -7.7045e-02,  1.9955e-01,  2.5598e-01,  3.7238e-01,
          2.0581e-01],
        [ 3.8936e-01,  1.3517e-01,  2.9211e-01, -1.0636e-01, -1.7532e-01,
         -2.6591e-01, -3.7515e-01,  2.8839e-02, -3.8143e-02, -2.7723e-01,
         -6.6166e-02,  2.4956e-01, -7.2398e-02,  1.0414e-01,  3.2954e-01,
          2.0471e-01],
        [-2.0229e-01,  7.8993e-02, -6.9790e-02, -5.0084e-02,  1.5430e-01,
          2.8568e-03,  3.3291e-01,  3.9725e-01,  1.9475e-01,  7.4479e-02,
         -7.1701e-02, -3.0505e-01, -2.0696e-01, -2.0740e-01,  4.1677e-02,
         -2.5288e-01],
        [-7.9939e-02, -3.3614e-01, -5.8633e-02,  3.8925e-01, -1.4905e-01,
          1.3876e-01,  2.5325e-01, -6.6898e-02,  8.4343e-03,  2.5139e-01,
          2.4987e-01, -2.5854e-01, -1.5520e-01, -3.3687e-01, -4.4927e-01,
          6.2816e-02],
        [ 3.7606e-01,  3.0542e-02,  6.7471e-02, -1.6837e-01,  1.5655e-01,
         -4.2195e-01, -3.0926e-01, -2.1243e-01, -2.3181e-01, -1.5013e-01,
          1.2035e-01,  2.0136e-01, -1.0796e-01,  3.0930e-01,  3.7961e-01,
          2.2505e-01],
        [ 2.7566e-01,  1.9930e-01,  3.6095e-01, -3.8163e-01, -9.0598e-02,
         -2.0099e-01, -2.0394e-01, -2.7245e-01, -3.4406e-01, -3.2398e-01,
         -1.0309e-01,  3.3715e-01,  2.5770e-01,  1.4557e-01,  7.4320e-03,
          4.1095e-02],
        [ 2.2826e-01, -1.3940e-01,  1.9060e-01, -1.4428e-01,  1.8638e-01,
         -2.9096e-01,  2.0676e-02, -1.9596e-01, -3.6884e-01,  5.7868e-02,
          1.7219e-01,  1.9305e-02,  5.4532e-02,  2.3416e-01,  7.9144e-02,
          3.2687e-01],
        [ 7.3424e-02,  1.2123e-02,  1.2099e-01,  5.4701e-02, -8.4074e-02,
         -2.6375e-01, -5.7982e-02, -3.6717e-01, -1.8615e-01, -3.6416e-01,
         -2.9261e-01,  1.4385e-01,  2.0209e-01,  3.3302e-01, -1.7389e-02,
          8.4273e-02],
        [ 2.3350e-01,  2.0517e-01,  3.1645e-01, -3.5622e-01, -6.3289e-03,
         -1.2534e-01, -3.7552e-01, -1.7191e-03, -3.6085e-01,  8.7124e-03,
          3.5956e-03,  7.3216e-02,  2.0298e-01,  2.9628e-01,  3.6620e-01,
          3.0398e-01],
        [-3.3393e-01, -3.6316e-02,  2.0647e-04,  2.1714e-01,  2.0461e-01,
          5.0375e-02,  3.8020e-01,  1.7257e-01, -5.7241e-02,  9.6176e-02,
          2.1616e-01, -2.7649e-01, -2.1235e-01, -1.8643e-01, -3.4363e-01,
         -1.0826e-01],
        [ 3.2197e-01,  1.4311e-01,  1.5732e-01, -1.4130e-01, -1.8558e-01,
         -3.1981e-01, -1.6376e-01, -3.4484e-01, -1.2910e-02, -1.0961e-01,
          3.2934e-03,  1.4336e-01,  3.1666e-01,  3.0676e-01,  3.0012e-01,
          2.7375e-01],
        [-2.8652e-01,  1.7391e-03, -3.3544e-01,  2.6108e-01, -2.3342e-01,
          1.7896e-01,  3.5410e-01,  2.9578e-01,  3.4300e-01,  2.2977e-01,
          1.8507e-01, -7.8178e-02,  4.7508e-02,  5.1344e-02, -1.0538e-01,
         -2.3327e-01],
        [-3.0181e-01, -1.7784e-01, -6.3924e-02,  3.2078e-02,  5.6196e-02,
          4.1640e-01,  4.0033e-01, -2.7763e-02,  2.1596e-01,  3.2189e-01,
         -1.9220e-01, -1.1137e-02, -2.9084e-01, -2.6664e-01, -3.0258e-01,
         -2.5393e-01],
        [ 8.5729e-02,  2.0450e-01,  2.8684e-01, -8.9839e-02,  1.7486e-01,
         -3.6101e-01, -4.3906e-01, -3.8220e-01, -3.0341e-01, -2.9453e-01,
          3.0950e-02,  1.3971e-03, -7.4120e-03,  2.6286e-01,  5.2804e-02,
          2.1114e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0941, -0.0606,  0.1860, -0.0263, -0.0867, -0.0402,  0.0748,  0.0644,
        -0.0250, -0.0589, -0.0326,  0.0539,  0.1297,  0.1019, -0.0179, -0.0042,
        -0.1399,  0.0210,  0.1185,  0.0200, -0.0211, -0.1778, -0.0106, -0.0476,
        -0.0370,  0.2287,  0.1256,  0.0169, -0.0478, -0.1506,  0.0133,  0.0320],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1944,  0.2856, -0.2113, -0.2431,  0.2666,  0.3170, -0.2627, -0.3652,
         -0.2876,  0.3071,  0.2485,  0.3604, -0.2227, -0.3637,  0.2854, -0.1567,
         -0.2840,  0.3243, -0.2154, -0.2297,  0.3443,  0.3411, -0.3609, -0.3667,
         -0.2621, -0.2932, -0.3067,  0.3281, -0.3507,  0.3720,  0.2853, -0.2239]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0116, -0.0039,  0.0256,  ...,  0.2092, -0.3533, -0.1137],
        [-0.0825, -0.1905,  0.0827,  ...,  0.1456, -0.3298,  0.0871],
        [-0.0535,  0.1583,  0.0912,  ...,  0.0104,  0.2364,  0.0345],
        ...,
        [ 0.0412, -0.1567,  0.0127,  ...,  0.0674, -0.2809, -0.1180],
        [ 0.0352, -0.0696,  0.0063,  ..., -0.3032,  0.1282,  0.1557],
        [-0.0845,  0.1620,  0.0125,  ..., -0.1728,  0.0640, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0512,  0.0543, -0.0931, -0.1202, -0.0574,  0.0456, -0.1293,  0.0622,
        -0.0465,  0.0924,  0.0332,  0.0079,  0.0093,  0.0628, -0.0786, -0.0205,
         0.0467, -0.1419, -0.0321, -0.0149, -0.1092,  0.0480,  0.0818, -0.0067,
        -0.0848,  0.0669,  0.0240, -0.0961,  0.0642,  0.1475,  0.1366, -0.0661],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0373, -0.1976, -0.0794,  ..., -0.1415, -0.0144,  0.2638],
        [-0.2373, -0.0463,  0.1060,  ..., -0.0721, -0.0012,  0.2723],
        [ 0.1658, -0.0182, -0.1776,  ...,  0.0842, -0.0250, -0.0698],
        ...,
        [ 0.1530,  0.1132,  0.0802,  ...,  0.2649, -0.2238,  0.0539],
        [-0.0540, -0.1751,  0.0778,  ...,  0.0012,  0.2504,  0.0875],
        [-0.0194, -0.1231,  0.2125,  ...,  0.0495,  0.1411,  0.1327]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0869,  0.1224, -0.0353, -0.0548, -0.0314, -0.0354, -0.0324, -0.0626,
         0.1099, -0.1751,  0.1225, -0.1330,  0.1649, -0.0183, -0.1430,  0.1053,
        -0.1272, -0.1538,  0.0133, -0.0297,  0.0087,  0.1087, -0.1891,  0.2023,
        -0.0698, -0.0288,  0.0881, -0.0373, -0.1120, -0.0600,  0.1109,  0.0008],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5196,  0.4439, -0.5221, -0.5253,  0.3703,  0.3785, -0.4265,  0.4352,
          0.4351, -0.4580, -0.4481,  0.4090,  0.4311, -0.3721,  0.4521,  0.4005,
         -0.5299, -0.5211,  0.3981,  0.4153, -0.4831, -0.4561, -0.5196,  0.3551,
          0.4943,  0.5207, -0.4947,  0.5627, -0.4303, -0.5120,  0.4968,  0.5118]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2411], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 9.1239e-03,  3.6092e-01,  3.2224e-01, -3.1571e-01, -3.2051e-01,
         -2.0383e-01, -9.1944e-02, -4.8082e-01, -2.5661e-01, -8.8423e-02,
         -2.6546e-02,  2.5205e-01,  1.0736e-01, -2.9480e-02,  3.1876e-02,
          3.7046e-01],
        [-2.6117e-01, -3.3789e-01, -1.1578e-01, -1.0867e-02,  6.5250e-02,
          2.8625e-01,  1.9746e-01,  2.3086e-01,  4.5653e-01,  1.5347e-01,
          2.8560e-01, -3.1418e-01, -2.1696e-02, -7.9428e-02,  2.5759e-01,
         -8.3282e-02],
        [ 9.0554e-02,  2.4864e-01,  3.9398e-01, -1.1016e-01, -1.7852e-01,
         -3.8333e-01, -8.2391e-02, -5.0061e-01, -3.4714e-02, -8.6564e-02,
         -1.3881e-01, -2.3465e-03,  4.3613e-01,  3.6767e-01,  1.4306e-01,
          2.6640e-01],
        [ 2.8573e-01,  7.3464e-02,  1.0253e-01, -7.2557e-02, -1.5076e-01,
         -2.4066e-01, -1.9157e-01, -1.7831e-01, -4.9250e-01, -4.2834e-01,
         -1.2072e-01,  4.2766e-01,  3.1021e-01, -7.3450e-02, -1.2410e-01,
          1.6310e-01],
        [-1.0407e-01,  8.5115e-02, -1.8402e-01, -3.0130e-02,  2.5877e-01,
          1.2635e-01,  7.6928e-02,  3.9962e-01,  2.0881e-01,  3.1812e-01,
          3.2090e-01, -2.1737e-01, -7.5027e-02, -2.7995e-01,  1.9203e-01,
         -1.5977e-01],
        [-1.8614e-02,  1.2395e-01, -3.7638e-01,  4.0232e-01,  4.3277e-01,
          1.6571e-02,  2.9696e-01,  4.4893e-02,  3.1790e-01,  2.3707e-01,
         -9.2414e-02, -1.4324e-01, -2.7336e-01,  8.7746e-02,  3.0823e-01,
         -8.4137e-02],
        [ 3.8517e-01,  1.1773e-01,  4.2529e-01, -1.8676e-01, -1.4330e-01,
         -2.5403e-01, -2.1649e-01, -3.1445e-01, -3.2296e-01, -5.0343e-02,
         -5.5834e-02,  1.1997e-01, -3.3134e-02,  2.7042e-01, -1.8566e-01,
          1.6305e-01],
        [-5.0717e-02,  2.6819e-01,  3.6955e-01, -3.5430e-01, -4.0420e-01,
         -3.3123e-01, -1.1484e-01, -3.2414e-01, -2.5133e-01, -2.3593e-01,
         -1.0243e-01,  7.5924e-02,  2.7173e-01, -4.7521e-02,  5.7563e-03,
          3.6359e-01],
        [ 4.7450e-02,  3.0523e-01,  3.1938e-01, -2.4366e-01, -1.4182e-01,
         -3.9032e-01, -2.0205e-01, -1.7853e-01, -2.0059e-02, -3.3833e-01,
         -2.5737e-01,  1.1466e-01, -3.4471e-02,  2.0636e-01, -2.4351e-01,
          1.0063e-01],
        [-3.0061e-01, -1.0706e-01, -1.1593e-01, -1.4497e-02,  1.7233e-01,
          2.0157e-01,  8.8762e-02,  3.2069e-01,  3.3801e-01,  2.5249e-02,
          3.3124e-01, -6.6367e-02, -3.0065e-01, -1.2815e-01,  9.1768e-02,
         -2.0604e-01],
        [-3.7196e-01,  4.6422e-02, -8.4709e-02, -3.2529e-02,  6.0892e-02,
          4.7510e-01,  2.7320e-01,  2.0880e-01,  4.2510e-01,  2.8436e-01,
          1.3410e-01, -6.0307e-02, -1.8824e-01,  6.5475e-02, -7.8244e-02,
         -3.4417e-01],
        [-1.3911e-01, -1.6107e-01, -4.2864e-02,  9.0384e-02,  2.6197e-01,
          1.6503e-01,  4.0772e-01,  2.3268e-01,  2.3123e-01,  3.7690e-01,
          2.4903e-01,  3.1931e-03, -4.0727e-01, -2.8661e-01, -1.4995e-02,
         -2.1441e-01],
        [ 3.5293e-01,  2.5042e-01,  1.9160e-01, -1.7426e-01, -2.4664e-01,
         -4.0599e-02, -1.3822e-01, -4.4036e-01, -4.1236e-01, -1.4465e-01,
         -1.6287e-01,  1.1369e-01, -8.1138e-03,  2.2582e-01, -1.7077e-01,
          4.6592e-02],
        [ 2.2144e-01,  3.3458e-01,  3.8449e-01, -1.3578e-02, -3.9081e-01,
         -6.0310e-02, -7.4782e-02, -1.4070e-01, -2.7418e-01, -1.8989e-01,
         -2.7299e-01,  1.6084e-01,  1.4896e-01,  1.0613e-01, -2.4941e-01,
          2.4784e-01],
        [-3.8757e-01, -2.9800e-01, -8.4123e-02, -4.2718e-02,  4.5362e-01,
          4.4950e-01,  1.3264e-01,  1.9282e-01,  3.1947e-02,  2.0723e-01,
          1.8578e-01, -3.6530e-01, -1.1420e-01, -1.6108e-01, -5.0705e-02,
         -1.7189e-01],
        [-5.9193e-02, -7.0590e-02,  2.1886e-01,  8.9066e-02, -4.4735e-01,
         -9.0256e-02, -2.4161e-01, -4.2258e-01, -2.9539e-01, -9.5142e-02,
         -1.2579e-01,  4.8886e-01,  2.0822e-01,  2.9532e-02,  1.5639e-01,
          8.2792e-02],
        [ 3.2888e-01,  2.7028e-01,  2.1797e-01, -3.5601e-01, -4.4854e-01,
         -8.1318e-02, -1.3954e-01, -7.7807e-02, -4.3218e-01, -2.1566e-01,
          9.8951e-02,  3.4761e-01,  3.9000e-01,  3.3371e-01, -6.7094e-02,
         -1.4597e-02],
        [-3.0709e-01, -8.5257e-03, -2.6057e-01,  1.4352e-01,  2.0806e-01,
          3.3458e-01,  3.1747e-01,  3.3741e-01,  1.9837e-01,  3.0760e-01,
         -4.6685e-04, -2.9201e-01, -1.8453e-01, -2.6973e-01,  2.0632e-01,
         -1.8617e-01],
        [ 2.2897e-01,  1.1781e-01,  1.5398e-01, -2.6822e-01, -3.2262e-01,
         -4.1261e-01, -3.1941e-01, -5.8804e-02, -4.8178e-01, -1.2511e-01,
         -1.0896e-01, -2.2131e-02,  2.6058e-01,  3.1876e-01,  9.6667e-02,
          1.9031e-01],
        [ 3.8742e-01,  1.3620e-01,  2.9041e-01, -9.1138e-02, -4.1102e-01,
         -2.7741e-01, -3.9613e-01, -5.5188e-02, -1.1957e-01, -3.0495e-01,
         -1.4918e-01,  3.1044e-01, -2.9744e-02,  1.6215e-01,  9.7569e-02,
          2.1050e-01],
        [-1.9097e-01,  5.2929e-02, -6.3137e-02, -6.7577e-02,  3.5142e-01,
         -1.7013e-03,  3.3671e-01,  4.2508e-01,  2.2958e-01,  9.5921e-02,
         -8.5356e-03, -3.1872e-01, -2.1608e-01, -2.4714e-01,  2.9402e-01,
         -2.6499e-01],
        [-8.3045e-02, -3.3474e-01, -6.2800e-02,  3.7891e-01,  6.7187e-02,
          1.5875e-01,  2.8930e-01,  1.9807e-02,  8.8312e-02,  2.8971e-01,
          3.8158e-01, -3.1438e-01, -2.2316e-01, -4.0878e-01, -1.7681e-01,
          4.8802e-02],
        [ 3.7812e-01,  3.3241e-02,  7.0417e-02, -1.6618e-01, -7.5045e-02,
         -4.3422e-01, -3.3029e-01, -2.9203e-01, -3.1089e-01, -1.8262e-01,
          6.5949e-02,  2.6045e-01, -6.5203e-02,  3.6698e-01,  1.9078e-01,
          2.3301e-01],
        [ 2.6845e-01,  2.0240e-01,  3.5575e-01, -3.7423e-01, -2.9789e-01,
         -1.9761e-01, -2.1069e-01, -3.3958e-01, -4.1049e-01, -3.4534e-01,
         -9.7153e-02,  3.8598e-01,  2.7015e-01,  1.8599e-01, -1.4574e-01,
          3.7454e-02],
        [ 2.2303e-01, -1.0974e-01,  1.9014e-01, -1.2225e-01, -3.2652e-02,
         -3.0488e-01,  1.8341e-03, -2.5628e-01, -4.3370e-01,  2.3580e-02,
          7.2902e-02,  6.2385e-02,  9.0155e-02,  2.9306e-01, -2.2383e-01,
          3.5011e-01],
        [ 5.2875e-02,  3.0965e-02,  1.0457e-01,  8.0623e-02, -3.0172e-01,
         -2.4906e-01, -4.9877e-02, -3.9552e-01, -2.1644e-01, -3.7741e-01,
         -3.5783e-01,  1.5642e-01,  1.9979e-01,  3.6261e-01, -2.8310e-01,
          9.0765e-02],
        [ 2.3468e-01,  1.9736e-01,  3.1804e-01, -3.5231e-01, -2.5293e-01,
         -1.3661e-01, -3.9442e-01, -8.7511e-02, -4.4419e-01, -2.1482e-02,
         -4.1569e-02,  1.3748e-01,  2.4527e-01,  3.4780e-01,  1.8713e-01,
          3.0893e-01],
        [-3.3151e-01, -5.5068e-02, -1.6522e-03,  2.0622e-01,  3.9797e-01,
          6.5955e-02,  4.0256e-01,  2.4917e-01,  1.2065e-02,  1.3274e-01,
          2.9465e-01, -3.2774e-01, -2.4453e-01, -2.5358e-01, -9.4258e-02,
         -1.2560e-01],
        [ 3.1727e-01,  1.6554e-01,  1.5559e-01, -1.3476e-01, -3.8096e-01,
         -3.2697e-01, -1.8021e-01, -4.1174e-01, -7.8959e-02, -1.3729e-01,
         -4.4414e-03,  1.9414e-01,  3.1675e-01,  3.6342e-01,  7.5125e-02,
          2.7914e-01],
        [-2.8418e-01,  2.1282e-02, -3.3402e-01,  2.5630e-01, -4.7266e-03,
          1.8191e-01,  3.6482e-01,  3.6551e-01,  4.1292e-01,  2.5696e-01,
          2.3788e-01, -1.2776e-01,  2.3986e-02,  8.5250e-04,  5.8891e-02,
         -2.3918e-01],
        [-3.0023e-01, -1.8647e-01, -6.3829e-02,  2.2046e-02,  2.8243e-01,
          4.2833e-01,  4.1905e-01,  4.8405e-02,  2.9256e-01,  3.5185e-01,
         -1.2794e-01, -6.8184e-02, -3.3207e-01, -3.2679e-01, -8.0919e-02,
         -2.6063e-01],
        [ 6.9139e-02,  1.7827e-01,  2.7131e-01, -4.9707e-02, -8.0987e-02,
         -3.6051e-01, -4.4204e-01, -4.5206e-01, -3.7876e-01, -2.9463e-01,
         -3.3825e-02,  4.7112e-02,  1.2943e-02,  3.1878e-01, -1.6948e-01,
          2.0520e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0520, -0.0134,  0.1090, -0.0349, -0.0608, -0.0929,  0.0751,  0.0828,
        -0.0182, -0.0601, -0.0075,  0.0576,  0.1488,  0.0807,  0.0181, -0.0472,
        -0.0500, -0.0054,  0.0924,  0.0073, -0.0445, -0.1401, -0.0277,  0.0011,
        -0.0026,  0.1627,  0.1196,  0.0176, -0.0642, -0.1421,  0.0297, -0.0424],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2356,  0.3261, -0.2322, -0.2663,  0.3281,  0.3663, -0.2862, -0.3884,
         -0.3188,  0.3516,  0.2683,  0.3787, -0.2692, -0.4029,  0.3083, -0.2918,
         -0.3250,  0.3358, -0.2329, -0.2544,  0.4052,  0.3170, -0.3758, -0.3827,
         -0.3349, -0.3443, -0.3177,  0.3562, -0.3640,  0.3870,  0.2941, -0.2415]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0137, -0.0092,  0.0437,  ...,  0.2362, -0.3692, -0.1137],
        [-0.0867, -0.1926,  0.0879,  ...,  0.1477, -0.3495,  0.0871],
        [-0.0399,  0.1766,  0.0728,  ..., -0.0051,  0.2696,  0.0345],
        ...,
        [ 0.0256, -0.1912,  0.0427,  ...,  0.0660, -0.2954, -0.1180],
        [ 0.0513, -0.0487, -0.0197,  ..., -0.3043,  0.1549,  0.1557],
        [-0.2050,  0.0491,  0.0024,  ...,  0.0415, -0.2406, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0568,  0.0572, -0.0878, -0.1192, -0.0577,  0.0530, -0.1276,  0.0608,
        -0.0488,  0.0816,  0.0310,  0.0095,  0.0260,  0.0735, -0.0779, -0.0170,
         0.0495, -0.1500, -0.0289, -0.0242, -0.0746,  0.0444,  0.0888, -0.0068,
        -0.0873,  0.0870,  0.0330, -0.0874,  0.0486,  0.1382,  0.1479, -0.1055],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0184, -0.1907, -0.0790,  ..., -0.1168, -0.0267,  0.0710],
        [-0.2649, -0.0448,  0.1169,  ..., -0.0488, -0.0057,  0.0589],
        [ 0.1837, -0.0290, -0.1777,  ...,  0.0545, -0.0096,  0.1670],
        ...,
        [ 0.1656,  0.0969,  0.0885,  ...,  0.2283, -0.2013,  0.2418],
        [-0.0785, -0.1647,  0.0793,  ...,  0.0320,  0.2377, -0.1655],
        [-0.0485, -0.1255,  0.2167,  ...,  0.0708,  0.1353, -0.0318]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0834,  0.1213, -0.0228, -0.0587, -0.0345, -0.0630, -0.0258, -0.0599,
         0.0943, -0.1348,  0.1353, -0.1271,  0.1514,  0.0573, -0.1344,  0.0872,
        -0.1176, -0.1454,  0.0028, -0.0141,  0.0073,  0.1099, -0.1833,  0.1727,
        -0.0643, -0.0313,  0.0910, -0.0426, -0.1090, -0.0532,  0.0948,  0.0030],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5256,  0.4477, -0.5247, -0.5275,  0.3923,  0.3833, -0.4393,  0.4338,
          0.4586, -0.4629, -0.4226,  0.4189,  0.4179,  0.4281,  0.4567,  0.4104,
         -0.5260, -0.5315,  0.3956,  0.4213, -0.4811, -0.4593, -0.5256,  0.3862,
          0.5096,  0.5335, -0.5092,  0.5585, -0.4378, -0.5228,  0.5044,  0.5255]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2441], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 0.0133,  0.0606,  0.2964, -0.3335, -0.2878, -0.1512, -0.0579, -0.4536,
         -0.2081, -0.0566,  0.1796,  0.2009,  0.0632, -0.0555, -0.1848,  0.3696],
        [-0.2640, -0.0692, -0.1014,  0.0165,  0.0445,  0.2482,  0.1668,  0.2064,
          0.4395,  0.1396,  0.0674, -0.2770, -0.0111, -0.0610,  0.4653, -0.0843],
        [ 0.0907,  0.0011,  0.3718, -0.1279, -0.1383, -0.3412, -0.0396, -0.4605,
          0.0101, -0.0626, -0.0804, -0.0477,  0.4040,  0.3248, -0.0593,  0.2623],
        [ 0.2730, -0.0610,  0.0712, -0.0847, -0.1086, -0.1816, -0.1377, -0.1302,
         -0.4449, -0.3944,  0.0321,  0.3638,  0.2959, -0.1150, -0.2916,  0.1450],
        [-0.1029,  0.3422, -0.1637, -0.0045,  0.2283,  0.0811,  0.0376,  0.3655,
          0.1781,  0.2997,  0.0659, -0.1723, -0.0567, -0.2509,  0.3808, -0.1578],
        [-0.0057,  0.3197, -0.3495,  0.4158,  0.3755, -0.0418,  0.2483, -0.0027,
          0.2778,  0.2101, -0.1131, -0.0920, -0.2350,  0.1186,  0.4492, -0.0747],
        [ 0.3750, -0.0133,  0.3989, -0.2007, -0.1129, -0.2054, -0.1685, -0.2740,
         -0.2797, -0.0256,  0.0047,  0.0705, -0.0603,  0.1852, -0.3598,  0.1511],
        [-0.0589,  0.1317,  0.3491, -0.3698, -0.3838, -0.2953, -0.0806, -0.2989,
         -0.2274, -0.2207, -0.0572,  0.0442,  0.2539, -0.0954, -0.1436,  0.3548],
        [ 0.0520,  0.0146,  0.3063, -0.2750, -0.1261, -0.3518, -0.1724, -0.1557,
          0.0011, -0.3265,  0.0153,  0.0784, -0.0441,  0.1911, -0.4421,  0.1057],
        [-0.3026,  0.1718, -0.1015,  0.0146,  0.1434,  0.1594,  0.0528,  0.2875,
          0.3096,  0.0108,  0.1065, -0.0270, -0.2814, -0.1096,  0.2834, -0.2095],
        [-0.3658,  0.2209, -0.0594, -0.0152,  0.0284,  0.4249,  0.2326,  0.1710,
          0.3895,  0.2583,  0.0018, -0.0096, -0.2149,  0.0820,  0.0935, -0.3353],
        [-0.1295,  0.0260, -0.0171,  0.1091,  0.2169,  0.1175,  0.3529,  0.1828,
          0.1865,  0.3501,  0.0864,  0.0568, -0.4212, -0.2405,  0.1382, -0.2036],
        [ 0.3494, -0.0088,  0.1615, -0.1970, -0.1965,  0.0211, -0.0908, -0.3926,
         -0.3749, -0.1135, -0.0943,  0.0556, -0.0122,  0.2066, -0.4003,  0.0388],
        [ 0.2175,  0.1041,  0.3667, -0.0347, -0.3641, -0.0230, -0.0374, -0.1103,
         -0.2531, -0.1737, -0.1061,  0.1238,  0.1327,  0.0681, -0.4349,  0.2432],
        [-0.3875, -0.0571, -0.0674, -0.0185,  0.4377,  0.4150,  0.1018,  0.1707,
          0.0100,  0.1941,  0.0320, -0.3307, -0.1083, -0.1374,  0.1590, -0.1698],
        [-0.0318, -0.4070,  0.2017,  0.0337, -0.4489, -0.0254, -0.2019, -0.4098,
         -0.2786, -0.0728, -0.0521,  0.4487,  0.1911, -0.0202, -0.1022,  0.1013],
        [ 0.3180,  0.0948,  0.1924, -0.3686, -0.3900, -0.0304, -0.0849, -0.0284,
         -0.3994, -0.1873,  0.1964,  0.2940,  0.3504,  0.2690, -0.1985, -0.0297],
        [-0.2907,  0.1217, -0.2300,  0.1509,  0.1522,  0.2855,  0.2642,  0.2913,
          0.1531,  0.2806, -0.0546, -0.2418, -0.1473, -0.1931,  0.2900, -0.1680],
        [ 0.2390, -0.0940,  0.1429, -0.2956, -0.2508, -0.3752, -0.2742, -0.0129,
         -0.4328, -0.1100,  0.0197, -0.0679,  0.2036,  0.2556, -0.0700,  0.1951],
        [ 0.3805, -0.0685,  0.2625, -0.1091, -0.3820, -0.2316, -0.3517, -0.0213,
         -0.0851, -0.2792,  0.0954,  0.2600, -0.0370,  0.1179, -0.1064,  0.1986],
        [-0.1786,  0.2424, -0.0363, -0.0562,  0.3036, -0.0474,  0.2934,  0.3856,
          0.1969,  0.0725, -0.1092, -0.2743, -0.1956, -0.2045,  0.4224, -0.2528],
        [-0.0969,  0.0180, -0.0573,  0.4185,  0.0667,  0.1270,  0.2662,  0.0072,
          0.0813,  0.2867,  0.2110, -0.2960, -0.2216, -0.3954,  0.0073,  0.0406],
        [ 0.3728, -0.1548,  0.0499, -0.1853, -0.0480, -0.3977, -0.2922, -0.2660,
         -0.2853, -0.1665,  0.2095,  0.2255, -0.0681,  0.3233,  0.0258,  0.2242],
        [ 0.2518,  0.1126,  0.3272, -0.3806, -0.2297, -0.1521, -0.1579, -0.2939,
         -0.3711, -0.3166,  0.0201,  0.3402,  0.2621,  0.1201, -0.2262,  0.0140],
        [ 0.2185, -0.3723,  0.1700, -0.1477,  0.0074, -0.2511,  0.0486, -0.2087,
         -0.3909,  0.0454,  0.1970,  0.0109,  0.0603,  0.2704, -0.4108,  0.3499],
        [ 0.0478, -0.1821,  0.0831,  0.0630, -0.2625, -0.2108, -0.0198, -0.3639,
         -0.1903, -0.3601, -0.2660,  0.1187,  0.1972,  0.3376, -0.4693,  0.0838],
        [ 0.2245, -0.0118,  0.2894, -0.3646, -0.2155, -0.0966, -0.3445, -0.0545,
         -0.4086,  0.0019,  0.0508,  0.0929,  0.2322,  0.2698,  0.0355,  0.2917],
        [-0.3305,  0.1729,  0.0180,  0.2309,  0.3641,  0.0233,  0.3566,  0.2108,
         -0.0253,  0.1134,  0.0708, -0.2816, -0.2327, -0.2121,  0.0747, -0.1221],
        [ 0.3041,  0.0436,  0.1265, -0.1463, -0.3310, -0.2826, -0.1334, -0.3692,
         -0.0412, -0.1103,  0.1144,  0.1442,  0.3552,  0.3213, -0.0508,  0.2619],
        [-0.2737,  0.1591, -0.3107,  0.2699, -0.0327,  0.1440,  0.3245,  0.3347,
          0.3821,  0.2383,  0.1453, -0.0924,  0.0435,  0.0530,  0.2065, -0.2271],
        [-0.2891,  0.0187, -0.0350,  0.0354,  0.2405,  0.3789,  0.3703,  0.0096,
          0.2556,  0.3256, -0.2334, -0.0156, -0.3143, -0.2776,  0.0800, -0.2458],
        [ 0.0639, -0.0171,  0.2446, -0.0680, -0.0406, -0.3121, -0.3876, -0.3978,
         -0.3285, -0.2666,  0.0968, -0.0124, -0.0331,  0.2270, -0.3435,  0.1966]],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0633, -0.0596,  0.1179, -0.0761, -0.0512, -0.0271,  0.0848,  0.1376,
        -0.0456, -0.0644,  0.0249,  0.0682,  0.1908,  0.1083, -0.0575,  0.0979,
        -0.1518, -0.0059,  0.0238,  0.0021, -0.0190, -0.1107, -0.0590, -0.0249,
        -0.1607,  0.2587,  0.1054,  0.0251, -0.0835, -0.2284,  0.1607, -0.0291],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2570,  0.3438, -0.2496, -0.2640,  0.3468,  0.3867, -0.3016, -0.3861,
         -0.3366,  0.3911,  0.2686,  0.3957, -0.2909, -0.4276,  0.3256, -0.3214,
         -0.3309,  0.3316, -0.2413, -0.2608,  0.4245,  0.3454, -0.3772, -0.3785,
         -0.3872, -0.3633, -0.3229,  0.3707, -0.3513,  0.3895,  0.2930, -0.2433]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0543,  0.1295,  0.0574,  ...,  0.2204, -0.3313, -0.1137],
        [-0.1231, -0.0290,  0.1171,  ...,  0.1554, -0.3310,  0.0871],
        [ 0.0130, -0.0604,  0.0185,  ...,  0.0278,  0.2340,  0.0345],
        ...,
        [-0.0051,  0.0353,  0.0579,  ...,  0.0850, -0.3211, -0.1180],
        [ 0.0995, -0.2303, -0.0535,  ..., -0.3284,  0.1537,  0.1557],
        [-0.2188,  0.1720,  0.0376,  ...,  0.0981, -0.2800, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0411,  0.0406, -0.0663, -0.1341, -0.0722,  0.0602, -0.1102,  0.0454,
        -0.0384,  0.0799,  0.0171,  0.0118,  0.0301,  0.0790, -0.0525, -0.0184,
         0.0585, -0.1552,  0.0025,  0.0282, -0.0499,  0.0326,  0.1093,  0.0058,
        -0.0938,  0.1046,  0.0473, -0.0939,  0.0536,  0.1392,  0.1672, -0.1230],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0765, -0.1825, -0.1160,  ..., -0.1324, -0.0147,  0.0739],
        [-0.2040, -0.0384,  0.0846,  ..., -0.0654,  0.0089,  0.0483],
        [ 0.1357, -0.0252, -0.1594,  ...,  0.0840, -0.0276,  0.1884],
        ...,
        [ 0.1159,  0.0955,  0.1207,  ...,  0.2540, -0.2265,  0.2466],
        [-0.0045, -0.1498,  0.0386,  ...,  0.0161,  0.2373, -0.1682],
        [-0.0016, -0.1353,  0.1988,  ...,  0.0347,  0.1650, -0.0512]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1031,  0.1474, -0.0585, -0.0834, -0.0003, -0.0434, -0.0577, -0.0439,
         0.1237, -0.1692,  0.1274, -0.1171,  0.1719,  0.0868, -0.1230,  0.1250,
        -0.1389, -0.1725, -0.0582, -0.0033, -0.0026,  0.0851, -0.2103,  0.2130,
        -0.0459, -0.0046,  0.0747, -0.0287, -0.1358, -0.0728,  0.1203,  0.0420],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4657,  0.3857, -0.4708, -0.4602,  0.3382,  0.3203, -0.3837,  0.3563,
          0.3849, -0.4079, -0.3545,  0.3712,  0.3545,  0.3343,  0.3984,  0.3932,
         -0.4614, -0.4746, -0.3290,  0.3747, -0.4192, -0.3977, -0.4715,  0.3177,
          0.4414,  0.4756, -0.4593,  0.4645, -0.3855, -0.4627,  0.4472,  0.4726]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2267], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-8.5422e-03,  3.5353e-01,  2.8539e-01, -3.0170e-01, -2.8108e-01,
         -1.2992e-01, -3.9384e-02, -4.4138e-01, -2.0236e-01, -3.7605e-02,
          1.5267e-01,  1.7710e-01,  4.6057e-02, -6.3541e-02, -1.7247e-01,
          3.4709e-01],
        [-2.4464e-01, -3.4487e-01, -8.6095e-02, -9.1329e-03,  3.3538e-02,
          2.3300e-01,  1.5610e-01,  1.9259e-01,  4.2407e-01,  1.2376e-01,
          7.4208e-02, -2.5615e-01,  1.5320e-03, -5.3112e-02,  4.5375e-01,
         -6.4355e-02],
        [ 7.0197e-02,  2.4204e-01,  3.5721e-01, -1.0207e-01, -1.3781e-01,
         -3.2799e-01, -3.0986e-02, -4.5569e-01,  1.3880e-02, -4.6468e-02,
         -8.7636e-02, -6.5861e-02,  3.9652e-01,  3.2414e-01, -5.1042e-02,
          2.4271e-01],
        [ 2.5682e-01,  6.7880e-02,  6.2433e-02, -6.5154e-02, -1.0698e-01,
         -1.7209e-01, -1.3467e-01, -1.2073e-01, -4.4001e-01, -3.8385e-01,
          2.4399e-02,  3.5027e-01,  2.9135e-01, -1.1272e-01, -2.9065e-01,
          1.2818e-01],
        [-9.6223e-02,  8.6170e-02, -1.5901e-01, -2.2259e-02,  2.4399e-01,
          7.4815e-02,  4.2775e-02,  3.7607e-01,  1.8668e-01,  2.9285e-01,
          9.1255e-02, -1.6515e-01, -6.6128e-02, -2.6293e-01,  4.0248e-01,
         -1.4649e-01],
        [ 1.1326e-04,  1.2557e-01, -3.4728e-01,  4.0254e-01,  3.8694e-01,
         -4.0786e-02,  2.5141e-01, -2.4987e-03,  2.7956e-01,  2.0590e-01,
         -1.1531e-01, -8.6323e-02, -2.4737e-01,  1.1102e-01,  4.9325e-01,
         -6.6663e-02],
        [ 3.5714e-01,  1.2196e-01,  3.8668e-01, -1.7880e-01, -1.0774e-01,
         -1.9651e-01, -1.6327e-01, -2.6234e-01, -2.6354e-01, -1.3381e-02,
          2.1026e-03,  5.5193e-02, -6.6506e-02,  1.8454e-01, -3.6003e-01,
          1.3416e-01],
        [-7.6779e-02,  2.7376e-01,  3.3607e-01, -3.4712e-01, -3.6592e-01,
         -2.8503e-01, -7.0960e-02, -2.8171e-01, -2.0982e-01, -2.0777e-01,
         -7.1520e-02,  2.6018e-02,  2.4382e-01, -9.9509e-02, -1.3212e-01,
          3.3891e-01],
        [ 3.4625e-02,  3.1831e-01,  2.9308e-01, -2.5196e-01, -1.1171e-01,
         -3.3869e-01, -1.6298e-01, -1.4059e-01,  1.2695e-02, -3.1223e-01,
          6.9067e-03,  6.0177e-02, -5.3820e-02,  1.8586e-01, -4.3340e-01,
          8.6425e-02],
        [-2.9264e-01, -1.1161e-01, -9.3681e-02, -4.6729e-03,  1.4832e-01,
          1.5119e-01,  5.1719e-02,  2.8911e-01,  3.1004e-01,  1.6504e-03,
          1.3026e-01, -1.5644e-02, -2.8302e-01, -1.1240e-01,  2.9194e-01,
         -1.9654e-01],
        [-3.5602e-01,  4.6145e-02, -5.5068e-02, -2.8394e-02,  3.4258e-02,
          4.1930e-01,  2.3222e-01,  1.7018e-01,  3.9189e-01,  2.5202e-01,
         -5.7428e-03, -2.1343e-03, -2.1212e-01,  7.2547e-02,  1.0791e-01,
         -3.2350e-01],
        [-1.1693e-01, -1.5225e-01, -8.9479e-03,  9.1068e-02,  2.1168e-01,
          1.0661e-01,  3.5233e-01,  1.7947e-01,  1.8080e-01,  3.4139e-01,
          1.0957e-01,  6.8325e-02, -4.1453e-01, -2.4907e-01,  1.3563e-01,
         -1.8992e-01],
        [ 3.2895e-01,  2.4656e-01,  1.4664e-01, -1.6784e-01, -2.0502e-01,
          3.9630e-02, -8.2629e-02, -3.9239e-01, -3.7028e-01, -9.5827e-02,
         -9.8868e-02,  3.3463e-02, -2.1033e-02,  2.0351e-01, -3.9789e-01,
          1.8700e-02],
        [ 1.9939e-01,  3.3927e-01,  3.5150e-01, -1.1915e-02, -3.5130e-01,
         -9.9880e-03, -2.9426e-02, -9.6371e-02, -2.3539e-01, -1.5925e-01,
         -1.1129e-01,  1.0577e-01,  1.2186e-01,  6.3479e-02, -4.2526e-01,
          2.2541e-01],
        [-3.7032e-01, -3.0627e-01, -5.4612e-02, -4.0907e-02,  4.2728e-01,
          4.0251e-01,  9.3691e-02,  1.5782e-01, -1.4903e-03,  1.8049e-01,
          3.8028e-02, -3.1326e-01, -9.8603e-02, -1.3363e-01,  1.4721e-01,
         -1.5224e-01],
        [-3.0305e-01, -2.2633e-01,  1.4105e-02,  2.5989e-01,  1.4914e-01,
          1.7910e-01,  1.0335e-01,  8.3807e-02,  1.7137e-01,  1.3358e-01,
          4.4632e-02,  1.4348e-01, -1.5432e-01, -3.0089e-01,  5.9740e-01,
         -9.2956e-02],
        [ 2.9955e-01,  2.3894e-01,  1.8219e-01, -3.4773e-01, -3.8043e-01,
         -1.9045e-02, -8.0461e-02, -9.7172e-03, -3.8551e-01, -1.7583e-01,
          1.7441e-01,  2.7843e-01,  3.3824e-01,  2.7309e-01, -1.7647e-01,
         -4.6447e-02],
        [-2.7506e-01,  4.1016e-02, -2.2063e-01,  1.3022e-01,  1.4738e-01,
          2.7969e-01,  2.6145e-01,  2.8015e-01,  1.4313e-01,  2.7096e-01,
         -4.9085e-02, -2.2829e-01, -1.4791e-01, -1.9116e-01,  2.9037e-01,
         -1.5263e-01],
        [ 2.2091e-01,  1.1520e-01,  1.3377e-01, -2.7338e-01, -2.5088e-01,
         -3.6427e-01, -2.7061e-01, -6.4843e-03, -4.3348e-01, -9.7323e-02,
          2.1534e-02, -8.2333e-02,  1.9793e-01,  2.5966e-01, -5.9575e-02,
          1.7511e-01],
        [ 3.6541e-01,  1.4070e-01,  2.5496e-01, -9.0943e-02, -3.7785e-01,
         -2.2082e-01, -3.5103e-01, -1.1165e-02, -8.0706e-02, -2.6910e-01,
          8.7598e-02,  2.4792e-01, -4.2842e-02,  1.2766e-01, -1.0168e-01,
          1.8147e-01],
        [-1.6819e-01,  6.4026e-02, -2.8520e-02, -7.3756e-02,  3.0834e-01,
         -5.2672e-02,  2.9479e-01,  3.8454e-01,  1.9306e-01,  6.4733e-02,
         -9.1017e-02, -2.6424e-01, -2.0068e-01, -2.1286e-01,  4.5541e-01,
         -2.4156e-01],
        [-8.4826e-02, -3.3870e-01, -5.1483e-02,  3.9882e-01,  5.2396e-02,
          1.1848e-01,  2.6269e-01, -3.7104e-03,  7.4725e-02,  2.7732e-01,
          2.2828e-01, -2.8035e-01, -2.1754e-01, -3.9800e-01,  3.0003e-03,
          5.3637e-02],
        [ 3.6248e-01,  2.2890e-02,  4.4695e-02, -1.6998e-01, -4.5874e-02,
         -3.9211e-01, -2.9416e-01, -2.5932e-01, -2.8156e-01, -1.6058e-01,
          1.8750e-01,  2.1727e-01, -6.8199e-02,  3.2974e-01,  3.0304e-02,
          2.1268e-01],
        [ 2.3087e-01,  1.7815e-01,  3.1491e-01, -3.5663e-01, -2.1341e-01,
         -1.4033e-01, -1.5045e-01, -2.6958e-01, -3.5312e-01, -3.0397e-01,
          6.8267e-03,  3.2054e-01,  2.4970e-01,  1.1721e-01, -1.9845e-01,
         -3.0976e-03],
        [ 2.1486e-01, -9.5595e-02,  1.6891e-01, -1.3548e-01, -3.6970e-03,
         -2.4975e-01,  4.3492e-02, -2.1437e-01, -3.9677e-01,  4.8203e-02,
          2.0035e-01,  7.5599e-03,  6.9234e-02,  2.8222e-01, -4.2755e-01,
          3.4370e-01],
        [ 3.4612e-02,  4.0041e-02,  7.2175e-02,  8.2502e-02, -2.6522e-01,
         -2.0237e-01, -1.3282e-02, -3.6223e-01, -1.8503e-01, -3.4958e-01,
         -2.7745e-01,  1.0501e-01,  1.9571e-01,  3.3998e-01, -4.8727e-01,
          7.0609e-02],
        [ 2.0814e-01,  1.6655e-01,  2.8025e-01, -3.4546e-01, -2.0695e-01,
         -8.5580e-02, -3.4422e-01, -4.0531e-02, -3.9843e-01,  1.1956e-02,
          3.1174e-02,  8.0366e-02,  2.2340e-01,  2.8361e-01,  4.4986e-02,
          2.7687e-01],
        [-3.2213e-01, -5.2266e-02,  2.1413e-02,  2.1491e-01,  3.6792e-01,
          1.5675e-02,  3.6022e-01,  2.1207e-01, -2.3991e-02,  1.0807e-01,
          9.4995e-02, -2.7379e-01, -2.3415e-01, -2.2822e-01,  8.7048e-02,
         -1.1153e-01],
        [ 2.8725e-01,  1.5738e-01,  1.1570e-01, -1.2671e-01, -3.2196e-01,
         -2.6966e-01, -1.3009e-01, -3.5590e-01, -2.9861e-02, -9.9299e-02,
          9.4691e-02,  1.2953e-01,  3.4449e-01,  3.2517e-01, -3.9526e-02,
          2.4676e-01],
        [-2.6152e-01,  1.8807e-02, -3.0289e-01,  2.5216e-01, -3.6203e-02,
          1.3883e-01,  3.2386e-01,  3.2789e-01,  3.7475e-01,  2.3078e-01,
          1.5193e-01, -8.1546e-02,  4.2734e-02,  4.7235e-02,  2.1500e-01,
         -2.1517e-01],
        [-2.7379e-01, -1.6424e-01, -2.6925e-02,  1.6819e-02,  2.3330e-01,
          3.6994e-01,  3.6821e-01, -4.2249e-03,  2.4867e-01,  3.1561e-01,
         -2.1885e-01, -3.5642e-03, -3.0929e-01, -2.8043e-01,  6.5012e-02,
         -2.2945e-01],
        [ 4.1850e-02,  1.3637e-01,  2.3107e-01, -4.1216e-02, -3.4539e-02,
         -2.9824e-01, -3.8216e-01, -3.9220e-01, -3.2262e-01, -2.5161e-01,
          8.9734e-02, -2.9461e-02, -4.3225e-02,  2.2528e-01, -3.2629e-01,
          1.7454e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0876, -0.0306,  0.1145, -0.0799, -0.0484, -0.0253,  0.0849,  0.1344,
        -0.0571, -0.0467,  0.0089,  0.0918,  0.1596,  0.0897, -0.0360, -0.0537,
        -0.1777,  0.0013,  0.0095, -0.0135, -0.0148, -0.0862, -0.0713, -0.0394,
        -0.1327,  0.2626,  0.0842,  0.0446, -0.1026, -0.2260,  0.1848, -0.0451],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2585,  0.3430, -0.2508, -0.2698,  0.3707,  0.4035, -0.3055, -0.3842,
         -0.3506,  0.3971,  0.2769,  0.3946, -0.2999, -0.4318,  0.3245,  0.3101,
         -0.3305,  0.3350, -0.2434, -0.2621,  0.4300,  0.3415, -0.3796, -0.3782,
         -0.4165, -0.3723, -0.3231,  0.3719, -0.3535,  0.3919,  0.2959, -0.2473]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0158,  0.1024,  0.0774,  ...,  0.1582, -0.2623, -0.1137],
        [-0.1131, -0.0409,  0.1176,  ...,  0.1306, -0.3117,  0.0871],
        [-0.0031, -0.0395,  0.0316,  ...,  0.0274,  0.2314,  0.0345],
        ...,
        [ 0.0080,  0.0210,  0.0540,  ...,  0.0664, -0.3114, -0.1180],
        [ 0.0927, -0.2199, -0.0535,  ..., -0.3024,  0.1390,  0.1557],
        [-0.1967,  0.1618,  0.0396,  ...,  0.0654, -0.2708, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0468,  0.0410, -0.0706, -0.1354, -0.0729,  0.0513, -0.1110,  0.0502,
        -0.0404,  0.0781,  0.0236,  0.0119,  0.0250,  0.0748, -0.0516, -0.0203,
         0.0575, -0.1577, -0.0617,  0.0363, -0.0559,  0.0303,  0.1055,  0.0066,
        -0.0886,  0.0535,  0.0428, -0.1133,  0.0544,  0.1432,  0.1669, -0.1269],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0650, -0.1799, -0.1081,  ..., -0.1210, -0.0257,  0.0752],
        [-0.2137, -0.0360,  0.1052,  ..., -0.0502, -0.0093,  0.0483],
        [ 0.1394, -0.0295, -0.1662,  ...,  0.0663, -0.0100,  0.1825],
        ...,
        [ 0.1121,  0.0780,  0.1246,  ...,  0.2328, -0.2022,  0.2305],
        [-0.0094, -0.1485,  0.0507,  ...,  0.0377,  0.2178, -0.1671],
        [-0.0006, -0.1230,  0.1953,  ...,  0.0589,  0.1412, -0.0372]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1058,  0.1590, -0.0593, -0.0818, -0.0067, -0.0428, -0.0566, -0.0433,
         0.1335, -0.1769,  0.1146, -0.1299,  0.1914,  0.1025, -0.1268,  0.1331,
        -0.1373, -0.1715,  0.0436, -0.0122, -0.0051,  0.0875, -0.1989,  0.2351,
        -0.0441, -0.0079,  0.0773, -0.0280, -0.1342, -0.0680,  0.1269,  0.0355],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4852,  0.4108, -0.4874, -0.4643,  0.3494,  0.3529, -0.3975,  0.3643,
          0.3856, -0.4300, -0.3775,  0.3739,  0.3706,  0.3597,  0.4054,  0.4169,
         -0.4713, -0.4838,  0.3343,  0.3821, -0.4327, -0.4126, -0.4805,  0.3290,
          0.4569,  0.4839, -0.4663,  0.4757, -0.3971, -0.4708,  0.4615,  0.4767]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2349], device='cuda:0', requires_grad=True)

