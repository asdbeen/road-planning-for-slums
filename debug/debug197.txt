Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-7.1629e-03,  4.0400e-01,  3.0651e-01, -3.3285e-01, -1.7710e-01,
         -1.4800e-01, -4.8081e-02, -3.6583e-01, -2.1181e-01, -6.8608e-02,
         -3.2868e-02,  1.7312e-01, -2.9287e-01, -6.7735e-02,  1.7230e-02,
          3.7896e-01],
        [-2.4553e-01, -3.9779e-01, -1.0120e-01, -3.6909e-03, -3.5690e-02,
          2.4243e-01,  1.4512e-01,  1.4126e-01,  3.9762e-01,  1.3168e-01,
          3.0324e-01, -2.4332e-01,  3.5220e-01, -3.2826e-02,  2.9810e-01,
         -8.8242e-02],
        [ 8.4567e-02,  3.0204e-01,  3.8735e-01, -1.3392e-01, -8.2861e-02,
         -3.4049e-01, -6.2160e-02, -4.1638e-01, -1.6105e-02, -7.7651e-02,
         -1.5961e-01, -6.2711e-02,  3.6919e-02,  3.4765e-01,  3.4772e-02,
          2.7864e-01],
        [ 2.8151e-01,  1.3006e-01,  9.8691e-02, -9.7397e-02, -5.8213e-02,
         -2.0995e-01, -1.5583e-01, -9.8361e-02, -4.3783e-01, -4.2348e-01,
         -2.2397e-01,  3.6546e-01, -6.7747e-02, -1.0953e-01, -1.6606e-01,
          1.7819e-01],
        [-9.2056e-02,  2.5323e-02, -1.7239e-01, -1.6878e-02,  1.5362e-01,
          8.2223e-02,  2.6808e-02,  3.0457e-01,  1.4875e-01,  2.9769e-01,
          3.5155e-01, -1.4546e-01,  3.1270e-01, -2.3523e-01,  2.4786e-01,
         -1.7019e-01],
        [-1.3171e-02,  5.3658e-02, -3.7182e-01,  4.2044e-01,  3.4132e-01,
         -1.7295e-02,  2.6211e-01, -2.8987e-02,  2.7390e-01,  2.2440e-01,
         -7.4546e-02, -8.5726e-02,  1.1196e-01,  1.2002e-01,  3.7619e-01,
         -9.8760e-02],
        [ 3.6503e-01,  2.5662e-01,  4.0889e-01, -1.9152e-01, -5.0307e-02,
         -2.0689e-01, -1.6988e-01, -2.2289e-01, -2.6218e-01, -2.8174e-02,
         -5.2098e-02,  4.8745e-02, -3.5034e-01,  2.1111e-01, -2.5600e-01,
          1.6128e-01],
        [-6.0833e-02,  3.7037e-01,  3.6281e-01, -3.6566e-01, -3.3837e-01,
         -2.9831e-01, -8.7677e-02, -2.5862e-01, -2.1202e-01, -2.2392e-01,
         -9.8282e-02,  2.5129e-02, -3.0998e-02, -9.2532e-02, -8.2431e-02,
          3.6891e-01],
        [ 2.8168e-02,  3.6227e-01,  3.0146e-01, -2.4817e-01, -3.9785e-02,
         -3.4320e-01, -1.3652e-01, -8.5446e-02,  4.5890e-02, -3.1312e-01,
         -2.8618e-01,  3.9121e-02, -4.0783e-01,  1.5952e-01, -2.4773e-01,
          1.0340e-01],
        [-2.9303e-01, -1.7182e-01, -1.0859e-01,  2.9451e-03,  7.5134e-02,
          1.6146e-01,  4.9227e-02,  2.3300e-01,  2.8195e-01,  8.3704e-03,
          3.6493e-01, -2.3513e-04,  1.0297e-01, -9.1327e-02,  1.5082e-01,
         -2.2120e-01],
        [-3.6483e-01,  6.2403e-03, -7.7632e-02, -1.2986e-02, -4.2650e-02,
          4.3653e-01,  2.4011e-01,  1.2558e-01,  3.7186e-01,  2.7288e-01,
          2.3105e-01,  5.3836e-03,  1.8333e-01,  9.9431e-02, -2.5434e-02,
         -3.5756e-01],
        [-1.3371e-01, -2.0862e-01, -3.6577e-02,  1.0329e-01,  1.7546e-01,
          1.3225e-01,  3.6411e-01,  1.5139e-01,  1.7895e-01,  3.6331e-01,
          4.0943e-01,  6.4078e-02, -6.9873e-02, -2.6334e-01, -1.0018e-02,
         -2.3009e-01],
        [ 3.3062e-01,  3.0166e-01,  1.6865e-01, -1.8031e-01, -9.1357e-02,
          2.9036e-02, -6.4355e-02, -3.0181e-01, -3.2338e-01, -1.0908e-01,
         -1.8247e-01,  1.6206e-02, -4.2313e-01,  1.5985e-01, -1.9880e-01,
          4.8646e-02],
        [ 2.0587e-01,  4.0830e-01,  3.7100e-01, -1.6979e-02, -3.0382e-01,
         -2.0599e-02, -2.2521e-02, -6.1503e-02, -2.1786e-01, -1.6918e-01,
         -2.8440e-01,  9.7776e-02, -1.9252e-01,  6.1049e-02, -2.8598e-01,
          2.5024e-01],
        [-3.7538e-01, -3.6261e-01, -7.4004e-02, -2.7811e-02,  3.6208e-01,
          4.0370e-01,  9.5741e-02,  1.0691e-01, -1.8049e-02,  1.9155e-01,
          1.9741e-01, -2.9729e-01,  2.4448e-01, -1.1782e-01,  2.8377e-02,
         -1.7926e-01],
        [-6.6159e-02,  2.6908e-02,  2.1255e-01,  4.6788e-02, -3.3471e-01,
         -2.2911e-02, -1.8371e-01, -2.9370e-01, -2.3073e-01, -7.6879e-02,
         -1.5560e-01,  4.0481e-01, -2.5913e-01, -1.8923e-02,  8.1341e-02,
          1.1505e-01],
        [ 3.2520e-01,  3.3658e-01,  2.1531e-01, -3.7148e-01, -3.7287e-01,
         -5.5794e-02, -9.9506e-02, -1.2332e-02, -3.8770e-01, -2.0750e-01,
          6.4769e-02,  2.9589e-01,  4.3908e-02,  3.0338e-01, -9.6667e-02,
         -4.1939e-04],
        [-3.0052e-01, -7.3578e-02, -2.5659e-01,  1.5739e-01,  1.3938e-01,
          3.0732e-01,  2.8823e-01,  2.7294e-01,  1.5786e-01,  2.9970e-01,
          2.0243e-02, -2.4243e-01,  1.0691e-01, -2.2584e-01,  2.5897e-01,
         -1.9485e-01],
        [ 2.1847e-01,  1.6356e-01,  1.4331e-01, -2.8907e-01, -2.0101e-01,
         -3.6637e-01, -2.9377e-01,  3.6425e-02, -4.5549e-01, -1.1375e-01,
         -1.2138e-01, -8.8333e-02, -1.2844e-01,  2.9525e-01,  1.0064e-03,
          2.0217e-01],
        [ 3.7249e-01,  1.9032e-01,  2.7822e-01, -1.0432e-01, -3.0525e-01,
         -2.3240e-01, -3.4379e-01,  3.9191e-02, -5.5662e-02, -2.8854e-01,
         -1.7999e-01,  2.3511e-01, -3.9429e-01,  1.1498e-01,  7.6280e-02,
          2.1571e-01],
        [-1.8735e-01, -9.1978e-03, -6.0452e-02, -5.2709e-02,  2.7867e-01,
         -2.6705e-02,  3.0424e-01,  3.6604e-01,  1.9961e-01,  8.7453e-02,
          1.5322e-02, -2.7307e-01,  1.1810e-01, -2.1387e-01,  3.5055e-01,
         -2.7748e-01],
        [-7.0163e-02, -4.1037e-01, -5.1129e-02,  3.9382e-01, -3.5062e-02,
          1.1099e-01,  2.4147e-01, -7.3004e-02,  2.9148e-02,  2.6738e-01,
          3.9854e-01, -2.4318e-01,  1.6753e-01, -3.6398e-01, -1.2134e-01,
          3.7898e-02],
        [ 3.6697e-01,  8.8511e-02,  6.1570e-02, -1.7737e-01,  6.8657e-03,
         -3.9605e-01, -2.9215e-01, -2.1794e-01, -2.6509e-01, -1.6798e-01,
          4.8540e-02,  2.0017e-01, -3.8316e-01,  3.2276e-01,  1.2974e-01,
          2.3984e-01],
        [ 2.6299e-01,  2.4623e-01,  3.5319e-01, -3.8538e-01, -2.4023e-01,
         -1.7641e-01, -1.7460e-01, -2.8261e-01, -3.6677e-01, -3.3979e-01,
         -1.4790e-01,  3.4117e-01,  1.8960e-02,  1.4173e-01, -1.5593e-01,
          4.5241e-02],
        [ 2.1352e-01, -3.5453e-02,  1.8072e-01, -1.4210e-01,  5.8868e-02,
         -2.6756e-01,  4.4258e-02, -1.7444e-01, -3.8135e-01,  3.8570e-02,
          4.0998e-02, -4.5582e-03, -3.3779e-01,  2.5948e-01, -2.7977e-01,
          3.6533e-01],
        [ 4.7564e-02,  9.7039e-02,  9.9795e-02,  6.3147e-02, -2.1728e-01,
         -2.1141e-01, -2.1700e-02, -3.2443e-01, -1.8152e-01, -3.6637e-01,
         -3.7104e-01,  1.0075e-01, -1.4152e-01,  3.2456e-01, -3.6004e-01,
          1.0406e-01],
        [ 2.2686e-01,  2.6193e-01,  3.1219e-01, -3.6396e-01, -1.7691e-01,
         -1.0534e-01, -3.5358e-01, -1.9600e-02, -3.9958e-01, -1.1096e-02,
         -6.3297e-02,  8.3488e-02, -7.5963e-02,  3.0835e-01,  1.4465e-01,
          3.1728e-01],
        [-3.2139e-01, -1.0825e-01,  8.0359e-03,  2.1926e-01,  3.0019e-01,
          2.5441e-02,  3.5652e-01,  1.5587e-01, -4.6896e-02,  1.1495e-01,
          3.8145e-01, -2.5834e-01,  1.2991e-01, -2.2103e-01, -5.8286e-02,
         -1.3706e-01],
        [ 3.1420e-01,  2.0226e-01,  1.5300e-01, -1.5148e-01, -3.0476e-01,
         -2.9762e-01, -1.4847e-01, -3.4417e-01, -3.7992e-02, -1.3014e-01,
         -1.1035e-01,  1.3937e-01,  3.9977e-02,  3.3374e-01,  4.0336e-02,
          2.9355e-01],
        [-2.6933e-01, -5.2769e-02, -3.2273e-01,  2.6139e-01, -8.0846e-02,
          1.4544e-01,  3.2720e-01,  2.9270e-01,  3.6493e-01,  2.4043e-01,
          2.3492e-01, -7.0589e-02,  3.2008e-01,  5.4806e-02,  1.0575e-01,
         -2.3971e-01],
        [-2.9741e-01, -2.4218e-01, -6.1563e-02,  4.1519e-02,  2.0174e-01,
          3.9986e-01,  3.8532e-01, -1.9908e-02,  2.4997e-01,  3.4524e-01,
         -8.1225e-02, -1.3597e-02,  2.0982e-02, -2.9865e-01, -1.8949e-02,
         -2.7624e-01],
        [ 4.7622e-02,  2.4565e-01,  2.5222e-01, -5.9292e-02,  1.3712e-02,
         -3.1084e-01, -3.9466e-01, -3.5193e-01, -3.3939e-01, -2.7536e-01,
         -4.8045e-02, -2.8067e-02, -3.4727e-01,  2.8008e-01, -2.1368e-01,
          2.0363e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0621, -0.0185,  0.0012, -0.0365,  0.0124, -0.2358,  0.1008,  0.1317,
        -0.0478, -0.0077,  0.0429,  0.0754,  0.1361,  0.0799,  0.0563, -0.0182,
        -0.0172, -0.0398,  0.0890, -0.0230, -0.0979, -0.0900, -0.0294,  0.0399,
        -0.0535,  0.1368,  0.1668,  0.0404, -0.0935, -0.1846,  0.0225,  0.0199],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1967,  0.2892, -0.2069, -0.2355,  0.2758,  0.3223, -0.2647, -0.3591,
         -0.3057,  0.3104,  0.2408,  0.3536, -0.2401, -0.3792,  0.2673, -0.1734,
         -0.2993,  0.3149, -0.2061, -0.2217,  0.3678,  0.2981, -0.3539, -0.3610,
         -0.2463, -0.3039, -0.3032,  0.3207, -0.3330,  0.3648,  0.2809, -0.2155]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0025,  0.0832,  0.0762,  ...,  0.1916, -0.3045, -0.1137],
        [-0.0786, -0.0724,  0.1197,  ...,  0.1035, -0.2814,  0.0871],
        [-0.1008,  0.1192,  0.1000,  ...,  0.1901,  0.0464,  0.0345],
        ...,
        [ 0.1061, -0.1253, -0.0348,  ..., -0.1750, -0.0318, -0.1180],
        [ 0.0430, -0.1719, -0.0430,  ..., -0.2611,  0.0871,  0.1557],
        [-0.1908,  0.1242,  0.0552,  ...,  0.0683, -0.2358, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0491,  0.0336, -0.1006, -0.1539, -0.0801,  0.0062, -0.1038,  0.0376,
        -0.0306,  0.0583,  0.0250,  0.0013,  0.0007,  0.1005, -0.0472, -0.0077,
         0.0445, -0.1656,  0.0015,  0.0793, -0.0605,  0.0197,  0.1105,  0.0200,
        -0.1118,  0.0982,  0.0441, -0.0918,  0.0424,  0.1978,  0.1678, -0.1292],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0534, -0.1641, -0.1848,  ...,  0.0357, -0.0464,  0.0643],
        [-0.2182, -0.0136, -0.0186,  ...,  0.1367, -0.0315,  0.0477],
        [ 0.1462, -0.0523, -0.0416,  ..., -0.1391,  0.0065,  0.1854],
        ...,
        [ 0.1336,  0.0657,  0.1938,  ...,  0.0967, -0.1798,  0.2478],
        [-0.0180, -0.1289, -0.0522,  ...,  0.2307,  0.2074, -0.1707],
        [-0.0061, -0.1052,  0.1236,  ...,  0.2168,  0.1223, -0.0444]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1009,  0.1463, -0.0448, -0.0946, -0.1119, -0.1729, -0.0569, -0.0330,
         0.1339, -0.1621,  0.1253, -0.1237,  0.1921,  0.0842, -0.1168,  0.1140,
        -0.1399, -0.1738,  0.0722,  0.0086, -0.0106,  0.0877, -0.2076,  0.2111,
        -0.0486, -0.0067,  0.0764, -0.0366, -0.1429, -0.0657,  0.1164,  0.0261],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3472,  0.2695, -0.3066, -0.3387, -0.1886, -0.1844, -0.2535,  0.2138,
          0.2503, -0.2663, -0.2157,  0.2322,  0.2417,  0.1989,  0.2559,  0.2386,
         -0.3397, -0.3456,  0.1884,  0.2304, -0.2928, -0.2440, -0.3458,  0.1960,
          0.3081,  0.3635, -0.3186,  0.3323, -0.2531, -0.3436,  0.3064,  0.3484]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1081], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.6432e-02,  3.7796e-01,  3.3089e-01, -3.4921e-01, -2.0162e-02,
         -1.8650e-01, -7.4080e-02, -3.9215e-01, -1.7225e-01, -9.2980e-02,
          1.6180e-02,  1.6918e-01,  3.7144e-02, -7.7516e-02,  3.2109e-01,
          3.7051e-01],
        [-2.7462e-01, -3.6136e-01, -1.3019e-01,  1.1398e-02, -1.7340e-01,
          2.8663e-01,  1.8869e-01,  1.6138e-01,  3.8891e-01,  1.3855e-01,
          2.3739e-01, -2.5995e-01,  2.9215e-02, -2.0946e-02,  4.4078e-03,
         -8.8276e-02],
        [ 1.0464e-01,  2.6770e-01,  4.0966e-01, -1.4402e-01,  1.4406e-01,
         -3.8337e-01, -7.0682e-02, -4.1854e-01,  5.5256e-02, -8.9571e-02,
         -1.0615e-01, -6.2180e-02,  3.7657e-01,  2.8671e-01,  4.3907e-01,
          2.7101e-01],
        [ 2.9912e-01,  9.5023e-02,  1.1750e-01, -9.8380e-02,  1.1293e-01,
         -2.4115e-01, -1.8055e-01, -9.5598e-02, -4.0458e-01, -4.1529e-01,
         -1.2582e-01,  3.5906e-01,  2.6354e-01, -1.4179e-01,  1.4954e-01,
          1.7093e-01],
        [-1.1362e-01,  8.3366e-02, -1.9399e-01, -7.2334e-03,  1.9843e-02,
          1.2399e-01,  6.6198e-02,  3.2385e-01,  1.3752e-01,  3.0054e-01,
          2.6886e-01, -1.6019e-01, -1.4740e-02, -2.0730e-01, -7.8384e-02,
         -1.4885e-01],
        [-2.2181e-02,  1.1152e-01, -3.8186e-01,  4.1258e-01,  1.2574e-01,
          7.1157e-03,  2.7806e-01, -4.4735e-02,  2.3381e-01,  2.1464e-01,
         -1.0715e-01, -6.8757e-02, -2.1429e-01,  1.4031e-01,  3.4514e-02,
         -8.1973e-02],
        [ 3.9569e-01,  2.2061e-01,  4.3726e-01, -2.0449e-01,  1.3418e-01,
         -2.5552e-01, -2.1395e-01, -2.4008e-01, -2.4627e-01, -3.3039e-02,
         -3.0067e-02,  6.1732e-02, -5.3708e-02,  2.0768e-01, -1.0851e-02,
          1.6625e-01],
        [-4.1419e-02,  3.3190e-01,  3.8002e-01, -3.6533e-01, -1.4219e-01,
         -3.3694e-01, -1.1328e-01, -2.4931e-01, -1.7694e-01, -2.1997e-01,
         -8.0944e-02,  1.8685e-02,  2.3906e-01, -1.0037e-01,  1.6465e-01,
          3.6901e-01],
        [ 5.1885e-02,  3.1991e-01,  3.2445e-01, -2.6286e-01,  3.6874e-02,
         -3.8029e-01, -1.8017e-01, -1.0902e-01,  5.3061e-02, -3.1309e-01,
         -1.2230e-01,  6.5556e-02, -1.0752e-01,  1.1218e-01,  4.5321e-03,
          9.4458e-02],
        [-3.0393e-01, -1.1315e-01, -1.1988e-01, -5.9622e-05, -6.5757e-02,
          1.9012e-01,  6.6422e-02,  2.3766e-01,  2.5641e-01, -1.4770e-03,
          2.6486e-01, -5.0069e-03, -2.2903e-01, -4.7202e-02, -1.8264e-01,
         -1.9612e-01],
        [-3.7319e-01,  5.0400e-02, -8.6836e-02, -2.3026e-02, -1.8115e-01,
          4.6262e-01,  2.5120e-01,  1.2257e-01,  3.3531e-01,  2.5640e-01,
          8.0485e-02,  1.0512e-02, -1.4099e-01,  1.5713e-01, -3.9365e-01,
         -3.3692e-01],
        [-1.4506e-01, -1.6366e-01, -4.6980e-02,  1.0519e-01,  1.0588e-01,
          1.5576e-01,  3.8998e-01,  1.6108e-01,  1.6268e-01,  3.4881e-01,
          1.6868e-01,  5.3623e-02, -3.7747e-01, -1.7849e-01, -2.5845e-01,
         -2.0378e-01],
        [ 3.6747e-01,  2.5663e-01,  2.0874e-01, -2.0288e-01,  9.4298e-02,
         -3.1859e-02, -1.1598e-01, -3.2638e-01, -3.2550e-01, -1.3073e-01,
         -1.4434e-01,  2.5680e-02, -5.8230e-02,  1.6811e-01,  1.6922e-01,
          4.5989e-02],
        [ 2.3363e-01,  3.7351e-01,  3.9726e-01, -3.0452e-02, -1.6602e-01,
         -6.1881e-02, -7.0283e-02, -7.8576e-02, -2.1006e-01, -1.7370e-01,
         -2.2921e-01,  1.1421e-01,  1.0407e-01,  4.9055e-02, -4.1440e-02,
          2.5296e-01],
        [-3.9788e-01, -3.2434e-01, -9.5948e-02, -2.5277e-02,  1.9484e-01,
          4.5089e-01,  1.2397e-01,  1.1959e-01, -4.2693e-02,  1.9131e-01,
          1.4295e-01, -3.0839e-01, -6.4585e-02, -9.9552e-02, -2.8472e-01,
         -1.7606e-01],
        [-9.5425e-02, -1.0010e-01,  1.8319e-01,  9.9107e-02, -1.3708e-01,
         -1.0761e-02, -1.5080e-01, -2.3767e-01, -1.2041e-01, -1.9740e-02,
         -5.1176e-02,  3.6495e-01,  5.7865e-02, -1.0182e-01,  3.9831e-01,
          4.6500e-02],
        [ 3.3855e-01,  2.9537e-01,  2.2820e-01, -3.7270e-01, -1.9690e-01,
         -8.0003e-02, -1.2889e-01, -2.4760e-03, -3.5552e-01, -1.9758e-01,
          1.2292e-01,  2.8422e-01,  3.2995e-01,  2.7342e-01,  1.3432e-01,
         -9.1665e-03],
        [-3.2192e-01, -4.0792e-02, -2.7544e-01,  1.6097e-01, -1.9842e-02,
          3.4608e-01,  3.1960e-01,  2.7894e-01,  1.3429e-01,  2.9586e-01,
         -2.3152e-02, -2.4598e-01, -1.5314e-01, -2.1056e-01,  3.4416e-02,
         -1.9399e-01],
        [ 2.5767e-01,  1.4860e-01,  1.8490e-01, -3.1810e-01, -9.2990e-03,
         -4.2283e-01, -3.1620e-01,  1.8823e-02, -3.9156e-01, -1.4385e-01,
         -5.0408e-02, -7.5778e-02,  1.8083e-01,  2.3471e-01,  3.7821e-01,
          2.1276e-01],
        [ 3.9351e-01,  1.5597e-01,  2.9852e-01, -1.0973e-01, -1.7070e-01,
         -2.7263e-01, -3.7925e-01,  2.5762e-02, -3.5274e-02, -2.8452e-01,
         -7.6405e-02,  2.4693e-01, -9.3469e-02,  8.2694e-02,  3.3234e-01,
          2.1084e-01],
        [-2.0206e-01,  4.1014e-02, -7.5637e-02, -5.0831e-02,  1.1143e-01,
          4.2416e-03,  3.3368e-01,  3.6736e-01,  1.7242e-01,  8.4629e-02,
         -3.2326e-02, -2.7105e-01, -1.6915e-01, -2.0254e-01,  4.6020e-02,
         -2.6680e-01],
        [-7.8976e-02, -3.5546e-01, -6.0132e-02,  3.8713e-01, -1.5737e-01,
          1.3952e-01,  2.5199e-01, -6.9928e-02, -1.3684e-03,  2.5442e-01,
          2.6242e-01, -2.4962e-01, -1.3006e-01, -3.1343e-01, -4.4417e-01,
          5.9505e-02],
        [ 3.8105e-01,  4.9487e-02,  7.4230e-02, -1.7306e-01,  1.6272e-01,
         -4.2924e-01, -3.1464e-01, -2.1487e-01, -2.3098e-01, -1.5815e-01,
          1.0925e-01,  1.9957e-01, -1.2387e-01,  2.9439e-01,  3.8476e-01,
          2.3150e-01],
        [ 2.8334e-01,  2.1931e-01,  3.7062e-01, -3.8933e-01, -8.4206e-02,
         -2.1160e-01, -2.1276e-01, -2.7609e-01, -3.4652e-01, -3.3498e-01,
         -1.1339e-01,  3.3704e-01,  2.4493e-01,  1.3490e-01,  1.6427e-02,
          4.9081e-02],
        [ 2.2522e-01, -1.0180e-01,  1.9376e-01, -1.4066e-01,  2.2007e-01,
         -2.8999e-01,  2.4322e-02, -1.7327e-01, -3.4753e-01,  5.0217e-02,
          1.4018e-01, -6.8763e-03,  1.4785e-02,  2.1397e-01,  7.0130e-02,
          3.3836e-01],
        [ 7.0455e-02,  4.8158e-02,  1.2412e-01,  5.8080e-02, -4.9160e-02,
         -2.6274e-01, -5.5030e-02, -3.4126e-01, -1.6362e-01, -3.7127e-01,
         -3.2397e-01,  1.1418e-01,  1.6233e-01,  3.1685e-01, -2.5109e-02,
          9.5200e-02],
        [ 2.3907e-01,  2.2309e-01,  3.2330e-01, -3.6137e-01, -3.5450e-03,
         -1.3330e-01, -3.8093e-01, -7.2442e-03, -3.6162e-01,  1.1013e-03,
         -4.7924e-03,  7.4335e-02,  1.8773e-01,  2.7879e-01,  3.7154e-01,
          3.0972e-01],
        [-3.3725e-01, -6.5398e-02, -7.0656e-03,  2.2024e-01,  1.8406e-01,
          5.6105e-02,  3.8382e-01,  1.6355e-01, -6.6891e-02,  1.0691e-01,
          2.4315e-01, -2.6344e-01, -1.8392e-01, -1.7213e-01, -3.4627e-01,
         -1.2013e-01],
        [ 3.2755e-01,  1.6521e-01,  1.6534e-01, -1.4678e-01, -1.7455e-01,
         -3.2783e-01, -1.7001e-01, -3.4396e-01, -1.0670e-02, -1.1964e-01,
         -1.2826e-02,  1.3886e-01,  2.9777e-01,  2.9407e-01,  3.0643e-01,
          2.8284e-01],
        [-2.9060e-01, -1.8366e-02, -3.4136e-01,  2.6505e-01, -2.4212e-01,
          1.8503e-01,  3.5775e-01,  2.9495e-01,  3.3989e-01,  2.3733e-01,
          1.9726e-01, -7.4152e-02,  6.5877e-02,  6.5618e-02, -1.0889e-01,
         -2.3982e-01],
        [-3.0579e-01, -1.9750e-01, -6.9876e-02,  3.5572e-02,  5.0746e-02,
          4.2272e-01,  4.0374e-01, -2.5583e-02,  2.1318e-01,  3.2911e-01,
         -1.8131e-01, -8.9074e-03, -2.7096e-01, -2.4778e-01, -3.0538e-01,
         -2.6002e-01],
        [ 8.9486e-02,  2.2754e-01,  2.9314e-01, -9.3032e-02,  1.8186e-01,
         -3.6727e-01, -4.4150e-01, -3.8262e-01, -2.9842e-01, -3.0241e-01,
          1.8589e-02, -2.7924e-03, -3.2134e-02,  2.4114e-01,  5.4447e-02,
          2.1829e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0871, -0.0644,  0.1893, -0.0289, -0.0644, -0.0198,  0.0784,  0.0671,
        -0.0183, -0.0517, -0.0360,  0.0534,  0.1296,  0.1070, -0.0194, -0.0635,
        -0.1423,  0.0221,  0.1257,  0.0269,  0.0166, -0.1834, -0.0064, -0.0443,
        -0.0498,  0.2121,  0.1316,  0.0237, -0.0478, -0.1522,  0.0087,  0.0364],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1889,  0.2789, -0.2057, -0.2348,  0.2438,  0.2956, -0.2575, -0.3614,
         -0.2838,  0.2915,  0.2421,  0.3502, -0.2103, -0.3584,  0.2792, -0.1079,
         -0.2738,  0.3177, -0.2098, -0.2253,  0.3122,  0.3339, -0.3550, -0.3622,
         -0.2394, -0.2742, -0.3014,  0.3152, -0.3429,  0.3683,  0.2781, -0.2189]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0192, -0.0134,  0.0282,  ...,  0.2059, -0.3308, -0.1137],
        [-0.0909, -0.2010,  0.0859,  ...,  0.1420, -0.3148,  0.0871],
        [-0.0454,  0.1685,  0.0878,  ...,  0.0156,  0.2166,  0.0345],
        ...,
        [ 0.0337, -0.1662,  0.0153,  ...,  0.0636, -0.2567, -0.1180],
        [ 0.0449, -0.0579,  0.0010,  ..., -0.2970,  0.1135,  0.1557],
        [-0.0769,  0.1716,  0.0097,  ..., -0.1688,  0.0366, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0508,  0.0533, -0.0917, -0.1205, -0.0585,  0.0457, -0.1280,  0.0618,
        -0.0471,  0.0915,  0.0317,  0.0089,  0.0097,  0.0631, -0.0784, -0.0208,
         0.0470, -0.1428, -0.0319, -0.0160, -0.1115,  0.0460,  0.0826, -0.0060,
        -0.0848,  0.0656,  0.0244, -0.0970,  0.0635,  0.1470,  0.1400, -0.0654],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0497, -0.1893, -0.0885,  ..., -0.1274, -0.0266,  0.2526],
        [-0.2229, -0.0398,  0.0985,  ..., -0.0579, -0.0122,  0.2637],
        [ 0.1545, -0.0266, -0.1678,  ...,  0.0721, -0.0144, -0.0588],
        ...,
        [ 0.1399,  0.1048,  0.0897,  ...,  0.2498, -0.2102,  0.0646],
        [-0.0410, -0.1655,  0.0669,  ...,  0.0149,  0.2387,  0.0753],
        [-0.0068, -0.1164,  0.2049,  ...,  0.0633,  0.1292,  0.1234]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0843,  0.1207, -0.0330, -0.0533, -0.0304, -0.0351, -0.0316, -0.0627,
         0.1094, -0.1721,  0.1234, -0.1331,  0.1650, -0.0186, -0.1436,  0.1031,
        -0.1258, -0.1522,  0.0134, -0.0293,  0.0101,  0.1102, -0.1863,  0.2015,
        -0.0720, -0.0300,  0.0892, -0.0408, -0.1113, -0.0582,  0.1077, -0.0007],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4520,  0.3756, -0.4516, -0.4576,  0.3010,  0.3082, -0.3576,  0.3648,
          0.3678, -0.3872, -0.3791,  0.3411,  0.3628, -0.3026,  0.3836,  0.3299,
         -0.4619, -0.4538,  0.3307,  0.3469, -0.4133, -0.3866, -0.4505,  0.2870,
          0.4253,  0.4537, -0.4262,  0.4931, -0.3618, -0.4444,  0.4265,  0.4447]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1798], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.6432e-02,  3.7796e-01,  3.3089e-01, -3.4921e-01, -2.0162e-02,
         -1.8650e-01, -7.4080e-02, -3.9215e-01, -1.7225e-01, -9.2980e-02,
          1.6180e-02,  1.6918e-01,  3.7144e-02, -7.7516e-02,  3.2109e-01,
          3.7051e-01],
        [-2.7462e-01, -3.6136e-01, -1.3019e-01,  1.1398e-02, -1.7340e-01,
          2.8663e-01,  1.8869e-01,  1.6138e-01,  3.8891e-01,  1.3855e-01,
          2.3739e-01, -2.5995e-01,  2.9215e-02, -2.0946e-02,  4.4078e-03,
         -8.8276e-02],
        [ 1.0464e-01,  2.6770e-01,  4.0966e-01, -1.4402e-01,  1.4406e-01,
         -3.8337e-01, -7.0682e-02, -4.1854e-01,  5.5256e-02, -8.9571e-02,
         -1.0615e-01, -6.2180e-02,  3.7657e-01,  2.8671e-01,  4.3907e-01,
          2.7101e-01],
        [ 2.9912e-01,  9.5023e-02,  1.1750e-01, -9.8380e-02,  1.1293e-01,
         -2.4115e-01, -1.8055e-01, -9.5598e-02, -4.0458e-01, -4.1529e-01,
         -1.2582e-01,  3.5906e-01,  2.6354e-01, -1.4179e-01,  1.4954e-01,
          1.7093e-01],
        [-1.1362e-01,  8.3366e-02, -1.9399e-01, -7.2334e-03,  1.9843e-02,
          1.2399e-01,  6.6198e-02,  3.2385e-01,  1.3752e-01,  3.0054e-01,
          2.6886e-01, -1.6019e-01, -1.4740e-02, -2.0730e-01, -7.8384e-02,
         -1.4885e-01],
        [-2.2181e-02,  1.1152e-01, -3.8186e-01,  4.1258e-01,  1.2574e-01,
          7.1156e-03,  2.7806e-01, -4.4735e-02,  2.3381e-01,  2.1464e-01,
         -1.0715e-01, -6.8757e-02, -2.1429e-01,  1.4031e-01,  3.4514e-02,
         -8.1973e-02],
        [ 3.9569e-01,  2.2061e-01,  4.3726e-01, -2.0449e-01,  1.3418e-01,
         -2.5552e-01, -2.1395e-01, -2.4008e-01, -2.4627e-01, -3.3039e-02,
         -3.0067e-02,  6.1732e-02, -5.3708e-02,  2.0768e-01, -1.0851e-02,
          1.6625e-01],
        [-4.1419e-02,  3.3190e-01,  3.8002e-01, -3.6533e-01, -1.4219e-01,
         -3.3694e-01, -1.1328e-01, -2.4931e-01, -1.7694e-01, -2.1997e-01,
         -8.0944e-02,  1.8685e-02,  2.3906e-01, -1.0037e-01,  1.6465e-01,
          3.6902e-01],
        [ 5.1885e-02,  3.1991e-01,  3.2445e-01, -2.6286e-01,  3.6873e-02,
         -3.8029e-01, -1.8017e-01, -1.0902e-01,  5.3061e-02, -3.1309e-01,
         -1.2230e-01,  6.5556e-02, -1.0752e-01,  1.1218e-01,  4.5321e-03,
          9.4458e-02],
        [-3.0393e-01, -1.1315e-01, -1.1988e-01, -5.9656e-05, -6.5757e-02,
          1.9012e-01,  6.6422e-02,  2.3766e-01,  2.5641e-01, -1.4771e-03,
          2.6486e-01, -5.0069e-03, -2.2903e-01, -4.7202e-02, -1.8264e-01,
         -1.9612e-01],
        [-3.7319e-01,  5.0400e-02, -8.6836e-02, -2.3026e-02, -1.8115e-01,
          4.6262e-01,  2.5120e-01,  1.2257e-01,  3.3531e-01,  2.5640e-01,
          8.0485e-02,  1.0512e-02, -1.4099e-01,  1.5713e-01, -3.9365e-01,
         -3.3692e-01],
        [-1.4506e-01, -1.6366e-01, -4.6980e-02,  1.0519e-01,  1.0588e-01,
          1.5576e-01,  3.8998e-01,  1.6108e-01,  1.6268e-01,  3.4881e-01,
          1.6868e-01,  5.3623e-02, -3.7747e-01, -1.7849e-01, -2.5845e-01,
         -2.0378e-01],
        [ 3.6747e-01,  2.5663e-01,  2.0874e-01, -2.0288e-01,  9.4298e-02,
         -3.1859e-02, -1.1598e-01, -3.2638e-01, -3.2550e-01, -1.3073e-01,
         -1.4434e-01,  2.5680e-02, -5.8230e-02,  1.6811e-01,  1.6922e-01,
          4.5989e-02],
        [ 2.3363e-01,  3.7351e-01,  3.9726e-01, -3.0452e-02, -1.6602e-01,
         -6.1881e-02, -7.0283e-02, -7.8576e-02, -2.1006e-01, -1.7370e-01,
         -2.2921e-01,  1.1421e-01,  1.0407e-01,  4.9055e-02, -4.1440e-02,
          2.5296e-01],
        [-3.9788e-01, -3.2434e-01, -9.5948e-02, -2.5277e-02,  1.9484e-01,
          4.5089e-01,  1.2397e-01,  1.1959e-01, -4.2693e-02,  1.9131e-01,
          1.4295e-01, -3.0839e-01, -6.4585e-02, -9.9552e-02, -2.8472e-01,
         -1.7606e-01],
        [-9.5425e-02, -1.0010e-01,  1.8319e-01,  9.9107e-02, -1.3708e-01,
         -1.0761e-02, -1.5080e-01, -2.3767e-01, -1.2041e-01, -1.9740e-02,
         -5.1176e-02,  3.6495e-01,  5.7865e-02, -1.0182e-01,  3.9831e-01,
          4.6500e-02],
        [ 3.3855e-01,  2.9537e-01,  2.2819e-01, -3.7270e-01, -1.9690e-01,
         -8.0003e-02, -1.2889e-01, -2.4760e-03, -3.5552e-01, -1.9758e-01,
          1.2292e-01,  2.8422e-01,  3.2995e-01,  2.7342e-01,  1.3432e-01,
         -9.1665e-03],
        [-3.2192e-01, -4.0792e-02, -2.7544e-01,  1.6097e-01, -1.9842e-02,
          3.4608e-01,  3.1960e-01,  2.7894e-01,  1.3429e-01,  2.9586e-01,
         -2.3152e-02, -2.4598e-01, -1.5314e-01, -2.1056e-01,  3.4416e-02,
         -1.9399e-01],
        [ 2.5767e-01,  1.4860e-01,  1.8490e-01, -3.1810e-01, -9.2990e-03,
         -4.2283e-01, -3.1620e-01,  1.8823e-02, -3.9156e-01, -1.4385e-01,
         -5.0408e-02, -7.5778e-02,  1.8083e-01,  2.3471e-01,  3.7821e-01,
          2.1276e-01],
        [ 3.9351e-01,  1.5597e-01,  2.9852e-01, -1.0973e-01, -1.7070e-01,
         -2.7263e-01, -3.7925e-01,  2.5762e-02, -3.5274e-02, -2.8452e-01,
         -7.6405e-02,  2.4693e-01, -9.3469e-02,  8.2694e-02,  3.3234e-01,
          2.1084e-01],
        [-2.0206e-01,  4.1014e-02, -7.5637e-02, -5.0831e-02,  1.1143e-01,
          4.2416e-03,  3.3368e-01,  3.6736e-01,  1.7242e-01,  8.4629e-02,
         -3.2326e-02, -2.7105e-01, -1.6915e-01, -2.0254e-01,  4.6020e-02,
         -2.6680e-01],
        [-7.8976e-02, -3.5546e-01, -6.0132e-02,  3.8713e-01, -1.5737e-01,
          1.3952e-01,  2.5199e-01, -6.9928e-02, -1.3685e-03,  2.5442e-01,
          2.6242e-01, -2.4962e-01, -1.3006e-01, -3.1343e-01, -4.4417e-01,
          5.9505e-02],
        [ 3.8105e-01,  4.9487e-02,  7.4230e-02, -1.7306e-01,  1.6272e-01,
         -4.2924e-01, -3.1464e-01, -2.1487e-01, -2.3098e-01, -1.5815e-01,
          1.0925e-01,  1.9957e-01, -1.2387e-01,  2.9439e-01,  3.8476e-01,
          2.3150e-01],
        [ 2.8334e-01,  2.1931e-01,  3.7062e-01, -3.8933e-01, -8.4206e-02,
         -2.1160e-01, -2.1276e-01, -2.7609e-01, -3.4652e-01, -3.3498e-01,
         -1.1339e-01,  3.3704e-01,  2.4493e-01,  1.3490e-01,  1.6427e-02,
          4.9081e-02],
        [ 2.2522e-01, -1.0180e-01,  1.9376e-01, -1.4066e-01,  2.2007e-01,
         -2.8999e-01,  2.4322e-02, -1.7327e-01, -3.4753e-01,  5.0217e-02,
          1.4018e-01, -6.8763e-03,  1.4785e-02,  2.1397e-01,  7.0130e-02,
          3.3836e-01],
        [ 7.0455e-02,  4.8158e-02,  1.2412e-01,  5.8080e-02, -4.9160e-02,
         -2.6274e-01, -5.5030e-02, -3.4126e-01, -1.6362e-01, -3.7127e-01,
         -3.2397e-01,  1.1418e-01,  1.6233e-01,  3.1685e-01, -2.5109e-02,
          9.5200e-02],
        [ 2.3907e-01,  2.2309e-01,  3.2330e-01, -3.6137e-01, -3.5450e-03,
         -1.3330e-01, -3.8093e-01, -7.2441e-03, -3.6162e-01,  1.1013e-03,
         -4.7924e-03,  7.4335e-02,  1.8773e-01,  2.7879e-01,  3.7154e-01,
          3.0972e-01],
        [-3.3725e-01, -6.5398e-02, -7.0656e-03,  2.2024e-01,  1.8406e-01,
          5.6105e-02,  3.8382e-01,  1.6355e-01, -6.6891e-02,  1.0691e-01,
          2.4315e-01, -2.6344e-01, -1.8392e-01, -1.7213e-01, -3.4627e-01,
         -1.2013e-01],
        [ 3.2755e-01,  1.6521e-01,  1.6534e-01, -1.4678e-01, -1.7455e-01,
         -3.2783e-01, -1.7001e-01, -3.4396e-01, -1.0670e-02, -1.1964e-01,
         -1.2826e-02,  1.3886e-01,  2.9777e-01,  2.9407e-01,  3.0643e-01,
          2.8284e-01],
        [-2.9060e-01, -1.8366e-02, -3.4136e-01,  2.6505e-01, -2.4212e-01,
          1.8503e-01,  3.5775e-01,  2.9495e-01,  3.3989e-01,  2.3733e-01,
          1.9726e-01, -7.4152e-02,  6.5877e-02,  6.5618e-02, -1.0889e-01,
         -2.3982e-01],
        [-3.0579e-01, -1.9750e-01, -6.9876e-02,  3.5572e-02,  5.0746e-02,
          4.2272e-01,  4.0374e-01, -2.5582e-02,  2.1318e-01,  3.2911e-01,
         -1.8131e-01, -8.9073e-03, -2.7096e-01, -2.4778e-01, -3.0538e-01,
         -2.6002e-01],
        [ 8.9486e-02,  2.2754e-01,  2.9314e-01, -9.3032e-02,  1.8186e-01,
         -3.6727e-01, -4.4150e-01, -3.8262e-01, -2.9842e-01, -3.0241e-01,
          1.8589e-02, -2.7924e-03, -3.2134e-02,  2.4114e-01,  5.4447e-02,
          2.1829e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0871, -0.0644,  0.1893, -0.0289, -0.0644, -0.0198,  0.0784,  0.0671,
        -0.0183, -0.0517, -0.0360,  0.0534,  0.1296,  0.1070, -0.0194, -0.0635,
        -0.1423,  0.0221,  0.1257,  0.0269,  0.0166, -0.1834, -0.0064, -0.0443,
        -0.0498,  0.2121,  0.1316,  0.0237, -0.0478, -0.1522,  0.0087,  0.0364],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1889,  0.2789, -0.2057, -0.2348,  0.2438,  0.2956, -0.2575, -0.3614,
         -0.2838,  0.2915,  0.2421,  0.3502, -0.2103, -0.3584,  0.2792, -0.1079,
         -0.2738,  0.3177, -0.2098, -0.2253,  0.3122,  0.3339, -0.3550, -0.3622,
         -0.2394, -0.2742, -0.3014,  0.3152, -0.3429,  0.3683,  0.2781, -0.2189]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0192, -0.0134,  0.0282,  ...,  0.2059, -0.3308, -0.1137],
        [-0.0909, -0.2010,  0.0859,  ...,  0.1420, -0.3148,  0.0871],
        [-0.0454,  0.1685,  0.0878,  ...,  0.0156,  0.2166,  0.0345],
        ...,
        [ 0.0337, -0.1662,  0.0153,  ...,  0.0636, -0.2567, -0.1180],
        [ 0.0449, -0.0579,  0.0010,  ..., -0.2970,  0.1135,  0.1557],
        [-0.0769,  0.1716,  0.0097,  ..., -0.1688,  0.0366, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0508,  0.0533, -0.0917, -0.1205, -0.0585,  0.0457, -0.1280,  0.0618,
        -0.0471,  0.0915,  0.0317,  0.0089,  0.0097,  0.0631, -0.0784, -0.0208,
         0.0470, -0.1428, -0.0319, -0.0160, -0.1115,  0.0460,  0.0826, -0.0060,
        -0.0848,  0.0656,  0.0244, -0.0970,  0.0635,  0.1470,  0.1400, -0.0654],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0497, -0.1893, -0.0885,  ..., -0.1274, -0.0266,  0.2526],
        [-0.2229, -0.0398,  0.0985,  ..., -0.0579, -0.0122,  0.2637],
        [ 0.1545, -0.0266, -0.1678,  ...,  0.0721, -0.0144, -0.0588],
        ...,
        [ 0.1399,  0.1048,  0.0897,  ...,  0.2498, -0.2102,  0.0646],
        [-0.0410, -0.1655,  0.0669,  ...,  0.0149,  0.2387,  0.0753],
        [-0.0068, -0.1164,  0.2049,  ...,  0.0633,  0.1292,  0.1234]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0843,  0.1207, -0.0330, -0.0533, -0.0304, -0.0351, -0.0316, -0.0627,
         0.1094, -0.1721,  0.1234, -0.1331,  0.1650, -0.0186, -0.1436,  0.1031,
        -0.1258, -0.1522,  0.0134, -0.0293,  0.0101,  0.1102, -0.1863,  0.2015,
        -0.0720, -0.0300,  0.0892, -0.0408, -0.1113, -0.0582,  0.1077, -0.0007],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4520,  0.3756, -0.4516, -0.4576,  0.3010,  0.3082, -0.3576,  0.3648,
          0.3678, -0.3872, -0.3791,  0.3411,  0.3628, -0.3026,  0.3836,  0.3299,
         -0.4619, -0.4538,  0.3307,  0.3469, -0.4133, -0.3866, -0.4505,  0.2870,
          0.4253,  0.4537, -0.4262,  0.4931, -0.3618, -0.4444,  0.4265,  0.4447]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1798], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.6603e-02,  3.9275e-01,  3.3024e-01, -3.4060e-01, -2.6280e-01,
         -1.9362e-01, -7.7292e-02, -4.3871e-01, -2.3060e-01, -9.4648e-02,
         -3.9676e-02,  2.3064e-01,  8.7638e-02, -2.0201e-02,  3.4505e-03,
          3.8689e-01],
        [-2.6551e-01, -3.6235e-01, -1.2041e-01,  6.5072e-03,  1.6587e-02,
          2.7866e-01,  1.8565e-01,  1.9953e-01,  4.3570e-01,  1.5694e-01,
          2.9634e-01, -2.9737e-01, -3.9673e-03, -8.5315e-02,  2.7980e-01,
         -9.3565e-02],
        [ 9.8351e-02,  2.7746e-01,  4.0206e-01, -1.3178e-01, -1.2249e-01,
         -3.7597e-01, -7.0407e-02, -4.6242e-01, -1.2479e-02, -9.3697e-02,
         -1.5144e-01, -2.0173e-02,  4.1951e-01,  3.7675e-01,  1.1314e-01,
          2.8046e-01],
        [ 2.9408e-01,  1.0000e-01,  1.1115e-01, -9.4369e-02, -1.0148e-01,
         -2.3567e-01, -1.8264e-01, -1.4593e-01, -4.7392e-01, -4.3592e-01,
         -1.3504e-01,  4.1233e-01,  2.9620e-01, -6.2939e-02, -1.5153e-01,
          1.7772e-01],
        [-1.1067e-01,  5.6547e-02, -1.9096e-01, -9.0082e-03,  2.0568e-01,
          1.1849e-01,  6.4632e-02,  3.6350e-01,  1.8725e-01,  3.2361e-01,
          3.3444e-01, -1.9928e-01, -5.7132e-02, -2.8852e-01,  2.1735e-01,
         -1.7302e-01],
        [-2.2850e-02,  9.7460e-02, -3.8114e-01,  4.1980e-01,  3.7737e-01,
          7.3310e-03,  2.8421e-01,  1.0128e-02,  2.9552e-01,  2.4049e-01,
         -8.1722e-02, -1.2413e-01, -2.5467e-01,  8.2515e-02,  3.2774e-01,
         -9.4070e-02],
        [ 3.9074e-01,  1.4189e-01,  4.3093e-01, -2.0428e-01, -9.3005e-02,
         -2.4776e-01, -2.0666e-01, -2.8447e-01, -3.0316e-01, -5.5468e-02,
         -6.6414e-02,  1.0476e-01, -4.5656e-02,  2.7770e-01, -2.1033e-01,
          1.7388e-01],
        [-4.5025e-02,  2.9005e-01,  3.7533e-01, -3.6954e-01, -3.5840e-01,
         -3.2728e-01, -1.0841e-01, -3.0024e-01, -2.3655e-01, -2.4177e-01,
         -1.1298e-01,  6.3987e-02,  2.6317e-01, -3.9784e-02, -1.6459e-02,
          3.7283e-01],
        [ 4.8545e-02,  3.2650e-01,  3.2062e-01, -2.5844e-01, -9.4377e-02,
         -3.8035e-01, -1.8718e-01, -1.4737e-01,  3.6330e-03, -3.3806e-01,
         -2.6366e-01,  9.6186e-02, -5.6854e-02,  2.0786e-01, -2.6039e-01,
          1.0794e-01],
        [-3.0486e-01, -1.3398e-01, -1.2065e-01,  4.1793e-03,  1.1915e-01,
          1.9185e-01,  7.4376e-02,  2.8431e-01,  3.1423e-01,  2.8361e-02,
          3.4218e-01, -4.6915e-02, -2.7949e-01, -1.3371e-01,  1.1319e-01,
         -2.1698e-01],
        [-3.7824e-01,  2.0544e-02, -9.1338e-02, -1.2741e-02,  1.0121e-02,
          4.6791e-01,  2.6155e-01,  1.7467e-01,  4.0456e-01,  2.8974e-01,
          1.4648e-01, -4.3225e-02, -1.7069e-01,  5.7302e-02, -5.2818e-02,
         -3.5680e-01],
        [-1.4426e-01, -1.8258e-01, -4.8017e-02,  1.0836e-01,  2.2002e-01,
          1.5879e-01,  3.9687e-01,  2.0417e-01,  2.1256e-01,  3.8091e-01,
          2.6077e-01,  1.7865e-02, -3.8966e-01, -2.9407e-01,  7.7770e-03,
         -2.2572e-01],
        [ 3.6131e-01,  2.8554e-01,  2.0069e-01, -2.0058e-01, -1.8260e-01,
         -2.8636e-02, -1.2146e-01, -3.9103e-01, -3.8357e-01, -1.5174e-01,
         -1.7641e-01,  8.9900e-02, -2.9910e-02,  2.3480e-01, -1.9847e-01,
          6.3680e-02],
        [ 2.2472e-01,  3.5607e-01,  3.8797e-01, -2.8060e-02, -3.4594e-01,
         -5.3601e-02, -6.4474e-02, -1.1407e-01, -2.5523e-01, -1.9258e-01,
         -2.8258e-01,  1.4605e-01,  1.3339e-01,  1.1075e-01, -2.6955e-01,
          2.5595e-01],
        [-3.9400e-01, -3.2252e-01, -9.0769e-02, -2.4426e-02,  4.0560e-01,
          4.4443e-01,  1.2409e-01,  1.6375e-01,  1.4871e-02,  2.1322e-01,
          1.9823e-01, -3.5089e-01, -1.0151e-01, -1.6969e-01, -2.4978e-02,
         -1.8338e-01],
        [-4.1661e-02, -1.5450e-02,  2.3676e-01,  4.4410e-02, -3.7532e-01,
         -7.7743e-02, -2.2345e-01, -3.6359e-01, -2.6475e-01, -1.0902e-01,
         -1.4634e-01,  4.6331e-01,  1.8723e-01,  4.5137e-02,  1.2553e-01,
          1.1175e-01],
        [ 3.3467e-01,  2.9291e-01,  2.2385e-01, -3.7354e-01, -4.0425e-01,
         -7.6269e-02, -1.3140e-01, -5.1737e-02, -4.1452e-01, -2.2101e-01,
          8.6317e-02,  3.3388e-01,  3.7569e-01,  3.4153e-01, -9.0818e-02,
         -3.7912e-03],
        [-3.1473e-01, -3.0667e-02, -2.6811e-01,  1.6122e-01,  1.6593e-01,
          3.3274e-01,  3.1275e-01,  3.1464e-01,  1.8534e-01,  3.1531e-01,
          1.2900e-02, -2.8186e-01, -1.7686e-01, -2.7991e-01,  2.3220e-01,
         -1.9750e-01],
        [ 2.3782e-01,  1.4796e-01,  1.6302e-01, -2.9174e-01, -2.6832e-01,
         -4.0535e-01, -3.0783e-01, -2.1263e-02, -4.5862e-01, -1.3312e-01,
         -1.2347e-01, -3.9810e-02,  2.4322e-01,  3.2920e-01,  6.4010e-02,
          2.0625e-01],
        [ 3.9423e-01,  1.6134e-01,  2.9728e-01, -1.1089e-01, -3.6285e-01,
         -2.7201e-01, -3.8637e-01, -2.4650e-02, -1.0095e-01, -3.1115e-01,
         -1.6183e-01,  2.9564e-01, -4.3826e-02,  1.7124e-01,  6.8355e-02,
          2.2309e-01],
        [-1.9795e-01,  2.8010e-02, -7.0380e-02, -4.9755e-02,  3.0631e-01,
         -5.5283e-03,  3.3025e-01,  3.9939e-01,  2.1558e-01,  1.0251e-01,
          5.4934e-03, -3.0632e-01, -2.0595e-01, -2.5621e-01,  3.1739e-01,
         -2.7627e-01],
        [-8.2482e-02, -3.5809e-01, -6.2844e-02,  3.9317e-01,  1.0200e-02,
          1.4519e-01,  2.7031e-01, -1.8695e-02,  5.9155e-02,  2.8793e-01,
          3.8628e-01, -2.9133e-01, -1.9578e-01, -4.0775e-01, -1.6373e-01,
          4.2854e-02],
        [ 3.8312e-01,  5.4700e-02,  7.5563e-02, -1.8175e-01, -3.0370e-02,
         -4.2923e-01, -3.2220e-01, -2.6664e-01, -2.9481e-01, -1.8734e-01,
          5.5034e-02,  2.4717e-01, -7.7480e-02,  3.7436e-01,  1.6800e-01,
          2.4233e-01],
        [ 2.7611e-01,  2.2235e-01,  3.6335e-01, -3.9116e-01, -2.6139e-01,
         -1.9729e-01, -2.0775e-01, -3.2064e-01, -3.9957e-01, -3.5341e-01,
         -1.1028e-01,  3.7810e-01,  2.6485e-01,  1.9609e-01, -1.6845e-01,
          4.8145e-02],
        [ 2.2494e-01, -8.2796e-02,  1.9264e-01, -1.4013e-01,  2.4470e-02,
         -2.9160e-01,  1.9573e-02, -2.1668e-01, -4.0520e-01,  2.3150e-02,
          6.3738e-02,  3.9044e-02,  6.3395e-02,  2.9618e-01, -2.4141e-01,
          3.5975e-01],
        [ 6.0219e-02,  5.7658e-02,  1.1217e-01,  6.1666e-02, -2.5147e-01,
         -2.4444e-01, -4.1848e-02, -3.6563e-01, -1.9987e-01, -3.8437e-01,
         -3.7124e-01,  1.4240e-01,  1.8808e-01,  3.7167e-01, -3.0883e-01,
          1.0271e-01],
        [ 2.3999e-01,  2.1961e-01,  3.2348e-01, -3.6827e-01, -2.0724e-01,
         -1.3144e-01, -3.8594e-01, -6.1426e-02, -4.2646e-01, -2.6769e-02,
         -5.2983e-02,  1.2411e-01,  2.3206e-01,  3.5506e-01,  1.6185e-01,
          3.1857e-01],
        [-3.3789e-01, -8.0055e-02, -8.2774e-03,  2.2590e-01,  3.5032e-01,
          5.9424e-02,  3.9173e-01,  2.1689e-01, -7.1231e-03,  1.3824e-01,
          3.0801e-01, -3.1169e-01, -2.2824e-01, -2.6267e-01, -6.7932e-02,
         -1.3830e-01],
        [ 3.2384e-01,  1.8605e-01,  1.6237e-01, -1.5195e-01, -3.4021e-01,
         -3.2363e-01, -1.7368e-01, -3.8719e-01, -6.4630e-02, -1.4366e-01,
         -1.7574e-02,  1.8217e-01,  3.0521e-01,  3.7306e-01,  5.2768e-02,
          2.9019e-01],
        [-2.8928e-01,  2.7083e-04, -3.3925e-01,  2.7106e-01, -4.9528e-02,
          1.7769e-01,  3.5734e-01,  3.4103e-01,  3.9788e-01,  2.6209e-01,
          2.4816e-01, -1.1564e-01,  3.4155e-02, -6.4165e-03,  8.1208e-02,
         -2.4798e-01],
        [-3.0638e-01, -2.0991e-01, -6.9956e-02,  4.0082e-02,  2.3706e-01,
          4.2312e-01,  4.1013e-01,  2.0830e-02,  2.7469e-01,  3.5732e-01,
         -1.1547e-01, -5.4312e-02, -3.1729e-01, -3.3483e-01, -5.4917e-02,
         -2.7195e-01],
        [ 7.7461e-02,  2.0497e-01,  2.7941e-01, -7.1353e-02, -3.3680e-02,
         -3.5584e-01, -4.3282e-01, -4.2118e-01, -3.6017e-01, -3.0183e-01,
         -4.7759e-02,  3.3057e-02, -5.3947e-04,  3.2906e-01, -2.0049e-01,
          2.1988e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0704, -0.0024,  0.0961, -0.0444, -0.0416, -0.0673,  0.0651,  0.0719,
        -0.0255, -0.0406,  0.0078,  0.0667,  0.1306,  0.0708,  0.0298, -0.0724,
        -0.0604, -0.0011,  0.0769, -0.0011, -0.0267, -0.1294, -0.0414,  0.0016,
        -0.0340,  0.1498,  0.1079,  0.0336, -0.0729, -0.1324,  0.0406, -0.0482],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2182,  0.3105, -0.2178, -0.2504,  0.3039,  0.3425, -0.2751, -0.3769,
         -0.3090,  0.3278,  0.2519,  0.3623, -0.2464, -0.3904,  0.2932, -0.2341,
         -0.3118,  0.3248, -0.2180, -0.2429,  0.3803,  0.3046, -0.3633, -0.3733,
         -0.3120, -0.3234, -0.3074,  0.3357, -0.3506,  0.3766,  0.2812, -0.2286]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0137, -0.0066,  0.0415,  ...,  0.2356, -0.3603, -0.1137],
        [-0.0858, -0.1894,  0.0849,  ...,  0.1477, -0.3400,  0.0871],
        [-0.0410,  0.1731,  0.0761,  ..., -0.0049,  0.2565,  0.0345],
        ...,
        [ 0.0261, -0.1881,  0.0399,  ...,  0.0654, -0.2811, -0.1180],
        [ 0.0507, -0.0517, -0.0171,  ..., -0.3037,  0.1458,  0.1557],
        [-0.2031,  0.0534, -0.0015,  ...,  0.0420, -0.2236, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0572,  0.0584, -0.0892, -0.1177, -0.0564,  0.0522, -0.1285,  0.0620,
        -0.0492,  0.0822,  0.0319,  0.0082,  0.0249,  0.0726, -0.0790, -0.0166,
         0.0513, -0.1491, -0.0273, -0.0232, -0.0751,  0.0432,  0.0882, -0.0083,
        -0.0865,  0.0862,  0.0332, -0.0872,  0.0490,  0.1390,  0.1472, -0.1036],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0111, -0.1896, -0.0759,  ..., -0.1220, -0.0277,  0.0652],
        [-0.2739, -0.0432,  0.1201,  ..., -0.0545, -0.0071,  0.0530],
        [ 0.1888, -0.0324, -0.1779,  ...,  0.0580, -0.0066,  0.1702],
        ...,
        [ 0.1742,  0.0964,  0.0846,  ...,  0.2346, -0.2014,  0.2480],
        [-0.0828, -0.1592,  0.0770,  ...,  0.0298,  0.2325, -0.1669],
        [-0.0568, -0.1253,  0.2209,  ...,  0.0648,  0.1355, -0.0383]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0817,  0.1192, -0.0198, -0.0571, -0.0362, -0.0620, -0.0235, -0.0607,
         0.0919, -0.1313,  0.1347, -0.1268,  0.1479,  0.0553, -0.1354,  0.0837,
        -0.1154, -0.1422,  0.0011, -0.0150,  0.0095,  0.1113, -0.1803,  0.1695,
        -0.0652, -0.0322,  0.0920, -0.0434, -0.1064, -0.0513,  0.0906,  0.0017],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4397,  0.3601, -0.4372, -0.4414,  0.3045,  0.2957, -0.3523,  0.3464,
          0.3735, -0.3746, -0.3386,  0.3342,  0.3321,  0.3418,  0.3705,  0.3207,
         -0.4402, -0.4456,  0.3109,  0.3352, -0.3937, -0.3725, -0.4374,  0.2999,
          0.4218,  0.4490, -0.4230,  0.4710, -0.3507, -0.4377,  0.4152,  0.4401]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1630], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.3743e-02,  1.6690e-01,  3.2105e-01, -3.5697e-01, -2.4032e-01,
         -1.6800e-01, -6.4038e-02, -4.0720e-01, -1.7956e-01, -8.6095e-02,
          1.7890e-01,  2.0508e-01,  6.8458e-02, -1.8116e-02, -1.0462e-01,
          3.9421e-01],
        [-2.6306e-01, -1.5114e-01, -1.1295e-01,  2.9401e-02,  1.3229e-02,
          2.5761e-01,  1.6968e-01,  1.7947e-01,  4.2083e-01,  1.5547e-01,
          6.2840e-02, -2.7801e-01, -1.3766e-02, -8.1095e-02,  4.0683e-01,
         -9.7915e-02],
        [ 9.0922e-02,  8.5872e-02,  3.8768e-01, -1.4376e-01, -9.7419e-02,
         -3.5081e-01, -4.1278e-02, -4.2475e-01,  2.8447e-02, -8.0476e-02,
         -8.8119e-02, -4.5168e-02,  4.0477e-01,  3.4749e-01,  1.8133e-02,
          2.7628e-01],
        [ 2.7872e-01,  2.8431e-03,  9.0289e-02, -1.0645e-01, -8.2770e-02,
         -1.9999e-01, -1.5027e-01, -1.0563e-01, -4.3124e-01, -4.1999e-01,
          3.3148e-02,  3.7413e-01,  3.1110e-01, -8.4550e-02, -2.3508e-01,
          1.6740e-01],
        [-1.0247e-01,  2.5367e-01, -1.7738e-01,  9.3878e-03,  1.9347e-01,
          9.0763e-02,  3.9960e-02,  3.3597e-01,  1.5979e-01,  3.1665e-01,
          6.8103e-02, -1.7424e-01, -5.8799e-02, -2.7341e-01,  3.1819e-01,
         -1.7178e-01],
        [-6.1844e-03,  2.6170e-01, -3.6119e-01,  4.2834e-01,  3.4703e-01,
         -3.2390e-02,  2.5041e-01, -2.6134e-02,  2.6458e-01,  2.2396e-01,
         -1.0826e-01, -9.4569e-02, -2.3736e-01,  1.0375e-01,  3.8031e-01,
         -8.5023e-02],
        [ 3.7936e-01,  4.1824e-02,  4.1511e-01, -2.1834e-01, -8.8009e-02,
         -2.1897e-01, -1.7664e-01, -2.5223e-01, -2.6877e-01, -4.5712e-02,
          2.3672e-03,  7.8448e-02, -5.0744e-02,  2.1172e-01, -3.0472e-01,
          1.6774e-01],
        [-5.5352e-02,  1.7973e-01,  3.6266e-01, -3.8450e-01, -3.5863e-01,
         -3.0499e-01, -8.5584e-02, -2.7919e-01, -2.1965e-01, -2.3641e-01,
         -6.7684e-02,  5.0665e-02,  2.5973e-01, -7.5881e-02, -9.0129e-02,
          3.6631e-01],
        [ 4.8394e-02,  1.0352e-01,  3.1555e-01, -2.8557e-01, -8.9449e-02,
         -3.5700e-01, -1.7094e-01, -1.2475e-01,  2.2349e-02, -3.3915e-01,
          1.4279e-02,  7.5350e-02, -4.6596e-02,  2.0701e-01, -3.8452e-01,
          1.1625e-01],
        [-2.9864e-01,  8.1891e-02, -1.0998e-01,  2.3870e-02,  1.0711e-01,
          1.6521e-01,  5.1043e-02,  2.5713e-01,  2.8799e-01,  2.2449e-02,
          1.0382e-01, -2.3948e-02, -2.7853e-01, -1.2324e-01,  2.1802e-01,
         -2.1897e-01],
        [-3.6619e-01,  1.4248e-01, -7.3648e-02,  2.3007e-04, -7.7707e-03,
          4.3548e-01,  2.3652e-01,  1.3964e-01,  3.7134e-01,  2.7648e-01,
          6.2053e-03, -1.2466e-02, -2.1860e-01,  6.0173e-02,  2.6174e-02,
         -3.5037e-01],
        [-1.3003e-01, -4.2690e-02, -2.9277e-02,  1.2323e-01,  1.8800e-01,
          1.2543e-01,  3.5681e-01,  1.5875e-01,  1.7135e-01,  3.6660e-01,
          8.9715e-02,  5.4213e-02, -4.2412e-01, -2.6262e-01,  9.7459e-02,
         -2.1836e-01],
        [ 3.5098e-01,  8.6656e-02,  1.8245e-01, -2.1731e-01, -1.5748e-01,
          4.0008e-03, -9.6968e-02, -3.5522e-01, -3.5237e-01, -1.3838e-01,
         -9.0919e-02,  6.0868e-02, -5.1578e-03,  2.3759e-01, -3.2149e-01,
          5.9252e-02],
        [ 2.1771e-01,  1.7410e-01,  3.7720e-01, -4.6536e-02, -3.3840e-01,
         -3.0701e-02, -4.0325e-02, -8.9224e-02, -2.3952e-01, -1.8758e-01,
         -1.0624e-01,  1.2593e-01,  1.3539e-01,  8.7047e-02, -3.8721e-01,
          2.5476e-01],
        [-3.8719e-01, -1.3500e-01, -7.9276e-02, -6.0097e-03,  4.0488e-01,
          4.2260e-01,  1.0333e-01,  1.4366e-01, -5.6615e-03,  2.0828e-01,
          3.6319e-02, -3.3215e-01, -1.0930e-01, -1.5598e-01,  9.7053e-02,
         -1.8095e-01],
        [-3.0704e-02, -2.9238e-01,  2.3649e-01,  4.1244e-03, -3.9380e-01,
         -5.0545e-02, -2.0939e-01, -3.5420e-01, -2.4080e-01, -1.1357e-01,
         -4.8464e-02,  4.5547e-01,  1.9917e-01,  2.7099e-02, -4.7797e-03,
          1.3089e-01],
        [ 3.2380e-01,  1.4424e-01,  2.0882e-01, -3.8877e-01, -3.7228e-01,
         -4.6597e-02, -9.6791e-02, -1.0979e-02, -3.8884e-01, -2.1034e-01,
          2.0126e-01,  3.0421e-01,  3.6424e-01,  2.9841e-01, -1.5531e-01,
         -9.6166e-03],
        [-3.0058e-01,  8.1215e-02, -2.5046e-01,  1.7328e-01,  1.3689e-01,
          3.0235e-01,  2.7732e-01,  2.7732e-01,  1.5295e-01,  3.0501e-01,
         -4.4653e-02, -2.5764e-01, -1.6368e-01, -2.2234e-01,  2.5360e-01,
         -1.8670e-01],
        [ 2.4307e-01, -1.8219e-02,  1.6248e-01, -3.1627e-01, -2.1624e-01,
         -3.8942e-01, -2.8254e-01,  1.8493e-02, -4.1749e-01, -1.3352e-01,
          1.4886e-02, -6.0168e-02,  2.1204e-01,  2.8677e-01, -4.8192e-03,
          2.1498e-01],
        [ 3.8332e-01,  7.9766e-03,  2.8031e-01, -1.2742e-01, -3.4885e-01,
         -2.4233e-01, -3.5785e-01,  7.7610e-03, -7.0607e-02, -3.0015e-01,
          8.9446e-02,  2.6593e-01, -3.1767e-02,  1.4808e-01, -5.3071e-02,
          2.1611e-01],
        [-1.8226e-01,  1.8692e-01, -5.0172e-02, -4.1992e-02,  2.8377e-01,
         -3.6698e-02,  2.9891e-01,  3.6995e-01,  1.9029e-01,  8.8521e-02,
         -1.0129e-01, -2.8145e-01, -2.0270e-01, -2.2525e-01,  3.7557e-01,
         -2.6508e-01],
        [-8.4668e-02, -7.9651e-02, -6.0355e-02,  4.2418e-01,  1.4657e-02,
          1.2670e-01,  2.5519e-01, -3.7383e-02,  4.4865e-02,  2.9407e-01,
          2.0559e-01, -2.8183e-01, -2.0886e-01, -4.0057e-01, -6.5151e-02,
          3.5349e-02],
        [ 3.7439e-01, -9.5587e-02,  6.2262e-02, -1.9892e-01, -2.0308e-02,
         -4.0582e-01, -2.9593e-01, -2.4380e-01, -2.7355e-01, -1.8172e-01,
          2.0417e-01,  2.2943e-01, -6.4511e-02,  3.4399e-01,  7.5296e-02,
          2.3596e-01],
        [ 2.6385e-01,  1.4392e-01,  3.4852e-01, -4.0640e-01, -2.2737e-01,
         -1.7289e-01, -1.7649e-01, -2.8644e-01, -3.7206e-01, -3.4495e-01,
          1.9392e-02,  3.6036e-01,  2.8485e-01,  1.5333e-01, -2.0507e-01,
          3.6878e-02],
        [ 2.1439e-01, -2.8983e-01,  1.7760e-01, -1.5630e-01,  4.2670e-02,
         -2.5661e-01,  5.0206e-02, -1.7953e-01, -3.6970e-01,  3.4403e-02,
          1.9909e-01,  7.5075e-03,  5.7387e-02,  2.8249e-01, -3.4340e-01,
          3.5885e-01],
        [ 5.0295e-02, -1.1324e-01,  9.7183e-02,  4.9073e-02, -2.3664e-01,
         -2.2085e-01, -2.3660e-02, -3.4297e-01, -1.8074e-01, -3.7578e-01,
         -2.7515e-01,  1.2415e-01,  2.0199e-01,  3.5778e-01, -4.0972e-01,
          9.5741e-02],
        [ 2.2848e-01,  4.7706e-02,  3.0553e-01, -3.8179e-01, -1.8952e-01,
         -1.0656e-01, -3.5110e-01, -3.2619e-02, -3.9898e-01, -1.7115e-02,
          4.3776e-02,  1.0025e-01,  2.3819e-01,  2.9794e-01,  8.0917e-02,
          3.0693e-01],
        [-3.2994e-01,  9.1255e-02,  4.9693e-03,  2.4503e-01,  3.3002e-01,
          3.1231e-02,  3.5922e-01,  1.8196e-01, -4.3458e-02,  1.3027e-01,
          7.4403e-02, -2.8298e-01, -2.3431e-01, -2.3549e-01,  2.5243e-02,
         -1.3686e-01],
        [ 3.0949e-01,  9.8581e-02,  1.4298e-01, -1.6432e-01, -3.0905e-01,
         -2.9458e-01, -1.4225e-01, -3.5045e-01, -3.4261e-02, -1.3038e-01,
          1.0726e-01,  1.5395e-01,  3.6493e-01,  3.4797e-01, -9.0583e-03,
          2.7817e-01],
        [-2.7825e-01,  1.1033e-01, -3.2553e-01,  2.8585e-01, -5.4736e-02,
          1.5495e-01,  3.3133e-01,  3.1684e-01,  3.7541e-01,  2.5581e-01,
          1.5361e-01, -1.0058e-01,  3.5453e-02,  3.0206e-02,  1.6088e-01,
         -2.4048e-01],
        [-2.9220e-01, -4.4204e-02, -5.0276e-02,  5.2335e-02,  2.1023e-01,
          3.8978e-01,  3.7632e-01, -1.5586e-02,  2.4327e-01,  3.4451e-01,
         -2.2656e-01, -2.1829e-02, -3.2048e-01, -3.0210e-01,  2.3334e-02,
         -2.6118e-01],
        [ 7.1265e-02,  5.0666e-02,  2.6712e-01, -9.0951e-02, -1.2642e-02,
         -3.2897e-01, -4.0039e-01, -3.7242e-01, -3.1873e-01, -2.9334e-01,
          8.9904e-02,  2.5577e-04, -1.9441e-02,  2.6413e-01, -2.8852e-01,
          2.1936e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0549, -0.0724,  0.1174, -0.0647, -0.0569, -0.0279,  0.0915,  0.1327,
        -0.0411, -0.0737,  0.0216,  0.0660,  0.2052,  0.1156, -0.0605,  0.1122,
        -0.1367, -0.0026,  0.0275,  0.0031, -0.0182, -0.1195, -0.0581, -0.0164,
        -0.1516,  0.2572,  0.1048,  0.0228, -0.0836, -0.2269,  0.1605, -0.0272],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2164,  0.3036, -0.2226, -0.2358,  0.3000,  0.3490, -0.2759, -0.3651,
         -0.3048,  0.3420,  0.2398,  0.3658, -0.2427, -0.3954,  0.2958, -0.2470,
         -0.3069,  0.3118, -0.2171, -0.2377,  0.3872,  0.3058, -0.3549, -0.3616,
         -0.3421, -0.3247, -0.3035,  0.3341, -0.3295,  0.3675,  0.2712, -0.2176]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0601,  0.1328,  0.0631,  ...,  0.2142, -0.3081, -0.1137],
        [-0.1313, -0.0206,  0.1199,  ...,  0.1530, -0.3138,  0.0871],
        [ 0.0207, -0.0672,  0.0154,  ...,  0.0324,  0.2119,  0.0345],
        ...,
        [-0.0117,  0.0407,  0.0615,  ...,  0.0813, -0.2931, -0.1180],
        [ 0.1076, -0.2377, -0.0576,  ..., -0.3240,  0.1320,  0.1557],
        [-0.2284,  0.1817,  0.0414,  ...,  0.0951, -0.2510, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0378,  0.0415, -0.0671, -0.1343, -0.0715,  0.0638, -0.1105,  0.0443,
        -0.0367,  0.0800,  0.0142,  0.0127,  0.0311,  0.0784, -0.0538, -0.0188,
         0.0581, -0.1586,  0.0043,  0.0266, -0.0462,  0.0296,  0.1090,  0.0040,
        -0.0958,  0.1059,  0.0472, -0.0898,  0.0524,  0.1387,  0.1679, -0.1228],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0758, -0.1759, -0.1266,  ..., -0.1302, -0.0178,  0.0753],
        [-0.2036, -0.0309,  0.0707,  ..., -0.0616,  0.0044,  0.0503],
        [ 0.1313, -0.0351, -0.1423,  ...,  0.0747, -0.0176,  0.1829],
        ...,
        [ 0.1146,  0.0895,  0.1297,  ...,  0.2511, -0.2208,  0.2453],
        [-0.0044, -0.1408,  0.0221,  ...,  0.0223,  0.2330, -0.1647],
        [-0.0008, -0.1278,  0.1858,  ...,  0.0395,  0.1595, -0.0484]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0985,  0.1427, -0.0523, -0.0804, -0.0018, -0.0389, -0.0546, -0.0445,
         0.1206, -0.1652,  0.1201, -0.1179,  0.1693,  0.0868, -0.1243,  0.1162,
        -0.1390, -0.1699, -0.0633, -0.0041,  0.0004,  0.0876, -0.2045,  0.2075,
        -0.0477, -0.0045,  0.0774, -0.0281, -0.1339, -0.0709,  0.1116,  0.0364],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3802,  0.2969, -0.3749, -0.3719,  0.2439,  0.2289, -0.2923,  0.2596,
          0.3012, -0.3191, -0.2674,  0.2826,  0.2684,  0.2465,  0.3073,  0.2976,
         -0.3762, -0.3881, -0.2381,  0.2831, -0.3285, -0.3043, -0.3796,  0.2318,
          0.3498,  0.3903, -0.3719,  0.3739, -0.2939, -0.3776,  0.3560,  0.3824]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1495], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-4.0145e-04,  4.0963e-01,  3.0872e-01, -3.3080e-01, -2.1928e-01,
         -1.4881e-01, -4.4174e-02, -3.9433e-01, -1.7032e-01, -6.8270e-02,
          1.4336e-01,  1.8270e-01,  4.4706e-02, -3.5105e-02, -8.6119e-02,
          3.7700e-01],
        [-2.5004e-01, -3.8602e-01, -1.0056e-01,  1.0152e-02, -7.1500e-03,
          2.4552e-01,  1.6004e-01,  1.6578e-01,  4.0460e-01,  1.4429e-01,
          8.0042e-02, -2.6075e-01,  4.8547e-04, -7.3231e-02,  3.8606e-01,
         -8.2850e-02],
        [ 7.4847e-02,  2.8405e-01,  3.7417e-01, -1.2277e-01, -8.2931e-02,
         -3.3956e-01, -3.1127e-02, -4.1460e-01,  3.6714e-02, -6.7064e-02,
         -1.0183e-01, -6.2502e-02,  3.8933e-01,  3.4245e-01,  3.5511e-02,
          2.5975e-01],
        [ 2.6783e-01,  1.1495e-01,  8.1980e-02, -9.1312e-02, -6.5563e-02,
         -1.9193e-01, -1.4570e-01, -9.5748e-02, -4.2187e-01, -4.1175e-01,
          2.0683e-02,  3.6126e-01,  3.0217e-01, -8.3911e-02, -2.2720e-01,
          1.5529e-01],
        [-9.9553e-02,  4.0436e-02, -1.7408e-01, -1.9895e-03,  1.9082e-01,
          8.6835e-02,  4.3809e-02,  3.3861e-01,  1.5866e-01,  3.1481e-01,
          9.8806e-02, -1.6646e-01, -6.1829e-02, -2.8206e-01,  3.2096e-01,
         -1.6607e-01],
        [-2.9654e-03,  8.6966e-02, -3.5850e-01,  4.1898e-01,  3.4524e-01,
         -2.9961e-02,  2.5295e-01, -2.9386e-02,  2.6008e-01,  2.2267e-01,
         -1.1192e-01, -8.8343e-02, -2.4487e-01,  9.7478e-02,  4.1194e-01,
         -8.0380e-02],
        [ 3.6576e-01,  1.6322e-01,  4.0378e-01, -2.0038e-01, -7.0340e-02,
         -2.1156e-01, -1.7022e-01, -2.3883e-01, -2.4952e-01, -3.5854e-02,
         -6.2351e-03,  6.4045e-02, -6.1914e-02,  2.0894e-01, -2.9477e-01,
          1.5395e-01],
        [-6.9615e-02,  3.0695e-01,  3.5043e-01, -3.6541e-01, -3.3343e-01,
         -2.9706e-01, -7.6014e-02, -2.6131e-01, -2.0074e-01, -2.2577e-01,
         -8.5068e-02,  3.4274e-02,  2.4591e-01, -8.1145e-02, -7.1015e-02,
          3.5280e-01],
        [ 3.5065e-02,  3.5476e-01,  3.0231e-01, -2.6598e-01, -6.9673e-02,
         -3.4549e-01, -1.6128e-01, -1.1175e-01,  3.6203e-02, -3.2717e-01,
          4.4260e-03,  5.8337e-02, -5.8751e-02,  1.9809e-01, -3.6967e-01,
          9.9775e-02],
        [-2.9298e-01, -1.5030e-01, -1.0411e-01,  1.0561e-02,  9.8693e-02,
          1.5925e-01,  5.0002e-02,  2.5439e-01,  2.8306e-01,  1.8113e-02,
          1.3633e-01, -1.3638e-02, -2.7597e-01, -1.2497e-01,  2.1230e-01,
         -2.1066e-01],
        [-3.5914e-01,  5.9986e-03, -6.8098e-02, -1.0021e-02, -1.6039e-02,
          4.3021e-01,  2.3323e-01,  1.3570e-01,  3.6649e-01,  2.7148e-01,
          9.8020e-04, -3.2131e-03, -2.0891e-01,  5.5834e-02,  3.1080e-02,
         -3.4143e-01],
        [-1.2091e-01, -1.8796e-01, -2.0677e-02,  1.0773e-01,  1.7454e-01,
          1.1617e-01,  3.5487e-01,  1.5540e-01,  1.6173e-01,  3.5948e-01,
          1.1303e-01,  6.5851e-02, -4.1503e-01, -2.6622e-01,  8.3013e-02,
         -2.0735e-01],
        [ 3.3876e-01,  3.0383e-01,  1.7139e-01, -1.9812e-01, -1.4432e-01,
          1.8534e-02, -8.8979e-02, -3.4610e-01, -3.4219e-01, -1.2686e-01,
         -1.0902e-01,  4.2025e-02, -2.1654e-02,  2.3215e-01, -3.0610e-01,
          4.6552e-02],
        [ 2.0425e-01,  3.7503e-01,  3.6406e-01, -2.8204e-02, -3.1921e-01,
         -1.9944e-02, -3.2801e-02, -7.5835e-02, -2.2146e-01, -1.7650e-01,
         -1.1905e-01,  1.1043e-01,  1.2268e-01,  8.1512e-02, -3.6840e-01,
          2.4005e-01],
        [-3.7439e-01, -3.4295e-01, -6.7455e-02, -2.3836e-02,  3.8569e-01,
          4.1267e-01,  9.5373e-02,  1.3010e-01, -1.9666e-02,  1.9795e-01,
          4.6825e-02, -3.1657e-01, -9.6588e-02, -1.5007e-01,  7.7077e-02,
         -1.6696e-01],
        [-3.0994e-01, -3.1696e-01, -2.1038e-02,  3.0776e-01,  4.8769e-02,
          2.0847e-01,  1.0134e-01, -1.0684e-03,  1.0663e-01,  1.8268e-01,
          6.2294e-02,  1.4150e-01, -1.3567e-01, -3.3443e-01,  4.7723e-01,
         -1.3226e-01],
        [ 3.0989e-01,  2.8190e-01,  1.9833e-01, -3.7085e-01, -3.5156e-01,
         -3.6927e-02, -9.1157e-02,  5.0922e-03, -3.7262e-01, -2.0034e-01,
          1.7716e-01,  2.8957e-01,  3.5078e-01,  3.0107e-01, -1.2974e-01,
         -2.3107e-02],
        [-2.8842e-01, -3.2935e-04, -2.4100e-01,  1.5596e-01,  1.2187e-01,
          2.9864e-01,  2.7381e-01,  2.6540e-01,  1.3877e-01,  2.9723e-01,
         -3.7612e-02, -2.4444e-01, -1.5974e-01, -2.2060e-01,  2.4340e-01,
         -1.7477e-01],
        [ 2.2911e-01,  1.6161e-01,  1.5210e-01, -2.9746e-01, -2.0270e-01,
         -3.8049e-01, -2.7673e-01,  2.5612e-02, -4.1097e-01, -1.2257e-01,
          1.7100e-02, -7.5329e-02,  2.0170e-01,  2.8635e-01,  1.0396e-02,
          1.9973e-01],
        [ 3.7132e-01,  1.8377e-01,  2.7046e-01, -1.1171e-01, -3.3381e-01,
         -2.3363e-01, -3.5479e-01,  1.8002e-02, -5.8950e-02, -2.9110e-01,
          8.5126e-02,  2.5247e-01, -4.1354e-02,  1.5086e-01, -3.8736e-02,
          2.0265e-01],
        [-1.7522e-01,  2.4218e-02, -4.3786e-02, -5.4614e-02,  2.7805e-01,
         -4.0051e-02,  3.0001e-01,  3.6510e-01,  1.8245e-01,  8.4303e-02,
         -7.8766e-02, -2.7203e-01, -2.0321e-01, -2.3218e-01,  3.8960e-01,
         -2.5703e-01],
        [-7.5874e-02, -3.7332e-01, -5.1246e-02,  4.0593e-01, -3.1825e-03,
          1.1824e-01,  2.5114e-01, -4.3392e-02,  3.5852e-02,  2.8464e-01,
          2.1654e-01, -2.6643e-01, -2.0242e-01, -3.9701e-01, -7.2826e-02,
          4.7278e-02],
        [ 3.6589e-01,  5.6858e-02,  5.5048e-02, -1.8520e-01, -8.8465e-03,
         -4.0108e-01, -2.9588e-01, -2.3629e-01, -2.6394e-01, -1.7639e-01,
          1.8529e-01,  2.1967e-01, -6.8408e-02,  3.4546e-01,  8.9502e-02,
          2.2649e-01],
        [ 2.4731e-01,  2.2074e-01,  3.3631e-01, -3.8549e-01, -2.0070e-01,
         -1.6278e-01, -1.6816e-01, -2.6427e-01, -3.5306e-01, -3.3325e-01,
          2.9231e-03,  3.4240e-01,  2.6987e-01,  1.5089e-01, -1.7447e-01,
          2.2647e-02],
        [ 2.1323e-01, -5.9975e-02,  1.7651e-01, -1.4793e-01,  4.5191e-02,
         -2.5573e-01,  4.6739e-02, -1.8061e-01, -3.6901e-01,  3.4432e-02,
          1.9696e-01,  3.1073e-03,  6.0534e-02,  2.9126e-01, -3.4738e-01,
          3.5540e-01],
        [ 4.0921e-02,  7.9197e-02,  8.8140e-02,  6.3254e-02, -2.2706e-01,
         -2.1449e-01, -1.6840e-02, -3.3596e-01, -1.7153e-01, -3.6895e-01,
         -2.9322e-01,  1.1177e-01,  1.9466e-01,  3.5854e-01, -4.1150e-01,
          8.5619e-02],
        [ 2.1504e-01,  2.0456e-01,  2.9492e-01, -3.6464e-01, -1.7222e-01,
         -9.7692e-02, -3.4919e-01, -1.8872e-02, -3.8448e-01, -7.8553e-03,
          2.5380e-02,  8.7282e-02,  2.2654e-01,  3.0648e-01,  1.0084e-01,
          2.9430e-01],
        [-3.2389e-01, -9.0239e-02,  1.0516e-02,  2.3106e-01,  3.2148e-01,
          2.4560e-02,  3.6024e-01,  1.8074e-01, -4.9595e-02,  1.2578e-01,
          9.7694e-02, -2.7312e-01, -2.3095e-01, -2.4344e-01,  2.0074e-02,
         -1.2849e-01],
        [ 2.9650e-01,  1.9506e-01,  1.3251e-01, -1.4815e-01, -2.9118e-01,
         -2.8403e-01, -1.3816e-01, -3.3680e-01, -2.0403e-02, -1.2126e-01,
          8.4685e-02,  1.4024e-01,  3.5116e-01,  3.4896e-01,  1.1707e-02,
          2.6581e-01],
        [-2.6822e-01, -1.5961e-02, -3.1680e-01,  2.7028e-01, -6.8534e-02,
          1.5054e-01,  3.2891e-01,  3.0792e-01,  3.6346e-01,  2.4916e-01,
          1.6187e-01, -8.8957e-02,  3.9983e-02,  2.7848e-02,  1.5689e-01,
         -2.3020e-01],
        [-2.8035e-01, -2.0299e-01, -4.1054e-02,  3.6535e-02,  1.9396e-01,
          3.8279e-01,  3.7307e-01, -2.8481e-02,  2.3144e-01,  3.3611e-01,
         -2.1417e-01, -9.4692e-03, -3.1272e-01, -3.0181e-01,  3.8768e-03,
         -2.4842e-01],
        [ 5.5317e-02,  1.8482e-01,  2.5499e-01, -6.9713e-02,  8.5281e-03,
         -3.1841e-01, -3.9383e-01, -3.6380e-01, -3.0789e-01, -2.8171e-01,
          7.7872e-02, -1.5641e-02, -3.4252e-02,  2.5916e-01, -2.6010e-01,
          2.0293e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0806, -0.0414,  0.1102, -0.0656, -0.0575, -0.0357,  0.0903,  0.1288,
        -0.0478, -0.0563,  0.0007,  0.0839,  0.1662,  0.0951, -0.0401, -0.0522,
        -0.1578,  0.0009,  0.0204, -0.0024, -0.0163, -0.1094, -0.0612, -0.0302,
        -0.1201,  0.2593,  0.0899,  0.0340, -0.1007, -0.2276,  0.1759, -0.0422],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2191,  0.3031, -0.2219, -0.2377,  0.3112,  0.3549, -0.2767, -0.3622,
         -0.3191,  0.3411,  0.2434,  0.3621, -0.2477, -0.3982,  0.2946,  0.2327,
         -0.3041,  0.3120, -0.2169, -0.2372,  0.3844,  0.3068, -0.3552, -0.3595,
         -0.3589, -0.3274, -0.3023,  0.3309, -0.3296,  0.3673,  0.2723, -0.2188]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0269,  0.1091,  0.0827,  ...,  0.1547, -0.2376, -0.1137],
        [-0.1251, -0.0309,  0.1212,  ...,  0.1295, -0.2986,  0.0871],
        [ 0.0083, -0.0473,  0.0278,  ...,  0.0304,  0.2104,  0.0345],
        ...,
        [-0.0015,  0.0246,  0.0595,  ...,  0.0618, -0.2861, -0.1180],
        [ 0.1037, -0.2269, -0.0586,  ..., -0.2984,  0.1208,  0.1557],
        [-0.2106,  0.1740,  0.0436,  ...,  0.0645, -0.2456, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0456,  0.0423, -0.0715, -0.1356, -0.0725,  0.0564, -0.1115,  0.0492,
        -0.0370,  0.0778,  0.0192,  0.0131,  0.0281,  0.0751, -0.0528, -0.0179,
         0.0564, -0.1603, -0.0589,  0.0353, -0.0510,  0.0287,  0.1066,  0.0046,
        -0.0923,  0.0541,  0.0439, -0.1093,  0.0526,  0.1412,  0.1679, -0.1255],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0730, -0.1748, -0.1178,  ..., -0.1168, -0.0316,  0.0786],
        [-0.2062, -0.0294,  0.0900,  ..., -0.0468, -0.0132,  0.0527],
        [ 0.1306, -0.0383, -0.1493,  ...,  0.0609, -0.0039,  0.1760],
        ...,
        [ 0.1042,  0.0753,  0.1315,  ...,  0.2290, -0.1964,  0.2289],
        [-0.0043, -0.1396,  0.0335,  ...,  0.0397,  0.2160, -0.1612],
        [ 0.0057, -0.1168,  0.1839,  ...,  0.0615,  0.1372, -0.0333]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1035,  0.1546, -0.0527, -0.0803, -0.0091, -0.0376, -0.0539, -0.0452,
         0.1298, -0.1724,  0.1098, -0.1295,  0.1864,  0.0996, -0.1308,  0.1234,
        -0.1375, -0.1691,  0.0390, -0.0111, -0.0030,  0.0896, -0.1955,  0.2254,
        -0.0457, -0.0086,  0.0818, -0.0260, -0.1317, -0.0679,  0.1185,  0.0315],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3991,  0.3191, -0.3927, -0.3762,  0.2570,  0.2556, -0.3069,  0.2678,
          0.3014, -0.3393, -0.2874,  0.2879,  0.2826,  0.2710,  0.3169,  0.3215,
         -0.3863, -0.3989,  0.2491,  0.2931, -0.3408, -0.3198, -0.3929,  0.2426,
          0.3635,  0.3998, -0.3806,  0.3837, -0.3074, -0.3870,  0.3703,  0.3894]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1596], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-4.0162e-04,  4.0963e-01,  3.0872e-01, -3.3080e-01, -2.1928e-01,
         -1.4881e-01, -4.4174e-02, -3.9433e-01, -1.7032e-01, -6.8270e-02,
          1.4336e-01,  1.8270e-01,  4.4706e-02, -3.5105e-02, -8.6120e-02,
          3.7700e-01],
        [-2.5004e-01, -3.8602e-01, -1.0056e-01,  1.0152e-02, -7.1499e-03,
          2.4552e-01,  1.6004e-01,  1.6578e-01,  4.0460e-01,  1.4429e-01,
          8.0042e-02, -2.6075e-01,  4.8548e-04, -7.3231e-02,  3.8606e-01,
         -8.2850e-02],
        [ 7.4847e-02,  2.8405e-01,  3.7417e-01, -1.2277e-01, -8.2931e-02,
         -3.3956e-01, -3.1127e-02, -4.1460e-01,  3.6714e-02, -6.7064e-02,
         -1.0183e-01, -6.2503e-02,  3.8933e-01,  3.4245e-01,  3.5510e-02,
          2.5975e-01],
        [ 2.6783e-01,  1.1495e-01,  8.1980e-02, -9.1312e-02, -6.5564e-02,
         -1.9193e-01, -1.4570e-01, -9.5748e-02, -4.2187e-01, -4.1175e-01,
          2.0684e-02,  3.6126e-01,  3.0217e-01, -8.3911e-02, -2.2720e-01,
          1.5529e-01],
        [-9.9553e-02,  4.0436e-02, -1.7407e-01, -1.9897e-03,  1.9082e-01,
          8.6835e-02,  4.3809e-02,  3.3861e-01,  1.5866e-01,  3.1481e-01,
          9.8805e-02, -1.6646e-01, -6.1829e-02, -2.8206e-01,  3.2096e-01,
         -1.6607e-01],
        [-2.9653e-03,  8.6966e-02, -3.5850e-01,  4.1898e-01,  3.4524e-01,
         -2.9962e-02,  2.5295e-01, -2.9386e-02,  2.6008e-01,  2.2267e-01,
         -1.1192e-01, -8.8343e-02, -2.4487e-01,  9.7478e-02,  4.1194e-01,
         -8.0380e-02],
        [ 3.6576e-01,  1.6322e-01,  4.0378e-01, -2.0038e-01, -7.0340e-02,
         -2.1156e-01, -1.7022e-01, -2.3883e-01, -2.4952e-01, -3.5854e-02,
         -6.2346e-03,  6.4044e-02, -6.1914e-02,  2.0894e-01, -2.9477e-01,
          1.5395e-01],
        [-6.9615e-02,  3.0695e-01,  3.5043e-01, -3.6541e-01, -3.3343e-01,
         -2.9706e-01, -7.6014e-02, -2.6131e-01, -2.0074e-01, -2.2577e-01,
         -8.5068e-02,  3.4274e-02,  2.4591e-01, -8.1145e-02, -7.1015e-02,
          3.5280e-01],
        [ 3.5065e-02,  3.5476e-01,  3.0231e-01, -2.6598e-01, -6.9673e-02,
         -3.4549e-01, -1.6128e-01, -1.1175e-01,  3.6203e-02, -3.2717e-01,
          4.4265e-03,  5.8337e-02, -5.8751e-02,  1.9809e-01, -3.6967e-01,
          9.9775e-02],
        [-2.9298e-01, -1.5030e-01, -1.0411e-01,  1.0561e-02,  9.8693e-02,
          1.5925e-01,  5.0002e-02,  2.5439e-01,  2.8306e-01,  1.8113e-02,
          1.3633e-01, -1.3638e-02, -2.7597e-01, -1.2497e-01,  2.1230e-01,
         -2.1066e-01],
        [-3.5914e-01,  5.9988e-03, -6.8097e-02, -1.0021e-02, -1.6039e-02,
          4.3021e-01,  2.3323e-01,  1.3570e-01,  3.6649e-01,  2.7148e-01,
          9.7958e-04, -3.2130e-03, -2.0891e-01,  5.5835e-02,  3.1080e-02,
         -3.4143e-01],
        [-1.2091e-01, -1.8796e-01, -2.0677e-02,  1.0773e-01,  1.7454e-01,
          1.1617e-01,  3.5487e-01,  1.5540e-01,  1.6173e-01,  3.5948e-01,
          1.1303e-01,  6.5851e-02, -4.1503e-01, -2.6622e-01,  8.3014e-02,
         -2.0735e-01],
        [ 3.3876e-01,  3.0383e-01,  1.7139e-01, -1.9812e-01, -1.4432e-01,
          1.8534e-02, -8.8979e-02, -3.4610e-01, -3.4219e-01, -1.2686e-01,
         -1.0902e-01,  4.2025e-02, -2.1654e-02,  2.3215e-01, -3.0610e-01,
          4.6552e-02],
        [ 2.0425e-01,  3.7503e-01,  3.6406e-01, -2.8204e-02, -3.1921e-01,
         -1.9944e-02, -3.2801e-02, -7.5835e-02, -2.2146e-01, -1.7650e-01,
         -1.1905e-01,  1.1043e-01,  1.2268e-01,  8.1512e-02, -3.6840e-01,
          2.4005e-01],
        [-3.7439e-01, -3.4295e-01, -6.7455e-02, -2.3836e-02,  3.8569e-01,
          4.1267e-01,  9.5373e-02,  1.3010e-01, -1.9666e-02,  1.9795e-01,
          4.6825e-02, -3.1657e-01, -9.6588e-02, -1.5007e-01,  7.7077e-02,
         -1.6696e-01],
        [-3.0994e-01, -3.1696e-01, -2.1037e-02,  3.0776e-01,  4.8769e-02,
          2.0847e-01,  1.0134e-01, -1.0682e-03,  1.0663e-01,  1.8268e-01,
          6.2293e-02,  1.4150e-01, -1.3567e-01, -3.3443e-01,  4.7723e-01,
         -1.3226e-01],
        [ 3.0989e-01,  2.8190e-01,  1.9833e-01, -3.7085e-01, -3.5156e-01,
         -3.6927e-02, -9.1156e-02,  5.0920e-03, -3.7262e-01, -2.0034e-01,
          1.7716e-01,  2.8957e-01,  3.5078e-01,  3.0107e-01, -1.2974e-01,
         -2.3107e-02],
        [-2.8842e-01, -3.2916e-04, -2.4100e-01,  1.5596e-01,  1.2187e-01,
          2.9864e-01,  2.7381e-01,  2.6540e-01,  1.3877e-01,  2.9723e-01,
         -3.7613e-02, -2.4444e-01, -1.5974e-01, -2.2060e-01,  2.4340e-01,
         -1.7477e-01],
        [ 2.2911e-01,  1.6161e-01,  1.5210e-01, -2.9746e-01, -2.0270e-01,
         -3.8049e-01, -2.7673e-01,  2.5611e-02, -4.1097e-01, -1.2257e-01,
          1.7100e-02, -7.5329e-02,  2.0170e-01,  2.8635e-01,  1.0396e-02,
          1.9973e-01],
        [ 3.7132e-01,  1.8377e-01,  2.7046e-01, -1.1171e-01, -3.3381e-01,
         -2.3363e-01, -3.5479e-01,  1.8002e-02, -5.8950e-02, -2.9110e-01,
          8.5127e-02,  2.5247e-01, -4.1354e-02,  1.5086e-01, -3.8736e-02,
          2.0265e-01],
        [-1.7522e-01,  2.4218e-02, -4.3785e-02, -5.4614e-02,  2.7805e-01,
         -4.0051e-02,  3.0001e-01,  3.6510e-01,  1.8245e-01,  8.4302e-02,
         -7.8767e-02, -2.7203e-01, -2.0321e-01, -2.3218e-01,  3.8960e-01,
         -2.5703e-01],
        [-7.5874e-02, -3.7332e-01, -5.1246e-02,  4.0593e-01, -3.1825e-03,
          1.1824e-01,  2.5114e-01, -4.3392e-02,  3.5852e-02,  2.8464e-01,
          2.1654e-01, -2.6643e-01, -2.0242e-01, -3.9701e-01, -7.2826e-02,
          4.7279e-02],
        [ 3.6589e-01,  5.6858e-02,  5.5047e-02, -1.8520e-01, -8.8466e-03,
         -4.0108e-01, -2.9588e-01, -2.3629e-01, -2.6394e-01, -1.7639e-01,
          1.8529e-01,  2.1967e-01, -6.8408e-02,  3.4546e-01,  8.9501e-02,
          2.2649e-01],
        [ 2.4731e-01,  2.2074e-01,  3.3631e-01, -3.8549e-01, -2.0070e-01,
         -1.6278e-01, -1.6816e-01, -2.6427e-01, -3.5306e-01, -3.3325e-01,
          2.9235e-03,  3.4240e-01,  2.6987e-01,  1.5089e-01, -1.7447e-01,
          2.2647e-02],
        [ 2.1323e-01, -5.9975e-02,  1.7651e-01, -1.4793e-01,  4.5191e-02,
         -2.5573e-01,  4.6739e-02, -1.8061e-01, -3.6901e-01,  3.4432e-02,
          1.9696e-01,  3.1071e-03,  6.0534e-02,  2.9126e-01, -3.4738e-01,
          3.5540e-01],
        [ 4.0921e-02,  7.9196e-02,  8.8140e-02,  6.3254e-02, -2.2707e-01,
         -2.1449e-01, -1.6839e-02, -3.3596e-01, -1.7153e-01, -3.6895e-01,
         -2.9322e-01,  1.1177e-01,  1.9466e-01,  3.5854e-01, -4.1150e-01,
          8.5619e-02],
        [ 2.1504e-01,  2.0456e-01,  2.9492e-01, -3.6464e-01, -1.7222e-01,
         -9.7692e-02, -3.4919e-01, -1.8872e-02, -3.8448e-01, -7.8552e-03,
          2.5381e-02,  8.7281e-02,  2.2654e-01,  3.0648e-01,  1.0084e-01,
          2.9430e-01],
        [-3.2389e-01, -9.0239e-02,  1.0516e-02,  2.3106e-01,  3.2148e-01,
          2.4560e-02,  3.6024e-01,  1.8074e-01, -4.9595e-02,  1.2578e-01,
          9.7693e-02, -2.7312e-01, -2.3095e-01, -2.4344e-01,  2.0074e-02,
         -1.2848e-01],
        [ 2.9650e-01,  1.9506e-01,  1.3251e-01, -1.4815e-01, -2.9118e-01,
         -2.8403e-01, -1.3816e-01, -3.3680e-01, -2.0403e-02, -1.2126e-01,
          8.4685e-02,  1.4024e-01,  3.5116e-01,  3.4896e-01,  1.1706e-02,
          2.6581e-01],
        [-2.6822e-01, -1.5961e-02, -3.1680e-01,  2.7028e-01, -6.8533e-02,
          1.5054e-01,  3.2891e-01,  3.0792e-01,  3.6346e-01,  2.4916e-01,
          1.6187e-01, -8.8957e-02,  3.9983e-02,  2.7848e-02,  1.5689e-01,
         -2.3020e-01],
        [-2.8035e-01, -2.0299e-01, -4.1054e-02,  3.6534e-02,  1.9396e-01,
          3.8279e-01,  3.7307e-01, -2.8481e-02,  2.3144e-01,  3.3611e-01,
         -2.1417e-01, -9.4690e-03, -3.1272e-01, -3.0181e-01,  3.8773e-03,
         -2.4842e-01],
        [ 5.5317e-02,  1.8482e-01,  2.5499e-01, -6.9713e-02,  8.5278e-03,
         -3.1841e-01, -3.9383e-01, -3.6380e-01, -3.0789e-01, -2.8171e-01,
          7.7873e-02, -1.5642e-02, -3.4252e-02,  2.5916e-01, -2.6010e-01,
          2.0293e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0806, -0.0414,  0.1102, -0.0656, -0.0575, -0.0357,  0.0903,  0.1289,
        -0.0478, -0.0563,  0.0007,  0.0839,  0.1662,  0.0951, -0.0401, -0.0522,
        -0.1578,  0.0009,  0.0204, -0.0024, -0.0163, -0.1094, -0.0612, -0.0302,
        -0.1201,  0.2593,  0.0899,  0.0340, -0.1007, -0.2276,  0.1759, -0.0422],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2191,  0.3031, -0.2219, -0.2377,  0.3112,  0.3549, -0.2767, -0.3622,
         -0.3191,  0.3411,  0.2434,  0.3621, -0.2477, -0.3982,  0.2946,  0.2327,
         -0.3041,  0.3120, -0.2169, -0.2372,  0.3844,  0.3068, -0.3552, -0.3595,
         -0.3589, -0.3274, -0.3023,  0.3309, -0.3296,  0.3673,  0.2723, -0.2188]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0269,  0.1091,  0.0827,  ...,  0.1547, -0.2376, -0.1137],
        [-0.1251, -0.0309,  0.1212,  ...,  0.1295, -0.2986,  0.0871],
        [ 0.0083, -0.0473,  0.0278,  ...,  0.0304,  0.2104,  0.0345],
        ...,
        [-0.0015,  0.0246,  0.0595,  ...,  0.0618, -0.2861, -0.1180],
        [ 0.1037, -0.2269, -0.0586,  ..., -0.2984,  0.1208,  0.1557],
        [-0.2106,  0.1740,  0.0436,  ...,  0.0645, -0.2456, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0456,  0.0423, -0.0715, -0.1356, -0.0725,  0.0564, -0.1115,  0.0492,
        -0.0370,  0.0778,  0.0192,  0.0131,  0.0281,  0.0751, -0.0528, -0.0179,
         0.0564, -0.1603, -0.0589,  0.0353, -0.0510,  0.0287,  0.1066,  0.0046,
        -0.0923,  0.0541,  0.0439, -0.1093,  0.0526,  0.1412,  0.1679, -0.1255],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0730, -0.1748, -0.1178,  ..., -0.1168, -0.0316,  0.0786],
        [-0.2062, -0.0294,  0.0900,  ..., -0.0468, -0.0132,  0.0527],
        [ 0.1306, -0.0383, -0.1493,  ...,  0.0609, -0.0039,  0.1760],
        ...,
        [ 0.1042,  0.0753,  0.1315,  ...,  0.2290, -0.1964,  0.2289],
        [-0.0043, -0.1396,  0.0335,  ...,  0.0397,  0.2160, -0.1612],
        [ 0.0057, -0.1168,  0.1839,  ...,  0.0615,  0.1372, -0.0333]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1035,  0.1546, -0.0527, -0.0803, -0.0091, -0.0376, -0.0539, -0.0452,
         0.1298, -0.1724,  0.1098, -0.1295,  0.1864,  0.0996, -0.1308,  0.1234,
        -0.1375, -0.1691,  0.0390, -0.0111, -0.0030,  0.0896, -0.1955,  0.2254,
        -0.0457, -0.0086,  0.0818, -0.0260, -0.1317, -0.0679,  0.1185,  0.0315],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3991,  0.3191, -0.3927, -0.3762,  0.2570,  0.2556, -0.3069,  0.2678,
          0.3014, -0.3393, -0.2874,  0.2879,  0.2826,  0.2710,  0.3169,  0.3215,
         -0.3863, -0.3989,  0.2491,  0.2931, -0.3408, -0.3198, -0.3929,  0.2426,
          0.3635,  0.3998, -0.3806,  0.3837, -0.3074, -0.3870,  0.3703,  0.3894]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1596], device='cuda:0', requires_grad=True)

