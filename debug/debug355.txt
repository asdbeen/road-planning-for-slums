Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 0.0079,  0.4000,  0.3101, -0.3242, -0.1950, -0.1515, -0.0983, -0.3994,
         -0.3023, -0.0811, -0.0263,  0.2036, -0.3297, -0.0608, -0.0597,  0.3982],
        [-0.2527, -0.3893, -0.1000, -0.0152, -0.0241,  0.2467,  0.1768,  0.1675,
          0.4687,  0.1390,  0.2943, -0.2684,  0.3787, -0.0329,  0.3644, -0.0973],
        [ 0.1045,  0.3013,  0.3948, -0.1311, -0.1101, -0.3440, -0.1153, -0.4600,
         -0.1100, -0.0960, -0.1576, -0.0230, -0.0071,  0.3610, -0.0495,  0.3012],
        [ 0.2906,  0.1203,  0.0975, -0.0831, -0.0723, -0.2169, -0.1937, -0.1316,
         -0.5176, -0.4324, -0.2145,  0.3959, -0.0985, -0.1091, -0.2368,  0.1892],
        [-0.1034,  0.0317, -0.1743, -0.0260,  0.1730,  0.0909,  0.0645,  0.3403,
          0.2245,  0.3094,  0.3466, -0.1785,  0.3457, -0.2401,  0.3199, -0.1827],
        [-0.0312,  0.0541, -0.3799,  0.4178,  0.3693, -0.0048,  0.3109,  0.0118,
          0.3602,  0.2426, -0.0723, -0.1247,  0.1525,  0.1055,  0.4651, -0.1182],
        [ 0.3702,  0.2473,  0.4059, -0.1800, -0.0578, -0.2057, -0.1989, -0.2439,
         -0.3336, -0.0332, -0.0407,  0.0692, -0.3744,  0.2083, -0.3216,  0.1691],
        [-0.0535,  0.3653,  0.3631, -0.3595, -0.3511, -0.2980, -0.1171, -0.2804,
         -0.2786, -0.2317, -0.0922,  0.0471, -0.0568, -0.0905, -0.1474,  0.3783],
        [ 0.0392,  0.3623,  0.3058, -0.2457, -0.0545, -0.3442, -0.1756, -0.1059,
         -0.0251, -0.3228, -0.2836,  0.0596, -0.4346,  0.1676, -0.3196,  0.1178],
        [-0.3102, -0.1724, -0.1166,  0.0012,  0.1011,  0.1727,  0.0958,  0.2707,
          0.3630,  0.0252,  0.3671, -0.0358,  0.1405, -0.1056,  0.2328, -0.2400],
        [-0.3776,  0.0116, -0.0803, -0.0214, -0.0231,  0.4453,  0.2813,  0.1619,
          0.4526,  0.2856,  0.2264, -0.0285,  0.2178,  0.0931,  0.0495, -0.3721],
        [-0.1479, -0.2113, -0.0440,  0.1032,  0.1954,  0.1377,  0.4104,  0.1773,
          0.2510,  0.3756,  0.4117,  0.0402, -0.0414, -0.2757,  0.0675, -0.2473],
        [ 0.3416,  0.2933,  0.1686, -0.1693, -0.1081,  0.0240, -0.1040, -0.3375,
         -0.4053, -0.1200, -0.1738,  0.0490, -0.4573,  0.1623, -0.2720,  0.0618],
        [ 0.2140,  0.4056,  0.3729, -0.0122, -0.3159, -0.0216, -0.0539, -0.0806,
         -0.2825, -0.1768, -0.2800,  0.1169, -0.2162,  0.0658, -0.3538,  0.2608],
        [-0.3838, -0.3568, -0.0742, -0.0354,  0.3762,  0.4048,  0.1269,  0.1344,
          0.0510,  0.2001,  0.1904, -0.3240,  0.2734, -0.1198,  0.0914, -0.1896],
        [-0.0305,  0.0136,  0.2224,  0.0656, -0.3879, -0.0543, -0.2648, -0.3817,
         -0.3811, -0.1152, -0.1506,  0.4859, -0.3534, -0.0034, -0.0254,  0.1503],
        [ 0.3368,  0.3360,  0.2197, -0.3677, -0.3879, -0.0596, -0.1379, -0.0354,
         -0.4620, -0.2174,  0.0675,  0.3187,  0.0164,  0.3129, -0.1718,  0.0142],
        [-0.3034, -0.0620, -0.2519,  0.1436,  0.1456,  0.3075,  0.3125,  0.2943,
          0.2234,  0.3031,  0.0076, -0.2629,  0.1282, -0.2196,  0.3183, -0.1994],
        [ 0.2347,  0.1569,  0.1458, -0.2790, -0.2208, -0.3700, -0.3457, -0.0029,
         -0.5538, -0.1280, -0.1128, -0.0525, -0.1694,  0.3019, -0.0831,  0.2223],
        [ 0.3787,  0.1835,  0.2764, -0.0942, -0.3127, -0.2282, -0.3786,  0.0202,
         -0.1275, -0.2935, -0.1691,  0.2530, -0.4186,  0.1133,  0.0122,  0.2257],
        [-0.1962, -0.0015, -0.0611, -0.0627,  0.2959, -0.0185,  0.3374,  0.3969,
          0.2694,  0.0973,  0.0104, -0.3021,  0.1466, -0.2172,  0.4248, -0.2870],
        [-0.0885, -0.4163, -0.0618,  0.3982, -0.0091,  0.1168,  0.2889, -0.0419,
          0.1077,  0.2847,  0.4036, -0.2741,  0.2046, -0.3821, -0.0406,  0.0168],
        [ 0.3725,  0.0811,  0.0601, -0.1681, -0.0027, -0.3982, -0.3175, -0.2397,
         -0.3288, -0.1739,  0.0570,  0.2219, -0.4067,  0.3224,  0.0707,  0.2471],
        [ 0.2641,  0.2352,  0.3477, -0.3716, -0.2418, -0.1727, -0.1971, -0.2968,
         -0.4289, -0.3409, -0.1332,  0.3552,  0.0019,  0.1335, -0.2072,  0.0487],
        [ 0.2388, -0.0345,  0.1927, -0.1387,  0.0259, -0.2888, -0.0132, -0.2257,
         -0.4876,  0.0147,  0.0385,  0.0445, -0.3900,  0.2797, -0.3731,  0.3924],
        [ 0.0571,  0.0882,  0.0996,  0.0729, -0.2364, -0.2175, -0.0546, -0.3606,
         -0.2553, -0.3777, -0.3642,  0.1355, -0.1755,  0.3265, -0.4267,  0.1144],
        [ 0.2352,  0.2584,  0.3135, -0.3587, -0.1882, -0.1039, -0.3880, -0.0384,
         -0.4716, -0.0186, -0.0571,  0.1023, -0.1008,  0.3127,  0.0725,  0.3289],
        [-0.3339, -0.1083,  0.0027,  0.2166,  0.3191,  0.0292,  0.3999,  0.1824,
          0.0236,  0.1262,  0.3813, -0.2825,  0.1582, -0.2304,  0.0186, -0.1521],
        [ 0.3229,  0.1992,  0.1549, -0.1461, -0.3184, -0.2985, -0.1832, -0.3666,
         -0.1061, -0.1382, -0.1058,  0.1609,  0.0154,  0.3387, -0.0293,  0.3047],
        [-0.2721, -0.0416, -0.3182,  0.2488, -0.0746,  0.1452,  0.3500,  0.3124,
          0.4278,  0.2441,  0.2229, -0.0899,  0.3412,  0.0614,  0.1614, -0.2441],
        [-0.3092, -0.2398, -0.0654,  0.0364,  0.2186,  0.4050,  0.4244,  0.0075,
          0.3260,  0.3561, -0.0843, -0.0401,  0.0506, -0.3070,  0.0588, -0.2905],
        [ 0.0510,  0.2302,  0.2452, -0.0393,  0.0080, -0.3120, -0.4266, -0.3789,
         -0.4184, -0.2789, -0.0314, -0.0040, -0.3727,  0.2717, -0.2789,  0.2095]],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0842, -0.0099, -0.0398, -0.0389,  0.0198, -0.2188,  0.0819,  0.1060,
        -0.0730,  0.0110,  0.0538,  0.0916,  0.1184,  0.0569,  0.0775, -0.0246,
        -0.0340, -0.0304,  0.0621, -0.0476, -0.0972, -0.0430, -0.0414,  0.0270,
        -0.0508,  0.1221,  0.1377,  0.0627, -0.1158, -0.1725,  0.0398,  0.0135],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2432,  0.3370, -0.2544, -0.2854,  0.3318,  0.3956, -0.3018, -0.3916,
         -0.3421,  0.3751,  0.2921,  0.4037, -0.2923, -0.4180,  0.3049, -0.2982,
         -0.3451,  0.3515, -0.2601, -0.2554,  0.4356,  0.3431, -0.3933, -0.3923,
         -0.3328, -0.3585, -0.3402,  0.3688, -0.3709,  0.3997,  0.3273, -0.2591]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0094,  0.1437,  0.0643,  ...,  0.2032, -0.3226, -0.1137],
        [-0.0691, -0.0633,  0.1194,  ...,  0.1017, -0.2941,  0.0871],
        [-0.1155,  0.1988,  0.0861,  ...,  0.2077, -0.0028,  0.0345],
        ...,
        [ 0.0938, -0.1232, -0.0386,  ..., -0.1681, -0.0157, -0.1180],
        [ 0.0359, -0.1936, -0.0394,  ..., -0.2624,  0.1000,  0.1557],
        [-0.1792,  0.1423,  0.0479,  ...,  0.0733, -0.2577, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0575,  0.0289, -0.0894, -0.1558, -0.0820, -0.0149, -0.1006,  0.0437,
        -0.0349,  0.0577,  0.0312, -0.0074,  0.0161,  0.1028, -0.0420, -0.0169,
         0.0514, -0.1670,  0.0065,  0.0840, -0.0641,  0.0165,  0.1112,  0.0254,
        -0.1091,  0.0987,  0.0446, -0.1042,  0.0490,  0.2073,  0.1694, -0.1274],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 5.0238e-02, -1.6407e-01, -1.8881e-01,  ...,  3.5842e-02,
         -4.3582e-02,  6.7339e-02],
        [-2.1705e-01, -1.7459e-02, -1.6319e-02,  ...,  1.4089e-01,
         -2.5577e-02,  5.0363e-02],
        [ 1.4957e-01, -4.7736e-02, -3.8672e-02,  ..., -1.4326e-01,
         -2.0465e-04,  1.8649e-01],
        ...,
        [ 1.5591e-01,  5.1450e-02,  2.2437e-01,  ...,  1.1148e-01,
         -1.7298e-01,  2.4433e-01],
        [-1.0878e-02, -1.4440e-01, -3.8534e-02,  ...,  2.4704e-01,
          2.2158e-01, -1.7500e-01],
        [ 8.8339e-04, -1.1471e-01,  1.3352e-01,  ...,  2.2742e-01,
          1.3206e-01, -4.4207e-02]], device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1008,  0.1498, -0.0478, -0.1051, -0.1024, -0.1794, -0.0699, -0.0215,
         0.1469, -0.1764,  0.1395, -0.1319,  0.2038,  0.0995, -0.1033,  0.1304,
        -0.1330, -0.1839,  0.0813,  0.0128, -0.0197,  0.0750, -0.2073,  0.2238,
        -0.0421, -0.0142,  0.0757, -0.0469, -0.1572, -0.0524,  0.1295,  0.0347],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4070,  0.3317, -0.3726, -0.4027, -0.2600, -0.2531, -0.3157,  0.2875,
          0.3059, -0.3230, -0.2804,  0.2940,  0.3020,  0.2574,  0.3197,  0.3017,
         -0.3988, -0.4037,  0.2533,  0.3013, -0.3598, -0.3089, -0.4110,  0.2519,
          0.3738,  0.4240, -0.3793,  0.3997, -0.3164, -0.4047,  0.3688,  0.4079]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1556], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.2495e-02,  3.2187e-01,  3.1513e-01, -3.3705e-01, -4.9550e-02,
         -1.8159e-01, -7.9763e-02, -4.2118e-01, -1.8531e-01, -6.3133e-02,
          3.3840e-02,  1.8779e-01,  9.2314e-02, -5.1015e-02,  3.3570e-01,
          3.4205e-01],
        [-2.8291e-01, -3.1114e-01, -1.2718e-01,  1.2806e-02, -1.3539e-01,
          2.9512e-01,  2.0551e-01,  2.0205e-01,  4.1522e-01,  1.2297e-01,
          2.1673e-01, -2.9019e-01, -3.6085e-02, -5.3169e-02, -2.4377e-02,
         -6.9778e-02],
        [ 9.3858e-02,  2.1430e-01,  3.9046e-01, -1.2561e-01,  1.1739e-01,
         -3.7283e-01, -7.2000e-02, -4.4101e-01,  4.7408e-02, -5.6253e-02,
         -8.5730e-02, -5.0316e-02,  4.2591e-01,  3.0420e-01,  4.4413e-01,
          2.4053e-01],
        [ 2.9199e-01,  3.8719e-02,  9.9564e-02, -8.3606e-02,  7.5564e-02,
         -2.3351e-01, -1.8232e-01, -1.2772e-01, -4.1690e-01, -3.8305e-01,
         -9.9251e-02,  3.7908e-01,  3.1663e-01, -1.2714e-01,  1.5713e-01,
          1.3912e-01],
        [-1.3053e-01,  1.5125e-01, -1.9267e-01,  6.6032e-05,  8.4588e-02,
          1.4114e-01,  9.0799e-02,  3.9151e-01,  1.8276e-01,  2.8099e-01,
          2.2326e-01, -2.1578e-01, -9.6550e-02, -2.4186e-01, -1.2018e-01,
         -1.2195e-01],
        [-3.1773e-02,  1.7276e-01, -3.7791e-01,  4.1581e-01,  1.8903e-01,
          1.8189e-02,  2.9357e-01,  1.7136e-02,  2.7388e-01,  1.9686e-01,
         -1.4741e-01, -1.2212e-01, -2.8826e-01,  1.1973e-01,  4.1167e-03,
         -5.8226e-02],
        [ 3.9322e-01,  1.7250e-01,  4.2668e-01, -1.9542e-01,  1.0502e-01,
         -2.5365e-01, -2.2158e-01, -2.6867e-01, -2.6089e-01, -9.8306e-03,
         -1.1741e-02,  7.9735e-02, -1.5969e-03,  2.2712e-01,  3.0559e-03,
          1.4400e-01],
        [-4.5683e-02,  2.8971e-01,  3.6929e-01, -3.5534e-01, -1.6672e-01,
         -3.3263e-01, -1.1661e-01, -2.7231e-01, -1.8659e-01, -1.9858e-01,
         -6.5813e-02,  3.2007e-02,  2.8145e-01, -8.5614e-02,  1.7199e-01,
          3.5048e-01],
        [ 6.2412e-02,  2.7818e-01,  3.2535e-01, -2.6836e-01,  8.6865e-03,
         -3.9055e-01, -1.9883e-01, -1.4112e-01,  2.9078e-02, -3.0239e-01,
         -1.1218e-01,  9.1923e-02, -4.7465e-02,  1.4461e-01,  3.9319e-02,
          8.2033e-02],
        [-3.1525e-01, -5.6346e-02, -1.1750e-01,  3.5356e-03, -1.4687e-02,
          2.0161e-01,  8.5881e-02,  2.8889e-01,  2.9004e-01, -1.8680e-02,
          2.3207e-01, -4.4980e-02, -3.0048e-01, -7.9446e-02, -2.1559e-01,
         -1.7450e-01],
        [-3.6641e-01,  1.0229e-01, -7.0707e-02, -3.7281e-02, -1.5287e-01,
          4.5545e-01,  2.5429e-01,  1.4686e-01,  3.4454e-01,  2.2709e-01,
          6.0790e-02, -3.4626e-03, -1.9239e-01,  1.3674e-01, -4.0176e-01,
         -3.0822e-01],
        [-1.4682e-01, -1.1503e-01, -3.8744e-02,  9.9587e-02,  1.3805e-01,
          1.5727e-01,  4.0235e-01,  1.9237e-01,  1.8122e-01,  3.2578e-01,
          1.4829e-01,  3.2083e-02, -4.3626e-01, -1.9833e-01, -2.7857e-01,
         -1.7950e-01],
        [ 3.7520e-01,  1.8724e-01,  1.9939e-01, -2.0026e-01,  4.5914e-02,
         -4.0187e-02, -1.3433e-01, -3.7859e-01, -3.5862e-01, -1.0350e-01,
         -1.1308e-01,  6.6182e-02,  1.5536e-02,  2.0411e-01,  2.0141e-01,
          1.4038e-02],
        [ 2.4456e-01,  3.3002e-01,  3.9857e-01, -3.5996e-02, -2.0314e-01,
         -7.3604e-02, -8.9266e-02, -1.1898e-01, -2.3886e-01, -1.6445e-01,
         -2.1153e-01,  1.4564e-01,  1.6887e-01,  8.0694e-02, -9.6497e-03,
          2.4039e-01],
        [-3.9634e-01, -2.7577e-01, -8.5487e-02, -3.3267e-02,  2.2739e-01,
          4.4906e-01,  1.3024e-01,  1.4966e-01, -2.8030e-02,  1.6856e-01,
          1.2207e-01, -3.2855e-01, -1.1692e-01, -1.1940e-01, -2.9830e-01,
         -1.5364e-01],
        [-6.7420e-02, -1.9341e-01,  1.8394e-01,  7.8283e-02, -2.3791e-01,
         -4.2509e-02, -1.8429e-01, -3.4927e-01, -2.0525e-01, -6.0063e-04,
          1.7110e-02,  4.7404e-01,  1.7791e-01, -6.9900e-02,  4.7165e-01,
          1.4067e-02],
        [ 3.3183e-01,  2.4405e-01,  2.1273e-01, -3.5904e-01, -2.3276e-01,
         -7.3103e-02, -1.3043e-01, -3.3218e-02, -3.6723e-01, -1.6806e-01,
          1.4731e-01,  3.0304e-01,  3.7700e-01,  2.8149e-01,  1.4089e-01,
         -3.6253e-02],
        [-3.1376e-01,  5.8276e-03, -2.6017e-01,  1.4650e-01,  1.0034e-02,
          3.3756e-01,  3.1937e-01,  3.0312e-01,  1.4138e-01,  2.6839e-01,
         -4.4350e-02, -2.5909e-01, -1.9545e-01, -2.2010e-01,  3.1878e-02,
         -1.6964e-01],
        [ 2.4340e-01,  9.8020e-02,  1.6305e-01, -2.9611e-01, -3.0577e-02,
         -4.0867e-01, -3.1412e-01,  2.5198e-03, -3.9409e-01, -1.0903e-01,
         -3.4418e-02, -6.9253e-02,  2.2529e-01,  2.4979e-01,  3.7850e-01,
          1.8255e-01],
        [ 3.8596e-01,  1.0894e-01,  2.8305e-01, -9.5182e-02, -1.9205e-01,
         -2.6453e-01, -3.8153e-01,  7.1378e-03, -4.0976e-02, -2.5683e-01,
         -6.3014e-02,  2.5692e-01, -4.6874e-02,  1.0268e-01,  3.4013e-01,
          1.8579e-01],
        [-2.1212e-01,  1.0094e-01, -7.2043e-02, -4.6192e-02,  1.7527e-01,
          1.5094e-02,  3.4836e-01,  4.2843e-01,  2.1291e-01,  6.8359e-02,
         -7.4234e-02, -3.2550e-01, -2.4344e-01, -2.2232e-01,  1.4066e-02,
         -2.4451e-01],
        [-8.1820e-02, -3.1211e-01, -5.4908e-02,  3.8443e-01, -1.3070e-01,
          1.4226e-01,  2.6319e-01, -4.2871e-02,  1.5475e-02,  2.3705e-01,
          2.4823e-01, -2.6941e-01, -1.8239e-01, -3.3847e-01, -4.6645e-01,
          7.6958e-02],
        [ 3.7235e-01,  6.8048e-03,  5.9379e-02, -1.5842e-01,  1.3986e-01,
         -4.1988e-01, -3.1312e-01, -2.3230e-01, -2.3415e-01, -1.3238e-01,
          1.2486e-01,  2.0790e-01, -8.5430e-02,  3.0642e-01,  3.8616e-01,
          2.0937e-01],
        [ 2.7120e-01,  1.7644e-01,  3.5214e-01, -3.7088e-01, -1.0596e-01,
         -1.9823e-01, -2.0702e-01, -2.9137e-01, -3.4604e-01, -3.0586e-01,
         -9.8559e-02,  3.4278e-01,  2.7924e-01,  1.4277e-01,  1.2152e-02,
          2.5869e-02],
        [ 2.3909e-01, -1.6708e-01,  1.9171e-01, -1.4546e-01,  1.5696e-01,
         -3.0510e-01,  7.4291e-04, -2.3691e-01, -3.8821e-01,  7.0612e-02,
          1.7979e-01,  4.2060e-02,  9.2243e-02,  2.4334e-01,  1.0941e-01,
          3.1151e-01],
        [ 8.4916e-02, -1.1132e-02,  1.2396e-01,  5.1080e-02, -1.0620e-01,
         -2.7812e-01, -7.6828e-02, -4.0217e-01, -2.0457e-01, -3.5661e-01,
         -2.8937e-01,  1.6425e-01,  2.3845e-01,  3.4923e-01,  1.2338e-02,
          7.4268e-02],
        [ 2.2798e-01,  1.7989e-01,  3.0671e-01, -3.4399e-01, -2.3651e-02,
         -1.2202e-01, -3.7862e-01, -2.1762e-02, -3.6321e-01,  2.8867e-02,
          1.0155e-02,  7.9803e-02,  2.2577e-01,  2.9135e-01,  3.7088e-01,
          2.8623e-01],
        [-3.3661e-01, -1.1662e-02,  4.4437e-03,  2.1223e-01,  2.2484e-01,
          5.4852e-02,  3.9132e-01,  1.9963e-01, -4.8379e-02,  8.0812e-02,
          2.1210e-01, -2.8856e-01, -2.4209e-01, -1.9150e-01, -3.6108e-01,
         -9.2333e-02],
        [ 3.1967e-01,  1.1948e-01,  1.5004e-01, -1.3262e-01, -2.0351e-01,
         -3.1922e-01, -1.6928e-01, -3.6628e-01, -1.6975e-02, -9.2515e-02,
          8.1939e-03,  1.5116e-01,  3.4124e-01,  3.0540e-01,  3.0913e-01,
          2.5749e-01],
        [-2.8477e-01,  2.3657e-02, -3.2951e-01,  2.5349e-01, -2.1800e-01,
          1.7909e-01,  3.5978e-01,  3.1536e-01,  3.4700e-01,  2.1513e-01,
          1.8096e-01, -8.5018e-02,  2.4257e-02,  5.0146e-02, -1.1395e-01,
         -2.2008e-01],
        [-2.9857e-01, -1.5125e-01, -5.5369e-02,  2.1431e-02,  7.6175e-02,
          4.1561e-01,  4.0670e-01, -3.7433e-03,  2.2129e-01,  3.0164e-01,
         -1.9910e-01, -2.0783e-02, -3.1738e-01, -2.6111e-01, -3.1188e-01,
         -2.3482e-01],
        [ 8.3715e-02,  1.7715e-01,  2.7858e-01, -7.9576e-02,  1.5527e-01,
         -3.6188e-01, -4.4811e-01, -4.0770e-01, -3.0991e-01, -2.7391e-01,
          3.6972e-02,  1.1634e-02,  2.1014e-02,  2.6053e-01,  6.5758e-02,
          1.9116e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-8.6209e-02, -7.0666e-02,  1.9897e-01, -1.4720e-02, -1.0653e-01,
        -5.9402e-02,  8.7673e-02,  7.5351e-02, -1.9214e-02, -7.3119e-02,
        -4.1612e-02,  4.3115e-02,  1.4439e-01,  1.1250e-01, -2.8624e-02,
        -1.0087e-02, -1.2410e-01,  8.4002e-03,  1.3054e-01,  2.7418e-02,
        -2.7911e-02, -1.8642e-01, -1.1625e-03, -3.9545e-02, -1.1406e-02,
         2.4329e-01,  1.3745e-01,  5.7784e-03, -3.7821e-02, -1.5983e-01,
        -2.0870e-04,  4.4374e-02], device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2086,  0.3041, -0.2270, -0.2602,  0.3061,  0.3452, -0.2754, -0.3759,
         -0.2991,  0.3402,  0.2657,  0.3823, -0.2491, -0.3780,  0.3022, -0.2177,
         -0.2998,  0.3381, -0.2284, -0.2415,  0.3858,  0.3581, -0.3743, -0.3775,
         -0.2940, -0.3272, -0.3182,  0.3558, -0.3677,  0.3835,  0.2992, -0.2369]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0083,  0.0011,  0.0250,  ...,  0.2103, -0.3700, -0.1137],
        [-0.0788, -0.1851,  0.0817,  ...,  0.1469, -0.3413,  0.0871],
        [-0.0572,  0.1529,  0.0926,  ...,  0.0082,  0.2516,  0.0345],
        ...,
        [ 0.0446, -0.1516,  0.0118,  ...,  0.0688, -0.2990, -0.1180],
        [ 0.0305, -0.0762,  0.0089,  ..., -0.3065,  0.1393,  0.1557],
        [-0.0878,  0.1570,  0.0133,  ..., -0.1743,  0.0840, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0510,  0.0545, -0.0938, -0.1203, -0.0570,  0.0459, -0.1298,  0.0621,
        -0.0459,  0.0927,  0.0342,  0.0070,  0.0095,  0.0631, -0.0783, -0.0200,
         0.0463, -0.1418, -0.0326, -0.0147, -0.1085,  0.0495,  0.0815, -0.0069,
        -0.0852,  0.0672,  0.0242, -0.0957,  0.0641,  0.1476,  0.1345, -0.0662],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0293, -0.2021, -0.0750,  ..., -0.1501, -0.0077,  0.2694],
        [-0.2465, -0.0496,  0.1088,  ..., -0.0805,  0.0038,  0.2767],
        [ 0.1729, -0.0136, -0.1824,  ...,  0.0916, -0.0313, -0.0751],
        ...,
        [ 0.1608,  0.1173,  0.0760,  ...,  0.2734, -0.2310,  0.0491],
        [-0.0623, -0.1802,  0.0829,  ..., -0.0071,  0.2568,  0.0935],
        [-0.0273, -0.1268,  0.2161,  ...,  0.0412,  0.1477,  0.1374]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0886,  0.1239, -0.0365, -0.0560, -0.0318, -0.0359, -0.0329, -0.0627,
         0.1103, -0.1770,  0.1225, -0.1328,  0.1650, -0.0189, -0.1429,  0.1067,
        -0.1280, -0.1546,  0.0137, -0.0299,  0.0081,  0.1078, -0.1909,  0.2035,
        -0.0684, -0.0280,  0.0877, -0.0354, -0.1126, -0.0609,  0.1129,  0.0020],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5607,  0.4852, -0.5645, -0.5664,  0.4121,  0.4208, -0.4682,  0.4777,
          0.4761, -0.5004, -0.4900,  0.4503,  0.4725, -0.4140,  0.4937,  0.4428,
         -0.5712, -0.5620,  0.4390,  0.4568, -0.5253, -0.4980, -0.5613,  0.3962,
          0.5361,  0.5616, -0.5362,  0.6048, -0.4717, -0.5532,  0.5390,  0.5527]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2784], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.2494e-02,  3.2186e-01,  3.1513e-01, -3.3705e-01, -4.9559e-02,
         -1.8159e-01, -7.9763e-02, -4.2119e-01, -1.8531e-01, -6.3127e-02,
          3.3843e-02,  1.8779e-01,  9.2322e-02, -5.1020e-02,  3.3570e-01,
          3.4205e-01],
        [-2.8291e-01, -3.1113e-01, -1.2718e-01,  1.2803e-02, -1.3538e-01,
          2.9512e-01,  2.0551e-01,  2.0206e-01,  4.1523e-01,  1.2297e-01,
          2.1673e-01, -2.9019e-01, -3.6092e-02, -5.3165e-02, -2.4380e-02,
         -6.9772e-02],
        [ 9.3857e-02,  2.1429e-01,  3.9045e-01, -1.2560e-01,  1.1738e-01,
         -3.7283e-01, -7.1999e-02, -4.4102e-01,  4.7406e-02, -5.6248e-02,
         -8.5727e-02, -5.0311e-02,  4.2592e-01,  3.0420e-01,  4.4414e-01,
          2.4052e-01],
        [ 2.9198e-01,  3.8710e-02,  9.9560e-02, -8.3604e-02,  7.5556e-02,
         -2.3351e-01, -1.8232e-01, -1.2773e-01, -4.1690e-01, -3.8305e-01,
         -9.9248e-02,  3.7909e-01,  3.1663e-01, -1.2714e-01,  1.5714e-01,
          1.3911e-01],
        [-1.3053e-01,  1.5126e-01, -1.9267e-01,  6.3474e-05,  8.4598e-02,
          1.4114e-01,  9.0799e-02,  3.9152e-01,  1.8276e-01,  2.8098e-01,
          2.2326e-01, -2.1578e-01, -9.6557e-02, -2.4186e-01, -1.2018e-01,
         -1.2195e-01],
        [-3.1773e-02,  1.7277e-01, -3.7790e-01,  4.1581e-01,  1.8903e-01,
          1.8189e-02,  2.9357e-01,  1.7143e-02,  2.7389e-01,  1.9686e-01,
         -1.4741e-01, -1.2213e-01, -2.8826e-01,  1.1974e-01,  4.1129e-03,
         -5.8220e-02],
        [ 3.9322e-01,  1.7249e-01,  4.2667e-01, -1.9541e-01,  1.0501e-01,
         -2.5365e-01, -2.2158e-01, -2.6867e-01, -2.6090e-01, -9.8258e-03,
         -1.1738e-02,  7.9740e-02, -1.5896e-03,  2.2712e-01,  3.0594e-03,
          1.4399e-01],
        [-4.5684e-02,  2.8970e-01,  3.6928e-01, -3.5534e-01, -1.6672e-01,
         -3.3263e-01, -1.1661e-01, -2.7231e-01, -1.8659e-01, -1.9857e-01,
         -6.5811e-02,  3.2011e-02,  2.8145e-01, -8.5618e-02,  1.7199e-01,
          3.5048e-01],
        [ 6.2411e-02,  2.7817e-01,  3.2535e-01, -2.6836e-01,  8.6796e-03,
         -3.9055e-01, -1.9883e-01, -1.4112e-01,  2.9077e-02, -3.0238e-01,
         -1.1218e-01,  9.1927e-02, -4.7459e-02,  1.4461e-01,  3.9323e-02,
          8.2027e-02],
        [-3.1525e-01, -5.6336e-02, -1.1750e-01,  3.5334e-03, -1.4678e-02,
          2.0161e-01,  8.5881e-02,  2.8890e-01,  2.9004e-01, -1.8685e-02,
          2.3207e-01, -4.4986e-02, -3.0049e-01, -7.9441e-02, -2.1559e-01,
         -1.7449e-01],
        [-3.6641e-01,  1.0230e-01, -7.0702e-02, -3.7284e-02, -1.5286e-01,
          4.5545e-01,  2.5429e-01,  1.4687e-01,  3.4455e-01,  2.2709e-01,
          6.0787e-02, -3.4679e-03, -1.9240e-01,  1.3674e-01, -4.0176e-01,
         -3.0821e-01],
        [-1.4682e-01, -1.1502e-01, -3.8740e-02,  9.9585e-02,  1.3805e-01,
          1.5727e-01,  4.0235e-01,  1.9237e-01,  1.8122e-01,  3.2577e-01,
          1.4829e-01,  3.2078e-02, -4.3627e-01, -1.9833e-01, -2.7858e-01,
         -1.7949e-01],
        [ 3.7520e-01,  1.8722e-01,  1.9939e-01, -2.0026e-01,  4.5904e-02,
         -4.0188e-02, -1.3433e-01, -3.7860e-01, -3.5862e-01, -1.0349e-01,
         -1.1307e-01,  6.6189e-02,  1.5544e-02,  2.0410e-01,  2.0141e-01,
          1.4029e-02],
        [ 2.4456e-01,  3.3001e-01,  3.9856e-01, -3.5994e-02, -2.0315e-01,
         -7.3605e-02, -8.9266e-02, -1.1899e-01, -2.3886e-01, -1.6445e-01,
         -2.1153e-01,  1.4564e-01,  1.6887e-01,  8.0689e-02, -9.6464e-03,
          2.4039e-01],
        [-3.9634e-01, -2.7576e-01, -8.5484e-02, -3.3269e-02,  2.2740e-01,
          4.4906e-01,  1.3024e-01,  1.4967e-01, -2.8028e-02,  1.6855e-01,
          1.2207e-01, -3.2856e-01, -1.1693e-01, -1.1940e-01, -2.9830e-01,
         -1.5363e-01],
        [-6.7420e-02, -1.9342e-01,  1.8393e-01,  7.8286e-02, -2.3792e-01,
         -4.2510e-02, -1.8429e-01, -3.4928e-01, -2.0526e-01, -5.9451e-04,
          1.7112e-02,  4.7405e-01,  1.7792e-01, -6.9903e-02,  4.7166e-01,
          1.4059e-02],
        [ 3.3183e-01,  2.4404e-01,  2.1272e-01, -3.5903e-01, -2.3276e-01,
         -7.3104e-02, -1.3043e-01, -3.3225e-02, -3.6724e-01, -1.6806e-01,
          1.4732e-01,  3.0305e-01,  3.7701e-01,  2.8149e-01,  1.4089e-01,
         -3.6259e-02],
        [-3.1376e-01,  5.8356e-03, -2.6017e-01,  1.4650e-01,  1.0041e-02,
          3.3756e-01,  3.1937e-01,  3.0312e-01,  1.4138e-01,  2.6839e-01,
         -4.4353e-02, -2.5909e-01, -1.9546e-01, -2.2010e-01,  3.1874e-02,
         -1.6963e-01],
        [ 2.4340e-01,  9.8011e-02,  1.6304e-01, -2.9611e-01, -3.0584e-02,
         -4.0867e-01, -3.1412e-01,  2.5133e-03, -3.9409e-01, -1.0902e-01,
         -3.4415e-02, -6.9248e-02,  2.2529e-01,  2.4979e-01,  3.7851e-01,
          1.8254e-01],
        [ 3.8596e-01,  1.0893e-01,  2.8305e-01, -9.5180e-02, -1.9205e-01,
         -2.6453e-01, -3.8153e-01,  7.1314e-03, -4.0978e-02, -2.5683e-01,
         -6.3012e-02,  2.5692e-01, -4.6866e-02,  1.0268e-01,  3.4014e-01,
          1.8578e-01],
        [-2.1212e-01,  1.0095e-01, -7.2039e-02, -4.6194e-02,  1.7528e-01,
          1.5094e-02,  3.4836e-01,  4.2844e-01,  2.1291e-01,  6.8355e-02,
         -7.4237e-02, -3.2551e-01, -2.4345e-01, -2.2232e-01,  1.4062e-02,
         -2.4451e-01],
        [-8.1819e-02, -3.1211e-01, -5.4905e-02,  3.8442e-01, -1.3069e-01,
          1.4226e-01,  2.6319e-01, -4.2865e-02,  1.5476e-02,  2.3704e-01,
          2.4823e-01, -2.6942e-01, -1.8240e-01, -3.3847e-01, -4.6645e-01,
          7.6963e-02],
        [ 3.7235e-01,  6.7968e-03,  5.9376e-02, -1.5842e-01,  1.3985e-01,
         -4.1988e-01, -3.1312e-01, -2.3231e-01, -2.3415e-01, -1.3237e-01,
          1.2486e-01,  2.0791e-01, -8.5423e-02,  3.0642e-01,  3.8617e-01,
          2.0936e-01],
        [ 2.7120e-01,  1.7643e-01,  3.5213e-01, -3.7088e-01, -1.0596e-01,
         -1.9823e-01, -2.0702e-01, -2.9137e-01, -3.4605e-01, -3.0585e-01,
         -9.8557e-02,  3.4278e-01,  2.7925e-01,  1.4276e-01,  1.2155e-02,
          2.5864e-02],
        [ 2.3909e-01, -1.6709e-01,  1.9170e-01, -1.4545e-01,  1.5695e-01,
         -3.0510e-01,  7.4300e-04, -2.3692e-01, -3.8821e-01,  7.0617e-02,
          1.7979e-01,  4.2066e-02,  9.2251e-02,  2.4333e-01,  1.0941e-01,
          3.1150e-01],
        [ 8.4916e-02, -1.1141e-02,  1.2395e-01,  5.1082e-02, -1.0621e-01,
         -2.7812e-01, -7.6828e-02, -4.0218e-01, -2.0457e-01, -3.5660e-01,
         -2.8937e-01,  1.6425e-01,  2.3846e-01,  3.4923e-01,  1.2342e-02,
          7.4261e-02],
        [ 2.2798e-01,  1.7988e-01,  3.0671e-01, -3.4399e-01, -2.3658e-02,
         -1.2202e-01, -3.7862e-01, -2.1768e-02, -3.6321e-01,  2.8871e-02,
          1.0157e-02,  7.9808e-02,  2.2578e-01,  2.9135e-01,  3.7088e-01,
          2.8623e-01],
        [-3.3661e-01, -1.1653e-02,  4.4478e-03,  2.1222e-01,  2.2484e-01,
          5.4852e-02,  3.9132e-01,  1.9963e-01, -4.8377e-02,  8.0807e-02,
          2.1210e-01, -2.8857e-01, -2.4210e-01, -1.9150e-01, -3.6108e-01,
         -9.2326e-02],
        [ 3.1967e-01,  1.1947e-01,  1.5003e-01, -1.3262e-01, -2.0351e-01,
         -3.1922e-01, -1.6928e-01, -3.6629e-01, -1.6977e-02, -9.2511e-02,
          8.1966e-03,  1.5117e-01,  3.4125e-01,  3.0540e-01,  3.0914e-01,
          2.5748e-01],
        [-2.8477e-01,  2.3665e-02, -3.2950e-01,  2.5349e-01, -2.1800e-01,
          1.7909e-01,  3.5978e-01,  3.1536e-01,  3.4700e-01,  2.1513e-01,
          1.8096e-01, -8.5023e-02,  2.4250e-02,  5.0150e-02, -1.1395e-01,
         -2.2007e-01],
        [-2.9857e-01, -1.5124e-01, -5.5365e-02,  2.1429e-02,  7.6182e-02,
          4.1561e-01,  4.0670e-01, -3.7371e-03,  2.2129e-01,  3.0163e-01,
         -1.9910e-01, -2.0788e-02, -3.1738e-01, -2.6110e-01, -3.1189e-01,
         -2.3481e-01],
        [ 8.3714e-02,  1.7714e-01,  2.7857e-01, -7.9573e-02,  1.5526e-01,
         -3.6188e-01, -4.4811e-01, -4.0771e-01, -3.0991e-01, -2.7391e-01,
          3.6975e-02,  1.1639e-02,  2.1022e-02,  2.6053e-01,  6.5762e-02,
          1.9115e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-8.6211e-02, -7.0665e-02,  1.9897e-01, -1.4721e-02, -1.0653e-01,
        -5.9400e-02,  8.7672e-02,  7.5350e-02, -1.9217e-02, -7.3117e-02,
        -4.1610e-02,  4.3116e-02,  1.4439e-01,  1.1250e-01, -2.8622e-02,
        -1.0104e-02, -1.2410e-01,  8.4012e-03,  1.3054e-01,  2.7416e-02,
        -2.7904e-02, -1.8641e-01, -1.1639e-03, -3.9546e-02, -1.1407e-02,
         2.4329e-01,  1.3745e-01,  5.7799e-03, -3.7822e-02, -1.5983e-01,
        -2.0763e-04,  4.4373e-02], device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2086,  0.3041, -0.2270, -0.2602,  0.3061,  0.3452, -0.2754, -0.3759,
         -0.2991,  0.3402,  0.2657,  0.3823, -0.2491, -0.3780,  0.3022, -0.2177,
         -0.2998,  0.3381, -0.2284, -0.2415,  0.3858,  0.3581, -0.3743, -0.3775,
         -0.2940, -0.3272, -0.3182,  0.3558, -0.3677,  0.3835,  0.2992, -0.2369]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0083,  0.0011,  0.0250,  ...,  0.2103, -0.3700, -0.1137],
        [-0.0788, -0.1851,  0.0817,  ...,  0.1469, -0.3413,  0.0871],
        [-0.0572,  0.1529,  0.0926,  ...,  0.0082,  0.2516,  0.0345],
        ...,
        [ 0.0446, -0.1516,  0.0118,  ...,  0.0688, -0.2990, -0.1180],
        [ 0.0305, -0.0762,  0.0089,  ..., -0.3065,  0.1393,  0.1557],
        [-0.0878,  0.1570,  0.0133,  ..., -0.1743,  0.0840, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0510,  0.0545, -0.0938, -0.1203, -0.0570,  0.0459, -0.1298,  0.0621,
        -0.0459,  0.0927,  0.0342,  0.0070,  0.0095,  0.0631, -0.0783, -0.0200,
         0.0463, -0.1418, -0.0326, -0.0147, -0.1085,  0.0495,  0.0815, -0.0069,
        -0.0852,  0.0672,  0.0242, -0.0957,  0.0641,  0.1476,  0.1345, -0.0662],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0293, -0.2021, -0.0750,  ..., -0.1501, -0.0077,  0.2694],
        [-0.2465, -0.0496,  0.1088,  ..., -0.0805,  0.0038,  0.2767],
        [ 0.1729, -0.0136, -0.1824,  ...,  0.0916, -0.0313, -0.0751],
        ...,
        [ 0.1608,  0.1173,  0.0760,  ...,  0.2734, -0.2310,  0.0491],
        [-0.0623, -0.1802,  0.0829,  ..., -0.0071,  0.2568,  0.0935],
        [-0.0273, -0.1268,  0.2161,  ...,  0.0412,  0.1477,  0.1374]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0886,  0.1239, -0.0365, -0.0560, -0.0318, -0.0359, -0.0329, -0.0627,
         0.1103, -0.1770,  0.1225, -0.1328,  0.1650, -0.0189, -0.1429,  0.1067,
        -0.1280, -0.1546,  0.0137, -0.0299,  0.0081,  0.1078, -0.1909,  0.2035,
        -0.0684, -0.0280,  0.0877, -0.0354, -0.1126, -0.0609,  0.1129,  0.0020],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5607,  0.4852, -0.5645, -0.5664,  0.4121,  0.4208, -0.4682,  0.4777,
          0.4761, -0.5004, -0.4900,  0.4503,  0.4725, -0.4140,  0.4937,  0.4428,
         -0.5712, -0.5620,  0.4390,  0.4568, -0.5253, -0.4980, -0.5613,  0.3962,
          0.5361,  0.5616, -0.5362,  0.6048, -0.4717, -0.5532,  0.5390,  0.5527]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2784], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-6.6321e-04,  3.3302e-01,  3.1048e-01, -2.9400e-01, -3.6476e-01,
         -2.0818e-01, -9.6938e-02, -5.1010e-01, -2.7325e-01, -7.6749e-02,
         -1.3364e-02,  2.6366e-01,  1.1919e-01, -4.1141e-02,  6.0768e-02,
          3.5279e-01],
        [-2.5521e-01, -3.1506e-01, -1.0843e-01, -2.6873e-02,  1.0419e-01,
          2.9019e-01,  2.0217e-01,  2.5331e-01,  4.7089e-01,  1.4564e-01,
          2.7391e-01, -3.2445e-01, -3.3227e-02, -7.0774e-02,  2.3159e-01,
         -7.1690e-02],
        [ 7.9969e-02,  2.2175e-01,  3.8188e-01, -8.9798e-02, -2.2099e-01,
         -3.8488e-01, -8.4813e-02, -5.2650e-01, -4.7449e-02, -7.3965e-02,
         -1.2568e-01,  6.4342e-03,  4.4401e-01,  3.5421e-01,  1.7610e-01,
          2.4988e-01],
        [ 2.7598e-01,  4.8822e-02,  9.1217e-02, -5.2721e-02, -1.9031e-01,
         -2.4170e-01, -1.9333e-01, -2.0166e-01, -5.0429e-01, -4.1663e-01,
         -1.0689e-01,  4.3569e-01,  3.1760e-01, -8.5897e-02, -9.5508e-02,
          1.4739e-01],
        [-9.4909e-02,  1.1225e-01, -1.7311e-01, -5.0234e-02,  3.0247e-01,
          1.2996e-01,  8.0713e-02,  4.2665e-01,  2.2342e-01,  3.0687e-01,
          3.0598e-01, -2.2858e-01, -8.6859e-02, -2.6671e-01,  1.6288e-01,
         -1.4406e-01],
        [-1.0989e-02,  1.4956e-01, -3.6723e-01,  3.8441e-01,  4.7635e-01,
          2.0560e-02,  3.0097e-01,  6.9574e-02,  3.3187e-01,  2.2758e-01,
         -1.0507e-01, -1.5409e-01, -2.8499e-01,  9.8361e-02,  2.8303e-01,
         -7.1114e-02],
        [ 3.7839e-01,  9.5486e-02,  4.1751e-01, -1.7092e-01, -1.8210e-01,
         -2.5653e-01, -2.1968e-01, -3.3507e-01, -3.3593e-01, -4.1582e-02,
         -4.5602e-02,  1.2848e-01, -2.5718e-02,  2.6135e-01, -1.5866e-01,
          1.5131e-01],
        [-5.7928e-02,  2.4738e-01,  3.6159e-01, -3.3933e-01, -4.3968e-01,
         -3.3170e-01, -1.1584e-01, -3.4046e-01, -2.5966e-01, -2.2675e-01,
         -9.2089e-02,  8.1540e-02,  2.7573e-01, -5.7658e-02,  3.0788e-02,
          3.5286e-01],
        [ 4.5595e-02,  2.8699e-01,  3.1654e-01, -2.3191e-01, -1.7752e-01,
         -3.9675e-01, -2.0983e-01, -1.9931e-01, -3.6958e-02, -3.3503e-01,
         -2.5047e-01,  1.2628e-01, -1.8730e-02,  2.0408e-01, -2.2336e-01,
          9.3362e-02],
        [-2.9319e-01, -8.1262e-02, -1.0681e-01, -3.2818e-02,  2.1497e-01,
          2.0631e-01,  9.4078e-02,  3.4690e-01,  3.5359e-01,  1.5985e-02,
          3.1807e-01, -7.7988e-02, -3.1403e-01, -1.1729e-01,  6.5055e-02,
         -1.9226e-01],
        [-3.6342e-01,  7.0874e-02, -7.4551e-02, -5.1183e-02,  1.0137e-01,
          4.7784e-01,  2.7665e-01,  2.3310e-01,  4.3823e-01,  2.7391e-01,
          1.2086e-01, -6.9820e-02, -1.9858e-01,  7.7238e-02, -1.0663e-01,
         -3.2957e-01],
        [-1.3307e-01, -1.4081e-01, -3.5640e-02,  7.4629e-02,  2.9620e-01,
          1.6827e-01,  4.1199e-01,  2.5293e-01,  2.4464e-01,  3.6919e-01,
          2.3681e-01, -5.7868e-03, -4.1936e-01, -2.7775e-01, -3.9855e-02,
         -2.0258e-01],
        [ 3.4048e-01,  2.1927e-01,  1.7687e-01, -1.5023e-01, -2.9469e-01,
         -4.4497e-02, -1.4255e-01, -4.7440e-01, -4.2919e-01, -1.3030e-01,
         -1.4832e-01,  1.2612e-01,  3.3752e-03,  2.1085e-01, -1.3924e-01,
          2.6340e-02],
        [ 2.1663e-01,  3.1427e-01,  3.7869e-01, -7.0513e-05, -4.2613e-01,
         -6.3627e-02, -7.8734e-02, -1.5911e-01, -2.8687e-01, -1.8333e-01,
         -2.6247e-01,  1.6960e-01,  1.5884e-01,  9.8853e-02, -2.2471e-01,
          2.3851e-01],
        [-3.7946e-01, -2.7459e-01, -7.4751e-02, -6.0185e-02,  4.9243e-01,
          4.5108e-01,  1.3465e-01,  2.1397e-01,  4.2953e-02,  1.9703e-01,
          1.7292e-01, -3.7342e-01, -1.2158e-01, -1.4950e-01, -7.9428e-02,
         -1.5876e-01],
        [-7.8898e-02, -1.0884e-01,  1.9615e-01,  1.2044e-01, -5.0181e-01,
         -9.1775e-02, -2.4287e-01, -4.6404e-01, -3.1355e-01, -7.3766e-02,
         -1.0692e-01,  5.0127e-01,  2.2143e-01,  9.9184e-03,  1.8383e-01,
          5.4758e-02],
        [ 3.2214e-01,  2.4935e-01,  2.1025e-01, -3.4026e-01, -4.8328e-01,
         -8.2925e-02, -1.4166e-01, -9.5639e-02, -4.4371e-01, -2.0718e-01,
          1.1076e-01,  3.5484e-01,  3.9785e-01,  3.2498e-01, -4.1956e-02,
         -2.5857e-02],
        [-2.9930e-01,  1.2127e-02, -2.5189e-01,  1.2762e-01,  2.4314e-01,
          3.3433e-01,  3.1768e-01,  3.5422e-01,  2.0738e-01,  2.9763e-01,
         -1.2341e-02, -2.9763e-01, -1.8861e-01, -2.5911e-01,  1.7981e-01,
         -1.7462e-01],
        [ 2.1726e-01,  9.0004e-02,  1.4077e-01, -2.4647e-01, -3.6323e-01,
         -4.1343e-01, -3.2107e-01, -8.3616e-02, -4.9438e-01, -1.1154e-01,
         -9.4544e-02, -1.4229e-02,  2.6792e-01,  3.0425e-01,  1.3144e-01,
          1.7207e-01],
        [ 3.7955e-01,  1.1297e-01,  2.8129e-01, -7.3658e-02, -4.4901e-01,
         -2.7932e-01, -3.9873e-01, -7.6508e-02, -1.3197e-01, -2.9482e-01,
         -1.3667e-01,  3.1883e-01, -2.1470e-02,  1.5141e-01,  1.2853e-01,
          1.9705e-01],
        [-1.8204e-01,  7.7399e-02, -5.2806e-02, -8.5692e-02,  3.9040e-01,
         -1.0370e-03,  3.3725e-01,  4.4510e-01,  2.3865e-01,  8.4895e-02,
         -2.2998e-02, -3.2579e-01, -2.2219e-01, -2.3433e-01,  2.6836e-01,
         -2.5155e-01],
        [-8.0632e-02, -3.1366e-01, -5.9017e-02,  3.6589e-01,  1.0857e-01,
          1.6663e-01,  2.9844e-01,  4.4845e-02,  1.0702e-01,  2.8571e-01,
          3.7433e-01, -3.2814e-01, -2.4027e-01, -4.0498e-01, -1.9862e-01,
          5.6952e-02],
        [ 3.7231e-01,  1.3356e-02,  6.3611e-02, -1.5196e-01, -1.1100e-01,
         -4.3646e-01, -3.3301e-01, -3.1012e-01, -3.2193e-01, -1.7496e-01,
          7.6496e-02,  2.6828e-01, -5.7231e-02,  3.5825e-01,  2.1513e-01,
          2.2307e-01],
        [ 2.6141e-01,  1.8438e-01,  3.4789e-01, -3.5965e-01, -3.2849e-01,
         -1.9641e-01, -2.1023e-01, -3.5338e-01, -4.1809e-01, -3.3614e-01,
         -8.6867e-02,  3.8991e-01,  2.7203e-01,  1.7723e-01, -1.2355e-01,
          2.7272e-02],
        [ 2.1780e-01, -1.3533e-01,  1.8312e-01, -1.0499e-01, -7.7763e-02,
         -3.1272e-01, -6.0267e-03, -2.8445e-01, -4.5359e-01,  3.0455e-02,
          8.4977e-02,  7.7222e-02,  1.0871e-01,  2.8497e-01, -2.0059e-01,
          3.3790e-01],
        [ 4.3083e-02,  4.9686e-03,  9.3394e-02,  9.9722e-02, -3.4310e-01,
         -2.4980e-01, -5.0699e-02, -4.1801e-01, -2.2653e-01, -3.6543e-01,
         -3.4349e-01,  1.6427e-01,  2.0601e-01,  3.4864e-01, -2.5308e-01,
          7.6131e-02],
        [ 2.2794e-01,  1.7673e-01,  3.1046e-01, -3.3744e-01, -2.8705e-01,
         -1.3773e-01, -3.9645e-01, -1.0434e-01, -4.5433e-01, -1.2784e-02,
         -3.0913e-02,  1.4364e-01,  2.5142e-01,  3.3845e-01,  2.1504e-01,
          2.9817e-01],
        [-3.2332e-01, -3.1093e-02,  8.0786e-03,  1.8785e-01,  4.3738e-01,
          6.8927e-02,  4.0601e-01,  2.7296e-01,  2.5185e-02,  1.2249e-01,
          2.8043e-01, -3.3753e-01, -2.5530e-01, -2.4117e-01, -1.2351e-01,
         -1.1120e-01],
        [ 3.1004e-01,  1.4595e-01,  1.4715e-01, -1.1899e-01, -4.1502e-01,
         -3.2779e-01, -1.8136e-01, -4.2969e-01, -8.8830e-02, -1.2808e-01,
          7.9987e-03,  2.0096e-01,  3.2354e-01,  3.5258e-01,  9.9095e-02,
          2.6752e-01],
        [-2.7790e-01,  4.1193e-02, -3.2686e-01,  2.4226e-01,  3.0924e-02,
          1.8321e-01,  3.6681e-01,  3.8266e-01,  4.2252e-01,  2.4858e-01,
          2.2761e-01, -1.3442e-01,  1.8239e-02,  1.0292e-02,  3.3383e-02,
         -2.2922e-01],
        [-2.9284e-01, -1.6443e-01, -5.5383e-02,  5.6414e-03,  3.1840e-01,
          4.2998e-01,  4.2125e-01,  6.7536e-02,  3.0428e-01,  3.4264e-01,
         -1.4037e-01, -7.5768e-02, -3.4045e-01, -3.1671e-01, -1.0907e-01,
         -2.4838e-01],
        [ 6.0639e-02,  1.5399e-01,  2.6153e-01, -3.1230e-02, -1.1981e-01,
         -3.6245e-01, -4.4489e-01, -4.7475e-01, -3.9254e-01, -2.8416e-01,
         -2.0894e-02,  5.5718e-02,  2.2011e-02,  3.0817e-01, -1.3946e-01,
          1.9059e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0470, -0.0170,  0.1141, -0.0332, -0.0745, -0.1089,  0.0759,  0.0866,
        -0.0186, -0.0722, -0.0150,  0.0550,  0.1579,  0.0836,  0.0123, -0.0322,
        -0.0512, -0.0028,  0.0967,  0.0083, -0.0573, -0.1439, -0.0236, -0.0064,
         0.0115,  0.1734,  0.1211,  0.0072, -0.0627, -0.1455,  0.0285, -0.0444],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2508,  0.3394, -0.2445, -0.2798,  0.3492,  0.3876, -0.2955, -0.3981,
         -0.3272,  0.3728,  0.2828,  0.3927, -0.2886, -0.4135,  0.3217, -0.3411,
         -0.3366,  0.3449, -0.2460, -0.2643,  0.4271,  0.3282, -0.3866, -0.3903,
         -0.3561, -0.3623, -0.3264,  0.3743, -0.3756,  0.3955,  0.3052, -0.2523]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0083, -0.0058,  0.0441,  ...,  0.2364, -0.3777, -0.1137],
        [-0.0815, -0.1895,  0.0887,  ...,  0.1474, -0.3599,  0.0871],
        [-0.0450,  0.1736,  0.0721,  ..., -0.0053,  0.2838,  0.0345],
        ...,
        [ 0.0307, -0.1882,  0.0432,  ...,  0.0664, -0.3100, -0.1180],
        [ 0.0452, -0.0527, -0.0194,  ..., -0.3053,  0.1648,  0.1557],
        [-0.2009,  0.0513,  0.0038,  ...,  0.0409, -0.2580, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0562,  0.0561, -0.0868, -0.1203, -0.0587,  0.0536, -0.1268,  0.0597,
        -0.0481,  0.0815,  0.0302,  0.0106,  0.0269,  0.0744, -0.0770, -0.0175,
         0.0479, -0.1508, -0.0302, -0.0247, -0.0741,  0.0476,  0.0895, -0.0059,
        -0.0879,  0.0876,  0.0328, -0.0875,  0.0482,  0.1377,  0.1478, -0.1071],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0231, -0.1897, -0.0822,  ..., -0.1122, -0.0255,  0.0734],
        [-0.2595, -0.0438,  0.1137,  ..., -0.0440, -0.0040,  0.0612],
        [ 0.1811, -0.0286, -0.1764,  ...,  0.0510, -0.0116,  0.1665],
        ...,
        [ 0.1601,  0.0951,  0.0926,  ...,  0.2229, -0.2013,  0.2392],
        [-0.0770, -0.1665,  0.0796,  ...,  0.0348,  0.2407, -0.1664],
        [-0.0429, -0.1234,  0.2121,  ...,  0.0762,  0.1353, -0.0286]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0851,  0.1232, -0.0254, -0.0600, -0.0332, -0.0634, -0.0278, -0.0598,
         0.0962, -0.1379,  0.1361, -0.1263,  0.1531,  0.0589, -0.1344,  0.0896,
        -0.1197, -0.1478,  0.0038, -0.0133,  0.0054,  0.1085, -0.1859,  0.1752,
        -0.0633, -0.0305,  0.0897, -0.0416, -0.1107, -0.0550,  0.0982,  0.0042],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.6021,  0.5253, -0.6018, -0.6038,  0.4695,  0.4607, -0.5163,  0.5105,
          0.5344, -0.5411, -0.4969,  0.4946,  0.4936,  0.5047,  0.5324,  0.4888,
         -0.6025, -0.6078,  0.4709,  0.4975, -0.5582, -0.5359, -0.6034,  0.4629,
          0.5872,  0.6088, -0.5858,  0.6354, -0.5147, -0.5987,  0.5825,  0.6015]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.3152], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.1915e-02,  3.8884e-03,  2.7810e-01, -3.1485e-01, -3.1304e-01,
         -1.3619e-01, -5.1130e-02, -4.7883e-01, -2.4015e-01, -3.3717e-02,
          1.7485e-01,  1.9133e-01,  4.5894e-02, -8.2638e-02, -2.1651e-01,
          3.4488e-01],
        [-2.6480e-01, -2.2753e-02, -9.2911e-02,  6.3858e-03,  6.0744e-02,
          2.3945e-01,  1.6237e-01,  2.2166e-01,  4.6109e-01,  1.2667e-01,
          7.6825e-02, -2.7263e-01, -3.2254e-04, -4.4267e-02,  4.8991e-01,
         -6.9862e-02],
        [ 8.8052e-02, -5.2293e-02,  3.5887e-01, -1.1470e-01, -1.6289e-01,
         -3.3429e-01, -3.9620e-02, -4.8180e-01, -6.5262e-03, -4.9800e-02,
         -7.4075e-02, -5.4594e-02,  3.9755e-01,  3.0988e-01, -9.2883e-02,
          2.4938e-01],
        [ 2.7155e-01, -9.6344e-02,  5.9528e-02, -7.0207e-02, -1.2084e-01,
         -1.6706e-01, -1.2746e-01, -1.4457e-01, -4.6899e-01, -3.7587e-01,
          2.2158e-02,  3.5513e-01,  2.7629e-01, -1.3669e-01, -3.1229e-01,
          1.2524e-01],
        [-1.0006e-01,  3.9601e-01, -1.5086e-01, -1.7324e-02,  2.4527e-01,
          7.1070e-02,  3.2984e-02,  3.8001e-01,  1.9381e-01,  2.8475e-01,
          6.3770e-02, -1.6340e-01, -4.4137e-02, -2.3128e-01,  4.0501e-01,
         -1.4224e-01],
        [-2.9253e-03,  3.6071e-01, -3.3906e-01,  4.0420e-01,  3.8993e-01,
         -5.0881e-02,  2.4510e-01,  9.7422e-03,  2.8992e-01,  1.9812e-01,
         -1.1510e-01, -8.4767e-02, -2.2429e-01,  1.3131e-01,  4.7621e-01,
         -6.3110e-02],
        [ 3.7135e-01, -4.7317e-02,  3.8698e-01, -1.8675e-01, -1.2333e-01,
         -1.9330e-01, -1.6071e-01, -2.8504e-01, -2.9513e-01, -9.7456e-03,
         -7.1594e-04,  6.0963e-02, -7.5849e-02,  1.6499e-01, -3.7862e-01,
          1.3464e-01],
        [-6.3144e-02,  9.9399e-02,  3.3855e-01, -3.5774e-01, -3.9596e-01,
         -2.8717e-01, -7.6934e-02, -3.0920e-01, -2.3582e-01, -2.0893e-01,
         -5.3156e-02,  3.5615e-02,  2.4454e-01, -1.0889e-01, -1.6381e-01,
          3.4377e-01],
        [ 5.3912e-02, -4.0578e-02,  2.9846e-01, -2.6594e-01, -1.4870e-01,
         -3.4778e-01, -1.7257e-01, -1.7623e-01, -2.0040e-02, -3.1627e-01,
          1.5953e-02,  7.7006e-02, -4.7587e-02,  1.7823e-01, -4.7242e-01,
          9.4663e-02],
        [-3.0393e-01,  2.2545e-01, -9.3700e-02,  6.0887e-03,  1.6316e-01,
          1.5307e-01,  5.1472e-02,  3.0458e-01,  3.2980e-01,  2.3914e-04,
          1.1067e-01, -2.4085e-02, -2.7425e-01, -9.6519e-02,  3.1236e-01,
         -1.9786e-01],
        [-3.6459e-01,  2.6661e-01, -4.8247e-02, -2.7711e-02,  4.6527e-02,
          4.1515e-01,  2.2776e-01,  1.8809e-01,  4.0955e-01,  2.4362e-01,
          3.7141e-03, -2.9472e-03, -2.0280e-01,  9.9473e-02,  1.2016e-01,
         -3.1981e-01],
        [-1.2955e-01,  7.1609e-02, -8.2764e-03,  9.9057e-02,  2.3594e-01,
          1.1262e-01,  3.5066e-01,  1.9980e-01,  2.0395e-01,  3.3843e-01,
          8.4037e-02,  6.0517e-02, -4.1609e-01, -2.2545e-01,  1.6070e-01,
         -1.9122e-01],
        [ 3.4568e-01, -6.3734e-02,  1.4383e-01, -1.7906e-01, -2.1506e-01,
          3.8298e-02, -8.1764e-02, -4.1110e-01, -3.9942e-01, -9.1910e-02,
         -1.0156e-01,  4.3728e-02, -3.4196e-02,  1.8006e-01, -4.2838e-01,
          1.5903e-02],
        [ 2.1735e-01,  6.0371e-02,  3.5904e-01, -2.5545e-02, -3.7880e-01,
         -1.6865e-02, -3.4523e-02, -1.2336e-01, -2.6908e-01, -1.6321e-01,
         -1.1024e-01,  1.1987e-01,  1.2562e-01,  5.3956e-02, -4.5743e-01,
          2.3202e-01],
        [-3.8607e-01, -8.8980e-03, -5.7690e-02, -2.9208e-02,  4.5555e-01,
          4.0824e-01,  9.9884e-02,  1.8613e-01,  2.5185e-02,  1.8273e-01,
          3.0639e-02, -3.2502e-01, -1.0092e-01, -1.2334e-01,  1.8557e-01,
         -1.5808e-01],
        [-3.8813e-02, -4.7296e-01,  1.7251e-01,  5.8276e-02, -4.7563e-01,
         -1.5560e-03, -1.9112e-01, -4.3434e-01, -3.1034e-01, -4.0396e-02,
         -5.1517e-02,  4.2967e-01,  1.6228e-01, -5.6524e-02, -1.3540e-01,
          7.1106e-02],
        [ 3.1677e-01,  6.5593e-02,  1.8271e-01, -3.5553e-01, -3.9926e-01,
         -1.8661e-02, -7.5640e-02, -4.0489e-02, -4.2047e-01, -1.7106e-01,
          1.8493e-01,  2.8696e-01,  3.3509e-01,  2.4829e-01, -2.1676e-01,
         -4.6880e-02],
        [-2.8176e-01,  1.4650e-01, -2.1485e-01,  1.3336e-01,  1.5361e-01,
          2.7077e-01,  2.5382e-01,  2.9477e-01,  1.5708e-01,  2.6207e-01,
         -5.6861e-02, -2.2530e-01, -1.2806e-01, -1.7233e-01,  2.9667e-01,
         -1.5107e-01],
        [ 2.3527e-01, -1.4044e-01,  1.2806e-01, -2.7918e-01, -2.6945e-01,
         -3.6368e-01, -2.6706e-01, -3.1752e-02, -4.5236e-01, -9.1784e-02,
          1.9504e-02, -7.7754e-02,  1.8955e-01,  2.3266e-01, -9.7554e-02,
          1.7620e-01],
        [ 3.7769e-01, -1.1680e-01,  2.4895e-01, -9.4378e-02, -4.0156e-01,
         -2.2340e-01, -3.4708e-01, -3.9959e-02, -1.0263e-01, -2.6334e-01,
          9.7439e-02,  2.5199e-01, -4.6324e-02,  9.6548e-02, -1.3213e-01,
          1.8211e-01],
        [-1.7239e-01,  2.7900e-01, -2.3980e-02, -6.8853e-02,  3.0966e-01,
         -5.8043e-02,  2.8773e-01,  3.8970e-01,  2.0051e-01,  5.9231e-02,
         -1.1432e-01, -2.6235e-01, -1.8175e-01, -1.8798e-01,  4.3340e-01,
         -2.4004e-01],
        [-1.0652e-01,  8.3038e-02, -5.3776e-02,  4.1293e-01,  1.0344e-01,
          1.2934e-01,  2.7392e-01,  4.1230e-02,  1.1666e-01,  2.8062e-01,
          2.1290e-01, -3.0472e-01, -2.2726e-01, -3.8951e-01,  5.2712e-02,
          4.7761e-02],
        [ 3.7049e-01, -1.9242e-01,  4.0210e-02, -1.7409e-01, -6.1659e-02,
         -3.9050e-01, -2.8832e-01, -2.7827e-01, -2.9820e-01, -1.5456e-01,
          2.0935e-01,  2.1877e-01, -7.6693e-02,  3.0753e-01,  5.2210e-03,
          2.1223e-01],
        [ 2.4466e-01,  9.6746e-02,  3.1347e-01, -3.6213e-01, -2.2289e-01,
         -1.3462e-01, -1.4218e-01, -2.9545e-01, -3.8254e-01, -2.9530e-01,
          1.0952e-02,  3.2400e-01,  2.3797e-01,  9.5386e-02, -2.2718e-01,
         -6.3833e-03],
        [ 2.2017e-01, -4.2153e-01,  1.6296e-01, -1.3960e-01, -1.0752e-02,
         -2.4447e-01,  5.0653e-02, -2.2470e-01, -4.1112e-01,  5.5863e-02,
          1.9081e-01,  8.2986e-03,  5.2409e-02,  2.5771e-01, -4.3944e-01,
          3.3840e-01],
        [ 4.1813e-02, -2.2710e-01,  7.0123e-02,  7.5948e-02, -2.7304e-01,
         -2.0057e-01, -1.5576e-02, -3.7158e-01, -1.9557e-01, -3.4703e-01,
         -2.5806e-01,  1.0718e-01,  1.8445e-01,  3.2145e-01, -4.8695e-01,
          7.1132e-02],
        [ 2.2112e-01, -5.1587e-02,  2.7742e-01, -3.5090e-01, -2.3090e-01,
         -8.9217e-02, -3.3993e-01, -6.8935e-02, -4.2195e-01,  1.5964e-02,
          5.2218e-02,  8.5064e-02,  2.2393e-01,  2.5046e-01,  1.3324e-02,
          2.7773e-01],
        [-3.3086e-01,  2.2525e-01,  2.7791e-02,  2.2032e-01,  3.8606e-01,
          1.7927e-02,  3.5503e-01,  2.3033e-01, -5.4459e-03,  1.0110e-01,
          6.8653e-02, -2.7787e-01, -2.2727e-01, -1.9591e-01,  1.0130e-01,
         -1.0883e-01],
        [ 2.9945e-01,  9.1533e-03,  1.1455e-01, -1.3274e-01, -3.4118e-01,
         -2.7321e-01, -1.2710e-01, -3.7894e-01, -5.0928e-02, -9.5895e-02,
          1.1626e-01,  1.3371e-01,  3.4330e-01,  3.0329e-01, -6.6207e-02,
          2.4779e-01],
        [-2.6875e-01,  1.9014e-01, -2.9925e-01,  2.5649e-01, -2.4481e-02,
          1.3392e-01,  3.1803e-01,  3.4265e-01,  3.9079e-01,  2.2433e-01,
          1.4502e-01, -8.1920e-02,  5.6420e-02,  7.0363e-02,  2.2142e-01,
         -2.1371e-01],
        [-2.8587e-01,  5.9838e-02, -2.3217e-02,  2.2097e-02,  2.5738e-01,
          3.7074e-01,  3.6580e-01,  2.5001e-02,  2.6993e-01,  3.1143e-01,
         -2.3705e-01, -7.5971e-03, -3.0472e-01, -2.6019e-01,  1.0498e-01,
         -2.3185e-01],
        [ 5.6931e-02, -5.7632e-02,  2.2780e-01, -5.0315e-02, -5.2105e-02,
         -2.9766e-01, -3.7749e-01, -4.0941e-01, -3.4189e-01, -2.4635e-01,
          9.7557e-02, -2.7028e-02, -5.2122e-02,  2.0096e-01, -3.6075e-01,
          1.7580e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0718, -0.0463,  0.1223, -0.0914, -0.0502, -0.0264,  0.0744,  0.1391,
        -0.0475, -0.0576,  0.0306,  0.0682,  0.1790,  0.1007, -0.0560,  0.0952,
        -0.1691, -0.0043,  0.0193,  0.0007, -0.0216, -0.1074, -0.0625, -0.0408,
        -0.1701,  0.2645,  0.1035,  0.0254, -0.0850, -0.2247,  0.1603, -0.0323],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2938,  0.3801, -0.2755, -0.2905,  0.3876,  0.4203, -0.3256, -0.4059,
         -0.3666,  0.4342,  0.2960,  0.4238, -0.3336, -0.4568,  0.3529, -0.3823,
         -0.3541,  0.3501, -0.2653, -0.2832,  0.4561,  0.3849, -0.3988, -0.3952,
         -0.4276, -0.3971, -0.3422,  0.4040, -0.3717,  0.4103,  0.3143, -0.2675]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0398,  0.1096,  0.0533,  ...,  0.2236, -0.3581, -0.1137],
        [-0.1073, -0.0513,  0.1137,  ...,  0.1575, -0.3495,  0.0871],
        [-0.0041, -0.0357,  0.0221,  ...,  0.0246,  0.2601,  0.0345],
        ...,
        [ 0.0106,  0.0133,  0.0543,  ...,  0.0875, -0.3518, -0.1180],
        [ 0.0840, -0.2084, -0.0500,  ..., -0.3309,  0.1769,  0.1557],
        [-0.2029,  0.1495,  0.0342,  ...,  0.1000, -0.3093, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0423,  0.0406, -0.0664, -0.1338, -0.0722,  0.0587, -0.1105,  0.0461,
        -0.0394,  0.0806,  0.0186,  0.0116,  0.0295,  0.0784, -0.0525, -0.0187,
         0.0589, -0.1535,  0.0015,  0.0281, -0.0515,  0.0340,  0.1088,  0.0061,
        -0.0930,  0.1039,  0.0474, -0.0972,  0.0545,  0.1395,  0.1669, -0.1230],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0725, -0.1920, -0.1064,  ..., -0.1472, -0.0142,  0.0730],
        [-0.2086, -0.0486,  0.0957,  ..., -0.0803,  0.0097,  0.0473],
        [ 0.1414, -0.0152, -0.1723,  ...,  0.0982, -0.0333,  0.1919],
        ...,
        [ 0.1212,  0.1045,  0.1122,  ...,  0.2692, -0.2280,  0.2472],
        [-0.0082, -0.1604,  0.0516,  ...,  0.0018,  0.2405, -0.1709],
        [-0.0059, -0.1446,  0.2096,  ...,  0.0208,  0.1678, -0.0531]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1051,  0.1495, -0.0617, -0.0850,  0.0005, -0.0450, -0.0592, -0.0431,
         0.1253, -0.1708,  0.1302, -0.1164,  0.1738,  0.0873, -0.1216,  0.1289,
        -0.1389, -0.1744, -0.0557, -0.0025, -0.0042,  0.0836, -0.2129,  0.2156,
        -0.0451, -0.0042,  0.0730, -0.0285, -0.1368, -0.0737,  0.1243,  0.0446],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5517,  0.4740, -0.5637, -0.5485,  0.4305,  0.4108, -0.4738,  0.4497,
          0.4694, -0.4964, -0.4413,  0.4599,  0.4405,  0.4216,  0.4884,  0.4858,
         -0.5471, -0.5609, -0.4187,  0.4651, -0.5091, -0.4894, -0.5620,  0.4036,
          0.5321,  0.5613, -0.5466,  0.5543, -0.4758, -0.5485,  0.5365,  0.5618]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.3014], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.5504e-02,  3.1819e-01,  2.6616e-01, -2.8274e-01, -3.2561e-01,
         -1.1687e-01, -3.2697e-02, -4.6744e-01, -2.3338e-01, -1.4013e-02,
          1.5925e-01,  1.7589e-01,  4.0488e-02, -9.2185e-02, -2.1317e-01,
          3.2106e-01],
        [-2.3972e-01, -3.1528e-01, -7.3424e-02, -2.3167e-02,  6.5529e-02,
          2.2294e-01,  1.4928e-01,  2.0637e-01,  4.4520e-01,  1.0623e-01,
          7.3749e-02, -2.5402e-01,  9.5539e-03, -2.9902e-02,  4.8670e-01,
         -4.5674e-02],
        [ 6.7215e-02,  2.2315e-01,  3.4346e-01, -9.1133e-02, -1.7714e-01,
         -3.2599e-01, -3.6521e-02, -4.8521e-01, -5.5810e-04, -3.5085e-02,
         -6.6418e-02, -6.4495e-02,  4.0884e-01,  3.1418e-01, -9.5925e-02,
          2.3534e-01],
        [ 2.4918e-01,  3.3100e-02,  4.6224e-02, -4.7017e-02, -1.4383e-01,
         -1.5654e-01, -1.2130e-01, -1.3420e-01, -4.6674e-01, -3.6018e-01,
          2.2933e-02,  3.4599e-01,  2.7477e-01, -1.4403e-01, -3.2355e-01,
          1.0216e-01],
        [-9.1626e-02,  1.1812e-01, -1.4484e-01, -3.7566e-02,  2.8340e-01,
          6.4347e-02,  3.6572e-02,  3.9581e-01,  2.1321e-01,  2.7340e-01,
          8.8636e-02, -1.6426e-01, -5.9988e-02, -2.3827e-01,  4.4211e-01,
         -1.2579e-01],
        [ 3.9336e-03,  1.5411e-01, -3.3711e-01,  3.8988e-01,  4.1747e-01,
         -5.0442e-02,  2.4597e-01,  1.0151e-02,  2.9886e-01,  1.9092e-01,
         -1.1291e-01, -8.4780e-02, -2.3950e-01,  1.2881e-01,  5.2839e-01,
         -5.1404e-02],
        [ 3.5035e-01,  9.4586e-02,  3.7277e-01, -1.6416e-01, -1.3665e-01,
         -1.8615e-01, -1.5657e-01, -2.7519e-01, -2.7866e-01,  3.8851e-03,
          7.7352e-03,  5.0554e-02, -7.4019e-02,  1.6152e-01, -3.9089e-01,
          1.1708e-01],
        [-8.2847e-02,  2.5527e-01,  3.2422e-01, -3.3540e-01, -3.8794e-01,
         -2.7841e-01, -6.8374e-02, -2.9369e-01, -2.1481e-01, -1.9542e-01,
         -5.6754e-02,  2.1000e-02,  2.4257e-01, -1.1329e-01, -1.6092e-01,
          3.2942e-01],
        [ 3.3647e-02,  2.9543e-01,  2.8231e-01, -2.4228e-01, -1.4663e-01,
         -3.3533e-01, -1.6339e-01, -1.6197e-01, -7.1721e-03, -2.9932e-01,
          2.0124e-02,  6.3935e-02, -4.9944e-02,  1.7085e-01, -4.7436e-01,
          7.5151e-02],
        [-2.9066e-01, -8.3643e-02, -8.3030e-02, -1.6486e-02,  1.8569e-01,
          1.4409e-01,  4.8607e-02,  3.0844e-01,  3.3499e-01, -1.3518e-02,
          1.2834e-01, -1.7520e-02, -2.8064e-01, -9.3724e-02,  3.3235e-01,
         -1.8066e-01],
        [-3.5279e-01,  7.3688e-02, -4.2102e-02, -4.1473e-02,  7.3816e-02,
          4.1146e-01,  2.2828e-01,  1.9185e-01,  4.1622e-01,  2.3500e-01,
         -1.4005e-02, -3.5189e-03, -2.1004e-01,  9.3254e-02,  1.4948e-01,
         -3.0628e-01],
        [-1.1365e-01, -1.2903e-01,  3.6553e-03,  7.9524e-02,  2.4450e-01,
          1.0087e-01,  3.4908e-01,  1.9807e-01,  1.9840e-01,  3.2583e-01,
          9.6879e-02,  6.7488e-02, -4.1424e-01, -2.2978e-01,  1.7235e-01,
         -1.7556e-01],
        [ 3.1920e-01,  2.0841e-01,  1.2711e-01, -1.4658e-01, -2.4616e-01,
          5.6984e-02, -7.2216e-02, -4.1301e-01, -3.9850e-01, -7.1300e-02,
         -9.9027e-02,  2.7295e-02, -3.5133e-02,  1.7323e-01, -4.3455e-01,
         -8.5884e-03],
        [ 1.9523e-01,  3.1525e-01,  3.4063e-01, -5.7361e-04, -3.7662e-01,
         -3.1240e-03, -2.5392e-02, -1.0814e-01, -2.4902e-01, -1.4550e-01,
         -1.0511e-01,  1.0367e-01,  1.1804e-01,  4.5090e-02, -4.5515e-01,
          2.1233e-01],
        [-3.6627e-01, -2.8378e-01, -4.2868e-02, -5.2446e-02,  4.5785e-01,
          3.9641e-01,  9.1773e-02,  1.7464e-01,  1.3016e-02,  1.6715e-01,
          2.6474e-02, -3.1199e-01, -9.8167e-02, -1.1779e-01,  1.8269e-01,
         -1.4020e-01],
        [-2.9491e-01, -1.8128e-01,  3.9558e-02,  2.3429e-01,  2.0924e-01,
          1.5979e-01,  1.0006e-01,  1.2572e-01,  2.1960e-01,  1.0203e-01,
          3.6172e-02,  1.4272e-01, -1.5498e-01, -2.6765e-01,  6.4756e-01,
         -6.1769e-02],
        [ 2.9235e-01,  2.0616e-01,  1.6766e-01, -3.3104e-01, -4.1050e-01,
         -5.2162e-03, -6.8088e-02, -1.9225e-02, -4.0670e-01, -1.5413e-01,
          1.7262e-01,  2.7384e-01,  3.2322e-01,  2.4221e-01, -2.0505e-01,
         -6.8840e-02],
        [-2.6492e-01,  6.6776e-02, -2.0461e-01,  1.1332e-01,  1.6698e-01,
          2.6715e-01,  2.5202e-01,  2.8730e-01,  1.4875e-01,  2.5189e-01,
         -5.9187e-02, -2.1811e-01, -1.3710e-01, -1.6698e-01,  3.1227e-01,
         -1.3563e-01],
        [ 2.1447e-01,  8.4610e-02,  1.1640e-01, -2.5684e-01, -2.9076e-01,
         -3.5369e-01, -2.6387e-01, -2.9148e-02, -4.5664e-01, -7.6340e-02,
          3.1931e-02, -8.3739e-02,  1.9333e-01,  2.3183e-01, -9.9639e-02,
          1.5408e-01],
        [ 3.6058e-01,  1.1286e-01,  2.3949e-01, -7.6660e-02, -4.1503e-01,
         -2.1298e-01, -3.4682e-01, -3.2654e-02, -1.0155e-01, -2.5068e-01,
          9.8703e-02,  2.4786e-01, -4.4298e-02,  1.0342e-01, -1.4049e-01,
          1.6374e-01],
        [-1.6066e-01,  9.0426e-02, -1.6116e-02, -8.8233e-02,  3.2608e-01,
         -6.3213e-02,  2.8799e-01,  3.9009e-01,  2.0081e-01,  4.9467e-02,
         -9.4055e-02, -2.5626e-01, -1.9093e-01, -1.9384e-01,  4.7779e-01,
         -2.2691e-01],
        [-9.0074e-02, -3.1675e-01, -4.4086e-02,  3.9294e-01,  9.8793e-02,
          1.2064e-01,  2.6967e-01,  2.8650e-02,  1.0505e-01,  2.6764e-01,
          2.1404e-01, -2.9356e-01, -2.3085e-01, -3.8908e-01,  5.6993e-02,
          6.0447e-02],
        [ 3.5962e-01,  9.6666e-04,  3.4281e-02, -1.5962e-01, -7.6849e-02,
         -3.8680e-01, -2.9180e-01, -2.7565e-01, -2.9760e-01, -1.4749e-01,
          1.9729e-01,  2.1780e-01, -6.8736e-02,  3.1286e-01, -5.8158e-03,
          2.0108e-01],
        [ 2.1835e-01,  1.4668e-01,  2.9669e-01, -3.3590e-01, -2.2834e-01,
         -1.2314e-01, -1.3396e-01, -2.7105e-01, -3.6057e-01, -2.7965e-01,
          1.0420e-02,  3.0653e-01,  2.3011e-01,  8.5052e-02, -2.1213e-01,
         -2.5739e-02],
        [ 2.1453e-01, -1.2316e-01,  1.6022e-01, -1.2519e-01, -4.1649e-02,
         -2.4363e-01,  4.6249e-02, -2.3351e-01, -4.2356e-01,  6.2261e-02,
          1.9893e-01,  1.1445e-02,  6.7358e-02,  2.6487e-01, -4.6977e-01,
          3.2867e-01],
        [ 2.7795e-02,  1.6932e-02,  5.9312e-02,  9.6031e-02, -2.8860e-01,
         -1.9401e-01, -9.8205e-03, -3.7397e-01, -1.9305e-01, -3.3594e-01,
         -2.6678e-01,  9.8644e-02,  1.9152e-01,  3.2425e-01, -5.1700e-01,
          5.8334e-02],
        [ 2.0284e-01,  1.4338e-01,  2.6651e-01, -3.3275e-01, -2.3641e-01,
         -7.8976e-02, -3.4101e-01, -5.7367e-02, -4.1063e-01,  2.7215e-02,
          4.4668e-02,  7.8167e-02,  2.2257e-01,  2.6313e-01,  1.0477e-02,
          2.6404e-01],
        [-3.2034e-01, -2.6746e-02,  3.2941e-02,  2.0371e-01,  4.0597e-01,
          9.8375e-03,  3.5775e-01,  2.3330e-01, -4.7419e-05,  9.2623e-02,
          8.7051e-02, -2.7679e-01, -2.3404e-01, -2.0885e-01,  1.2757e-01,
         -9.5974e-02],
        [ 2.8013e-01,  1.3496e-01,  1.0145e-01, -1.1278e-01, -3.4645e-01,
         -2.6115e-01, -1.2454e-01, -3.6836e-01, -3.7954e-02, -8.3326e-02,
          1.0836e-01,  1.2367e-01,  3.3977e-01,  3.0551e-01, -6.7965e-02,
          2.3294e-01],
        [-2.5625e-01,  4.0600e-02, -2.9149e-01,  2.4032e-01, -1.1741e-02,
          1.3153e-01,  3.1985e-01,  3.3949e-01,  3.8503e-01,  2.1722e-01,
          1.4259e-01, -7.7801e-02,  4.6440e-02,  6.4307e-02,  2.4404e-01,
         -2.0325e-01],
        [-2.6824e-01, -1.3965e-01, -1.2373e-02,  3.0766e-03,  2.6674e-01,
          3.6211e-01,  3.6352e-01,  1.4369e-02,  2.6396e-01,  2.9845e-01,
         -2.3402e-01, -1.6697e-03, -3.0721e-01, -2.5860e-01,  1.0317e-01,
         -2.1429e-01],
        [ 3.1820e-02,  1.0673e-01,  2.1198e-01, -2.2873e-02, -6.8166e-02,
         -2.8537e-01, -3.7302e-01, -4.0934e-01, -3.3845e-01, -2.2963e-01,
          1.0150e-01, -3.6677e-02, -5.1875e-02,  1.9663e-01, -3.5968e-01,
          1.5268e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0905, -0.0190,  0.1374, -0.0957, -0.0394, -0.0112,  0.0821,  0.1480,
        -0.0484, -0.0375,  0.0096,  0.0845,  0.1474,  0.0879, -0.0422, -0.0537,
        -0.1930, -0.0027,  0.0116, -0.0091, -0.0089, -0.0986, -0.0676, -0.0457,
        -0.1473,  0.2682,  0.0933,  0.0443, -0.0937, -0.2297,  0.1752, -0.0406],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2960,  0.3801, -0.2792, -0.3005,  0.4219,  0.4469, -0.3326, -0.4061,
         -0.3805,  0.4464,  0.3086,  0.4241, -0.3470, -0.4630,  0.3535,  0.3779,
         -0.3560,  0.3567, -0.2695, -0.2865,  0.4688,  0.3752, -0.4031, -0.3967,
         -0.4670, -0.4119, -0.3438,  0.4092, -0.3763,  0.4153,  0.3187, -0.2739]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0129,  0.1022,  0.0762,  ...,  0.1596, -0.2965, -0.1137],
        [-0.1099, -0.0428,  0.1173,  ...,  0.1308, -0.3288,  0.0871],
        [-0.0055, -0.0392,  0.0318,  ...,  0.0267,  0.2584,  0.0345],
        ...,
        [ 0.0102,  0.0222,  0.0525,  ...,  0.0687, -0.3452, -0.1180],
        [ 0.0900, -0.2196, -0.0525,  ..., -0.3039,  0.1636,  0.1557],
        [-0.1931,  0.1591,  0.0395,  ...,  0.0650, -0.3003, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0465,  0.0396, -0.0691, -0.1361, -0.0740,  0.0495, -0.1099,  0.0501,
        -0.0416,  0.0775,  0.0248,  0.0123,  0.0239,  0.0753, -0.0502, -0.0211,
         0.0569, -0.1573, -0.0643,  0.0378, -0.0580,  0.0302,  0.1054,  0.0084,
        -0.0874,  0.0523,  0.0428, -0.1165,  0.0546,  0.1436,  0.1673, -0.1287],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0604, -0.1841, -0.1030,  ..., -0.1234, -0.0169,  0.0722],
        [-0.2161, -0.0413,  0.1128,  ..., -0.0505, -0.0030,  0.0445],
        [ 0.1418, -0.0226, -0.1763,  ...,  0.0668, -0.0160,  0.1879],
        ...,
        [ 0.1162,  0.0808,  0.1210,  ...,  0.2346, -0.2114,  0.2324],
        [-0.0101, -0.1561,  0.0616,  ...,  0.0388,  0.2221, -0.1729],
        [-0.0023, -0.1280,  0.2021,  ...,  0.0591,  0.1469, -0.0408]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1073,  0.1621, -0.0640, -0.0827, -0.0045, -0.0450, -0.0586, -0.0408,
         0.1366, -0.1797,  0.1168, -0.1294,  0.1952,  0.1052, -0.1231,  0.1390,
        -0.1377, -0.1740,  0.0471, -0.0122, -0.0066,  0.0859, -0.2012,  0.2417,
        -0.0432, -0.0065,  0.0731, -0.0291, -0.1364, -0.0685,  0.1326,  0.0386],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5514,  0.4798, -0.5578, -0.5316,  0.4190,  0.4251, -0.4660,  0.4357,
          0.4504, -0.4986, -0.4455,  0.4399,  0.4373,  0.4271,  0.4725,  0.4874,
         -0.5367, -0.5491,  0.3996,  0.4498, -0.5020, -0.4824, -0.5474,  0.3943,
          0.5272,  0.5488, -0.5318,  0.5447, -0.4652, -0.5356,  0.5297,  0.5435]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2910], device='cuda:0', requires_grad=True)

