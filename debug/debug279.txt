Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-7.5892e-04,  3.9474e-01,  3.0724e-01, -3.2633e-01, -1.9369e-01,
         -1.5425e-01, -7.8656e-02, -3.9381e-01, -2.5787e-01, -7.8453e-02,
         -3.0114e-02,  1.9782e-01, -3.0965e-01, -6.9623e-02, -3.6312e-02,
          3.8587e-01],
        [-2.4823e-01, -3.8831e-01, -9.9758e-02, -1.0978e-02, -2.4462e-02,
          2.4734e-01,  1.6476e-01,  1.6195e-01,  4.3344e-01,  1.3760e-01,
          2.9885e-01, -2.6252e-01,  3.6385e-01, -2.8686e-02,  3.4438e-01,
         -9.1051e-02],
        [ 9.3667e-02,  2.9522e-01,  3.9026e-01, -1.3103e-01, -1.0405e-01,
         -3.4827e-01, -9.2887e-02, -4.5031e-01, -6.4216e-02, -9.0424e-02,
         -1.5893e-01, -3.2473e-02,  1.6633e-02,  3.5008e-01, -2.1085e-02,
          2.8792e-01],
        [ 2.8436e-01,  1.1884e-01,  9.6614e-02, -8.8003e-02, -7.0754e-02,
         -2.1595e-01, -1.7873e-01, -1.2328e-01, -4.7724e-01, -4.3006e-01,
         -2.1888e-01,  3.8767e-01, -8.0625e-02, -1.1466e-01, -2.1529e-01,
          1.8103e-01],
        [-9.6356e-02,  3.4123e-02, -1.7214e-01, -2.2985e-02,  1.6828e-01,
          8.9015e-02,  4.8805e-02,  3.2981e-01,  1.8610e-01,  3.0554e-01,
          3.4874e-01, -1.6848e-01,  3.2678e-01, -2.3314e-01,  2.9672e-01,
         -1.7433e-01],
        [-2.0547e-02,  6.0268e-02, -3.7436e-01,  4.1710e-01,  3.5980e-01,
         -8.0916e-03,  2.8914e-01, -1.3721e-03,  3.1639e-01,  2.3535e-01,
         -7.4147e-02, -1.1158e-01,  1.2964e-01,  1.1753e-01,  4.3348e-01,
         -1.0602e-01],
        [ 3.6685e-01,  2.4680e-01,  4.0664e-01, -1.8407e-01, -5.9881e-02,
         -2.0971e-01, -1.8783e-01, -2.4168e-01, -2.9846e-01, -3.3005e-02,
         -4.6539e-02,  6.6175e-02, -3.6100e-01,  2.0524e-01, -3.0106e-01,
          1.6348e-01],
        [-5.7947e-02,  3.6353e-01,  3.6223e-01, -3.6128e-01, -3.4931e-01,
         -3.0046e-01, -1.0502e-01, -2.7570e-01, -2.4577e-01, -2.2946e-01,
         -9.4922e-02,  4.1675e-02, -4.2185e-02, -9.4807e-02, -1.2621e-01,
          3.7224e-01],
        [ 3.2866e-02,  3.5687e-01,  3.0278e-01, -2.4522e-01, -5.2136e-02,
         -3.4630e-01, -1.5954e-01, -1.0219e-01,  1.0301e-02, -3.2016e-01,
         -2.8508e-01,  5.5364e-02, -4.2008e-01,  1.5913e-01, -2.9634e-01,
          1.0877e-01],
        [-3.0079e-01, -1.6654e-01, -1.1182e-01,  8.3493e-04,  9.3578e-02,
          1.7053e-01,  7.6113e-02,  2.5974e-01,  3.2279e-01,  1.9380e-02,
          3.6616e-01, -2.5154e-02,  1.2020e-01, -9.4625e-02,  2.0532e-01,
         -2.2885e-01],
        [-3.7019e-01,  1.4475e-02, -7.8113e-02, -1.8520e-02, -2.7059e-02,
          4.4385e-01,  2.6487e-01,  1.5206e-01,  4.1273e-01,  2.8171e-01,
          2.2868e-01, -1.8831e-02,  1.9848e-01,  1.0013e-01,  2.6512e-02,
         -3.6296e-01],
        [-1.3980e-01, -2.0388e-01, -3.9154e-02,  1.0114e-01,  1.9012e-01,
          1.3800e-01,  3.9021e-01,  1.7108e-01,  2.1466e-01,  3.7178e-01,
          4.1065e-01,  4.5803e-02, -5.6524e-02, -2.6435e-01,  4.1499e-02,
         -2.3641e-01],
        [ 3.3521e-01,  2.9162e-01,  1.6783e-01, -1.7334e-01, -1.0643e-01,
          2.2256e-02, -8.8447e-02, -3.2986e-01, -3.6502e-01, -1.1748e-01,
         -1.7832e-01,  4.1196e-02, -4.3833e-01,  1.5680e-01, -2.4901e-01,
          5.3317e-02],
        [ 2.0937e-01,  4.0220e-01,  3.7131e-01, -1.3180e-02, -3.1477e-01,
         -2.3817e-02, -4.1218e-02, -7.7512e-02, -2.5047e-01, -1.7511e-01,
         -2.8245e-01,  1.1332e-01, -2.0349e-01,  5.9350e-02, -3.3176e-01,
          2.5408e-01],
        [-3.7872e-01, -3.5514e-01, -7.3382e-02, -3.2693e-02,  3.7474e-01,
          4.0666e-01,  1.1459e-01,  1.2811e-01,  1.6801e-02,  1.9800e-01,
          1.9393e-01, -3.1740e-01,  2.5706e-01, -1.1516e-01,  7.1820e-02,
         -1.8294e-01],
        [-5.0232e-02,  9.9522e-03,  2.1673e-01,  5.6323e-02, -3.7383e-01,
         -4.3906e-02, -2.3260e-01, -3.5370e-01, -3.0917e-01, -1.0232e-01,
         -1.5420e-01,  4.5971e-01, -3.0088e-01, -1.5647e-02,  7.1960e-03,
          1.2964e-01],
        [ 3.2988e-01,  3.3017e-01,  2.1638e-01, -3.6721e-01, -3.8543e-01,
         -6.1070e-02, -1.2149e-01, -3.1314e-02, -4.2423e-01, -2.1478e-01,
          6.5914e-02,  3.1405e-01,  3.1200e-02,  3.0240e-01, -1.4546e-01,
          4.5275e-03],
        [-3.0067e-01, -6.2900e-02, -2.5306e-01,  1.4859e-01,  1.4681e-01,
          3.0953e-01,  3.0279e-01,  2.9003e-01,  1.9022e-01,  3.0281e-01,
          1.3312e-02, -2.5826e-01,  1.1545e-01, -2.1803e-01,  2.9946e-01,
         -1.9522e-01],
        [ 2.2559e-01,  1.5273e-01,  1.4363e-01, -2.8180e-01, -2.1929e-01,
         -3.7460e-01, -3.2496e-01,  3.5572e-03, -5.0596e-01, -1.2490e-01,
         -1.1766e-01, -5.9510e-02, -1.4732e-01,  2.9313e-01, -5.5751e-02,
          2.0963e-01],
        [ 3.7487e-01,  1.8142e-01,  2.7655e-01, -9.7558e-02, -3.1562e-01,
         -2.3335e-01, -3.6572e-01,  2.0986e-02, -9.2387e-02, -2.9379e-01,
         -1.7498e-01,  2.5175e-01, -4.0529e-01,  1.0938e-01,  3.0614e-02,
          2.1881e-01],
        [-1.9032e-01,  3.0652e-05, -5.9436e-02, -5.9489e-02,  2.9074e-01,
         -2.0493e-02,  3.2274e-01,  3.8724e-01,  2.3378e-01,  9.3705e-02,
          1.1953e-02, -2.9280e-01,  1.2998e-01, -2.1102e-01,  3.9954e-01,
         -2.8019e-01],
        [-7.8661e-02, -4.0808e-01, -5.5769e-02,  3.9492e-01, -1.6832e-02,
          1.1694e-01,  2.6863e-01, -5.0446e-02,  6.8938e-02,  2.7857e-01,
          4.0124e-01, -2.6520e-01,  1.8486e-01, -3.6942e-01, -6.8306e-02,
          2.8863e-02],
        [ 3.6895e-01,  8.0427e-02,  6.0086e-02, -1.7138e-01, -2.5170e-03,
         -3.9943e-01, -3.0762e-01, -2.3518e-01, -2.9738e-01, -1.7267e-01,
          5.3002e-02,  2.1689e-01, -3.9330e-01,  3.1899e-01,  8.8747e-02,
          2.4206e-01],
        [ 2.6249e-01,  2.3604e-01,  3.4944e-01, -3.7651e-01, -2.4571e-01,
         -1.7665e-01, -1.8871e-01, -2.9608e-01, -3.9782e-01, -3.4191e-01,
         -1.4029e-01,  3.5383e-01,  1.1964e-02,  1.3302e-01, -1.9150e-01,
          4.5217e-02],
        [ 2.2470e-01, -4.3269e-02,  1.8541e-01, -1.3800e-01,  3.5072e-02,
         -2.8420e-01,  1.1312e-02, -2.1174e-01, -4.3439e-01,  2.3013e-02,
          3.9372e-02,  3.0192e-02, -3.6172e-01,  2.6396e-01, -3.4048e-01,
          3.7587e-01],
        [ 5.1073e-02,  8.7871e-02,  9.8690e-02,  6.9102e-02, -2.3122e-01,
         -2.1651e-01, -4.0743e-02, -3.4911e-01, -2.1829e-01, -3.7360e-01,
         -3.6688e-01,  1.2386e-01, -1.5556e-01,  3.2214e-01, -4.0446e-01,
          1.0766e-01],
        [ 2.3058e-01,  2.5510e-01,  3.1228e-01, -3.5975e-01, -1.8801e-01,
         -1.0813e-01, -3.7402e-01, -3.6530e-02, -4.3659e-01, -1.7286e-02,
         -6.0492e-02,  9.9665e-02, -8.7609e-02,  3.0648e-01,  9.6168e-02,
          3.2162e-01],
        [-3.2658e-01, -1.0261e-01,  6.4962e-03,  2.1618e-01,  3.1432e-01,
          2.9862e-02,  3.8126e-01,  1.7573e-01, -1.1885e-02,  1.2267e-01,
          3.8130e-01, -2.7650e-01,  1.4273e-01, -2.2092e-01, -6.4859e-03,
         -1.4246e-01],
        [ 3.1763e-01,  1.9577e-01,  1.5302e-01, -1.4708e-01, -3.1628e-01,
         -3.0085e-01, -1.6851e-01, -3.6224e-01, -7.2014e-02, -1.3611e-01,
         -1.0798e-01,  1.5640e-01,  2.8964e-02,  3.3172e-01, -6.3037e-03,
          2.9730e-01],
        [-2.6987e-01, -4.2995e-02, -3.1976e-01,  2.5383e-01, -7.3209e-02,
          1.4708e-01,  3.4162e-01,  3.0849e-01,  3.9697e-01,  2.4377e-01,
          2.2852e-01, -8.5393e-02,  3.2877e-01,  6.1354e-02,  1.4517e-01,
         -2.4061e-01],
        [-3.0234e-01, -2.3528e-01, -6.2476e-02,  3.7060e-02,  2.1536e-01,
          4.0596e-01,  4.0792e-01,  1.4814e-03,  2.8797e-01,  3.5307e-01,
         -8.2675e-02, -3.3809e-02,  3.4497e-02, -2.9797e-01,  3.2701e-02,
         -2.8134e-01],
        [ 4.8083e-02,  2.3155e-01,  2.4758e-01, -4.6956e-02,  4.3001e-03,
         -3.1530e-01, -4.1480e-01, -3.7525e-01, -3.7917e-01, -2.7987e-01,
         -3.9770e-02, -7.8480e-03, -3.5811e-01,  2.7032e-01, -2.5979e-01,
          2.0410e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0682, -0.0187, -0.0134, -0.0339,  0.0123, -0.2351,  0.0967,  0.1224,
        -0.0567, -0.0053,  0.0445,  0.0778,  0.1327,  0.0734,  0.0650, -0.0217,
        -0.0185, -0.0390,  0.0832, -0.0327, -0.1042, -0.0700, -0.0315,  0.0364,
        -0.0373,  0.1319,  0.1583,  0.0476, -0.0999, -0.1810,  0.0239,  0.0225],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2190,  0.3127, -0.2294, -0.2607,  0.3041,  0.3599, -0.2826, -0.3750,
         -0.3230,  0.3418,  0.2659,  0.3778, -0.2654, -0.3977,  0.2857, -0.2394,
         -0.3212,  0.3335, -0.2318, -0.2379,  0.4034,  0.3184, -0.3731, -0.3767,
         -0.2883, -0.3319, -0.3204,  0.3444, -0.3515,  0.3821,  0.3032, -0.2372]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0061,  0.1150,  0.0699,  ...,  0.1972, -0.3100, -0.1137],
        [-0.0748, -0.0647,  0.1197,  ...,  0.1020, -0.2866,  0.0871],
        [-0.1077,  0.1586,  0.0931,  ...,  0.1984,  0.0276,  0.0345],
        ...,
        [ 0.0978, -0.1214, -0.0372,  ..., -0.1704, -0.0247, -0.1180],
        [ 0.0398, -0.1850, -0.0411,  ..., -0.2614,  0.0921,  0.1557],
        [-0.1854,  0.1358,  0.0512,  ...,  0.0706, -0.2439, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0534,  0.0307, -0.0953, -0.1551, -0.0813, -0.0078, -0.1020,  0.0406,
        -0.0327,  0.0577,  0.0279, -0.0028,  0.0082,  0.1021, -0.0440, -0.0122,
         0.0478, -0.1664,  0.0043,  0.0822, -0.0623,  0.0180,  0.1111,  0.0234,
        -0.1106,  0.0985,  0.0443, -0.0981,  0.0457,  0.2038,  0.1689, -0.1285],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0525, -0.1636, -0.1868,  ...,  0.0357, -0.0453,  0.0657],
        [-0.2173, -0.0151, -0.0175,  ...,  0.1388, -0.0288,  0.0488],
        [ 0.1477, -0.0499, -0.0398,  ..., -0.1415,  0.0031,  0.1865],
        ...,
        [ 0.1414,  0.0582,  0.2071,  ...,  0.1042, -0.1761,  0.2451],
        [-0.0144, -0.1366, -0.0450,  ...,  0.2396,  0.2143, -0.1728],
        [-0.0025, -0.1096,  0.1287,  ...,  0.2223,  0.1269, -0.0444]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1010,  0.1483, -0.0468, -0.1003, -0.1073, -0.1764, -0.0638, -0.0268,
         0.1410, -0.1698,  0.1328, -0.1275,  0.1983,  0.0927, -0.1093,  0.1234,
        -0.1369, -0.1790,  0.0771,  0.0109, -0.0154,  0.0810, -0.2080,  0.2179,
        -0.0453, -0.0100,  0.0760, -0.0415, -0.1508, -0.0594,  0.1235,  0.0306],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3777,  0.3014, -0.3406, -0.3715, -0.2252, -0.2199, -0.2857,  0.2523,
          0.2788, -0.2956, -0.2482,  0.2636,  0.2728,  0.2291,  0.2888,  0.2717,
         -0.3696, -0.3755,  0.2217,  0.2669, -0.3274, -0.2776, -0.3793,  0.2247,
          0.3419,  0.3940, -0.3497,  0.3663, -0.2860, -0.3742,  0.3388,  0.3789]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1330], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.2643e-02,  3.5403e-01,  3.2341e-01, -3.4654e-01, -2.5887e-02,
         -1.7842e-01, -6.7627e-02, -3.8978e-01, -1.7640e-01, -8.5375e-02,
          2.8090e-02,  1.7499e-01,  5.9403e-02, -5.2480e-02,  3.1653e-01,
          3.6467e-01],
        [-2.7655e-01, -3.3861e-01, -1.2825e-01,  1.3997e-02, -1.6009e-01,
          2.8577e-01,  1.8925e-01,  1.6928e-01,  4.0071e-01,  1.3560e-01,
          2.2191e-01, -2.7354e-01,  5.4293e-04, -4.5039e-02,  6.0523e-04,
         -8.4581e-02],
        [ 9.9976e-02,  2.4810e-01,  4.0288e-01, -1.4017e-01,  1.4183e-01,
         -3.7495e-01, -6.4855e-02, -4.1271e-01,  5.4022e-02, -8.2660e-02,
         -9.6342e-02, -6.1556e-02,  3.9486e-01,  3.0999e-01,  4.3325e-01,
          2.6624e-01],
        [ 2.9241e-01,  6.8647e-02,  1.0717e-01, -9.2194e-02,  9.9954e-02,
         -2.3071e-01, -1.7148e-01, -9.7559e-02, -4.0762e-01, -4.0336e-01,
         -1.0736e-01,  3.6645e-01,  2.8433e-01, -1.2786e-01,  1.4086e-01,
          1.6027e-01],
        [-1.1691e-01,  1.2129e-01, -1.9010e-01, -3.4231e-03,  5.4496e-02,
          1.2379e-01,  6.6884e-02,  3.4830e-01,  1.6050e-01,  2.9254e-01,
          2.3104e-01, -1.9094e-01, -5.3905e-02, -2.2596e-01, -8.3085e-02,
         -1.3740e-01],
        [-2.1765e-02,  1.4635e-01, -3.7586e-01,  4.1266e-01,  1.6131e-01,
          4.2743e-03,  2.7556e-01, -1.9909e-02,  2.5258e-01,  2.0555e-01,
         -1.3836e-01, -9.8577e-02, -2.4808e-01,  1.3291e-01,  3.3425e-02,
         -7.0274e-02],
        [ 3.9399e-01,  2.0226e-01,  4.3331e-01, -2.0349e-01,  1.2920e-01,
         -2.5100e-01, -2.1148e-01, -2.3907e-01, -2.5092e-01, -2.8834e-02,
         -2.0662e-02,  6.6378e-02, -3.3686e-02,  2.2939e-01, -1.1941e-02,
          1.6289e-01],
        [-4.4357e-02,  3.1568e-01,  3.7529e-01, -3.6285e-01, -1.4629e-01,
         -3.3124e-01, -1.0903e-01, -2.4670e-01, -1.7885e-01, -2.1502e-01,
         -7.2992e-02,  2.1328e-02,  2.5382e-01, -8.4118e-02,  1.6094e-01,
          3.6552e-01],
        [ 5.7028e-02,  3.0542e-01,  3.2659e-01, -2.6962e-01,  3.1673e-02,
         -3.8313e-01, -1.8399e-01, -1.1209e-01,  4.1142e-02, -3.1534e-01,
         -1.1388e-01,  7.6239e-02, -8.1970e-02,  1.4186e-01,  1.3897e-02,
          9.6414e-02],
        [-3.0618e-01, -8.4431e-02, -1.1712e-01,  2.6492e-03, -4.2152e-02,
          1.8946e-01,  6.7032e-02,  2.5256e-01,  2.7250e-01, -6.7876e-03,
          2.3829e-01, -2.5199e-02, -2.6158e-01, -6.7519e-02, -1.8645e-01,
         -1.8917e-01],
        [-3.6914e-01,  7.0953e-02, -8.0088e-02, -2.6529e-02, -1.7631e-01,
          4.5504e-01,  2.4528e-01,  1.1954e-01,  3.3737e-01,  2.4929e-01,
          6.8690e-02,  7.7086e-03, -1.6042e-01,  1.3452e-01, -3.8789e-01,
         -3.3124e-01],
        [-1.4523e-01, -1.4560e-01, -4.4312e-02,  1.0604e-01,  1.1223e-01,
          1.5298e-01,  3.8902e-01,  1.6193e-01,  1.7003e-01,  3.4504e-01,
          1.5585e-01,  4.7105e-02, -4.0085e-01, -2.0246e-01, -2.5868e-01,
         -2.0072e-01],
        [ 3.6776e-01,  2.2113e-01,  2.0267e-01, -2.0400e-01,  7.4966e-02,
         -2.7673e-02, -1.1418e-01, -3.3840e-01, -3.4101e-01, -1.2254e-01,
         -1.2259e-01,  4.5576e-02, -2.4002e-02,  1.9519e-01,  1.7065e-01,
          3.6308e-02],
        [ 2.3743e-01,  3.5481e-01,  3.9779e-01, -3.5041e-02, -1.7864e-01,
         -6.3760e-02, -7.3430e-02, -8.7407e-02, -2.2327e-01, -1.7367e-01,
         -2.1634e-01,  1.2826e-01,  1.3236e-01,  7.2604e-02, -3.4359e-02,
          2.5156e-01],
        [-3.9586e-01, -3.0400e-01, -9.1082e-02, -2.6731e-02,  2.0386e-01,
          4.4589e-01,  1.2010e-01,  1.2108e-01, -3.7190e-02,  1.8568e-01,
          1.2918e-01, -3.1586e-01, -8.5354e-02, -1.1841e-01, -2.8211e-01,
         -1.7108e-01],
        [-8.7902e-02, -1.5564e-01,  1.7944e-01,  8.9680e-02, -2.0002e-01,
         -1.6854e-02, -1.5567e-01, -2.9368e-01, -1.6869e-01, -8.9442e-03,
          1.0094e-02,  4.3131e-01,  1.1744e-01, -9.4592e-02,  4.1399e-01,
          2.8877e-02],
        [ 3.3314e-01,  2.7386e-01,  2.2018e-01, -3.6777e-01, -2.0659e-01,
         -7.1263e-02, -1.2147e-01, -2.4406e-03, -3.5739e-01, -1.8833e-01,
          1.3717e-01,  2.8921e-01,  3.4598e-01,  2.8626e-01,  1.2745e-01,
         -1.6545e-02],
        [-3.1641e-01, -2.1606e-02, -2.6787e-01,  1.5568e-01, -1.2432e-02,
          3.3746e-01,  3.1240e-01,  2.7714e-01,  1.3442e-01,  2.8732e-01,
         -3.5489e-02, -2.4852e-01, -1.6720e-01, -2.2364e-01,  4.2099e-02,
         -1.8749e-01],
        [ 2.5221e-01,  1.3268e-01,  1.7792e-01, -3.1369e-01, -6.7134e-03,
         -4.1344e-01, -3.0915e-01,  2.9409e-02, -3.8899e-01, -1.3805e-01,
         -4.5112e-02, -7.9643e-02,  1.9488e-01,  2.5905e-01,  3.7128e-01,
          2.0992e-01],
        [ 3.9037e-01,  1.4007e-01,  2.9345e-01, -1.0758e-01, -1.7045e-01,
         -2.6605e-01, -3.7416e-01,  3.2747e-02, -3.5992e-02, -2.8019e-01,
         -6.9690e-02,  2.4695e-01, -7.6933e-02,  1.0715e-01,  3.2809e-01,
          2.0842e-01],
        [-2.0182e-01,  7.6654e-02, -6.9615e-02, -5.0586e-02,  1.5207e-01,
          1.8536e-03,  3.3122e-01,  3.9583e-01,  1.9340e-01,  7.4782e-02,
         -7.0724e-02, -3.0422e-01, -2.0369e-01, -2.0577e-01,  4.4682e-02,
         -2.5391e-01],
        [-8.0759e-02, -3.4075e-01, -5.9674e-02,  3.9025e-01, -1.5407e-01,
          1.3885e-01,  2.5238e-01, -7.0394e-02,  6.5138e-03,  2.5386e-01,
          2.5355e-01, -2.5630e-01, -1.5098e-01, -3.3964e-01, -4.4789e-01,
          5.9658e-02],
        [ 3.7682e-01,  3.4561e-02,  6.8481e-02, -1.6931e-01,  1.6094e-01,
         -4.2206e-01, -3.0849e-01, -2.0903e-01, -2.2998e-01, -1.5237e-01,
          1.1721e-01,  1.9915e-01, -1.1183e-01,  3.1181e-01,  3.7848e-01,
          2.2774e-01],
        [ 2.7624e-01,  2.0282e-01,  3.6181e-01, -3.8238e-01, -8.6889e-02,
         -2.0095e-01, -2.0302e-01, -2.6934e-01, -3.4235e-01, -3.2592e-01,
         -1.0553e-01,  3.3517e-01,  2.5413e-01,  1.4746e-01,  6.1067e-03,
          4.3385e-02],
        [ 2.2837e-01, -1.3485e-01,  1.9108e-01, -1.4450e-01,  1.9166e-01,
         -2.9012e-01,  2.2663e-02, -1.9211e-01, -3.6651e-01,  5.5966e-02,
          1.6875e-01,  1.7041e-02,  5.0077e-02,  2.3501e-01,  7.6201e-02,
          3.2993e-01],
        [ 7.3085e-02,  1.5487e-02,  1.2098e-01,  5.4992e-02, -8.0032e-02,
         -2.6263e-01, -5.5936e-02, -3.6412e-01, -1.8399e-01, -3.6515e-01,
         -2.9514e-01,  1.4197e-01,  1.9811e-01,  3.3260e-01, -2.0503e-02,
          8.6241e-02],
        [ 2.3448e-01,  2.0949e-01,  3.1767e-01, -3.5741e-01, -1.9934e-03,
         -1.2561e-01, -3.7484e-01,  1.7441e-03, -3.5896e-01,  6.1423e-03,
          3.8960e-04,  7.0967e-02,  1.9894e-01,  2.9891e-01,  3.6528e-01,
          3.0697e-01],
        [-3.3438e-01, -4.0422e-02, -5.6158e-04,  2.1771e-01,  1.9989e-01,
          5.0059e-02,  3.7882e-01,  1.6928e-01, -5.9148e-02,  9.8189e-02,
          2.1966e-01, -2.7447e-01, -2.0824e-01, -1.8820e-01, -3.4161e-01,
         -1.1128e-01],
        [ 3.2257e-01,  1.4686e-01,  1.5819e-01, -1.4205e-01, -1.8133e-01,
         -3.1976e-01, -1.6277e-01, -3.4175e-01, -1.1207e-02, -1.1160e-01,
          2.5106e-04,  1.4143e-01,  3.1278e-01,  3.0883e-01,  2.9869e-01,
          2.7641e-01],
        [-2.8706e-01, -1.9656e-03, -3.3622e-01,  2.6176e-01, -2.3758e-01,
          1.7887e-01,  3.5316e-01,  2.9247e-01,  3.4114e-01,  2.3170e-01,
          1.8799e-01, -7.6069e-02,  5.1189e-02,  4.9269e-02, -1.0406e-01,
         -2.3564e-01],
        [-3.0280e-01, -1.8243e-01, -6.5182e-02,  3.3278e-02,  5.1569e-02,
          4.1660e-01,  3.9947e-01, -3.1386e-02,  2.1393e-01,  3.2461e-01,
         -1.8879e-01, -8.8054e-03, -2.8637e-01, -2.6939e-01, -3.0140e-01,
         -2.5725e-01],
        [ 8.6737e-02,  2.0940e-01,  2.8816e-01, -9.1046e-02,  1.7962e-01,
         -3.6107e-01, -4.3791e-01, -3.7833e-01, -3.0121e-01, -2.9747e-01,
          2.7441e-02, -1.0601e-03, -1.2093e-02,  2.6554e-01,  5.1268e-02,
          2.1489e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0969, -0.0577,  0.1828, -0.0287, -0.0835, -0.0387,  0.0716,  0.0617,
        -0.0269, -0.0561, -0.0299,  0.0561,  0.1261,  0.0988, -0.0148,  0.0003,
        -0.1425,  0.0236,  0.1155,  0.0172, -0.0221, -0.1749, -0.0134, -0.0498,
        -0.0403,  0.2257,  0.1226,  0.0196, -0.0502, -0.1476,  0.0161,  0.0291],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1941,  0.2853, -0.2108, -0.2423,  0.2649,  0.3152, -0.2625, -0.3650,
         -0.2880,  0.3057,  0.2478,  0.3596, -0.2217, -0.3638,  0.2849, -0.1526,
         -0.2832,  0.3237, -0.2150, -0.2295,  0.3419,  0.3409, -0.3604, -0.3663,
         -0.2607, -0.2917, -0.3063,  0.3267, -0.3499,  0.3717,  0.2848, -0.2236]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0108, -0.0031,  0.0258,  ...,  0.2090, -0.3525, -0.1137],
        [-0.0818, -0.1898,  0.0829,  ...,  0.1452, -0.3292,  0.0871],
        [-0.0542,  0.1576,  0.0910,  ...,  0.0108,  0.2356,  0.0345],
        ...,
        [ 0.0420, -0.1559,  0.0128,  ...,  0.0671, -0.2800, -0.1180],
        [ 0.0345, -0.0703,  0.0060,  ..., -0.3028,  0.1276,  0.1557],
        [-0.0852,  0.1613,  0.0122,  ..., -0.1724,  0.0630, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0510,  0.0540, -0.0928, -0.1205, -0.0577,  0.0458, -0.1290,  0.0620,
        -0.0463,  0.0922,  0.0329,  0.0082,  0.0095,  0.0630, -0.0783, -0.0203,
         0.0465, -0.1422, -0.0324, -0.0152, -0.1095,  0.0477,  0.0820, -0.0064,
        -0.0850,  0.0666,  0.0242, -0.0960,  0.0640,  0.1472,  0.1369, -0.0658],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0381, -0.1962, -0.0807,  ..., -0.1400, -0.0156,  0.2627],
        [-0.2363, -0.0449,  0.1046,  ..., -0.0705, -0.0025,  0.2713],
        [ 0.1651, -0.0194, -0.1763,  ...,  0.0830, -0.0240, -0.0687],
        ...,
        [ 0.1521,  0.1117,  0.0816,  ...,  0.2632, -0.2225,  0.0551],
        [-0.0532, -0.1738,  0.0765,  ...,  0.0025,  0.2494,  0.0864],
        [-0.0185, -0.1218,  0.2112,  ...,  0.0511,  0.1399,  0.1316]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0870,  0.1225, -0.0353, -0.0548, -0.0311, -0.0352, -0.0325, -0.0624,
         0.1100, -0.1752,  0.1224, -0.1328,  0.1652, -0.0187, -0.1429,  0.1054,
        -0.1272, -0.1539,  0.0136, -0.0295,  0.0086,  0.1086, -0.1892,  0.2026,
        -0.0698, -0.0287,  0.0881, -0.0374, -0.1122, -0.0601,  0.1110,  0.0009],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5161,  0.4404, -0.5185, -0.5218,  0.3667,  0.3748, -0.4229,  0.4316,
          0.4316, -0.4544, -0.4445,  0.4054,  0.4276, -0.3685,  0.4485,  0.3969,
         -0.5264, -0.5176,  0.3945,  0.4117, -0.4795, -0.4525, -0.5160,  0.3515,
          0.4907,  0.5172, -0.4911,  0.5591, -0.4267, -0.5085,  0.4932,  0.5083]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2380], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.2642e-02,  3.5403e-01,  3.2341e-01, -3.4654e-01, -2.5888e-02,
         -1.7842e-01, -6.7627e-02, -3.8978e-01, -1.7640e-01, -8.5375e-02,
          2.8090e-02,  1.7499e-01,  5.9403e-02, -5.2481e-02,  3.1653e-01,
          3.6467e-01],
        [-2.7655e-01, -3.3861e-01, -1.2824e-01,  1.3996e-02, -1.6009e-01,
          2.8577e-01,  1.8925e-01,  1.6928e-01,  4.0071e-01,  1.3560e-01,
          2.2191e-01, -2.7354e-01,  5.4242e-04, -4.5038e-02,  6.0530e-04,
         -8.4581e-02],
        [ 9.9976e-02,  2.4810e-01,  4.0288e-01, -1.4017e-01,  1.4183e-01,
         -3.7495e-01, -6.4855e-02, -4.1271e-01,  5.4022e-02, -8.2659e-02,
         -9.6342e-02, -6.1556e-02,  3.9486e-01,  3.0999e-01,  4.3325e-01,
          2.6623e-01],
        [ 2.9241e-01,  6.8646e-02,  1.0717e-01, -9.2194e-02,  9.9953e-02,
         -2.3071e-01, -1.7148e-01, -9.7560e-02, -4.0762e-01, -4.0336e-01,
         -1.0736e-01,  3.6645e-01,  2.8433e-01, -1.2786e-01,  1.4086e-01,
          1.6027e-01],
        [-1.1691e-01,  1.2130e-01, -1.9010e-01, -3.4235e-03,  5.4497e-02,
          1.2379e-01,  6.6884e-02,  3.4831e-01,  1.6050e-01,  2.9254e-01,
          2.3104e-01, -1.9094e-01, -5.3906e-02, -2.2596e-01, -8.3085e-02,
         -1.3740e-01],
        [-2.1765e-02,  1.4635e-01, -3.7586e-01,  4.1266e-01,  1.6131e-01,
          4.2741e-03,  2.7556e-01, -1.9908e-02,  2.5258e-01,  2.0555e-01,
         -1.3836e-01, -9.8578e-02, -2.4808e-01,  1.3291e-01,  3.3425e-02,
         -7.0273e-02],
        [ 3.9399e-01,  2.0226e-01,  4.3331e-01, -2.0349e-01,  1.2920e-01,
         -2.5100e-01, -2.1148e-01, -2.3907e-01, -2.5092e-01, -2.8833e-02,
         -2.0661e-02,  6.6378e-02, -3.3685e-02,  2.2939e-01, -1.1941e-02,
          1.6289e-01],
        [-4.4358e-02,  3.1568e-01,  3.7529e-01, -3.6285e-01, -1.4629e-01,
         -3.3124e-01, -1.0903e-01, -2.4670e-01, -1.7885e-01, -2.1501e-01,
         -7.2991e-02,  2.1328e-02,  2.5382e-01, -8.4118e-02,  1.6094e-01,
          3.6552e-01],
        [ 5.7028e-02,  3.0542e-01,  3.2659e-01, -2.6962e-01,  3.1672e-02,
         -3.8313e-01, -1.8399e-01, -1.1209e-01,  4.1142e-02, -3.1534e-01,
         -1.1388e-01,  7.6240e-02, -8.1970e-02,  1.4186e-01,  1.3897e-02,
          9.6414e-02],
        [-3.0618e-01, -8.4430e-02, -1.1712e-01,  2.6489e-03, -4.2151e-02,
          1.8946e-01,  6.7032e-02,  2.5256e-01,  2.7250e-01, -6.7881e-03,
          2.3829e-01, -2.5200e-02, -2.6158e-01, -6.7519e-02, -1.8645e-01,
         -1.8917e-01],
        [-3.6914e-01,  7.0954e-02, -8.0088e-02, -2.6530e-02, -1.7631e-01,
          4.5504e-01,  2.4528e-01,  1.1954e-01,  3.3737e-01,  2.4929e-01,
          6.8690e-02,  7.7082e-03, -1.6042e-01,  1.3452e-01, -3.8789e-01,
         -3.3124e-01],
        [-1.4523e-01, -1.4560e-01, -4.4311e-02,  1.0604e-01,  1.1223e-01,
          1.5298e-01,  3.8902e-01,  1.6193e-01,  1.7003e-01,  3.4504e-01,
          1.5585e-01,  4.7105e-02, -4.0085e-01, -2.0246e-01, -2.5868e-01,
         -2.0072e-01],
        [ 3.6776e-01,  2.2113e-01,  2.0267e-01, -2.0400e-01,  7.4965e-02,
         -2.7673e-02, -1.1418e-01, -3.3840e-01, -3.4101e-01, -1.2254e-01,
         -1.2259e-01,  4.5576e-02, -2.4002e-02,  1.9519e-01,  1.7065e-01,
          3.6307e-02],
        [ 2.3743e-01,  3.5481e-01,  3.9779e-01, -3.5041e-02, -1.7865e-01,
         -6.3760e-02, -7.3430e-02, -8.7407e-02, -2.2327e-01, -1.7366e-01,
         -2.1634e-01,  1.2826e-01,  1.3236e-01,  7.2604e-02, -3.4360e-02,
          2.5156e-01],
        [-3.9586e-01, -3.0400e-01, -9.1082e-02, -2.6731e-02,  2.0386e-01,
          4.4589e-01,  1.2010e-01,  1.2108e-01, -3.7190e-02,  1.8568e-01,
          1.2918e-01, -3.1586e-01, -8.5354e-02, -1.1841e-01, -2.8211e-01,
         -1.7108e-01],
        [-8.7902e-02, -1.5564e-01,  1.7944e-01,  8.9680e-02, -2.0002e-01,
         -1.6854e-02, -1.5567e-01, -2.9368e-01, -1.6869e-01, -8.9437e-03,
          1.0095e-02,  4.3131e-01,  1.1744e-01, -9.4593e-02,  4.1399e-01,
          2.8876e-02],
        [ 3.3314e-01,  2.7386e-01,  2.2018e-01, -3.6777e-01, -2.0659e-01,
         -7.1263e-02, -1.2147e-01, -2.4411e-03, -3.5739e-01, -1.8833e-01,
          1.3717e-01,  2.8921e-01,  3.4598e-01,  2.8626e-01,  1.2745e-01,
         -1.6546e-02],
        [-3.1641e-01, -2.1606e-02, -2.6787e-01,  1.5568e-01, -1.2432e-02,
          3.3746e-01,  3.1240e-01,  2.7714e-01,  1.3442e-01,  2.8732e-01,
         -3.5490e-02, -2.4852e-01, -1.6720e-01, -2.2364e-01,  4.2099e-02,
         -1.8749e-01],
        [ 2.5221e-01,  1.3268e-01,  1.7791e-01, -3.1369e-01, -6.7139e-03,
         -4.1344e-01, -3.0915e-01,  2.9408e-02, -3.8899e-01, -1.3805e-01,
         -4.5112e-02, -7.9642e-02,  1.9488e-01,  2.5905e-01,  3.7128e-01,
          2.0991e-01],
        [ 3.9037e-01,  1.4007e-01,  2.9345e-01, -1.0758e-01, -1.7046e-01,
         -2.6605e-01, -3.7416e-01,  3.2747e-02, -3.5993e-02, -2.8019e-01,
         -6.9690e-02,  2.4695e-01, -7.6932e-02,  1.0715e-01,  3.2809e-01,
          2.0842e-01],
        [-2.0182e-01,  7.6655e-02, -6.9615e-02, -5.0587e-02,  1.5207e-01,
          1.8535e-03,  3.3122e-01,  3.9583e-01,  1.9340e-01,  7.4782e-02,
         -7.0724e-02, -3.0422e-01, -2.0369e-01, -2.0577e-01,  4.4682e-02,
         -2.5391e-01],
        [-8.0759e-02, -3.4075e-01, -5.9673e-02,  3.9025e-01, -1.5406e-01,
          1.3885e-01,  2.5238e-01, -7.0394e-02,  6.5139e-03,  2.5386e-01,
          2.5355e-01, -2.5630e-01, -1.5098e-01, -3.3964e-01, -4.4788e-01,
          5.9659e-02],
        [ 3.7682e-01,  3.4560e-02,  6.8481e-02, -1.6930e-01,  1.6094e-01,
         -4.2206e-01, -3.0849e-01, -2.0903e-01, -2.2998e-01, -1.5237e-01,
          1.1721e-01,  1.9915e-01, -1.1183e-01,  3.1181e-01,  3.7848e-01,
          2.2774e-01],
        [ 2.7624e-01,  2.0282e-01,  3.6181e-01, -3.8238e-01, -8.6890e-02,
         -2.0095e-01, -2.0302e-01, -2.6934e-01, -3.4235e-01, -3.2592e-01,
         -1.0553e-01,  3.3517e-01,  2.5413e-01,  1.4746e-01,  6.1066e-03,
          4.3384e-02],
        [ 2.2837e-01, -1.3485e-01,  1.9108e-01, -1.4450e-01,  1.9166e-01,
         -2.9012e-01,  2.2663e-02, -1.9211e-01, -3.6651e-01,  5.5966e-02,
          1.6875e-01,  1.7041e-02,  5.0077e-02,  2.3501e-01,  7.6201e-02,
          3.2993e-01],
        [ 7.3085e-02,  1.5486e-02,  1.2098e-01,  5.4993e-02, -8.0033e-02,
         -2.6262e-01, -5.5936e-02, -3.6412e-01, -1.8399e-01, -3.6515e-01,
         -2.9514e-01,  1.4198e-01,  1.9811e-01,  3.3260e-01, -2.0503e-02,
          8.6241e-02],
        [ 2.3448e-01,  2.0949e-01,  3.1767e-01, -3.5741e-01, -1.9939e-03,
         -1.2561e-01, -3.7484e-01,  1.7437e-03, -3.5896e-01,  6.1426e-03,
          3.8992e-04,  7.0968e-02,  1.9894e-01,  2.9891e-01,  3.6528e-01,
          3.0697e-01],
        [-3.3437e-01, -4.0421e-02, -5.6121e-04,  2.1771e-01,  1.9989e-01,
          5.0059e-02,  3.7882e-01,  1.6928e-01, -5.9147e-02,  9.8189e-02,
          2.1966e-01, -2.7447e-01, -2.0824e-01, -1.8820e-01, -3.4161e-01,
         -1.1128e-01],
        [ 3.2257e-01,  1.4686e-01,  1.5819e-01, -1.4205e-01, -1.8133e-01,
         -3.1976e-01, -1.6277e-01, -3.4175e-01, -1.1207e-02, -1.1160e-01,
          2.5147e-04,  1.4143e-01,  3.1278e-01,  3.0883e-01,  2.9869e-01,
          2.7641e-01],
        [-2.8706e-01, -1.9649e-03, -3.3622e-01,  2.6176e-01, -2.3758e-01,
          1.7887e-01,  3.5316e-01,  2.9247e-01,  3.4114e-01,  2.3170e-01,
          1.8799e-01, -7.6069e-02,  5.1189e-02,  4.9269e-02, -1.0406e-01,
         -2.3564e-01],
        [-3.0280e-01, -1.8242e-01, -6.5182e-02,  3.3277e-02,  5.1570e-02,
          4.1660e-01,  3.9947e-01, -3.1386e-02,  2.1393e-01,  3.2461e-01,
         -1.8879e-01, -8.8057e-03, -2.8637e-01, -2.6939e-01, -3.0140e-01,
         -2.5725e-01],
        [ 8.6737e-02,  2.0940e-01,  2.8816e-01, -9.1045e-02,  1.7962e-01,
         -3.6107e-01, -4.3791e-01, -3.7833e-01, -3.0121e-01, -2.9747e-01,
          2.7442e-02, -1.0598e-03, -1.2092e-02,  2.6554e-01,  5.1268e-02,
          2.1489e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0969, -0.0577,  0.1828, -0.0287, -0.0835, -0.0387,  0.0716,  0.0617,
        -0.0269, -0.0561, -0.0299,  0.0561,  0.1261,  0.0988, -0.0148,  0.0003,
        -0.1425,  0.0236,  0.1155,  0.0172, -0.0221, -0.1749, -0.0134, -0.0498,
        -0.0403,  0.2257,  0.1226,  0.0196, -0.0502, -0.1476,  0.0161,  0.0291],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1941,  0.2853, -0.2108, -0.2423,  0.2649,  0.3152, -0.2625, -0.3650,
         -0.2880,  0.3057,  0.2478,  0.3596, -0.2217, -0.3638,  0.2849, -0.1526,
         -0.2832,  0.3237, -0.2150, -0.2295,  0.3419,  0.3409, -0.3604, -0.3663,
         -0.2607, -0.2917, -0.3063,  0.3267, -0.3499,  0.3717,  0.2848, -0.2236]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0108, -0.0031,  0.0258,  ...,  0.2090, -0.3525, -0.1137],
        [-0.0818, -0.1898,  0.0829,  ...,  0.1452, -0.3292,  0.0871],
        [-0.0542,  0.1576,  0.0910,  ...,  0.0108,  0.2356,  0.0345],
        ...,
        [ 0.0420, -0.1559,  0.0128,  ...,  0.0671, -0.2800, -0.1180],
        [ 0.0345, -0.0703,  0.0060,  ..., -0.3028,  0.1276,  0.1557],
        [-0.0852,  0.1613,  0.0122,  ..., -0.1724,  0.0630, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0510,  0.0540, -0.0928, -0.1205, -0.0577,  0.0458, -0.1290,  0.0620,
        -0.0463,  0.0922,  0.0329,  0.0082,  0.0095,  0.0630, -0.0783, -0.0203,
         0.0465, -0.1422, -0.0324, -0.0152, -0.1095,  0.0477,  0.0820, -0.0064,
        -0.0850,  0.0666,  0.0242, -0.0960,  0.0640,  0.1472,  0.1369, -0.0658],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0381, -0.1962, -0.0807,  ..., -0.1400, -0.0156,  0.2627],
        [-0.2363, -0.0449,  0.1046,  ..., -0.0705, -0.0025,  0.2713],
        [ 0.1651, -0.0194, -0.1763,  ...,  0.0830, -0.0240, -0.0687],
        ...,
        [ 0.1521,  0.1117,  0.0816,  ...,  0.2632, -0.2225,  0.0551],
        [-0.0532, -0.1738,  0.0765,  ...,  0.0025,  0.2494,  0.0864],
        [-0.0185, -0.1218,  0.2112,  ...,  0.0511,  0.1399,  0.1316]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0870,  0.1225, -0.0353, -0.0548, -0.0311, -0.0352, -0.0325, -0.0624,
         0.1100, -0.1752,  0.1224, -0.1328,  0.1652, -0.0187, -0.1429,  0.1054,
        -0.1272, -0.1539,  0.0136, -0.0295,  0.0086,  0.1086, -0.1892,  0.2026,
        -0.0698, -0.0287,  0.0881, -0.0374, -0.1122, -0.0601,  0.1110,  0.0009],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5161,  0.4404, -0.5185, -0.5218,  0.3667,  0.3748, -0.4229,  0.4316,
          0.4316, -0.4544, -0.4445,  0.4054,  0.4276, -0.3685,  0.4485,  0.3969,
         -0.5264, -0.5176,  0.3945,  0.4117, -0.4795, -0.4525, -0.5160,  0.3515,
          0.4907,  0.5172, -0.4911,  0.5591, -0.4267, -0.5085,  0.4932,  0.5083]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2380], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 9.5065e-03,  3.6228e-01,  3.2275e-01, -3.1617e-01, -3.1533e-01,
         -2.0219e-01, -9.1668e-02, -4.7778e-01, -2.5367e-01, -8.8335e-02,
         -2.8237e-02,  2.4881e-01,  1.0609e-01, -2.8016e-02,  2.9574e-02,
          3.7100e-01],
        [-2.6135e-01, -3.3895e-01, -1.1604e-01, -1.0561e-02,  6.0735e-02,
          2.8504e-01,  1.9712e-01,  2.2852e-01,  4.5419e-01,  1.5331e-01,
          2.8708e-01, -3.1167e-01, -2.0493e-02, -8.0452e-02,  2.5952e-01,
         -8.3579e-02],
        [ 9.0852e-02,  2.4980e-01,  3.9437e-01, -1.1051e-01, -1.7341e-01,
         -3.8188e-01, -8.2128e-02, -4.9780e-01, -3.2067e-02, -8.6436e-02,
         -1.4017e-01, -5.2944e-03,  4.3500e-01,  3.6883e-01,  1.4100e-01,
          2.6677e-01],
        [ 2.8628e-01,  7.4744e-02,  1.0316e-01, -7.3147e-02, -1.4620e-01,
         -2.3964e-01, -1.9165e-01, -1.7595e-01, -4.9039e-01, -4.2849e-01,
         -1.2243e-01,  4.2510e-01,  3.0963e-01, -7.1832e-02, -1.2675e-01,
          1.6373e-01],
        [-1.0424e-01,  8.3988e-02, -1.8431e-01, -2.9865e-02,  2.5379e-01,
          1.2482e-01,  7.6526e-02,  3.9684e-01,  2.0599e-01,  3.1793e-01,
          3.2253e-01, -2.1436e-01, -7.3311e-02, -2.8096e-01,  1.9341e-01,
         -1.6008e-01],
        [-1.8914e-02,  1.2255e-01, -3.7680e-01,  4.0275e-01,  4.2799e-01,
          1.5317e-02,  2.9677e-01,  4.2399e-02,  3.1541e-01,  2.3710e-01,
         -9.0764e-02, -1.4048e-01, -2.7196e-01,  8.6629e-02,  3.0961e-01,
         -8.4566e-02],
        [ 3.8542e-01,  1.1874e-01,  4.2559e-01, -1.8708e-01, -1.3868e-01,
         -2.5292e-01, -2.1625e-01, -3.1225e-01, -3.2076e-01, -5.0215e-02,
         -5.7035e-02,  1.1761e-01, -3.3876e-02,  2.7150e-01, -1.8775e-01,
          1.6336e-01],
        [-5.0413e-02,  2.6915e-01,  3.6990e-01, -3.5463e-01, -4.0007e-01,
         -3.3046e-01, -1.1483e-01, -3.2243e-01, -2.4962e-01, -2.3597e-01,
         -1.0355e-01,  7.3971e-02,  2.7128e-01, -4.6501e-02,  3.9802e-03,
          3.6391e-01],
        [ 4.7252e-02,  3.0584e-01,  3.1924e-01, -2.4362e-01, -1.3731e-01,
         -3.8885e-01, -2.0127e-01, -1.7617e-01, -1.7468e-02, -3.3770e-01,
         -2.5839e-01,  1.1209e-01, -3.6185e-02,  2.0675e-01, -2.4481e-01,
          1.0056e-01],
        [-3.0072e-01, -1.0822e-01, -1.1618e-01, -1.4242e-02,  1.6748e-01,
          2.0005e-01,  8.8304e-02,  3.1795e-01,  3.3518e-01,  2.5036e-02,
          3.3284e-01, -6.3433e-02, -2.9888e-01, -1.2911e-01,  9.3114e-02,
         -2.0631e-01],
        [-3.7222e-01,  4.5324e-02, -8.5066e-02, -3.2198e-02,  5.6199e-02,
          4.7380e-01,  2.7294e-01,  2.0626e-01,  4.2260e-01,  2.8426e-01,
          1.3564e-01, -5.7553e-02, -1.8694e-01,  6.4339e-02, -7.6394e-02,
         -3.4453e-01],
        [-1.3917e-01, -1.6177e-01, -4.2968e-02,  9.0542e-02,  2.5784e-01,
          1.6379e-01,  4.0725e-01,  2.3048e-01,  2.2891e-01,  3.7655e-01,
          2.5029e-01,  5.5861e-03, -4.0591e-01, -2.8744e-01, -1.3269e-02,
         -2.1457e-01],
        [ 3.5336e-01,  2.5200e-01,  1.9219e-01, -1.7476e-01, -2.4101e-01,
         -3.8665e-02, -1.3794e-01, -4.3679e-01, -4.0908e-01, -1.4461e-01,
         -1.6461e-01,  1.1005e-01, -9.6535e-03,  2.2725e-01, -1.7268e-01,
          4.7160e-02],
        [ 2.2152e-01,  3.3542e-01,  3.8462e-01, -1.3760e-02, -3.8666e-01,
         -5.9251e-02, -7.4413e-02, -1.3873e-01, -2.7209e-01, -1.8964e-01,
         -2.7419e-01,  1.5867e-01,  1.4788e-01,  1.0688e-01, -2.5102e-01,
          2.4800e-01],
        [-3.8781e-01, -2.9896e-01, -8.4433e-02, -4.2429e-02,  4.4912e-01,
          4.4841e-01,  1.3245e-01,  1.9066e-01,  2.9825e-02,  2.0713e-01,
          1.8711e-01, -3.6288e-01, -1.1327e-01, -1.6211e-01, -4.8826e-02,
         -1.7220e-01],
        [-5.9093e-02, -6.9153e-02,  2.1936e-01,  8.9155e-02, -4.4065e-01,
         -8.6482e-02, -2.4085e-01, -4.1802e-01, -2.8993e-01, -9.4677e-02,
         -1.2794e-01,  4.8337e-01,  2.0455e-01,  3.0545e-02,  1.5666e-01,
          8.3090e-02],
        [ 3.2928e-01,  2.7135e-01,  2.1841e-01, -3.5648e-01, -4.4460e-01,
         -8.0507e-02, -1.3951e-01, -7.5992e-02, -4.3046e-01, -2.1570e-01,
          9.7530e-02,  3.4558e-01,  3.8958e-01,  3.3509e-01, -6.9690e-02,
         -1.4127e-02],
        [-3.0749e-01, -9.4416e-03, -2.6099e-01,  1.4393e-01,  2.0400e-01,
          3.3387e-01,  3.1752e-01,  3.3572e-01,  1.9679e-01,  3.0764e-01,
          7.6174e-04, -2.9007e-01, -1.8432e-01, -2.7098e-01,  2.0868e-01,
         -1.8658e-01],
        [ 2.2944e-01,  1.1911e-01,  1.5452e-01, -2.6872e-01, -3.1778e-01,
         -4.1130e-01, -3.1931e-01, -5.6151e-02, -4.7928e-01, -1.2509e-01,
         -1.1048e-01, -2.4922e-02,  2.5981e-01,  3.2026e-01,  9.3978e-02,
          1.9085e-01],
        [ 3.8759e-01,  1.3705e-01,  2.9063e-01, -9.1353e-02, -4.0633e-01,
         -2.7617e-01, -3.9579e-01, -5.2879e-02, -1.1725e-01, -3.0466e-01,
         -1.5041e-01,  3.0789e-01, -3.0748e-02,  1.6312e-01,  9.5445e-02,
          2.1073e-01],
        [-1.9140e-01,  5.1682e-02, -6.3664e-02, -6.7112e-02,  3.4724e-01,
         -2.5842e-03,  3.3681e-01,  4.2311e-01,  2.2763e-01,  9.6140e-02,
         -6.7695e-03, -3.1644e-01, -2.1512e-01, -2.4841e-01,  2.9555e-01,
         -2.6550e-01],
        [-8.2713e-02, -3.3552e-01, -6.2575e-02,  3.7880e-01,  6.2079e-02,
          1.5696e-01,  2.8832e-01,  1.6954e-02,  8.5238e-02,  2.8898e-01,
          3.8247e-01, -3.1136e-01, -2.2102e-01, -4.0897e-01, -1.7616e-01,
          4.8982e-02],
        [ 3.7832e-01,  3.4112e-02,  7.0676e-02, -1.6644e-01, -7.0901e-02,
         -4.3328e-01, -3.3010e-01, -2.9015e-01, -3.0897e-01, -1.8253e-01,
          6.4730e-02,  2.5832e-01, -6.6039e-02,  3.6795e-01,  1.8897e-01,
          2.3328e-01],
        [ 2.6887e-01,  2.0322e-01,  3.5618e-01, -3.7464e-01, -2.9425e-01,
         -1.9706e-01, -2.1084e-01, -3.3817e-01, -4.0920e-01, -3.4539e-01,
         -9.8248e-02,  3.8428e-01,  2.7034e-01,  1.8728e-01, -1.4804e-01,
          3.7854e-02],
        [ 2.2315e-01, -1.0838e-01,  1.9040e-01, -1.2260e-01, -2.7758e-02,
         -3.0328e-01,  2.3731e-03, -2.5344e-01, -4.3073e-01,  2.3775e-02,
          7.1165e-02,  5.9367e-02,  8.8212e-02,  2.9414e-01, -2.2532e-01,
          3.5045e-01],
        [ 5.3239e-02,  3.2185e-02,  1.0502e-01,  8.0199e-02, -2.9707e-01,
         -2.4801e-01, -4.9832e-02, -3.9326e-01, -2.1430e-01, -3.7748e-01,
         -3.5936e-01,  1.5393e-01,  1.9882e-01,  3.6376e-01, -2.8476e-01,
          9.1202e-02],
        [ 2.3493e-01,  1.9829e-01,  3.1834e-01, -3.5261e-01, -2.4878e-01,
         -1.3569e-01, -3.9427e-01, -8.5630e-02, -4.4227e-01, -2.1408e-02,
         -4.2745e-02,  1.3538e-01,  2.4463e-01,  3.4886e-01,  1.8499e-01,
          3.0922e-01],
        [-3.3163e-01, -5.5960e-02, -1.8587e-03,  2.0641e-01,  3.9336e-01,
          6.4590e-02,  4.0216e-01,  2.4667e-01,  9.5077e-03,  1.3249e-01,
          2.9611e-01, -3.2502e-01, -2.4302e-01, -2.5450e-01, -9.2673e-02,
         -1.2583e-01],
        [ 3.1758e-01,  1.6637e-01,  1.5595e-01, -1.3511e-01, -3.7709e-01,
         -3.2614e-01, -1.8015e-01, -4.0992e-01, -7.7219e-02, -1.3727e-01,
         -5.7398e-03,  1.9205e-01,  3.1614e-01,  3.6461e-01,  7.3172e-02,
          2.7950e-01],
        [-2.8435e-01,  2.0438e-02, -3.3425e-01,  2.5653e-01, -8.9792e-03,
          1.8100e-01,  3.6463e-01,  3.6365e-01,  4.1102e-01,  2.5687e-01,
          2.3899e-01, -1.2568e-01,  2.4765e-02,  7.7398e-06,  6.0458e-02,
         -2.3940e-01],
        [-3.0050e-01, -1.8740e-01, -6.4136e-02,  2.2375e-02,  2.7825e-01,
          4.2733e-01,  4.1886e-01,  4.6421e-02,  2.9059e-01,  3.5173e-01,
         -1.2668e-01, -6.5974e-02, -3.3134e-01, -3.2790e-01, -7.8637e-02,
         -2.6096e-01],
        [ 6.9441e-02,  1.7923e-01,  2.7164e-01, -5.0051e-02, -7.6347e-02,
         -3.5930e-01, -4.4178e-01, -4.4970e-01, -3.7646e-01, -2.9442e-01,
         -3.5172e-02,  4.4602e-02,  1.2144e-02,  3.2000e-01, -1.7205e-01,
          2.0558e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0544, -0.0114,  0.1076, -0.0367, -0.0581, -0.0900,  0.0737,  0.0817,
        -0.0196, -0.0574, -0.0055,  0.0591,  0.1467,  0.0792,  0.0198, -0.0499,
        -0.0516, -0.0045,  0.0908,  0.0061, -0.0419, -0.1387, -0.0294,  0.0007,
        -0.0065,  0.1608,  0.1185,  0.0196, -0.0655, -0.1410,  0.0311, -0.0437],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2329,  0.3238, -0.2302, -0.2640,  0.3251,  0.3630, -0.2845, -0.3866,
         -0.3170,  0.3485,  0.2660,  0.3765, -0.2660, -0.4009,  0.3062, -0.2856,
         -0.3231,  0.3343, -0.2307, -0.2527,  0.4023,  0.3147, -0.3741, -0.3812,
         -0.3315, -0.3417, -0.3161,  0.3536, -0.3622,  0.3855,  0.2923, -0.2398]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0137, -0.0092,  0.0435,  ...,  0.2364, -0.3683, -0.1137],
        [-0.0866, -0.1926,  0.0877,  ...,  0.1479, -0.3485,  0.0871],
        [-0.0400,  0.1766,  0.0730,  ..., -0.0053,  0.2683,  0.0345],
        ...,
        [ 0.0257, -0.1912,  0.0424,  ...,  0.0662, -0.2939, -0.1180],
        [ 0.0513, -0.0487, -0.0195,  ..., -0.3045,  0.1539,  0.1557],
        [-0.2049,  0.0492,  0.0021,  ...,  0.0418, -0.2389, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0571,  0.0576, -0.0881, -0.1188, -0.0573,  0.0527, -0.1279,  0.0611,
        -0.0491,  0.0819,  0.0314,  0.0092,  0.0256,  0.0732, -0.0782, -0.0172,
         0.0498, -0.1497, -0.0285, -0.0239, -0.0749,  0.0447,  0.0885, -0.0072,
        -0.0870,  0.0867,  0.0328, -0.0876,  0.0488,  0.1386,  0.1475, -0.1051],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0181, -0.1903, -0.0799,  ..., -0.1162, -0.0285,  0.0709],
        [-0.2653, -0.0443,  0.1159,  ..., -0.0483, -0.0077,  0.0588],
        [ 0.1839, -0.0295, -0.1768,  ...,  0.0540, -0.0079,  0.1670],
        ...,
        [ 0.1660,  0.0965,  0.0893,  ...,  0.2279, -0.1996,  0.2420],
        [-0.0788, -0.1641,  0.0782,  ...,  0.0325,  0.2358, -0.1654],
        [-0.0488, -0.1251,  0.2159,  ...,  0.0713,  0.1335, -0.0319]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0830,  0.1209, -0.0224, -0.0583, -0.0349, -0.0633, -0.0254, -0.0603,
         0.0939, -0.1342,  0.1356, -0.1274,  0.1510,  0.0569, -0.1348,  0.0867,
        -0.1172, -0.1449,  0.0024, -0.0145,  0.0077,  0.1103, -0.1829,  0.1722,
        -0.0647, -0.0316,  0.0914, -0.0429, -0.1085, -0.0528,  0.0943,  0.0026],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5207,  0.4427, -0.5197, -0.5226,  0.3873,  0.3783, -0.4343,  0.4288,
          0.4537, -0.4579, -0.4178,  0.4140,  0.4129,  0.4232,  0.4518,  0.4053,
         -0.5211, -0.5266,  0.3907,  0.4164, -0.4761, -0.4544, -0.5205,  0.3813,
          0.5046,  0.5287, -0.5043,  0.5535, -0.4328, -0.5179,  0.4993,  0.5206]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2393], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.1489e-02,  6.7380e-02,  2.9759e-01, -3.3474e-01, -2.8165e-01,
         -1.5026e-01, -5.7131e-02, -4.4554e-01, -2.0247e-01, -5.8281e-02,
          1.7806e-01,  1.9865e-01,  6.2207e-02, -5.2874e-02, -1.7644e-01,
          3.7042e-01],
        [-2.6297e-01, -7.4500e-02, -1.0195e-01,  1.7185e-02,  4.0512e-02,
          2.4775e-01,  1.6649e-01,  2.0161e-01,  4.3604e-01,  1.4056e-01,
          6.7918e-02, -2.7553e-01, -1.0606e-02, -6.2519e-02,  4.5909e-01,
         -8.4858e-02],
        [ 8.9776e-02,  7.5250e-03,  3.7305e-01, -1.2895e-01, -1.3337e-01,
         -3.4048e-01, -3.9291e-02, -4.5453e-01,  1.3265e-02, -6.3944e-02,
         -8.3334e-02, -4.8874e-02,  4.0340e-01,  3.2695e-01, -5.1323e-02,
          2.6286e-01],
        [ 2.7262e-01, -5.5490e-02,  7.2742e-02, -8.6426e-02, -1.0424e-01,
         -1.8172e-01, -1.3845e-01, -1.2464e-01, -4.4167e-01, -3.9647e-01,
          3.0416e-02,  3.6319e-01,  2.9660e-01, -1.1202e-01, -2.8436e-01,
          1.4651e-01],
        [-1.0151e-01,  3.3755e-01, -1.6388e-01, -4.0968e-03,  2.2394e-01,
          8.0371e-02,  3.6751e-02,  3.6028e-01,  1.7415e-01,  3.0031e-01,
          6.5859e-02, -1.7039e-01, -5.5694e-02, -2.5205e-01,  3.7459e-01,
         -1.5804e-01],
        [-4.7172e-03,  3.1623e-01, -3.4988e-01,  4.1626e-01,  3.7186e-01,
         -4.2448e-02,  2.4776e-01, -6.8324e-03,  2.7499e-01,  2.1066e-01,
         -1.1243e-01, -9.0716e-02, -2.3414e-01,  1.1785e-01,  4.4234e-01,
         -7.4797e-02],
        [ 3.7450e-01, -9.1877e-03,  3.9995e-01, -2.0185e-01, -1.0916e-01,
         -2.0524e-01, -1.6865e-01, -2.6956e-01, -2.7699e-01, -2.6957e-02,
          3.2878e-03,  6.9787e-02, -6.0240e-02,  1.8742e-01, -3.5344e-01,
          1.5189e-01],
        [-5.9227e-02,  1.3555e-01,  3.5008e-01, -3.7084e-01, -3.8044e-01,
         -2.9502e-01, -8.0736e-02, -2.9523e-01, -2.2548e-01, -2.2188e-01,
         -5.9546e-02,  4.3733e-02,  2.5387e-01, -9.3657e-02, -1.3767e-01,
          3.5528e-01],
        [ 5.1026e-02,  2.1318e-02,  3.0702e-01, -2.7577e-01, -1.2179e-01,
         -3.5112e-01, -1.7197e-01, -1.5085e-01,  4.2234e-03, -3.2743e-01,
          1.3165e-02,  7.6960e-02, -4.4681e-02,  1.9271e-01, -4.3602e-01,
          1.0619e-01],
        [-3.0124e-01,  1.6654e-01, -1.0162e-01,  1.4886e-02,  1.3921e-01,
          1.5860e-01,  5.1930e-02,  2.8262e-01,  3.0590e-01,  1.1200e-02,
          1.0686e-01, -2.5149e-02, -2.8034e-01, -1.1034e-01,  2.7692e-01,
         -2.0961e-01],
        [-3.6499e-01,  2.1493e-01, -6.0417e-02, -1.4103e-02,  2.3794e-02,
          4.2443e-01,  2.3258e-01,  1.6544e-01,  3.8622e-01,  2.5967e-01,
          3.9467e-03, -8.4881e-03, -2.1465e-01,  7.9937e-02,  8.6178e-02,
         -3.3610e-01],
        [-1.2901e-01,  1.9809e-02, -1.8234e-02,  1.1032e-01,  2.1305e-01,
          1.1729e-01,  3.5309e-01,  1.7843e-01,  1.8393e-01,  3.5148e-01,
          8.8477e-02,  5.7589e-02, -4.2125e-01, -2.4299e-01,  1.3320e-01,
         -2.0455e-01],
        [ 3.4757e-01, -4.0428e-03,  1.6186e-01, -1.9758e-01, -1.9131e-01,
          2.1954e-02, -8.9739e-02, -3.8577e-01, -3.6965e-01, -1.1439e-01,
         -9.3823e-02,  5.3251e-02, -1.3504e-02,  2.0798e-01, -3.9257e-01,
          3.9142e-02],
        [ 2.1678e-01,  1.0919e-01,  3.6729e-01, -3.5374e-02, -3.6070e-01,
         -2.2652e-02, -3.7210e-02, -1.0645e-01, -2.5057e-01, -1.7460e-01,
         -1.0750e-01,  1.2282e-01,  1.3238e-01,  6.9645e-02, -4.2958e-01,
          2.4370e-01],
        [-3.8668e-01, -6.2484e-02, -6.8148e-02, -1.7760e-02,  4.3375e-01,
          4.1443e-01,  1.0152e-01,  1.6623e-01,  7.1927e-03,  1.9497e-01,
          3.3881e-02, -3.2952e-01, -1.0779e-01, -1.3893e-01,  1.5268e-01,
         -1.7014e-01],
        [-3.5337e-02, -4.0233e-01,  2.0146e-01,  3.3414e-02, -4.4179e-01,
         -2.3715e-02, -1.9952e-01, -3.9990e-01, -2.6947e-01, -7.3615e-02,
         -5.0378e-02,  4.4435e-01,  1.8857e-01, -1.8974e-02, -9.3134e-02,
          1.0135e-01],
        [ 3.1788e-01,  9.9670e-02,  1.9390e-01, -3.7040e-01, -3.8652e-01,
         -3.0775e-02, -8.5775e-02, -2.4159e-02, -3.9691e-01, -1.8933e-01,
          1.9474e-01,  2.9380e-01,  3.5133e-01,  2.7207e-01, -1.9240e-01,
         -2.8279e-02],
        [-2.9084e-01,  1.1826e-01, -2.3169e-01,  1.5258e-01,  1.4921e-01,
          2.8576e-01,  2.6507e-01,  2.8745e-01,  1.5153e-01,  2.8256e-01,
         -5.2544e-02, -2.4193e-01, -1.4816e-01, -1.9587e-01,  2.8509e-01,
         -1.6915e-01],
        [ 2.3848e-01, -8.7718e-02,  1.4462e-01, -2.9724e-01, -2.4597e-01,
         -3.7494e-01, -2.7459e-01, -6.9322e-03, -4.2976e-01, -1.1189e-01,
          1.6973e-02, -6.8665e-02,  2.0382e-01,  2.5874e-01, -6.2492e-02,
          1.9623e-01],
        [ 3.7998e-01, -6.2279e-02,  2.6400e-01, -1.1050e-01, -3.7758e-01,
         -2.3127e-01, -3.5190e-01, -1.6011e-02, -8.2273e-02, -2.8086e-01,
          9.2957e-02,  2.5922e-01, -3.7044e-02,  1.2077e-01, -1.0032e-01,
          1.9949e-01],
        [-1.7772e-01,  2.3997e-01, -3.6488e-02, -5.5825e-02,  3.0083e-01,
         -4.7720e-02,  2.9294e-01,  3.8233e-01,  1.9437e-01,  7.3038e-02,
         -1.0952e-01, -2.7317e-01, -1.9511e-01, -2.0540e-01,  4.1776e-01,
         -2.5295e-01],
        [-9.5394e-02,  9.9016e-03, -5.7886e-02,  4.1917e-01,  6.1272e-02,
          1.2591e-01,  2.6524e-01,  1.1893e-03,  7.7065e-02,  2.8749e-01,
          2.1383e-01, -2.9393e-01, -2.2041e-01, -3.9673e-01,  3.0737e-05,
          4.0397e-02],
        [ 3.7237e-01, -1.5019e-01,  5.0856e-02, -1.8634e-01, -4.4469e-02,
         -3.9741e-01, -2.9227e-01, -2.6210e-01, -2.8311e-01, -1.6772e-01,
          2.0751e-01,  2.2480e-01, -6.8188e-02,  3.2527e-01,  3.1177e-02,
          2.2477e-01],
        [ 2.5236e-01,  1.1595e-01,  3.2933e-01, -3.8294e-01, -2.2753e-01,
         -1.5302e-01, -1.5948e-01, -2.9051e-01, -3.6976e-01, -3.1924e-01,
          1.8467e-02,  3.4098e-01,  2.6388e-01,  1.2367e-01, -2.2223e-01,
          1.5777e-02],
        [ 2.1721e-01, -3.6737e-01,  1.7012e-01, -1.4795e-01,  1.1474e-02,
         -2.5030e-01,  4.9345e-02, -2.0405e-01, -3.8735e-01,  4.5001e-02,
          1.9666e-01,  9.0753e-03,  5.9293e-02,  2.7105e-01, -4.0413e-01,
          3.5003e-01],
        [ 4.6798e-02, -1.7878e-01,  8.3392e-02,  6.2644e-02, -2.5919e-01,
         -2.1021e-01, -1.9210e-02, -3.5998e-01, -1.8754e-01, -3.6067e-01,
         -2.6624e-01,  1.1735e-01,  1.9646e-01,  3.3848e-01, -4.6360e-01,
          8.3910e-02],
        [ 2.2425e-01, -6.5530e-03,  2.9084e-01, -3.6591e-01, -2.1185e-01,
         -9.6425e-02, -3.4488e-01, -5.0286e-02, -4.0658e-01,  3.4020e-04,
          4.8122e-02,  9.2565e-02,  2.3235e-01,  2.7272e-01,  4.0975e-02,
          2.9252e-01],
        [-3.2963e-01,  1.6651e-01,  1.7060e-02,  2.3191e-01,  3.5969e-01,
          2.2794e-02,  3.5639e-01,  2.0570e-01, -2.8526e-02,  1.1458e-01,
          7.2702e-02, -2.8037e-01, -2.3233e-01, -2.1432e-01,  6.9064e-02,
         -1.2281e-01],
        [ 3.0395e-01,  4.8378e-02,  1.2790e-01, -1.4770e-01, -3.2760e-01,
         -2.8258e-01, -1.3391e-01, -3.6514e-01, -3.9262e-02, -1.1201e-01,
          1.1208e-01,  1.4391e-01,  3.5568e-01,  3.2396e-01, -4.5548e-02,
          2.6292e-01],
        [-2.7336e-01,  1.5544e-01, -3.1173e-01,  2.7089e-01, -3.5834e-02,
          1.4388e-01,  3.2463e-01,  3.3110e-01,  3.8012e-01,  2.3949e-01,
          1.4707e-01, -9.1861e-02,  4.3443e-02,  5.1175e-02,  2.0136e-01,
         -2.2773e-01],
        [-2.8875e-01,  1.3140e-02, -3.6424e-02,  3.6808e-02,  2.3638e-01,
          3.7874e-01,  3.7068e-01,  4.8585e-03,  2.5330e-01,  3.2725e-01,
         -2.3063e-01, -1.5163e-02, -3.1461e-01, -2.8029e-01,  7.3349e-02,
         -2.4673e-01],
        [ 6.3425e-02, -1.2011e-02,  2.4625e-01, -6.9659e-02, -3.6309e-02,
         -3.1207e-01, -3.8817e-01, -3.9229e-01, -3.2544e-01, -2.6856e-01,
          9.4923e-02, -1.2970e-02, -3.2660e-02,  2.3035e-01, -3.3696e-01,
          1.9784e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-6.4387e-02, -5.9531e-02,  1.1522e-01, -7.7035e-02, -5.1460e-02,
        -2.6486e-02,  8.3784e-02,  1.3532e-01, -4.7423e-02, -6.4287e-02,
         2.6646e-02,  6.9962e-02,  1.9159e-01,  1.0735e-01, -5.5964e-02,
         9.9633e-02, -1.5270e-01, -4.0731e-03,  2.1496e-02, -4.4964e-05,
        -1.9553e-02, -1.0809e-01, -6.0698e-02, -2.5951e-02, -1.6076e-01,
         2.5858e-01,  1.0305e-01,  2.6708e-02, -8.5504e-02, -2.2689e-01,
         1.6310e-01, -3.0419e-02], device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2523,  0.3393, -0.2465, -0.2608,  0.3419,  0.3829, -0.2986, -0.3836,
         -0.3331,  0.3859,  0.2653,  0.3925, -0.2857, -0.4241,  0.3222, -0.3138,
         -0.3283,  0.3293, -0.2385, -0.2582,  0.4205,  0.3412, -0.3746, -0.3765,
         -0.3824, -0.3592, -0.3207,  0.3668, -0.3488,  0.3869,  0.2905, -0.2403]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0540,  0.1290,  0.0574,  ...,  0.2203, -0.3293, -0.1137],
        [-0.1230, -0.0293,  0.1171,  ...,  0.1553, -0.3297,  0.0871],
        [ 0.0128, -0.0598,  0.0185,  ...,  0.0279,  0.2323,  0.0345],
        ...,
        [-0.0049,  0.0348,  0.0579,  ...,  0.0850, -0.3189, -0.1180],
        [ 0.0994, -0.2298, -0.0536,  ..., -0.3283,  0.1521,  0.1557],
        [-0.2188,  0.1717,  0.0377,  ...,  0.0980, -0.2779, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0412,  0.0407, -0.0664, -0.1340, -0.0721,  0.0600, -0.1103,  0.0455,
        -0.0385,  0.0799,  0.0173,  0.0117,  0.0300,  0.0790, -0.0525, -0.0185,
         0.0585, -0.1552,  0.0024,  0.0281, -0.0499,  0.0325,  0.1092,  0.0058,
        -0.0936,  0.1045,  0.0472, -0.0942,  0.0537,  0.1393,  0.1671, -0.1230],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0773, -0.1812, -0.1172,  ..., -0.1308, -0.0164,  0.0748],
        [-0.2032, -0.0371,  0.0832,  ..., -0.0638,  0.0071,  0.0493],
        [ 0.1349, -0.0263, -0.1579,  ...,  0.0826, -0.0261,  0.1874],
        ...,
        [ 0.1151,  0.0942,  0.1219,  ...,  0.2525, -0.2246,  0.2456],
        [-0.0037, -0.1487,  0.0373,  ...,  0.0176,  0.2358, -0.1673],
        [-0.0008, -0.1341,  0.1976,  ...,  0.0362,  0.1634, -0.0503]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1029,  0.1471, -0.0582, -0.0831, -0.0005, -0.0436, -0.0575, -0.0441,
         0.1236, -0.1690,  0.1276, -0.1174,  0.1718,  0.0868, -0.1232,  0.1247,
        -0.1387, -0.1724, -0.0581, -0.0035, -0.0023,  0.0854, -0.2100,  0.2129,
        -0.0462, -0.0047,  0.0749, -0.0291, -0.1356, -0.0726,  0.1201,  0.0417],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4601,  0.3800, -0.4646, -0.4545,  0.3321,  0.3144, -0.3778,  0.3501,
          0.3794, -0.4022, -0.3489,  0.3654,  0.3489,  0.3286,  0.3925,  0.3872,
         -0.4558, -0.4690, -0.3231,  0.3688, -0.4134, -0.3917, -0.4656,  0.3121,
          0.4355,  0.4701, -0.4536,  0.4587, -0.3796, -0.4571,  0.4414,  0.4667]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2220], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-7.8028e-03,  3.5467e-01,  2.8746e-01, -3.0249e-01, -2.7955e-01,
         -1.3042e-01, -3.9886e-02, -4.3983e-01, -2.0362e-01, -3.8775e-02,
          1.4846e-01,  1.7821e-01,  4.5856e-02, -6.2346e-02, -1.6880e-01,
          3.4706e-01],
        [-2.4511e-01, -3.4575e-01, -8.7402e-02, -8.5852e-03,  3.2597e-02,
          2.3336e-01,  1.5648e-01,  1.9174e-01,  4.2492e-01,  1.2459e-01,
          7.8243e-02, -2.5696e-01,  1.5746e-03, -5.3978e-02,  4.5073e-01,
         -6.4405e-02],
        [ 7.0505e-02,  2.4275e-01,  3.5862e-01, -1.0256e-01, -1.3582e-01,
         -3.2804e-01, -3.0969e-02, -4.5377e-01,  1.3122e-02, -4.7090e-02,
         -9.1522e-02, -6.5345e-02,  3.9574e-01,  3.2468e-01, -4.6817e-02,
          2.4236e-01],
        [ 2.5755e-01,  6.8949e-02,  6.4022e-02, -6.5902e-02, -1.0619e-01,
         -1.7272e-01, -1.3535e-01, -1.2004e-01, -4.4123e-01, -3.8497e-01,
          2.0799e-02,  3.5147e-01,  2.9173e-01, -1.1152e-01, -2.8787e-01,
          1.2846e-01],
        [-9.6760e-02,  8.5226e-02, -1.6059e-01, -2.1653e-02,  2.4282e-01,
          7.5196e-02,  4.3174e-02,  3.7494e-01,  1.8766e-01,  2.9378e-01,
          9.5946e-02, -1.6605e-01, -6.5862e-02, -2.6385e-01,  3.9895e-01,
         -1.4645e-01],
        [-2.8470e-04,  1.2469e-01, -3.4840e-01,  4.0304e-01,  3.8598e-01,
         -4.0434e-02,  2.5172e-01, -3.3185e-03,  2.8021e-01,  2.0662e-01,
         -1.1212e-01, -8.7012e-02, -2.4724e-01,  1.1035e-01,  4.8980e-01,
         -6.6689e-02],
        [ 3.5762e-01,  1.2278e-01,  3.8794e-01, -1.7935e-01, -1.0671e-01,
         -1.9686e-01, -1.6361e-01, -2.6143e-01, -2.6446e-01, -1.4166e-02,
         -1.2023e-03,  5.5976e-02, -6.6575e-02,  1.8539e-01, -3.5690e-01,
          1.3420e-01],
        [-7.6374e-02,  2.7440e-01,  3.3711e-01, -3.4763e-01, -3.6500e-01,
         -2.8529e-01, -7.1196e-02, -2.8088e-01, -2.1073e-01, -2.0839e-01,
         -7.4446e-02,  2.6702e-02,  2.4371e-01, -9.8867e-02, -1.2926e-01,
          3.3890e-01],
        [ 3.4930e-02,  3.1911e-01,  2.9422e-01, -2.5239e-01, -1.1056e-01,
         -3.3887e-01, -1.6312e-01, -1.3959e-01,  1.2184e-02, -3.1287e-01,
          3.4596e-03,  6.0693e-02, -5.3990e-02,  1.8656e-01, -4.3057e-01,
          8.6350e-02],
        [-2.9300e-01, -1.1247e-01, -9.4943e-02, -4.2089e-03,  1.4710e-01,
          1.5145e-01,  5.1974e-02,  2.8802e-01,  3.1066e-01,  2.3918e-03,
          1.3481e-01, -1.6283e-02, -2.8273e-01, -1.1313e-01,  2.8848e-01,
         -1.9647e-01],
        [-3.5646e-01,  4.5275e-02, -5.6411e-02, -2.7878e-02,  3.3053e-02,
          4.1963e-01,  2.3254e-01,  1.6912e-01,  3.9267e-01,  2.5283e-01,
         -1.7694e-03, -2.8939e-03, -2.1202e-01,  7.1713e-02,  1.0469e-01,
         -3.2349e-01],
        [-1.1736e-01, -1.5305e-01, -1.0138e-02,  9.1570e-02,  2.1079e-01,
          1.0690e-01,  3.5262e-01,  1.7872e-01,  1.8151e-01,  3.4213e-01,
          1.1252e-01,  6.7605e-02, -4.1455e-01, -2.4988e-01,  1.3324e-01,
         -1.9000e-01],
        [ 3.2967e-01,  2.4767e-01,  1.4867e-01, -1.6865e-01, -2.0342e-01,
          3.9130e-02, -8.3126e-02, -3.9069e-01, -3.7158e-01, -9.6970e-02,
         -1.0331e-01,  3.4583e-02, -2.1556e-02,  2.0456e-01, -3.9372e-01,
          1.8604e-02],
        [ 1.9976e-01,  3.4002e-01,  3.5256e-01, -1.2377e-02, -3.5046e-01,
         -1.0245e-02, -2.9678e-02, -9.5633e-02, -2.3607e-01, -1.5991e-01,
         -1.1477e-01,  1.0640e-01,  1.2178e-01,  6.4208e-02, -4.2257e-01,
          2.2543e-01],
        [-3.7066e-01, -3.0694e-01, -5.5738e-02, -4.0472e-02,  4.2609e-01,
          4.0270e-01,  9.3847e-02,  1.5676e-01, -7.6048e-04,  1.8110e-01,
          4.1821e-02, -3.1386e-01, -9.8336e-02, -1.3424e-01,  1.4398e-01,
         -1.5213e-01],
        [-3.0427e-01, -2.2812e-01,  1.0663e-02,  2.6132e-01,  1.4648e-01,
          1.7987e-01,  1.0399e-01,  8.0832e-02,  1.7324e-01,  1.3554e-01,
          5.0131e-02,  1.4167e-01, -1.5323e-01, -3.0252e-01,  5.9232e-01,
         -9.2631e-02],
        [ 3.0011e-01,  2.3994e-01,  1.8341e-01, -3.4835e-01, -3.7972e-01,
         -1.9551e-02, -8.0969e-02, -9.2003e-03, -3.8636e-01, -1.7676e-01,
          1.7169e-01,  2.7938e-01,  3.3860e-01,  2.7415e-01, -1.7411e-01,
         -4.6180e-02],
        [-2.7570e-01,  4.0212e-02, -2.2195e-01,  1.3092e-01,  1.4678e-01,
          2.8017e-01,  2.6194e-01,  2.7953e-01,  1.4446e-01,  2.7186e-01,
         -4.6116e-02, -2.2934e-01, -1.4808e-01, -1.9211e-01,  2.8791e-01,
         -1.5280e-01],
        [ 2.2147e-01,  1.1621e-01,  1.3531e-01, -2.7402e-01, -2.4946e-01,
         -3.6466e-01, -2.7099e-01, -5.2501e-03, -4.3437e-01, -9.8263e-02,
          1.8087e-02, -8.1457e-02,  1.9793e-01,  2.6073e-01, -5.6311e-02,
          1.7518e-01],
        [ 3.6585e-01,  1.4157e-01,  2.5633e-01, -9.1473e-02, -3.7655e-01,
         -2.2110e-01, -3.5128e-01, -1.0024e-02, -8.1483e-02, -2.6990e-01,
          8.4384e-02,  2.4864e-01, -4.2915e-02,  1.2859e-01, -9.8707e-02,
          1.8145e-01],
        [-1.6867e-01,  6.3274e-02, -2.9727e-02, -7.3177e-02,  3.0773e-01,
         -5.2319e-02,  2.9515e-01,  3.8386e-01,  1.9401e-01,  6.5500e-02,
         -8.6933e-02, -2.6504e-01, -2.0050e-01, -2.1358e-01,  4.5218e-01,
         -2.4159e-01],
        [-8.4793e-02, -3.3950e-01, -5.2373e-02,  3.9900e-01,  5.0582e-02,
          1.1838e-01,  2.6248e-01, -5.2147e-03,  7.4569e-02,  2.7769e-01,
          2.3134e-01, -2.8040e-01, -2.1705e-01, -3.9837e-01, -3.8257e-04,
          5.3989e-02],
        [ 3.6275e-01,  2.3555e-02,  4.5623e-02, -1.7034e-01, -4.4808e-02,
         -3.9228e-01, -2.9431e-01, -2.5847e-01, -2.8208e-01, -1.6113e-01,
          1.8457e-01,  2.1776e-01, -6.8299e-02,  3.3036e-01,  3.3031e-02,
          2.1264e-01],
        [ 2.3154e-01,  1.7905e-01,  3.1619e-01, -3.5738e-01, -2.1308e-01,
         -1.4091e-01, -1.5107e-01, -2.6922e-01, -3.5439e-01, -3.0498e-01,
          4.5829e-03,  3.2174e-01,  2.5019e-01,  1.1830e-01, -1.9685e-01,
         -2.7831e-03],
        [ 2.1520e-01, -9.4700e-02,  1.7006e-01, -1.3592e-01, -2.6146e-03,
         -2.5003e-01,  4.3212e-02, -2.1345e-01, -3.9727e-01,  4.7480e-02,
          1.9588e-01,  8.1619e-03,  6.9047e-02,  2.8295e-01, -4.2431e-01,
          3.4369e-01],
        [ 3.5055e-02,  4.0709e-02,  7.3450e-02,  8.1958e-02, -2.6423e-01,
         -2.0263e-01, -1.3538e-02, -3.6119e-01, -1.8601e-01, -3.5028e-01,
         -2.8187e-01,  1.0575e-01,  1.9529e-01,  3.4061e-01, -4.8359e-01,
          7.0502e-02],
        [ 2.0850e-01,  1.6734e-01,  2.8136e-01, -3.4595e-01, -2.0571e-01,
         -8.5805e-02, -3.4442e-01, -3.9518e-02, -3.9907e-01,  1.1283e-02,
          2.8395e-02,  8.0958e-02,  2.2332e-01,  2.8443e-01,  4.7881e-02,
          2.7687e-01],
        [-3.2249e-01, -5.3072e-02,  2.0186e-02,  2.1535e-01,  3.6676e-01,
          1.5919e-02,  3.6045e-01,  2.1108e-01, -2.3365e-02,  1.0878e-01,
          9.8511e-02, -2.7443e-01, -2.3403e-01, -2.2898e-01,  8.4142e-02,
         -1.1149e-01],
        [ 2.8774e-01,  1.5811e-01,  1.1692e-01, -1.2729e-01, -3.2111e-01,
         -2.6999e-01, -1.3044e-01, -3.5511e-01, -3.0864e-02, -1.0007e-01,
          9.1553e-02,  1.3038e-01,  3.4452e-01,  3.2598e-01, -3.6905e-02,
          2.4684e-01],
        [-2.6188e-01,  1.8157e-02, -3.0388e-01,  2.5260e-01, -3.7107e-02,
          1.3908e-01,  3.2409e-01,  3.2712e-01,  3.7551e-01,  2.3139e-01,
          1.5496e-01, -8.2176e-02,  4.2826e-02,  4.6584e-02,  2.1224e-01,
         -2.1516e-01],
        [-2.7427e-01, -1.6509e-01, -2.8167e-02,  1.7391e-02,  2.3223e-01,
          3.7028e-01,  3.6853e-01, -5.1154e-03,  2.4952e-01,  3.1640e-01,
         -2.1560e-01, -4.3575e-03, -3.0933e-01, -2.8131e-01,  6.2141e-02,
         -2.2954e-01],
        [ 4.2589e-02,  1.3730e-01,  2.3279e-01, -4.1965e-02, -3.3495e-02,
         -2.9874e-01, -3.8271e-01, -3.9115e-01, -3.2408e-01, -2.5266e-01,
          8.6005e-02, -2.8310e-02, -4.3200e-02,  2.2642e-01, -3.2314e-01,
          1.7464e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0922, -0.0263,  0.1098, -0.0837, -0.0433, -0.0213,  0.0811,  0.1308,
        -0.0610, -0.0417,  0.0133,  0.0950,  0.1547,  0.0859, -0.0317, -0.0476,
        -0.1804,  0.0046,  0.0058, -0.0171, -0.0103, -0.0826, -0.0745, -0.0418,
        -0.1376,  0.2575,  0.0811,  0.0484, -0.1061, -0.2225,  0.1883, -0.0491],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2571,  0.3418, -0.2496, -0.2689,  0.3688,  0.4018, -0.3045, -0.3834,
         -0.3495,  0.3953,  0.2758,  0.3936, -0.2981, -0.4307,  0.3235,  0.3072,
         -0.3298,  0.3342, -0.2426, -0.2613,  0.4284,  0.3404, -0.3788, -0.3777,
         -0.4146, -0.3706, -0.3224,  0.3707, -0.3527,  0.3910,  0.2952, -0.2463]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0164,  0.1027,  0.0775,  ...,  0.1582, -0.2608, -0.1137],
        [-0.1137, -0.0405,  0.1176,  ...,  0.1308, -0.3109,  0.0871],
        [-0.0025, -0.0397,  0.0316,  ...,  0.0273,  0.2301,  0.0345],
        ...,
        [ 0.0073,  0.0212,  0.0543,  ...,  0.0663, -0.3099, -0.1180],
        [ 0.0933, -0.2201, -0.0536,  ..., -0.3024,  0.1379,  0.1557],
        [-0.1974,  0.1623,  0.0396,  ...,  0.0656, -0.2693, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0469,  0.0413, -0.0709, -0.1352, -0.0727,  0.0514, -0.1113,  0.0503,
        -0.0404,  0.0783,  0.0235,  0.0117,  0.0250,  0.0746, -0.0519, -0.0202,
         0.0577, -0.1576, -0.0614,  0.0361, -0.0556,  0.0304,  0.1054,  0.0063,
        -0.0886,  0.0537,  0.0427, -0.1129,  0.0545,  0.1432,  0.1667, -0.1266],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0652, -0.1798, -0.1085,  ..., -0.1209, -0.0259,  0.0753],
        [-0.2137, -0.0357,  0.1044,  ..., -0.0503, -0.0093,  0.0486],
        [ 0.1393, -0.0300, -0.1651,  ...,  0.0664, -0.0100,  0.1821],
        ...,
        [ 0.1119,  0.0779,  0.1249,  ...,  0.2327, -0.2019,  0.2304],
        [-0.0095, -0.1480,  0.0495,  ...,  0.0375,  0.2180, -0.1667],
        [-0.0006, -0.1226,  0.1946,  ...,  0.0587,  0.1412, -0.0369]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1057,  0.1587, -0.0587, -0.0816, -0.0070, -0.0425, -0.0563, -0.0437,
         0.1331, -0.1766,  0.1147, -0.1299,  0.1909,  0.1022, -0.1273,  0.1324,
        -0.1372, -0.1712,  0.0431, -0.0122, -0.0049,  0.0878, -0.1986,  0.2343,
        -0.0443, -0.0081,  0.0778, -0.0280, -0.1339, -0.0679,  0.1262,  0.0351],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4810,  0.4064, -0.4829, -0.4600,  0.3450,  0.3483, -0.3931,  0.3597,
          0.3815, -0.4257, -0.3732,  0.3697,  0.3663,  0.3554,  0.4011,  0.4123,
         -0.4672, -0.4797,  0.3301,  0.3778, -0.4283, -0.4082, -0.4763,  0.3248,
          0.4524,  0.4798, -0.4621,  0.4713, -0.3927, -0.4667,  0.4570,  0.4725]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2312], device='cuda:0', requires_grad=True)

