Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-7.2183e-04,  3.9519e-01,  3.0749e-01, -3.2663e-01, -1.9373e-01,
         -1.5436e-01, -7.8596e-02, -3.9359e-01, -2.5722e-01, -7.8496e-02,
         -3.0439e-02,  1.9749e-01, -3.0941e-01, -6.9135e-02, -3.5525e-02,
          3.8600e-01],
        [-2.4827e-01, -3.8867e-01, -9.9945e-02, -1.0711e-02, -2.4441e-02,
          2.4736e-01,  1.6474e-01,  1.6172e-01,  4.3291e-01,  1.3764e-01,
          2.9911e-01, -2.6222e-01,  3.6366e-01, -2.9109e-02,  3.4373e-01,
         -9.1157e-02],
        [ 9.3604e-02,  2.9557e-01,  3.9041e-01, -1.3123e-01, -1.0394e-01,
         -3.4827e-01, -9.2727e-02, -4.4990e-01, -6.3481e-02, -9.0367e-02,
         -1.5915e-01, -3.2975e-02,  1.6995e-02,  3.5046e-01, -2.0292e-02,
          2.8795e-01],
        [ 2.8442e-01,  1.1928e-01,  9.6862e-02, -8.8335e-02, -7.0808e-02,
         -2.1602e-01, -1.7872e-01, -1.2304e-01, -4.7668e-01, -4.3012e-01,
         -2.1920e-01,  3.8735e-01, -8.0442e-02, -1.1416e-01, -2.1457e-01,
          1.8119e-01],
        [-9.6371e-02,  3.3750e-02, -1.7232e-01, -2.2743e-02,  1.6826e-01,
          8.9009e-02,  4.8773e-02,  3.2952e-01,  1.8555e-01,  3.0555e-01,
          3.4900e-01, -1.6810e-01,  3.2655e-01, -2.3357e-01,  2.9604e-01,
         -1.7443e-01],
        [-2.0522e-02,  5.9922e-02, -3.7451e-01,  4.1729e-01,  3.5973e-01,
         -8.0994e-03,  2.8905e-01, -1.6645e-03,  3.1579e-01,  2.3532e-01,
         -7.3943e-02, -1.1118e-01,  1.2936e-01,  1.1715e-01,  4.3269e-01,
         -1.0608e-01],
        [ 3.6689e-01,  2.4715e-01,  4.0683e-01, -1.8433e-01, -5.9907e-02,
         -2.0976e-01, -1.8778e-01, -2.4146e-01, -2.9789e-01, -3.3050e-02,
         -4.6793e-02,  6.5903e-02, -3.6082e-01,  2.0567e-01, -3.0039e-01,
          1.6358e-01],
        [-5.7935e-02,  3.6380e-01,  3.6236e-01, -3.6147e-01, -3.4930e-01,
         -3.0051e-01, -1.0493e-01, -2.7551e-01, -2.4526e-01, -2.2949e-01,
         -9.5118e-02,  4.1432e-02, -4.2009e-02, -9.4472e-02, -1.2556e-01,
          3.7230e-01],
        [ 3.2870e-02,  3.5715e-01,  3.0291e-01, -2.4538e-01, -5.2146e-02,
         -3.4638e-01, -1.5946e-01, -1.0208e-01,  1.0801e-02, -3.2017e-01,
         -2.8530e-01,  5.5158e-02, -4.1990e-01,  1.5945e-01, -2.9561e-01,
          1.0882e-01],
        [-3.0074e-01, -1.6685e-01, -1.1194e-01,  9.9175e-04,  9.3485e-02,
          1.7046e-01,  7.6032e-02,  2.5943e-01,  3.2219e-01,  1.9318e-02,
          3.6634e-01, -2.4732e-02,  1.1990e-01, -9.4954e-02,  2.0459e-01,
         -2.2888e-01],
        [-3.7020e-01,  1.4103e-02, -7.8297e-02, -1.8268e-02, -2.7082e-02,
          4.4386e-01,  2.6480e-01,  1.5176e-01,  4.1214e-01,  2.8171e-01,
          2.2894e-01, -1.8452e-02,  1.9824e-01,  9.9712e-02,  2.5788e-02,
         -3.6305e-01],
        [-1.3974e-01, -2.0412e-01, -3.9229e-02,  1.0121e-01,  1.9005e-01,
          1.3796e-01,  3.9017e-01,  1.7089e-01,  2.1411e-01,  3.7171e-01,
          4.1081e-01,  4.6139e-02, -5.6787e-02, -2.6463e-01,  4.0765e-02,
         -2.3641e-01],
        [ 3.3524e-01,  2.9203e-01,  1.6805e-01, -1.7363e-01, -1.0643e-01,
          2.2236e-02, -8.8388e-02, -3.2953e-01, -3.6440e-01, -1.1751e-01,
         -1.7861e-01,  4.0806e-02, -4.3808e-01,  1.5727e-01, -2.4831e-01,
          5.3427e-02],
        [ 2.0937e-01,  4.0246e-01,  3.7143e-01, -1.3337e-02, -3.1477e-01,
         -2.3849e-02, -4.1169e-02, -7.7363e-02, -2.4998e-01, -1.7511e-01,
         -2.8264e-01,  1.1308e-01, -2.0331e-01,  5.9670e-02, -3.3109e-01,
          2.5413e-01],
        [-3.7875e-01, -3.5546e-01, -7.3552e-02, -3.2477e-02,  3.7474e-01,
          4.0674e-01,  1.1452e-01,  1.2788e-01,  1.6287e-02,  1.9804e-01,
          1.9417e-01, -3.1710e-01,  2.5687e-01, -1.1556e-01,  7.1180e-02,
         -1.8302e-01],
        [-5.0218e-02,  1.0887e-02,  2.1720e-01,  5.5708e-02, -3.7375e-01,
         -4.3804e-02, -2.3252e-01, -3.5296e-01, -3.0807e-01, -1.0232e-01,
         -1.5479e-01,  4.5878e-01, -3.0020e-01, -1.4817e-02,  8.1634e-03,
          1.2988e-01],
        [ 3.2988e-01,  3.3047e-01,  2.1652e-01, -3.6737e-01, -3.8544e-01,
         -6.1130e-02, -1.2145e-01, -3.1182e-02, -4.2371e-01, -2.1478e-01,
          6.5698e-02,  3.1380e-01,  3.1391e-02,  3.0276e-01, -1.4471e-01,
          4.5861e-03],
        [-3.0071e-01, -6.3247e-02, -2.5324e-01,  1.4885e-01,  1.4684e-01,
          3.0956e-01,  3.0275e-01,  2.8981e-01,  1.8970e-01,  3.0287e-01,
          1.3574e-02, -2.5799e-01,  1.1530e-01, -2.1847e-01,  2.9883e-01,
         -1.9532e-01],
        [ 2.2558e-01,  1.5317e-01,  1.4385e-01, -2.8209e-01, -2.1926e-01,
         -3.7463e-01, -3.2484e-01,  3.9048e-03, -5.0519e-01, -1.2489e-01,
         -1.1796e-01, -5.9951e-02, -1.4699e-01,  2.9361e-01, -5.4927e-02,
          2.0972e-01],
        [ 3.7492e-01,  1.8179e-01,  2.7676e-01, -9.7812e-02, -3.1568e-01,
         -2.3346e-01, -3.6568e-01,  2.1136e-02, -9.1839e-02, -2.9385e-01,
         -1.7528e-01,  2.5151e-01, -4.0513e-01,  1.0982e-01,  3.1316e-02,
          2.1891e-01],
        [-1.9031e-01, -3.1039e-04, -5.9580e-02, -5.9269e-02,  2.9069e-01,
         -2.0576e-02,  3.2272e-01,  3.8693e-01,  2.3324e-01,  9.3684e-02,
          1.2160e-02, -2.9240e-01,  1.2973e-01, -2.1141e-01,  3.9888e-01,
         -2.8026e-01],
        [-7.8609e-02, -4.0831e-01, -5.5850e-02,  3.9501e-01, -1.6907e-02,
          1.1700e-01,  2.6849e-01, -5.0629e-02,  6.8386e-02,  2.7852e-01,
          4.0139e-01, -2.6490e-01,  1.8460e-01, -3.6968e-01, -6.9052e-02,
          2.8867e-02],
        [ 3.6898e-01,  8.0729e-02,  6.0240e-02, -1.7160e-01, -2.5321e-03,
         -3.9947e-01, -3.0758e-01, -2.3498e-01, -2.9690e-01, -1.7271e-01,
          5.2778e-02,  2.1663e-01, -3.9314e-01,  3.1937e-01,  8.9359e-02,
          2.4214e-01],
        [ 2.6255e-01,  2.3637e-01,  3.4962e-01, -3.7678e-01, -2.4577e-01,
         -1.7673e-01, -1.8868e-01, -2.9592e-01, -3.9733e-01, -3.4198e-01,
         -1.4058e-01,  3.5363e-01,  1.2075e-02,  1.3345e-01, -1.9092e-01,
          4.5329e-02],
        [ 2.2467e-01, -4.2817e-02,  1.8560e-01, -1.3825e-01,  3.5151e-02,
         -2.8415e-01,  1.1391e-02, -2.1137e-01, -4.3364e-01,  2.3067e-02,
          3.9111e-02,  2.9687e-02, -3.6134e-01,  2.6442e-01, -3.3964e-01,
          3.7594e-01],
        [ 5.1081e-02,  8.8223e-02,  9.8862e-02,  6.8855e-02, -2.3117e-01,
         -2.1650e-01, -4.0658e-02, -3.4876e-01, -2.1772e-01, -3.7362e-01,
         -3.6711e-01,  1.2346e-01, -1.5531e-01,  3.2255e-01, -4.0384e-01,
          1.0774e-01],
        [ 2.3056e-01,  2.5537e-01,  3.1240e-01, -3.5991e-01, -1.8799e-01,
         -1.0816e-01, -3.7392e-01, -3.6352e-02, -4.3601e-01, -1.7283e-02,
         -6.0683e-02,  9.9414e-02, -8.7404e-02,  3.0680e-01,  9.6886e-02,
          3.2166e-01],
        [-3.2656e-01, -1.0289e-01,  6.3788e-03,  2.1631e-01,  3.1428e-01,
          2.9863e-02,  3.8122e-01,  1.7554e-01, -1.2399e-02,  1.2264e-01,
          3.8150e-01, -2.7619e-01,  1.4250e-01, -2.2125e-01, -7.2120e-03,
         -1.4250e-01],
        [ 3.1763e-01,  1.9605e-01,  1.5314e-01, -1.4724e-01, -3.1626e-01,
         -3.0087e-01, -1.6845e-01, -3.6204e-01, -7.1489e-02, -1.3611e-01,
         -1.0818e-01,  1.5611e-01,  2.9161e-02,  3.3206e-01, -5.6063e-03,
          2.9735e-01],
        [-2.6991e-01, -4.3324e-02, -3.1993e-01,  2.5409e-01, -7.3178e-02,
          1.4711e-01,  3.4158e-01,  3.0828e-01,  3.9647e-01,  2.4383e-01,
          2.2877e-01, -8.5148e-02,  3.2862e-01,  6.0951e-02,  1.4460e-01,
         -2.4071e-01],
        [-3.0231e-01, -2.3558e-01, -6.2597e-02,  3.7220e-02,  2.1531e-01,
          4.0595e-01,  4.0786e-01,  1.2551e-03,  2.8739e-01,  3.5303e-01,
         -8.2484e-02, -3.3476e-02,  3.4250e-02, -2.9831e-01,  3.1937e-02,
         -2.8138e-01],
        [ 4.8128e-02,  2.3200e-01,  2.4782e-01, -4.7308e-02,  4.2710e-03,
         -3.1528e-01, -4.1481e-01, -3.7493e-01, -3.7851e-01, -2.7991e-01,
         -4.0092e-02, -8.2340e-03, -3.5789e-01,  2.7084e-01, -2.5910e-01,
          2.0425e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0679, -0.0187, -0.0133, -0.0338,  0.0123, -0.2352,  0.0967,  0.1226,
        -0.0564, -0.0053,  0.0445,  0.0777,  0.1327,  0.0735,  0.0648, -0.0219,
        -0.0183, -0.0390,  0.0833, -0.0325, -0.1039, -0.0704, -0.0315,  0.0364,
        -0.0373,  0.1319,  0.1584,  0.0475, -0.0998, -0.1810,  0.0238,  0.0223],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2188,  0.3124, -0.2292, -0.2604,  0.3038,  0.3594, -0.2824, -0.3748,
         -0.3228,  0.3414,  0.2657,  0.3776, -0.2651, -0.3975,  0.2855, -0.2386,
         -0.3210,  0.3333, -0.2315, -0.2378,  0.4030,  0.3182, -0.3729, -0.3766,
         -0.2878, -0.3317, -0.3202,  0.3442, -0.3514,  0.3820,  0.3030, -0.2370]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0062,  0.1149,  0.0700,  ...,  0.1971, -0.3100, -0.1137],
        [-0.0750, -0.0644,  0.1196,  ...,  0.1021, -0.2865,  0.0871],
        [-0.1078,  0.1583,  0.0933,  ...,  0.1983,  0.0277,  0.0345],
        ...,
        [ 0.0980, -0.1216, -0.0372,  ..., -0.1705, -0.0247, -0.1180],
        [ 0.0400, -0.1852, -0.0411,  ..., -0.2614,  0.0921,  0.1557],
        [-0.1856,  0.1360,  0.0512,  ...,  0.0706, -0.2438, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0533,  0.0308, -0.0954, -0.1551, -0.0812, -0.0076, -0.1020,  0.0406,
        -0.0326,  0.0577,  0.0278, -0.0027,  0.0080,  0.1021, -0.0440, -0.0121,
         0.0478, -0.1663,  0.0042,  0.0822, -0.0623,  0.0180,  0.1111,  0.0234,
        -0.1106,  0.0985,  0.0442, -0.0980,  0.0457,  0.2037,  0.1689, -0.1284],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0523, -0.1637, -0.1870,  ...,  0.0356, -0.0453,  0.0655],
        [-0.2175, -0.0151, -0.0178,  ...,  0.1387, -0.0289,  0.0487],
        [ 0.1478, -0.0499, -0.0396,  ..., -0.1415,  0.0031,  0.1866],
        ...,
        [ 0.1414,  0.0584,  0.2070,  ...,  0.1041, -0.1762,  0.2453],
        [-0.0146, -0.1365, -0.0453,  ...,  0.2394,  0.2142, -0.1729],
        [-0.0028, -0.1096,  0.1284,  ...,  0.2222,  0.1268, -0.0445]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1010,  0.1482, -0.0467, -0.1003, -0.1074, -0.1764, -0.0637, -0.0269,
         0.1409, -0.1697,  0.1327, -0.1275,  0.1982,  0.0925, -0.1094,  0.1233,
        -0.1370, -0.1789,  0.0771,  0.0109, -0.0153,  0.0811, -0.2080,  0.2178,
        -0.0454, -0.0100,  0.0760, -0.0414, -0.1506, -0.0596,  0.1234,  0.0306],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3775,  0.3012, -0.3403, -0.3712, -0.2250, -0.2197, -0.2854,  0.2520,
          0.2786, -0.2953, -0.2480,  0.2633,  0.2725,  0.2288,  0.2885,  0.2714,
         -0.3694, -0.3753,  0.2215,  0.2666, -0.3271, -0.2774, -0.3791,  0.2245,
          0.3416,  0.3938, -0.3495,  0.3661, -0.2857, -0.3740,  0.3386,  0.3786]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1328], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.2592e-02,  3.5463e-01,  3.2348e-01, -3.4645e-01, -2.5060e-02,
         -1.7834e-01, -6.7499e-02, -3.8941e-01, -1.7628e-01, -8.5466e-02,
          2.7370e-02,  1.7458e-01,  5.9370e-02, -5.2222e-02,  3.1594e-01,
          3.6507e-01],
        [-2.7645e-01, -3.3907e-01, -1.2823e-01,  1.3864e-02, -1.6083e-01,
          2.8566e-01,  1.8908e-01,  1.6898e-01,  4.0059e-01,  1.3560e-01,
          2.2254e-01, -2.7320e-01,  6.0914e-04, -4.5081e-02,  1.2104e-03,
         -8.4821e-02],
        [ 1.0004e-01,  2.4876e-01,  4.0303e-01, -1.4019e-01,  1.4267e-01,
         -3.7496e-01, -6.4825e-02, -4.1231e-01,  5.4191e-02, -8.2900e-02,
         -9.7149e-02, -6.1986e-02,  3.9477e-01,  3.1040e-01,  4.3284e-01,
          2.6673e-01],
        [ 2.9231e-01,  6.9086e-02,  1.0718e-01, -9.2075e-02,  1.0061e-01,
         -2.3061e-01, -1.7131e-01, -9.7324e-02, -4.0758e-01, -4.0335e-01,
         -1.0792e-01,  3.6617e-01,  2.8437e-01, -1.2781e-01,  1.4024e-01,
          1.6052e-01],
        [-1.1668e-01,  1.2081e-01, -1.9002e-01, -3.6713e-03,  5.3704e-02,
          1.2358e-01,  6.6589e-02,  3.4798e-01,  1.6040e-01,  2.9243e-01,
          2.3172e-01, -1.9057e-01, -5.3884e-02, -2.2579e-01, -8.2170e-02,
         -1.3760e-01],
        [-2.1539e-02,  1.4606e-01, -3.7575e-01,  4.1240e-01,  1.6079e-01,
          4.0578e-03,  2.7529e-01, -2.0093e-02,  2.5255e-01,  2.0538e-01,
         -1.3803e-01, -9.8330e-02, -2.4810e-01,  1.3324e-01,  3.4263e-02,
         -7.0311e-02],
        [ 3.9398e-01,  2.0279e-01,  4.3337e-01, -2.0345e-01,  1.2995e-01,
         -2.5096e-01, -2.1139e-01, -2.3872e-01, -2.5077e-01, -2.8954e-02,
         -2.1327e-02,  6.6000e-02, -3.3775e-02,  2.2965e-01, -1.2386e-02,
          1.6322e-01],
        [-4.4382e-02,  3.1610e-01,  3.7533e-01, -3.6280e-01, -1.4569e-01,
         -3.3120e-01, -1.0895e-01, -2.4643e-01, -1.7876e-01, -2.1508e-01,
         -7.3489e-02,  2.1025e-02,  2.5379e-01, -8.3959e-02,  1.6054e-01,
          3.6574e-01],
        [ 5.7049e-02,  3.0605e-01,  3.2667e-01, -2.6959e-01,  3.2532e-02,
         -3.8311e-01, -1.8395e-01, -1.1174e-01,  4.1328e-02, -3.1550e-01,
         -1.1473e-01,  7.5812e-02, -8.2145e-02,  1.4226e-01,  1.3506e-02,
          9.6821e-02],
        [-3.0605e-01, -8.4893e-02, -1.1710e-01,  2.4942e-03, -4.2918e-02,
          1.8933e-01,  6.6825e-02,  2.5229e-01,  2.7242e-01, -6.8230e-03,
          2.3897e-01, -2.4891e-02, -2.6155e-01, -6.7463e-02, -1.8577e-01,
         -1.8939e-01],
        [-3.6913e-01,  7.0367e-02, -8.0182e-02, -2.6566e-02, -1.7712e-01,
          4.5501e-01,  2.4519e-01,  1.1918e-01,  3.3723e-01,  2.4942e-01,
          6.9449e-02,  8.1053e-03, -1.6035e-01,  1.3419e-01, -3.8739e-01,
         -3.3165e-01],
        [-1.4525e-01, -1.4622e-01, -4.4413e-02,  1.0603e-01,  1.1141e-01,
          1.5296e-01,  3.8897e-01,  1.6159e-01,  1.6987e-01,  3.4520e-01,
          1.5668e-01,  4.7503e-02, -4.0070e-01, -2.0285e-01, -2.5827e-01,
         -2.0117e-01],
        [ 3.6761e-01,  2.2175e-01,  2.0267e-01, -2.0381e-01,  7.5864e-02,
         -2.7510e-02, -1.1394e-01, -3.3799e-01, -3.4089e-01, -1.2256e-01,
         -1.2335e-01,  4.5146e-02, -2.4030e-02,  1.9527e-01,  1.6981e-01,
          3.6705e-02],
        [ 2.3735e-01,  3.5523e-01,  3.9777e-01, -3.4923e-02, -1.7793e-01,
         -6.3651e-02, -7.3277e-02, -8.7104e-02, -2.2312e-01, -1.7367e-01,
         -2.1696e-01,  1.2793e-01,  1.3224e-01,  7.2657e-02, -3.4891e-02,
          2.5176e-01],
        [-3.9583e-01, -3.0452e-01, -9.1145e-02, -2.6785e-02,  2.0305e-01,
          4.4584e-01,  1.2001e-01,  1.2072e-01, -3.7318e-02,  1.8578e-01,
          1.2990e-01, -3.1546e-01, -8.5311e-02, -1.1869e-01, -2.8163e-01,
         -1.7140e-01],
        [-8.8338e-02, -1.5521e-01,  1.7921e-01,  9.0178e-02, -1.9937e-01,
         -1.6402e-02, -1.5518e-01, -2.9328e-01, -1.6843e-01, -8.6485e-03,
          9.7670e-03,  4.3074e-01,  1.1719e-01, -9.5092e-02,  4.1250e-01,
          2.8890e-02],
        [ 3.3308e-01,  2.7427e-01,  2.2021e-01, -3.6769e-01, -2.0598e-01,
         -7.1195e-02, -1.2134e-01, -2.2160e-03, -3.5734e-01, -1.8834e-01,
          1.3666e-01,  2.8895e-01,  3.4599e-01,  2.8635e-01,  1.2695e-01,
         -1.6331e-02],
        [-3.1638e-01, -2.2018e-02, -2.6791e-01,  1.5562e-01, -1.3043e-02,
          3.3742e-01,  3.1231e-01,  2.7689e-01,  1.3435e-01,  2.8738e-01,
         -3.4960e-02, -2.4824e-01, -1.6720e-01, -2.2378e-01,  4.2557e-02,
         -1.8771e-01],
        [ 2.5228e-01,  1.3335e-01,  1.7807e-01, -3.1371e-01, -5.9098e-03,
         -4.1345e-01, -3.0913e-01,  2.9822e-02, -3.8878e-01, -1.3830e-01,
         -4.5874e-02, -8.0102e-02,  1.9473e-01,  2.5948e-01,  3.7088e-01,
          2.1042e-01],
        [ 3.9041e-01,  1.4073e-01,  2.9359e-01, -1.0759e-01, -1.6958e-01,
         -2.6605e-01, -3.7414e-01,  3.3193e-02, -3.5778e-02, -2.8042e-01,
         -7.0511e-02,  2.4645e-01, -7.7071e-02,  1.0764e-01,  3.2768e-01,
          2.0890e-01],
        [-2.0160e-01,  7.6367e-02, -6.9506e-02, -5.0840e-02,  1.5155e-01,
          1.6346e-03,  3.3094e-01,  3.9563e-01,  1.9333e-01,  7.4615e-02,
         -7.0392e-02, -3.0394e-01, -2.0366e-01, -2.0546e-01,  4.5527e-02,
         -2.5395e-01],
        [-8.0821e-02, -3.4139e-01, -5.9790e-02,  3.9028e-01, -1.5498e-01,
          1.3887e-01,  2.5238e-01, -7.0783e-02,  6.3326e-03,  2.5408e-01,
          2.5447e-01, -2.5586e-01, -1.5085e-01, -3.4012e-01, -4.4756e-01,
          5.9215e-02],
        [ 3.7684e-01,  3.5075e-02,  6.8577e-02, -1.6931e-01,  1.6169e-01,
         -4.2206e-01, -3.0845e-01, -2.0868e-01, -2.2984e-01, -1.5252e-01,
          1.1653e-01,  1.9876e-01, -1.1191e-01,  3.1217e-01,  3.7813e-01,
          2.2807e-01],
        [ 2.7619e-01,  2.0317e-01,  3.6184e-01, -3.8231e-01, -8.6389e-02,
         -2.0090e-01, -2.0292e-01, -2.6914e-01, -3.4230e-01, -3.2593e-01,
         -1.0594e-01,  3.3492e-01,  2.5414e-01,  1.4755e-01,  5.6581e-03,
          4.3564e-02],
        [ 2.2820e-01, -1.3435e-01,  1.9103e-01, -1.4430e-01,  1.9245e-01,
         -2.8994e-01,  2.2925e-02, -1.9181e-01, -3.6642e-01,  5.6044e-02,
          1.6812e-01,  1.6713e-02,  5.0030e-02,  2.3487e-01,  7.5397e-02,
          3.3015e-01],
        [ 7.2875e-02,  1.5864e-02,  1.2088e-01,  5.5233e-02, -7.9363e-02,
         -2.6241e-01, -5.5652e-02, -3.6384e-01, -1.8390e-01, -3.6503e-01,
         -2.9565e-01,  1.4166e-01,  1.9808e-01,  3.3237e-01, -2.1340e-02,
          8.6363e-02],
        [ 2.3453e-01,  2.1002e-01,  3.1778e-01, -3.5743e-01, -1.2793e-03,
         -1.2562e-01, -3.7482e-01,  2.0871e-03, -3.5880e-01,  5.9626e-03,
         -2.7326e-04,  7.0591e-02,  1.9884e-01,  2.9926e-01,  3.6495e-01,
          3.0732e-01],
        [-3.3435e-01, -4.0969e-02, -6.3436e-04,  2.1766e-01,  1.9903e-01,
          5.0021e-02,  3.7872e-01,  1.6894e-01, -5.9241e-02,  9.8289e-02,
          2.2050e-01, -2.7410e-01, -2.0824e-01, -1.8849e-01, -3.4110e-01,
         -1.1165e-01],
        [ 3.2256e-01,  1.4732e-01,  1.5825e-01, -1.4201e-01, -1.8061e-01,
         -3.1973e-01, -1.6270e-01, -3.4146e-01, -1.1112e-02, -1.1169e-01,
         -4.0760e-04,  1.4111e-01,  3.1275e-01,  3.0909e-01,  2.9826e-01,
          2.7670e-01],
        [-2.8706e-01, -2.4140e-03, -3.3628e-01,  2.6174e-01, -2.3825e-01,
          1.7885e-01,  3.5310e-01,  2.9217e-01,  3.4104e-01,  2.3180e-01,
          1.8859e-01, -7.5746e-02,  5.1222e-02,  4.9033e-02, -1.0367e-01,
         -2.3590e-01],
        [-3.0283e-01, -1.8300e-01, -6.5287e-02,  3.3273e-02,  5.0798e-02,
          4.1659e-01,  3.9943e-01, -3.1761e-02,  2.1374e-01,  3.2479e-01,
         -1.8806e-01, -8.3854e-03, -2.8622e-01, -2.6976e-01, -3.0101e-01,
         -2.5764e-01],
        [ 8.6757e-02,  2.1002e-01,  2.8827e-01, -9.1022e-02,  1.8041e-01,
         -3.6105e-01, -4.3785e-01, -3.7795e-01, -3.0102e-01, -2.9765e-01,
          2.6684e-02, -1.4914e-03, -1.2226e-02,  2.6589e-01,  5.0802e-02,
          2.1533e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-9.7664e-02, -5.6866e-02,  1.8189e-01, -2.9361e-02, -8.2283e-02,
        -3.8026e-02,  7.0831e-02,  6.1070e-02, -2.7644e-02, -5.5116e-02,
        -2.9136e-02,  5.6820e-02,  1.2498e-01,  9.7914e-02, -1.3909e-02,
        -1.6000e-04, -1.4312e-01,  2.4218e-02,  1.1469e-01,  1.6363e-02,
        -2.1338e-02, -1.7401e-01, -1.4203e-02, -5.0244e-02, -4.1285e-02,
         2.2458e-01,  1.2186e-01,  2.0561e-02, -5.0955e-02, -1.4685e-01,
         1.6829e-02,  2.8277e-02], device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1939,  0.2852, -0.2106, -0.2421,  0.2644,  0.3148, -0.2624, -0.3648,
         -0.2879,  0.3054,  0.2476,  0.3594, -0.2214, -0.3636,  0.2847, -0.1518,
         -0.2829,  0.3236, -0.2148, -0.2293,  0.3415,  0.3407, -0.3602, -0.3661,
         -0.2603, -0.2913, -0.3062,  0.3263, -0.3496,  0.3716,  0.2846, -0.2235]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0107, -0.0030,  0.0258,  ...,  0.2090, -0.3524, -0.1137],
        [-0.0817, -0.1898,  0.0830,  ...,  0.1452, -0.3291,  0.0871],
        [-0.0543,  0.1575,  0.0910,  ...,  0.0109,  0.2356,  0.0345],
        ...,
        [ 0.0421, -0.1558,  0.0129,  ...,  0.0670, -0.2800, -0.1180],
        [ 0.0345, -0.0704,  0.0060,  ..., -0.3027,  0.1276,  0.1557],
        [-0.0852,  0.1613,  0.0122,  ..., -0.1724,  0.0629, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0510,  0.0540, -0.0928, -0.1205, -0.0577,  0.0458, -0.1289,  0.0619,
        -0.0463,  0.0922,  0.0329,  0.0082,  0.0096,  0.0630, -0.0783, -0.0203,
         0.0465, -0.1422, -0.0324, -0.0153, -0.1095,  0.0477,  0.0820, -0.0064,
        -0.0850,  0.0665,  0.0242, -0.0960,  0.0640,  0.1472,  0.1370, -0.0658],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0382, -0.1960, -0.0809,  ..., -0.1398, -0.0158,  0.2625],
        [-0.2363, -0.0447,  0.1043,  ..., -0.0702, -0.0027,  0.2711],
        [ 0.1650, -0.0196, -0.1761,  ...,  0.0828, -0.0238, -0.0686],
        ...,
        [ 0.1520,  0.1115,  0.0819,  ...,  0.2630, -0.2222,  0.0553],
        [-0.0532, -0.1736,  0.0762,  ...,  0.0027,  0.2491,  0.0863],
        [-0.0184, -0.1216,  0.2110,  ...,  0.0513,  0.1396,  0.1314]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0870,  0.1225, -0.0354, -0.0548, -0.0311, -0.0352, -0.0326, -0.0624,
         0.1101, -0.1752,  0.1225, -0.1328,  0.1652, -0.0187, -0.1429,  0.1055,
        -0.1273, -0.1539,  0.0136, -0.0295,  0.0086,  0.1085, -0.1892,  0.2026,
        -0.0698, -0.0287,  0.0881, -0.0374, -0.1122, -0.0601,  0.1110,  0.0010],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5159,  0.4402, -0.5183, -0.5216,  0.3665,  0.3746, -0.4228,  0.4314,
          0.4314, -0.4542, -0.4443,  0.4052,  0.4274, -0.3683,  0.4483,  0.3967,
         -0.5262, -0.5174,  0.3944,  0.4115, -0.4793, -0.4523, -0.5158,  0.3514,
          0.4905,  0.5170, -0.4909,  0.5589, -0.4265, -0.5083,  0.4930,  0.5081]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2378], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.2591e-02,  3.5463e-01,  3.2348e-01, -3.4645e-01, -2.5060e-02,
         -1.7834e-01, -6.7499e-02, -3.8941e-01, -1.7628e-01, -8.5466e-02,
          2.7371e-02,  1.7458e-01,  5.9371e-02, -5.2222e-02,  3.1594e-01,
          3.6507e-01],
        [-2.7645e-01, -3.3907e-01, -1.2823e-01,  1.3864e-02, -1.6083e-01,
          2.8566e-01,  1.8908e-01,  1.6898e-01,  4.0059e-01,  1.3560e-01,
          2.2254e-01, -2.7320e-01,  6.0867e-04, -4.5081e-02,  1.2105e-03,
         -8.4820e-02],
        [ 1.0004e-01,  2.4876e-01,  4.0303e-01, -1.4019e-01,  1.4267e-01,
         -3.7496e-01, -6.4825e-02, -4.1231e-01,  5.4191e-02, -8.2900e-02,
         -9.7148e-02, -6.1986e-02,  3.9477e-01,  3.1040e-01,  4.3284e-01,
          2.6673e-01],
        [ 2.9231e-01,  6.9085e-02,  1.0718e-01, -9.2074e-02,  1.0061e-01,
         -2.3061e-01, -1.7131e-01, -9.7324e-02, -4.0758e-01, -4.0335e-01,
         -1.0792e-01,  3.6617e-01,  2.8437e-01, -1.2782e-01,  1.4024e-01,
          1.6052e-01],
        [-1.1668e-01,  1.2081e-01, -1.9002e-01, -3.6716e-03,  5.3705e-02,
          1.2358e-01,  6.6589e-02,  3.4798e-01,  1.6041e-01,  2.9243e-01,
          2.3172e-01, -1.9057e-01, -5.3885e-02, -2.2579e-01, -8.2170e-02,
         -1.3760e-01],
        [-2.1539e-02,  1.4606e-01, -3.7575e-01,  4.1240e-01,  1.6079e-01,
          4.0576e-03,  2.7529e-01, -2.0093e-02,  2.5255e-01,  2.0538e-01,
         -1.3803e-01, -9.8330e-02, -2.4810e-01,  1.3324e-01,  3.4264e-02,
         -7.0310e-02],
        [ 3.9398e-01,  2.0279e-01,  4.3337e-01, -2.0345e-01,  1.2995e-01,
         -2.5096e-01, -2.1139e-01, -2.3872e-01, -2.5077e-01, -2.8954e-02,
         -2.1327e-02,  6.6001e-02, -3.3775e-02,  2.2965e-01, -1.2386e-02,
          1.6321e-01],
        [-4.4382e-02,  3.1610e-01,  3.7533e-01, -3.6280e-01, -1.4569e-01,
         -3.3120e-01, -1.0895e-01, -2.4643e-01, -1.7876e-01, -2.1508e-01,
         -7.3489e-02,  2.1025e-02,  2.5379e-01, -8.3959e-02,  1.6054e-01,
          3.6574e-01],
        [ 5.7049e-02,  3.0605e-01,  3.2667e-01, -2.6959e-01,  3.2532e-02,
         -3.8311e-01, -1.8395e-01, -1.1174e-01,  4.1328e-02, -3.1550e-01,
         -1.1473e-01,  7.5812e-02, -8.2145e-02,  1.4226e-01,  1.3506e-02,
          9.6821e-02],
        [-3.0605e-01, -8.4892e-02, -1.1710e-01,  2.4939e-03, -4.2917e-02,
          1.8933e-01,  6.6825e-02,  2.5229e-01,  2.7242e-01, -6.8235e-03,
          2.3897e-01, -2.4892e-02, -2.6155e-01, -6.7462e-02, -1.8577e-01,
         -1.8939e-01],
        [-3.6913e-01,  7.0367e-02, -8.0181e-02, -2.6566e-02, -1.7712e-01,
          4.5501e-01,  2.4519e-01,  1.1918e-01,  3.3723e-01,  2.4942e-01,
          6.9449e-02,  8.1049e-03, -1.6035e-01,  1.3419e-01, -3.8739e-01,
         -3.3165e-01],
        [-1.4525e-01, -1.4621e-01, -4.4412e-02,  1.0603e-01,  1.1141e-01,
          1.5296e-01,  3.8897e-01,  1.6159e-01,  1.6987e-01,  3.4520e-01,
          1.5668e-01,  4.7503e-02, -4.0070e-01, -2.0285e-01, -2.5827e-01,
         -2.0116e-01],
        [ 3.6761e-01,  2.2174e-01,  2.0267e-01, -2.0381e-01,  7.5863e-02,
         -2.7509e-02, -1.1394e-01, -3.3799e-01, -3.4089e-01, -1.2256e-01,
         -1.2335e-01,  4.5147e-02, -2.4030e-02,  1.9527e-01,  1.6981e-01,
          3.6704e-02],
        [ 2.3735e-01,  3.5523e-01,  3.9777e-01, -3.4923e-02, -1.7793e-01,
         -6.3651e-02, -7.3277e-02, -8.7105e-02, -2.2312e-01, -1.7367e-01,
         -2.1696e-01,  1.2793e-01,  1.3224e-01,  7.2656e-02, -3.4891e-02,
          2.5176e-01],
        [-3.9583e-01, -3.0452e-01, -9.1144e-02, -2.6785e-02,  2.0305e-01,
          4.4584e-01,  1.2001e-01,  1.2072e-01, -3.7318e-02,  1.8578e-01,
          1.2990e-01, -3.1546e-01, -8.5311e-02, -1.1869e-01, -2.8163e-01,
         -1.7140e-01],
        [-8.8338e-02, -1.5521e-01,  1.7921e-01,  9.0178e-02, -1.9937e-01,
         -1.6402e-02, -1.5518e-01, -2.9328e-01, -1.6843e-01, -8.6479e-03,
          9.7676e-03,  4.3074e-01,  1.1719e-01, -9.5092e-02,  4.1250e-01,
          2.8889e-02],
        [ 3.3308e-01,  2.7427e-01,  2.2021e-01, -3.6769e-01, -2.0598e-01,
         -7.1194e-02, -1.2134e-01, -2.2165e-03, -3.5734e-01, -1.8834e-01,
          1.3666e-01,  2.8895e-01,  3.4599e-01,  2.8635e-01,  1.2695e-01,
         -1.6331e-02],
        [-3.1638e-01, -2.2017e-02, -2.6791e-01,  1.5562e-01, -1.3043e-02,
          3.3742e-01,  3.1231e-01,  2.7689e-01,  1.3435e-01,  2.8738e-01,
         -3.4961e-02, -2.4824e-01, -1.6720e-01, -2.2378e-01,  4.2557e-02,
         -1.8771e-01],
        [ 2.5228e-01,  1.3335e-01,  1.7807e-01, -3.1371e-01, -5.9103e-03,
         -4.1345e-01, -3.0913e-01,  2.9822e-02, -3.8878e-01, -1.3830e-01,
         -4.5874e-02, -8.0102e-02,  1.9473e-01,  2.5948e-01,  3.7088e-01,
          2.1042e-01],
        [ 3.9041e-01,  1.4073e-01,  2.9359e-01, -1.0759e-01, -1.6958e-01,
         -2.6605e-01, -3.7414e-01,  3.3193e-02, -3.5779e-02, -2.8042e-01,
         -7.0511e-02,  2.4645e-01, -7.7071e-02,  1.0764e-01,  3.2768e-01,
          2.0890e-01],
        [-2.0160e-01,  7.6367e-02, -6.9505e-02, -5.0841e-02,  1.5156e-01,
          1.6345e-03,  3.3094e-01,  3.9563e-01,  1.9333e-01,  7.4614e-02,
         -7.0393e-02, -3.0394e-01, -2.0366e-01, -2.0546e-01,  4.5527e-02,
         -2.5395e-01],
        [-8.0821e-02, -3.4139e-01, -5.9790e-02,  3.9028e-01, -1.5498e-01,
          1.3887e-01,  2.5238e-01, -7.0782e-02,  6.3326e-03,  2.5408e-01,
          2.5447e-01, -2.5586e-01, -1.5085e-01, -3.4012e-01, -4.4756e-01,
          5.9216e-02],
        [ 3.7684e-01,  3.5075e-02,  6.8577e-02, -1.6930e-01,  1.6169e-01,
         -4.2206e-01, -3.0845e-01, -2.0868e-01, -2.2984e-01, -1.5252e-01,
          1.1653e-01,  1.9876e-01, -1.1191e-01,  3.1217e-01,  3.7813e-01,
          2.2807e-01],
        [ 2.7619e-01,  2.0317e-01,  3.6184e-01, -3.8231e-01, -8.6390e-02,
         -2.0090e-01, -2.0292e-01, -2.6914e-01, -3.4230e-01, -3.2593e-01,
         -1.0594e-01,  3.3492e-01,  2.5414e-01,  1.4755e-01,  5.6580e-03,
          4.3563e-02],
        [ 2.2820e-01, -1.3435e-01,  1.9103e-01, -1.4430e-01,  1.9245e-01,
         -2.8994e-01,  2.2925e-02, -1.9182e-01, -3.6642e-01,  5.6044e-02,
          1.6812e-01,  1.6714e-02,  5.0031e-02,  2.3487e-01,  7.5397e-02,
          3.3015e-01],
        [ 7.2874e-02,  1.5863e-02,  1.2088e-01,  5.5233e-02, -7.9364e-02,
         -2.6241e-01, -5.5652e-02, -3.6384e-01, -1.8390e-01, -3.6503e-01,
         -2.9565e-01,  1.4166e-01,  1.9808e-01,  3.3236e-01, -2.1341e-02,
          8.6363e-02],
        [ 2.3453e-01,  2.1002e-01,  3.1778e-01, -3.5742e-01, -1.2798e-03,
         -1.2562e-01, -3.7482e-01,  2.0868e-03, -3.5880e-01,  5.9629e-03,
         -2.7296e-04,  7.0591e-02,  1.9884e-01,  2.9926e-01,  3.6495e-01,
          3.0732e-01],
        [-3.3435e-01, -4.0968e-02, -6.3400e-04,  2.1766e-01,  1.9903e-01,
          5.0021e-02,  3.7872e-01,  1.6894e-01, -5.9241e-02,  9.8288e-02,
          2.2050e-01, -2.7410e-01, -2.0824e-01, -1.8849e-01, -3.4110e-01,
         -1.1165e-01],
        [ 3.2256e-01,  1.4732e-01,  1.5825e-01, -1.4201e-01, -1.8062e-01,
         -3.1973e-01, -1.6270e-01, -3.4146e-01, -1.1112e-02, -1.1169e-01,
         -4.0720e-04,  1.4111e-01,  3.1275e-01,  3.0909e-01,  2.9826e-01,
          2.7670e-01],
        [-2.8706e-01, -2.4134e-03, -3.3628e-01,  2.6174e-01, -2.3825e-01,
          1.7885e-01,  3.5310e-01,  2.9217e-01,  3.4104e-01,  2.3180e-01,
          1.8859e-01, -7.5746e-02,  5.1222e-02,  4.9033e-02, -1.0367e-01,
         -2.3590e-01],
        [-3.0283e-01, -1.8300e-01, -6.5287e-02,  3.3273e-02,  5.0799e-02,
          4.1659e-01,  3.9943e-01, -3.1761e-02,  2.1374e-01,  3.2478e-01,
         -1.8806e-01, -8.3856e-03, -2.8623e-01, -2.6976e-01, -3.0101e-01,
         -2.5764e-01],
        [ 8.6756e-02,  2.1002e-01,  2.8827e-01, -9.1022e-02,  1.8041e-01,
         -3.6105e-01, -4.3785e-01, -3.7795e-01, -3.0102e-01, -2.9765e-01,
          2.6684e-02, -1.4911e-03, -1.2226e-02,  2.6589e-01,  5.0802e-02,
          2.1533e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-9.7664e-02, -5.6866e-02,  1.8189e-01, -2.9361e-02, -8.2283e-02,
        -3.8026e-02,  7.0831e-02,  6.1070e-02, -2.7644e-02, -5.5116e-02,
        -2.9136e-02,  5.6820e-02,  1.2498e-01,  9.7914e-02, -1.3909e-02,
        -1.6066e-04, -1.4312e-01,  2.4217e-02,  1.1469e-01,  1.6363e-02,
        -2.1338e-02, -1.7401e-01, -1.4203e-02, -5.0244e-02, -4.1284e-02,
         2.2458e-01,  1.2186e-01,  2.0561e-02, -5.0955e-02, -1.4685e-01,
         1.6829e-02,  2.8277e-02], device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1939,  0.2852, -0.2106, -0.2421,  0.2644,  0.3148, -0.2624, -0.3648,
         -0.2879,  0.3054,  0.2476,  0.3594, -0.2214, -0.3636,  0.2847, -0.1518,
         -0.2829,  0.3236, -0.2148, -0.2293,  0.3415,  0.3407, -0.3602, -0.3661,
         -0.2603, -0.2913, -0.3062,  0.3263, -0.3496,  0.3716,  0.2846, -0.2235]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0107, -0.0030,  0.0258,  ...,  0.2090, -0.3524, -0.1137],
        [-0.0817, -0.1898,  0.0830,  ...,  0.1452, -0.3291,  0.0871],
        [-0.0543,  0.1575,  0.0910,  ...,  0.0109,  0.2356,  0.0345],
        ...,
        [ 0.0421, -0.1558,  0.0129,  ...,  0.0670, -0.2800, -0.1180],
        [ 0.0345, -0.0704,  0.0060,  ..., -0.3027,  0.1276,  0.1557],
        [-0.0852,  0.1613,  0.0122,  ..., -0.1724,  0.0629, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0510,  0.0540, -0.0928, -0.1205, -0.0577,  0.0458, -0.1289,  0.0619,
        -0.0463,  0.0922,  0.0329,  0.0082,  0.0096,  0.0630, -0.0783, -0.0203,
         0.0465, -0.1422, -0.0324, -0.0153, -0.1095,  0.0477,  0.0820, -0.0064,
        -0.0850,  0.0665,  0.0242, -0.0960,  0.0640,  0.1472,  0.1370, -0.0658],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0382, -0.1960, -0.0809,  ..., -0.1398, -0.0158,  0.2625],
        [-0.2363, -0.0447,  0.1043,  ..., -0.0702, -0.0027,  0.2711],
        [ 0.1650, -0.0196, -0.1761,  ...,  0.0828, -0.0238, -0.0686],
        ...,
        [ 0.1520,  0.1115,  0.0819,  ...,  0.2630, -0.2222,  0.0553],
        [-0.0532, -0.1736,  0.0762,  ...,  0.0027,  0.2491,  0.0863],
        [-0.0184, -0.1216,  0.2110,  ...,  0.0513,  0.1396,  0.1314]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0870,  0.1225, -0.0354, -0.0548, -0.0311, -0.0352, -0.0326, -0.0624,
         0.1101, -0.1752,  0.1225, -0.1328,  0.1652, -0.0187, -0.1429,  0.1055,
        -0.1273, -0.1539,  0.0136, -0.0295,  0.0086,  0.1085, -0.1892,  0.2026,
        -0.0698, -0.0287,  0.0881, -0.0374, -0.1122, -0.0601,  0.1110,  0.0010],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5159,  0.4402, -0.5183, -0.5216,  0.3665,  0.3746, -0.4228,  0.4314,
          0.4314, -0.4542, -0.4443,  0.4052,  0.4274, -0.3683,  0.4483,  0.3967,
         -0.5262, -0.5174,  0.3944,  0.4115, -0.4793, -0.4523, -0.5158,  0.3514,
          0.4905,  0.5170, -0.4909,  0.5589, -0.4265, -0.5083,  0.4930,  0.5081]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2378], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 9.7346e-03,  3.6267e-01,  3.2300e-01, -3.1641e-01, -3.1441e-01,
         -2.0206e-01, -9.1617e-02, -4.7729e-01, -2.5335e-01, -8.8459e-02,
         -2.8565e-02,  2.4846e-01,  1.0624e-01, -2.7438e-02,  2.8196e-02,
          3.7121e-01],
        [-2.6147e-01, -3.3923e-01, -1.1616e-01, -1.0414e-02,  5.9912e-02,
          2.8491e-01,  1.9704e-01,  2.2812e-01,  4.5389e-01,  1.5334e-01,
          2.8733e-01, -3.1136e-01, -2.0531e-02, -8.0834e-02,  2.6060e-01,
         -8.3694e-02],
        [ 9.1033e-02,  2.5014e-01,  3.9457e-01, -1.1071e-01, -1.7245e-01,
         -3.8175e-01, -8.2053e-02, -4.9730e-01, -3.1765e-02, -8.6524e-02,
         -1.4042e-01, -5.6391e-03,  4.3514e-01,  3.6933e-01,  1.3971e-01,
          2.6694e-01],
        [ 2.8648e-01,  7.5072e-02,  1.0337e-01, -7.3370e-02, -1.4536e-01,
         -2.3957e-01, -1.9162e-01, -1.7555e-01, -4.9015e-01, -4.2860e-01,
         -1.2272e-01,  4.2483e-01,  3.0984e-01, -7.1312e-02, -1.2799e-01,
          1.6392e-01],
        [-1.0438e-01,  8.3672e-02, -1.8446e-01, -2.9685e-02,  2.5285e-01,
          1.2466e-01,  7.6410e-02,  3.9634e-01,  2.0563e-01,  3.1798e-01,
          3.2281e-01, -2.1400e-01, -7.3305e-02, -2.8139e-01,  1.9452e-01,
         -1.6022e-01],
        [-1.9038e-02,  1.2224e-01, -3.7694e-01,  4.0291e-01,  4.2709e-01,
          1.5178e-02,  2.9667e-01,  4.1952e-02,  3.1508e-01,  2.3716e-01,
         -9.0521e-02, -1.4015e-01, -2.7197e-01,  8.6250e-02,  3.1067e-01,
         -8.4687e-02],
        [ 3.8554e-01,  1.1900e-01,  4.2572e-01, -1.8722e-01, -1.3783e-01,
         -2.5282e-01, -2.1618e-01, -3.1188e-01, -3.2050e-01, -5.0259e-02,
         -5.7230e-02,  1.1733e-01, -3.3793e-02,  2.7189e-01, -1.8885e-01,
          1.6348e-01],
        [-5.0279e-02,  2.6941e-01,  3.7004e-01, -3.5478e-01, -3.9931e-01,
         -3.3041e-01, -1.1481e-01, -3.2214e-01, -2.4944e-01, -2.3606e-01,
         -1.0376e-01,  7.3759e-02,  2.7140e-01, -4.6111e-02,  2.9896e-03,
          3.6403e-01],
        [ 4.7294e-02,  3.0604e-01,  3.1928e-01, -2.4368e-01, -1.3655e-01,
         -3.8868e-01, -2.0115e-01, -1.7582e-01, -1.7145e-02, -3.3765e-01,
         -2.5856e-01,  1.1176e-01, -3.6250e-02,  2.0698e-01, -2.4568e-01,
          1.0061e-01],
        [-3.0085e-01, -1.0855e-01, -1.1632e-01, -1.4070e-02,  1.6658e-01,
          1.9989e-01,  8.8191e-02,  3.1746e-01,  3.3480e-01,  2.5088e-02,
          3.3313e-01, -6.3066e-02, -2.9886e-01, -1.2953e-01,  9.4223e-02,
         -2.0644e-01],
        [-3.7238e-01,  4.5001e-02, -8.5249e-02, -3.2002e-02,  5.5325e-02,
          4.7368e-01,  2.7288e-01,  2.0581e-01,  4.2230e-01,  2.8435e-01,
          1.3594e-01, -5.7228e-02, -1.8704e-01,  6.3864e-02, -7.5208e-02,
         -3.4469e-01],
        [-1.3928e-01, -1.6201e-01, -4.3087e-02,  9.0682e-02,  2.5709e-01,
          1.6367e-01,  4.0717e-01,  2.3012e-01,  2.2864e-01,  3.7658e-01,
          2.5055e-01,  5.8866e-03, -4.0595e-01, -2.8783e-01, -1.2304e-02,
         -2.1469e-01],
        [ 3.5357e-01,  2.5241e-01,  1.9244e-01, -1.7501e-01, -2.3993e-01,
         -3.8472e-02, -1.3783e-01, -4.3614e-01, -4.0866e-01, -1.4472e-01,
         -1.6491e-01,  1.0960e-01, -9.5770e-03,  2.2781e-01, -1.7399e-01,
          4.7373e-02],
        [ 2.2160e-01,  3.3565e-01,  3.8471e-01, -1.3861e-02, -3.8591e-01,
         -5.9135e-02, -7.4330e-02, -1.3840e-01, -2.7182e-01, -1.8965e-01,
         -2.7438e-01,  1.5840e-01,  1.4790e-01,  1.0719e-01, -2.5199e-01,
          2.4808e-01],
        [-3.8795e-01, -2.9924e-01, -8.4586e-02, -4.2264e-02,  4.4831e-01,
          4.4833e-01,  1.3240e-01,  1.9030e-01,  2.9588e-02,  2.0720e-01,
          1.8736e-01, -3.6261e-01, -1.1338e-01, -1.6252e-01, -4.7710e-02,
         -1.7234e-01],
        [-5.8748e-02, -6.8611e-02,  2.1975e-01,  8.8772e-02, -4.3935e-01,
         -8.6161e-02, -2.4064e-01, -4.1713e-01, -2.8923e-01, -9.4862e-02,
         -1.2837e-01,  4.8278e-01,  2.0449e-01,  3.1267e-02,  1.5529e-01,
          8.3400e-02],
        [ 3.2943e-01,  2.7161e-01,  2.1856e-01, -3.5665e-01, -4.4391e-01,
         -8.0454e-02, -1.3949e-01, -7.5714e-02, -4.3028e-01, -2.1577e-01,
          9.7305e-02,  3.4536e-01,  3.8978e-01,  3.3552e-01, -7.0805e-02,
         -1.3994e-02],
        [-3.0763e-01, -9.6881e-03, -2.6113e-01,  1.4409e-01,  2.0324e-01,
          3.3382e-01,  3.1750e-01,  3.3543e-01,  1.9663e-01,  3.0771e-01,
          9.5772e-04, -2.8986e-01, -1.8451e-01, -2.7139e-01,  2.0971e-01,
         -1.8670e-01],
        [ 2.2966e-01,  1.1947e-01,  1.5475e-01, -2.6894e-01, -3.1688e-01,
         -4.1120e-01, -3.1927e-01, -5.5695e-02, -4.7902e-01, -1.2520e-01,
         -1.1075e-01, -2.5243e-02,  2.6003e-01,  3.2082e-01,  9.2580e-02,
          1.9106e-01],
        [ 3.8773e-01,  1.3732e-01,  2.9078e-01, -9.1501e-02, -4.0549e-01,
         -2.7606e-01, -3.9572e-01, -5.2503e-02, -1.1700e-01, -3.0471e-01,
         -1.5064e-01,  3.0759e-01, -3.0621e-02,  1.6355e-01,  9.4250e-02,
          2.1086e-01],
        [-1.9155e-01,  5.1369e-02, -6.3831e-02, -6.6914e-02,  3.4640e-01,
         -2.6674e-03,  3.3676e-01,  4.2272e-01,  2.2736e-01,  9.6241e-02,
         -6.4767e-03, -3.1616e-01, -2.1518e-01, -2.4883e-01,  2.9658e-01,
         -2.6565e-01],
        [-8.2754e-02, -3.3575e-01, -6.2628e-02,  3.7886e-01,  6.1195e-02,
          1.5675e-01,  2.8817e-01,  1.6510e-02,  8.4851e-02,  2.8893e-01,
          3.8264e-01, -3.1097e-01, -2.2093e-01, -4.0923e-01, -1.7524e-01,
          4.8940e-02],
        [ 3.7844e-01,  3.4368e-02,  7.0808e-02, -1.6659e-01, -7.0159e-02,
         -4.3321e-01, -3.3007e-01, -2.8985e-01, -3.0876e-01, -1.8260e-01,
          6.4494e-02,  2.5808e-01, -6.5928e-02,  3.6834e-01,  1.8794e-01,
          2.3339e-01],
        [ 2.6901e-01,  2.0343e-01,  3.5632e-01, -3.7479e-01, -2.9360e-01,
         -1.9704e-01, -2.1083e-01, -3.3796e-01, -4.0910e-01, -3.4545e-01,
         -9.8409e-02,  3.8412e-01,  2.7063e-01,  1.8769e-01, -1.4898e-01,
          3.7971e-02],
        [ 2.2326e-01, -1.0807e-01,  1.9053e-01, -1.2275e-01, -2.6894e-02,
         -3.0311e-01,  2.4961e-03, -2.5297e-01, -4.3035e-01,  2.3744e-02,
          7.0895e-02,  5.9000e-02,  8.8167e-02,  2.9453e-01, -2.2642e-01,
          3.5056e-01],
        [ 5.3380e-02,  3.2492e-02,  1.0518e-01,  8.0019e-02, -2.9615e-01,
         -2.4790e-01, -4.9752e-02, -3.9282e-01, -2.1401e-01, -3.7756e-01,
         -3.5960e-01,  1.5362e-01,  1.9887e-01,  3.6416e-01, -2.8582e-01,
          9.1339e-02],
        [ 2.3506e-01,  1.9855e-01,  3.1848e-01, -3.5275e-01, -2.4802e-01,
         -1.3562e-01, -3.9424e-01, -8.5319e-02, -4.4207e-01, -2.1474e-02,
         -4.2958e-02,  1.3514e-01,  2.4479e-01,  3.4928e-01,  1.8386e-01,
          3.0934e-01],
        [-3.3177e-01, -5.6246e-02, -2.0112e-03,  2.0658e-01,  3.9252e-01,
          6.4461e-02,  4.0208e-01,  2.4624e-01,  9.2021e-03,  1.3255e-01,
          2.9640e-01, -3.2469e-01, -2.4306e-01, -2.5494e-01, -9.1559e-02,
         -1.2597e-01],
        [ 3.1772e-01,  1.6662e-01,  1.5610e-01, -1.3527e-01, -3.7639e-01,
         -3.2608e-01, -1.8012e-01, -4.0962e-01, -7.7039e-02, -1.3735e-01,
         -5.9817e-03,  1.9183e-01,  3.1633e-01,  3.6504e-01,  7.2215e-02,
          2.7964e-01],
        [-2.8446e-01,  2.0197e-02, -3.3436e-01,  2.5665e-01, -9.7838e-03,
          1.8092e-01,  3.6458e-01,  3.6332e-01,  4.1079e-01,  2.5692e-01,
          2.3919e-01, -1.2543e-01,  2.4687e-02, -3.4827e-04,  6.1412e-02,
         -2.3950e-01],
        [-3.0064e-01, -1.8768e-01, -6.4285e-02,  2.2539e-02,  2.7749e-01,
          4.2725e-01,  4.1883e-01,  4.6092e-02,  2.9038e-01,  3.5179e-01,
         -1.2644e-01, -6.5720e-02, -3.3150e-01, -3.2833e-01, -7.7497e-02,
         -2.6110e-01],
        [ 6.9605e-02,  1.7954e-01,  2.7181e-01, -5.0239e-02, -7.5497e-02,
         -3.5920e-01, -4.4172e-01, -4.4930e-01, -3.7620e-01, -2.9448e-01,
         -3.5421e-02,  4.4306e-02,  1.2295e-02,  3.2048e-01, -1.7331e-01,
          2.0574e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0550, -0.0110,  0.1072, -0.0370, -0.0576, -0.0894,  0.0734,  0.0814,
        -0.0199, -0.0568, -0.0050,  0.0594,  0.1461,  0.0789,  0.0202, -0.0506,
        -0.0518, -0.0043,  0.0904,  0.0058, -0.0414, -0.1383, -0.0298,  0.0006,
        -0.0071,  0.1604,  0.1182,  0.0201, -0.0658, -0.1406,  0.0315, -0.0440],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2326,  0.3236, -0.2300, -0.2638,  0.3248,  0.3626, -0.2844, -0.3864,
         -0.3169,  0.3482,  0.2658,  0.3763, -0.2657, -0.4008,  0.3060, -0.2848,
         -0.3229,  0.3341, -0.2305, -0.2525,  0.4020,  0.3145, -0.3739, -0.3811,
         -0.3312, -0.3414, -0.3160,  0.3533, -0.3620,  0.3854,  0.2921, -0.2396]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0140, -0.0094,  0.0437,  ...,  0.2364, -0.3682, -0.1137],
        [-0.0869, -0.1928,  0.0878,  ...,  0.1479, -0.3485,  0.0871],
        [-0.0398,  0.1769,  0.0729,  ..., -0.0053,  0.2682,  0.0345],
        ...,
        [ 0.0254, -0.1915,  0.0426,  ...,  0.0662, -0.2938, -0.1180],
        [ 0.0516, -0.0484, -0.0196,  ..., -0.3044,  0.1539,  0.1557],
        [-0.2052,  0.0489,  0.0023,  ...,  0.0417, -0.2388, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0570,  0.0575, -0.0881, -0.1189, -0.0574,  0.0527, -0.1278,  0.0611,
        -0.0491,  0.0819,  0.0313,  0.0093,  0.0257,  0.0733, -0.0782, -0.0172,
         0.0498, -0.1497, -0.0286, -0.0239, -0.0749,  0.0446,  0.0886, -0.0072,
        -0.0870,  0.0867,  0.0329, -0.0876,  0.0488,  0.1385,  0.1476, -0.1051],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0182, -0.1905, -0.0796,  ..., -0.1165, -0.0281,  0.0708],
        [-0.2653, -0.0445,  0.1163,  ..., -0.0485, -0.0074,  0.0588],
        [ 0.1839, -0.0293, -0.1770,  ...,  0.0542, -0.0082,  0.1671],
        ...,
        [ 0.1660,  0.0968,  0.0890,  ...,  0.2282, -0.1999,  0.2420],
        [-0.0787, -0.1643,  0.0785,  ...,  0.0323,  0.2361, -0.1654],
        [-0.0488, -0.1253,  0.2162,  ...,  0.0711,  0.1339, -0.0320]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0831,  0.1209, -0.0224, -0.0583, -0.0348, -0.0632, -0.0254, -0.0603,
         0.0939, -0.1343,  0.1355, -0.1273,  0.1510,  0.0570, -0.1348,  0.0867,
        -0.1173, -0.1449,  0.0024, -0.0145,  0.0077,  0.1102, -0.1829,  0.1723,
        -0.0646, -0.0316,  0.0913, -0.0429, -0.1085, -0.0529,  0.0943,  0.0027],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5200,  0.4420, -0.5190, -0.5218,  0.3866,  0.3776, -0.4335,  0.4281,
          0.4530, -0.4571, -0.4170,  0.4133,  0.4122,  0.4224,  0.4510,  0.4045,
         -0.5203, -0.5259,  0.3900,  0.4156, -0.4754, -0.4536, -0.5198,  0.3805,
          0.5039,  0.5279, -0.5036,  0.5527, -0.4321, -0.5172,  0.4985,  0.5198]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2386], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.1533e-02,  6.8440e-02,  2.9796e-01, -3.3492e-01, -2.8127e-01,
         -1.5059e-01, -5.7449e-02, -4.4520e-01, -2.0215e-01, -5.8699e-02,
          1.7807e-01,  1.9876e-01,  6.2494e-02, -5.2105e-02, -1.7565e-01,
          3.7085e-01],
        [-2.6299e-01, -7.5322e-02, -1.0213e-01,  1.7281e-02,  4.0288e-02,
          2.4794e-01,  1.6666e-01,  2.0144e-01,  4.3584e-01,  1.4079e-01,
          6.7839e-02, -2.7559e-01, -1.0778e-02, -6.2957e-02,  4.5854e-01,
         -8.5103e-02],
        [ 8.9780e-02,  8.4458e-03,  3.7327e-01, -1.2905e-01, -1.3296e-01,
         -3.4064e-01, -3.9418e-02, -4.5420e-01,  1.3500e-02, -6.4165e-02,
         -8.3406e-02, -4.8842e-02,  4.0350e-01,  3.2738e-01, -5.0480e-02,
          2.6309e-01],
        [ 2.7270e-01, -5.4849e-02,  7.2995e-02, -8.6596e-02, -1.0409e-01,
         -1.8202e-01, -1.3873e-01, -1.2453e-01, -4.4151e-01, -3.9679e-01,
          3.0489e-02,  3.6334e-01,  2.9692e-01, -1.1151e-01, -2.8384e-01,
          1.4685e-01],
        [-1.0153e-01,  3.3663e-01, -1.6410e-01, -3.9917e-03,  2.2367e-01,
          8.0563e-02,  3.6927e-02,  3.6008e-01,  1.7396e-01,  3.0056e-01,
          6.5889e-02, -1.7047e-01, -5.5866e-02, -2.5254e-01,  3.7397e-01,
         -1.5830e-01],
        [-4.7450e-03,  3.1561e-01, -3.5006e-01,  4.1636e-01,  3.7164e-01,
         -4.2257e-02,  2.4790e-01, -6.9954e-03,  2.7485e-01,  2.1086e-01,
         -1.1243e-01, -9.0785e-02, -2.3431e-01,  1.1753e-01,  4.4168e-01,
         -7.4991e-02],
        [ 3.7457e-01, -8.6067e-03,  4.0017e-01, -2.0200e-01, -1.0899e-01,
         -2.0547e-01, -1.6886e-01, -2.6943e-01, -2.7687e-01, -2.7220e-02,
          3.3093e-03,  6.9911e-02, -6.0008e-02,  1.8789e-01, -3.5291e-01,
          1.5216e-01],
        [-5.9178e-02,  1.3608e-01,  3.5026e-01, -3.7096e-01, -3.8022e-01,
         -2.9518e-01, -8.0869e-02, -2.9508e-01, -2.2539e-01, -2.2208e-01,
         -5.9624e-02,  4.3820e-02,  2.5402e-01, -9.3322e-02, -1.3711e-01,
          3.5546e-01],
        [ 5.0995e-02,  2.2238e-02,  3.0716e-01, -2.7583e-01, -1.2146e-01,
         -3.5124e-01, -1.7208e-01, -1.5059e-01,  4.4830e-03, -3.2761e-01,
          1.3205e-02,  7.6952e-02, -4.4610e-02,  1.9309e-01, -4.3541e-01,
          1.0639e-01],
        [-3.0122e-01,  1.6561e-01, -1.0178e-01,  1.4953e-02,  1.3892e-01,
          1.5876e-01,  5.2053e-02,  2.8240e-01,  3.0568e-01,  1.1394e-02,
          1.0682e-01, -2.5175e-02, -2.8045e-01, -1.1072e-01,  2.7629e-01,
         -2.0981e-01],
        [-3.6501e-01,  2.1412e-01, -6.0625e-02, -1.3988e-02,  2.3504e-02,
          4.2464e-01,  2.3276e-01,  1.6521e-01,  3.8601e-01,  2.5992e-01,
          3.9480e-03, -8.5584e-03, -2.1483e-01,  7.9499e-02,  8.5508e-02,
         -3.3636e-01],
        [-1.2901e-01,  1.9077e-02, -1.8391e-02,  1.1041e-01,  2.1278e-01,
          1.1742e-01,  3.5322e-01,  1.7823e-01,  1.8372e-01,  3.5168e-01,
          8.8458e-02,  5.7557e-02, -4.2135e-01, -2.4339e-01,  1.3275e-01,
         -2.0478e-01],
        [ 3.4764e-01, -3.0691e-03,  1.6219e-01, -1.9776e-01, -1.9103e-01,
          2.1619e-02, -9.0035e-02, -3.8553e-01, -3.6944e-01, -1.1477e-01,
         -9.3794e-02,  5.3396e-02, -1.3173e-02,  2.0864e-01, -3.9183e-01,
          3.9518e-02],
        [ 2.1680e-01,  1.0992e-01,  3.6744e-01, -3.5460e-02, -3.6049e-01,
         -2.2795e-02, -3.7339e-02, -1.0630e-01, -2.5041e-01, -1.7479e-01,
         -1.0745e-01,  1.2288e-01,  1.3250e-01,  7.0021e-02, -4.2910e-01,
          2.4389e-01],
        [-3.8669e-01, -6.3317e-02, -6.8319e-02, -1.7675e-02,  4.3346e-01,
          4.1457e-01,  1.0163e-01,  1.6601e-01,  7.0081e-03,  1.9516e-01,
          3.3914e-02, -3.2956e-01, -1.0790e-01, -1.3930e-01,  1.5203e-01,
         -1.7033e-01],
        [-3.5268e-02, -4.0115e-01,  2.0201e-01,  3.3186e-02, -4.4133e-01,
         -2.4184e-02, -1.9994e-01, -3.9949e-01, -2.6908e-01, -7.4203e-02,
         -5.0411e-02,  4.4453e-01,  1.8899e-01, -1.7972e-02, -9.2183e-02,
          1.0188e-01],
        [ 3.1795e-01,  1.0016e-01,  1.9411e-01, -3.7056e-01, -3.8643e-01,
         -3.1026e-02, -8.6013e-02, -2.4087e-02, -3.9676e-01, -1.8962e-01,
          1.9488e-01,  2.9394e-01,  3.5159e-01,  2.7255e-01, -1.9200e-01,
         -2.7982e-02],
        [-2.9096e-01,  1.1782e-01, -2.3194e-01,  1.5276e-01,  1.4912e-01,
          2.8600e-01,  2.6529e-01,  2.8739e-01,  1.5153e-01,  2.8285e-01,
         -5.2468e-02, -2.4212e-01, -1.4842e-01, -1.9630e-01,  2.8473e-01,
         -1.6942e-01],
        [ 2.3853e-01, -8.6928e-02,  1.4488e-01, -2.9740e-01, -2.4567e-01,
         -3.7517e-01, -2.7481e-01, -6.6918e-03, -4.2955e-01, -1.1219e-01,
          1.6984e-02, -6.8563e-02,  2.0404e-01,  2.5929e-01, -6.1808e-02,
          1.9655e-01],
        [ 3.8001e-01, -6.1459e-02,  2.6423e-01, -1.1063e-01, -3.7727e-01,
         -2.3145e-01, -3.5208e-01, -1.5766e-02, -8.2071e-02, -2.8112e-01,
          9.2939e-02,  2.5929e-01, -3.6897e-02,  1.2130e-01, -9.9731e-02,
          1.9977e-01],
        [-1.7778e-01,  2.3936e-01, -3.6690e-02, -5.5704e-02,  3.0069e-01,
         -4.7542e-02,  2.9310e-01,  3.8224e-01,  1.9433e-01,  7.3254e-02,
         -1.0942e-01, -2.7329e-01, -1.9530e-01, -2.0578e-01,  4.1732e-01,
         -2.5315e-01],
        [-9.5256e-02,  8.8782e-03, -5.7965e-02,  4.1916e-01,  6.0762e-02,
          1.2597e-01,  2.6525e-01,  7.6433e-04,  7.6603e-02,  2.8762e-01,
          2.1369e-01, -2.9379e-01, -2.2037e-01, -3.9702e-01, -7.7072e-04,
          4.0238e-02],
        [ 3.7239e-01, -1.4955e-01,  5.1024e-02, -1.8644e-01, -4.4232e-02,
         -3.9755e-01, -2.9240e-01, -2.6193e-01, -2.8297e-01, -1.6792e-01,
          2.0749e-01,  2.2486e-01, -6.8066e-02,  3.2565e-01,  3.1696e-02,
          2.2496e-01],
        [ 2.5250e-01,  1.1627e-01,  3.2959e-01, -3.8317e-01, -2.2760e-01,
         -1.5331e-01, -1.5978e-01, -2.9055e-01, -3.6976e-01, -3.1957e-01,
          1.8510e-02,  3.4123e-01,  2.6423e-01,  1.2415e-01, -2.2205e-01,
          1.6095e-02],
        [ 2.1720e-01, -3.6654e-01,  1.7027e-01, -1.4801e-01,  1.1731e-02,
         -2.5046e-01,  4.9220e-02, -2.0385e-01, -3.8714e-01,  4.4811e-02,
          1.9672e-01,  9.1042e-03,  5.9422e-02,  2.7141e-01, -4.0351e-01,
          3.5023e-01],
        [ 4.6844e-02, -1.7803e-01,  8.3594e-02,  6.2537e-02, -2.5898e-01,
         -2.1037e-01, -1.9349e-02, -3.5983e-01, -1.8745e-01, -3.6088e-01,
         -2.6635e-01,  1.1744e-01,  1.9662e-01,  3.3886e-01, -4.6300e-01,
          8.4107e-02],
        [ 2.2429e-01, -5.9051e-03,  2.9104e-01, -3.6605e-01, -2.1161e-01,
         -9.6582e-02, -3.4505e-01, -5.0103e-02, -4.0644e-01,  1.0815e-04,
          4.8106e-02,  9.2648e-02,  2.3249e-01,  2.7319e-01,  4.1481e-02,
          2.9276e-01],
        [-3.2963e-01,  1.6565e-01,  1.6881e-02,  2.3200e-01,  3.5938e-01,
          2.2936e-02,  3.5653e-01,  2.0546e-01, -2.8757e-02,  1.1480e-01,
          7.2695e-02, -2.8040e-01, -2.3244e-01, -2.1478e-01,  6.8526e-02,
         -1.2305e-01],
        [ 3.0401e-01,  4.8973e-02,  1.2810e-01, -1.4784e-01, -3.2741e-01,
         -2.8276e-01, -1.3408e-01, -3.6501e-01, -3.9166e-02, -1.1224e-01,
          1.1203e-01,  1.4403e-01,  3.5586e-01,  3.2438e-01, -4.5104e-02,
          2.6315e-01],
        [-2.7343e-01,  1.5491e-01, -3.1193e-01,  2.7103e-01, -3.5995e-02,
          1.4406e-01,  3.2480e-01,  3.3098e-01,  3.8004e-01,  2.3972e-01,
          1.4712e-01, -9.1979e-02,  4.3259e-02,  5.0782e-02,  2.0090e-01,
         -2.2794e-01],
        [-2.8879e-01,  1.2461e-02, -3.6617e-02,  3.6929e-02,  2.3609e-01,
          3.7891e-01,  3.7084e-01,  4.6515e-03,  2.5312e-01,  3.2747e-01,
         -2.3061e-01, -1.5233e-02, -3.1476e-01, -2.8070e-01,  7.2729e-02,
         -2.4696e-01],
        [ 6.3514e-02, -1.1297e-02,  2.4653e-01, -6.9833e-02, -3.6087e-02,
         -3.1233e-01, -3.8844e-01, -3.9213e-01, -3.2532e-01, -2.6888e-01,
          9.4884e-02, -1.2812e-02, -3.2397e-02,  2.3095e-01, -3.3640e-01,
          1.9818e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-6.4252e-02, -5.9739e-02,  1.1524e-01, -7.6824e-02, -5.1550e-02,
        -2.6594e-02,  8.3928e-02,  1.3533e-01, -4.7282e-02, -6.4446e-02,
         2.6529e-02,  6.9856e-02,  1.9176e-01,  1.0751e-01, -5.6034e-02,
         9.9741e-02, -1.5243e-01, -4.0812e-03,  2.1624e-02,  3.7393e-05,
        -1.9549e-02, -1.0832e-01, -6.0622e-02, -2.5788e-02, -1.6055e-01,
         2.5856e-01,  1.0313e-01,  2.6606e-02, -8.5457e-02, -2.2693e-01,
         1.6302e-01, -3.0349e-02], device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2519,  0.3389, -0.2462, -0.2605,  0.3414,  0.3825, -0.2984, -0.3834,
         -0.3328,  0.3855,  0.2650,  0.3923, -0.2852, -0.4238,  0.3219, -0.3131,
         -0.3281,  0.3291, -0.2383, -0.2580,  0.4202,  0.3409, -0.3743, -0.3763,
         -0.3820, -0.3588, -0.3205,  0.3665, -0.3486,  0.3867,  0.2903, -0.2401]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0538,  0.1287,  0.0574,  ...,  0.2203, -0.3288, -0.1137],
        [-0.1229, -0.0295,  0.1171,  ...,  0.1553, -0.3293,  0.0871],
        [ 0.0126, -0.0595,  0.0185,  ...,  0.0280,  0.2318,  0.0345],
        ...,
        [-0.0047,  0.0345,  0.0579,  ...,  0.0849, -0.3183, -0.1180],
        [ 0.0992, -0.2295, -0.0535,  ..., -0.3282,  0.1516,  0.1557],
        [-0.2187,  0.1715,  0.0377,  ...,  0.0979, -0.2773, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0412,  0.0407, -0.0664, -0.1340, -0.0721,  0.0600, -0.1103,  0.0455,
        -0.0385,  0.0799,  0.0173,  0.0117,  0.0300,  0.0790, -0.0526, -0.0185,
         0.0585, -0.1552,  0.0024,  0.0281, -0.0499,  0.0326,  0.1092,  0.0058,
        -0.0936,  0.1045,  0.0472, -0.0942,  0.0537,  0.1393,  0.1671, -0.1230],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0774, -0.1808, -0.1176,  ..., -0.1306, -0.0170,  0.0750],
        [-0.2030, -0.0367,  0.0828,  ..., -0.0636,  0.0065,  0.0496],
        [ 0.1347, -0.0266, -0.1575,  ...,  0.0823, -0.0257,  0.1872],
        ...,
        [ 0.1150,  0.0939,  0.1222,  ...,  0.2522, -0.2240,  0.2454],
        [-0.0036, -0.1483,  0.0369,  ...,  0.0178,  0.2353, -0.1671],
        [-0.0007, -0.1338,  0.1972,  ...,  0.0364,  0.1629, -0.0501]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1028,  0.1471, -0.0581, -0.0831, -0.0006, -0.0436, -0.0574, -0.0442,
         0.1235, -0.1689,  0.1277, -0.1175,  0.1718,  0.0867, -0.1233,  0.1246,
        -0.1387, -0.1723, -0.0581, -0.0036, -0.0022,  0.0855, -0.2099,  0.2128,
        -0.0462, -0.0048,  0.0749, -0.0292, -0.1356, -0.0726,  0.1200,  0.0417],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4587,  0.3785, -0.4631, -0.4530,  0.3306,  0.3129, -0.3763,  0.3485,
          0.3780, -0.4007, -0.3474,  0.3640,  0.3475,  0.3271,  0.3911,  0.3856,
         -0.4544, -0.4675, -0.3216,  0.3673, -0.4119, -0.3902, -0.4641,  0.3107,
          0.4340,  0.4687, -0.4522,  0.4572, -0.3781, -0.4557,  0.4399,  0.4653]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2208], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-7.5264e-03,  3.5526e-01,  2.8788e-01, -3.0290e-01, -2.7895e-01,
         -1.3059e-01, -3.9973e-02, -4.3939e-01, -2.0341e-01, -3.9137e-02,
          1.4794e-01,  1.7842e-01,  4.5828e-02, -6.2162e-02, -1.6802e-01,
          3.4742e-01],
        [-2.4526e-01, -3.4617e-01, -8.7644e-02, -8.3312e-03,  3.2182e-02,
          2.3347e-01,  1.5653e-01,  1.9149e-01,  4.2477e-01,  1.2482e-01,
          7.8690e-02, -2.5709e-01,  1.5801e-03, -5.4100e-02,  4.5008e-01,
         -6.4613e-02],
        [ 7.0676e-02,  2.4317e-01,  3.5892e-01, -1.0285e-01, -1.3526e-01,
         -3.2812e-01, -3.0970e-02, -4.5334e-01,  1.3237e-02, -4.7321e-02,
         -9.2064e-02, -6.5211e-02,  3.9560e-01,  3.2476e-01, -4.5985e-02,
          2.4255e-01],
        [ 2.5777e-01,  6.9445e-02,  6.4321e-02, -6.6231e-02, -1.0576e-01,
         -1.7289e-01, -1.3549e-01, -1.1982e-01, -4.4107e-01, -3.8528e-01,
          2.0439e-02,  3.5168e-01,  2.9182e-01, -1.1132e-01, -2.8727e-01,
          1.2876e-01],
        [-9.6909e-02,  8.4780e-02, -1.6086e-01, -2.1388e-02,  2.4229e-01,
          7.5281e-02,  4.3192e-02,  3.7459e-01,  1.8745e-01,  2.9402e-01,
          9.6470e-02, -1.6615e-01, -6.5793e-02, -2.6393e-01,  3.9820e-01,
         -1.4666e-01],
        [-3.9953e-04,  1.2430e-01, -3.4859e-01,  4.0326e-01,  3.8556e-01,
         -4.0352e-02,  2.5174e-01, -3.5704e-03,  2.8006e-01,  2.0680e-01,
         -1.1178e-01, -8.7104e-02, -2.4720e-01,  1.1027e-01,  4.8907e-01,
         -6.6841e-02],
        [ 3.5781e-01,  1.2320e-01,  3.8821e-01, -1.7963e-01, -1.0633e-01,
         -1.9699e-01, -1.6369e-01, -2.6121e-01, -2.6438e-01, -1.4418e-02,
         -1.5960e-03,  5.6151e-02, -6.6548e-02,  1.8555e-01, -3.5630e-01,
          1.3442e-01],
        [-7.6206e-02,  2.7475e-01,  3.3734e-01, -3.4788e-01, -3.6472e-01,
         -2.8541e-01, -7.1269e-02, -2.8070e-01, -2.1074e-01, -2.0861e-01,
         -7.4862e-02,  2.6883e-02,  2.4373e-01, -9.8726e-02, -1.2871e-01,
          3.3907e-01],
        [ 3.5037e-02,  3.1949e-01,  2.9443e-01, -2.5260e-01, -1.1014e-01,
         -3.3892e-01, -1.6313e-01, -1.3931e-01,  1.2352e-02, -3.1305e-01,
          3.0611e-03,  6.0767e-02, -5.4046e-02,  1.8661e-01, -4.2996e-01,
          8.6510e-02],
        [-2.9309e-01, -1.1285e-01, -9.5143e-02, -4.0044e-03,  1.4659e-01,
          1.5150e-01,  5.1961e-02,  2.8768e-01,  3.1044e-01,  2.5690e-03,
          1.3533e-01, -1.6337e-02, -2.8263e-01, -1.1316e-01,  2.8772e-01,
         -1.9662e-01],
        [-3.5661e-01,  4.4851e-02, -5.6657e-02, -2.7620e-02,  3.2556e-02,
          4.1972e-01,  2.3258e-01,  1.6880e-01,  3.9248e-01,  2.5305e-01,
         -1.3020e-03, -3.0071e-03, -2.1198e-01,  7.1617e-02,  1.0398e-01,
         -3.2370e-01],
        [-1.1749e-01, -1.5342e-01, -1.0351e-02,  9.1792e-02,  2.1042e-01,
          1.0698e-01,  3.5266e-01,  1.7850e-01,  1.8138e-01,  3.4234e-01,
          1.1286e-01,  6.7494e-02, -4.1454e-01, -2.4997e-01,  1.3272e-01,
         -1.9019e-01],
        [ 3.2993e-01,  2.4823e-01,  1.4907e-01, -1.6904e-01, -2.0280e-01,
          3.8966e-02, -8.3192e-02, -3.9024e-01, -3.7139e-01, -9.7305e-02,
         -1.0383e-01,  3.4785e-02, -2.1614e-02,  2.0473e-01, -3.9290e-01,
          1.8906e-02],
        [ 1.9988e-01,  3.4038e-01,  3.5276e-01, -1.2591e-02, -3.5014e-01,
         -1.0326e-02, -2.9720e-02, -9.5437e-02, -2.3598e-01, -1.6010e-01,
         -1.1519e-01,  1.0651e-01,  1.2177e-01,  6.4318e-02, -4.2202e-01,
          2.2559e-01],
        [-3.7080e-01, -3.0732e-01, -5.5974e-02, -4.0228e-02,  4.2569e-01,
          4.0279e-01,  9.3885e-02,  1.5650e-01, -8.5583e-04,  1.8131e-01,
          4.2308e-02, -3.1399e-01, -9.8303e-02, -1.3434e-01,  1.4333e-01,
         -1.5230e-01],
        [-3.0467e-01, -2.2894e-01,  1.0054e-02,  2.6195e-01,  1.4551e-01,
          1.8007e-01,  1.0398e-01,  8.0025e-02,  1.7282e-01,  1.3606e-01,
          5.0811e-02,  1.4142e-01, -1.5294e-01, -3.0265e-01,  5.9126e-01,
         -9.3056e-02],
        [ 3.0029e-01,  2.4040e-01,  1.8364e-01, -3.4864e-01, -3.7941e-01,
         -1.9712e-02, -8.1099e-02, -9.0803e-03, -3.8623e-01, -1.7703e-01,
          1.7147e-01,  2.7957e-01,  3.3872e-01,  2.7435e-01, -1.7367e-01,
         -4.5917e-02],
        [-2.7593e-01,  3.9779e-02, -2.2225e-01,  1.3125e-01,  1.4655e-01,
          2.8035e-01,  2.6209e-01,  2.7941e-01,  1.4450e-01,  2.7216e-01,
         -4.5746e-02, -2.2961e-01, -1.4819e-01, -1.9234e-01,  2.8748e-01,
         -1.5305e-01],
        [ 2.2168e-01,  1.1671e-01,  1.3562e-01, -2.7435e-01, -2.4899e-01,
         -3.6481e-01, -2.7108e-01, -4.9648e-03, -4.3420e-01, -9.8558e-02,
          1.7717e-02, -8.1271e-02,  1.9796e-01,  2.6091e-01, -5.5672e-02,
          1.7547e-01],
        [ 3.6603e-01,  1.4202e-01,  2.5661e-01, -9.1765e-02, -3.7612e-01,
         -2.2121e-01, -3.5135e-01, -9.7569e-03, -8.1338e-02, -2.7016e-01,
          8.4025e-02,  2.4880e-01, -4.2905e-02,  1.2874e-01, -9.8114e-02,
          1.8170e-01],
        [-1.6881e-01,  6.2911e-02, -2.9945e-02, -7.2950e-02,  3.0745e-01,
         -5.2221e-02,  2.9520e-01,  3.8369e-01,  1.9396e-01,  6.5696e-02,
         -8.6483e-02, -2.6518e-01, -2.0050e-01, -2.1369e-01,  4.5161e-01,
         -2.4175e-01],
        [-8.4805e-02, -3.3987e-01, -5.2481e-02,  3.9914e-01,  5.0013e-02,
          1.1835e-01,  2.6238e-01, -5.6046e-03,  7.4228e-02,  2.7778e-01,
          2.3163e-01, -2.8035e-01, -2.1688e-01, -3.9828e-01, -1.1301e-03,
          5.3904e-02],
        [ 3.6287e-01,  2.3919e-02,  4.5813e-02, -1.7055e-01, -4.4447e-02,
         -3.9236e-01, -2.9435e-01, -2.5826e-01, -2.8195e-01, -1.6132e-01,
          1.8424e-01,  2.1787e-01, -6.8300e-02,  3.3046e-01,  3.3583e-02,
          2.1280e-01],
        [ 2.3180e-01,  1.7953e-01,  3.1649e-01, -3.5774e-01, -2.1297e-01,
         -1.4114e-01, -1.5128e-01, -2.6921e-01, -3.5442e-01, -3.0532e-01,
          4.3816e-03,  3.2207e-01,  2.5040e-01,  1.1859e-01, -1.9664e-01,
         -2.4819e-03],
        [ 2.1527e-01, -9.4337e-02,  1.7023e-01, -1.3610e-01, -2.1198e-03,
         -2.5007e-01,  4.3233e-02, -2.1314e-01, -3.9703e-01,  4.7328e-02,
          1.9542e-01,  8.1876e-03,  6.8948e-02,  2.8296e-01, -4.2356e-01,
          3.4382e-01],
        [ 3.5207e-02,  4.1070e-02,  7.3696e-02,  8.1714e-02, -2.6387e-01,
         -2.0272e-01, -1.3570e-02, -3.6094e-01, -1.8597e-01, -3.5048e-01,
         -2.8242e-01,  1.0589e-01,  1.9525e-01,  3.4071e-01, -4.8292e-01,
          7.0656e-02],
        [ 2.0866e-01,  1.6775e-01,  2.8160e-01, -3.4621e-01, -2.0537e-01,
         -8.5916e-02, -3.4449e-01, -3.9318e-02, -3.9899e-01,  1.1053e-02,
          2.8074e-02,  8.1115e-02,  2.2335e-01,  2.8459e-01,  4.8413e-02,
          2.7708e-01],
        [-3.2261e-01, -5.3461e-02,  1.9969e-02,  2.1557e-01,  3.6628e-01,
          1.5983e-02,  3.6046e-01,  2.1077e-01, -2.3561e-02,  1.0898e-01,
          9.8931e-02, -2.7451e-01, -2.3398e-01, -2.2904e-01,  8.3480e-02,
         -1.1167e-01],
        [ 2.8793e-01,  1.5851e-01,  1.1718e-01, -1.2758e-01, -3.2082e-01,
         -2.7012e-01, -1.3054e-01, -3.5494e-01, -3.0847e-02, -1.0032e-01,
          9.1157e-02,  1.3059e-01,  3.4457e-01,  3.2615e-01, -3.6417e-02,
          2.4705e-01],
        [-2.6203e-01,  1.7797e-02, -3.0410e-01,  2.5284e-01, -3.7421e-02,
          1.3918e-01,  3.2415e-01,  3.2693e-01,  3.7546e-01,  2.3160e-01,
          1.5536e-01, -8.2330e-02,  4.2811e-02,  4.6448e-02,  2.1170e-01,
         -2.1533e-01],
        [-2.7445e-01, -1.6551e-01, -2.8416e-02,  1.7664e-02,  2.3186e-01,
          3.7040e-01,  3.6862e-01, -5.3206e-03,  2.4941e-01,  3.1664e-01,
         -2.1524e-01, -4.5250e-03, -3.0937e-01, -2.8146e-01,  6.1584e-02,
         -2.2976e-01],
        [ 4.2864e-02,  1.3780e-01,  2.3316e-01, -4.2336e-02, -3.3083e-02,
         -2.9892e-01, -3.8286e-01, -3.9090e-01, -3.2403e-01, -2.5300e-01,
          8.5547e-02, -2.8047e-02, -4.3124e-02,  2.2666e-01, -3.2254e-01,
          1.7496e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0925, -0.0261,  0.1094, -0.0838, -0.0431, -0.0212,  0.0809,  0.1305,
        -0.0612, -0.0414,  0.0136,  0.0951,  0.1544,  0.0857, -0.0314, -0.0472,
        -0.1804,  0.0048,  0.0056, -0.0172, -0.0100, -0.0824, -0.0747, -0.0418,
        -0.1378,  0.2571,  0.0809,  0.0487, -0.1063, -0.2222,  0.1885, -0.0494],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2567,  0.3413, -0.2493, -0.2686,  0.3681,  0.4013, -0.3042, -0.3831,
         -0.3492,  0.3947,  0.2754,  0.3933, -0.2975, -0.4303,  0.3231,  0.3063,
         -0.3295,  0.3340, -0.2423, -0.2610,  0.4279,  0.3400, -0.3785, -0.3775,
         -0.4140, -0.3701, -0.3222,  0.3702, -0.3525,  0.3908,  0.2949, -0.2460]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0169,  0.1037,  0.0776,  ...,  0.1582, -0.2608, -0.1137],
        [-0.1142, -0.0396,  0.1177,  ...,  0.1308, -0.3109,  0.0871],
        [-0.0020, -0.0407,  0.0316,  ...,  0.0273,  0.2301,  0.0345],
        ...,
        [ 0.0068,  0.0222,  0.0544,  ...,  0.0663, -0.3099, -0.1180],
        [ 0.0938, -0.2211, -0.0537,  ..., -0.3024,  0.1378,  0.1557],
        [-0.1978,  0.1631,  0.0396,  ...,  0.0657, -0.2693, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0469,  0.0413, -0.0709, -0.1352, -0.0728,  0.0515, -0.1113,  0.0503,
        -0.0403,  0.0783,  0.0234,  0.0117,  0.0250,  0.0747, -0.0519, -0.0202,
         0.0577, -0.1577, -0.0614,  0.0361, -0.0556,  0.0305,  0.1055,  0.0062,
        -0.0887,  0.0537,  0.0428, -0.1125,  0.0545,  0.1432,  0.1667, -0.1265],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0651, -0.1800, -0.1081,  ..., -0.1206, -0.0253,  0.0749],
        [-0.2138, -0.0359,  0.1049,  ..., -0.0500, -0.0087,  0.0482],
        [ 0.1393, -0.0300, -0.1654,  ...,  0.0661, -0.0103,  0.1823],
        ...,
        [ 0.1119,  0.0782,  0.1244,  ...,  0.2323, -0.2025,  0.2308],
        [-0.0096, -0.1480,  0.0498,  ...,  0.0377,  0.2184, -0.1669],
        [-0.0007, -0.1228,  0.1950,  ...,  0.0591,  0.1418, -0.0372]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1057,  0.1587, -0.0586, -0.0816, -0.0069, -0.0424, -0.0563, -0.0438,
         0.1331, -0.1766,  0.1146, -0.1299,  0.1908,  0.1022, -0.1273,  0.1323,
        -0.1372, -0.1712,  0.0431, -0.0122, -0.0049,  0.0877, -0.1987,  0.2341,
        -0.0442, -0.0081,  0.0778, -0.0279, -0.1339, -0.0680,  0.1262,  0.0351],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4804,  0.4057, -0.4822, -0.4594,  0.3443,  0.3475, -0.3925,  0.3590,
          0.3809, -0.4250, -0.3725,  0.3691,  0.3657,  0.3548,  0.4005,  0.4117,
         -0.4665, -0.4791,  0.3295,  0.3771, -0.4276, -0.4075, -0.4756,  0.3242,
          0.4517,  0.4792, -0.4615,  0.4706, -0.3921, -0.4661,  0.4564,  0.4719]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2306], device='cuda:0', requires_grad=True)

