Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 9.0411e-03,  3.9158e-01,  3.0422e-01, -3.0899e-01, -1.9403e-01,
         -1.5247e-01, -1.0253e-01, -4.1026e-01, -3.2977e-01, -8.0005e-02,
         -1.7374e-02,  2.1544e-01, -3.4436e-01, -7.2481e-02, -6.9318e-02,
          3.9696e-01],
        [-2.5154e-01, -3.7961e-01, -9.3661e-02, -2.9583e-02, -2.6488e-02,
          2.4891e-01,  1.7733e-01,  1.7675e-01,  4.8958e-01,  1.3695e-01,
          2.8616e-01, -2.7788e-01,  3.8964e-01, -1.9364e-02,  3.6993e-01,
         -9.4047e-02],
        [ 1.1014e-01,  2.9609e-01,  3.9226e-01, -1.2052e-01, -1.1549e-01,
         -3.4657e-01, -1.2587e-01, -4.7690e-01, -1.4366e-01, -9.9443e-02,
         -1.5274e-01, -5.3354e-03, -2.8399e-02,  3.5288e-01, -6.6316e-02,
          3.0383e-01],
        [ 2.8862e-01,  1.0891e-01,  8.9438e-02, -6.5976e-02, -6.8750e-02,
         -2.1888e-01, -1.9336e-01, -1.4185e-01, -5.3988e-01, -4.2938e-01,
         -2.0435e-01,  4.0666e-01, -1.0993e-01, -1.2437e-01, -2.4275e-01,
          1.8472e-01],
        [-1.0402e-01,  4.0957e-02, -1.6877e-01, -3.9734e-02,  1.7309e-01,
          9.5370e-02,  6.7033e-02,  3.5345e-01,  2.4890e-01,  3.0912e-01,
          3.3928e-01, -1.9228e-01,  3.6028e-01, -2.2796e-01,  3.2907e-01,
         -1.8069e-01],
        [-3.5404e-02,  6.1278e-02, -3.7706e-01,  4.0621e-01,  3.7453e-01,
          1.1448e-03,  3.1861e-01,  2.8577e-02,  3.9138e-01,  2.4577e-01,
         -7.7067e-02, -1.4275e-01,  1.7150e-01,  1.1355e-01,  4.8299e-01,
         -1.1923e-01],
        [ 3.6928e-01,  2.3891e-01,  3.9994e-01, -1.6704e-01, -5.5306e-02,
         -2.0537e-01, -2.0123e-01, -2.5172e-01, -3.5620e-01, -3.0909e-02,
         -3.2978e-02,  7.7016e-02, -3.8510e-01,  1.9470e-01, -3.2944e-01,
          1.6638e-01],
        [-5.2070e-02,  3.6012e-01,  3.6015e-01, -3.5097e-01, -3.5281e-01,
         -2.9889e-01, -1.2235e-01, -2.8976e-01, -3.0191e-01, -2.3240e-01,
         -8.7970e-02,  5.7198e-02, -6.9494e-02, -9.9800e-02, -1.5875e-01,
          3.7808e-01],
        [ 4.1527e-02,  3.5802e-01,  3.0369e-01, -2.3678e-01, -5.6402e-02,
         -3.4564e-01, -1.8159e-01, -1.1426e-01, -4.9192e-02, -3.2370e-01,
         -2.7895e-01,  6.9089e-02, -4.4653e-01,  1.6097e-01, -3.3019e-01,
          1.1870e-01],
        [-3.1433e-01, -1.6663e-01, -1.1457e-01, -8.9770e-03,  1.0568e-01,
          1.7865e-01,  1.0282e-01,  2.8573e-01,  3.9167e-01,  2.8149e-02,
          3.6297e-01, -5.1862e-02,  1.5788e-01, -9.9084e-02,  2.4739e-01,
         -2.4144e-01],
        [-3.7812e-01,  2.0811e-02, -7.4683e-02, -3.5730e-02, -2.2900e-02,
          4.4936e-01,  2.8443e-01,  1.7496e-01,  4.7787e-01,  2.8532e-01,
          2.1923e-01, -4.1894e-02,  2.3264e-01,  1.0547e-01,  5.8691e-02,
         -3.7007e-01],
        [-1.5309e-01, -2.0915e-01, -4.4361e-02,  9.6706e-02,  2.0041e-01,
          1.4213e-01,  4.1859e-01,  1.8840e-01,  2.7822e-01,  3.7889e-01,
          4.0901e-01,  2.7575e-02, -2.7432e-02, -2.7369e-01,  8.1490e-02,
         -2.5079e-01],
        [ 3.4150e-01,  2.8283e-01,  1.6155e-01, -1.5355e-01, -1.0707e-01,
          2.0768e-02, -1.0684e-01, -3.5099e-01, -4.3135e-01, -1.1873e-01,
         -1.6540e-01,  6.2130e-02, -4.7285e-01,  1.4763e-01, -2.8085e-01,
          5.8881e-02],
        [ 2.1567e-01,  4.0080e-01,  3.7043e-01, -3.6971e-03, -3.1714e-01,
         -2.2911e-02, -5.8494e-02, -8.8548e-02, -3.0480e-01, -1.7714e-01,
         -2.7532e-01,  1.2573e-01, -2.2708e-01,  5.8635e-02, -3.6406e-01,
          2.6099e-01],
        [-3.8384e-01, -3.4966e-01, -6.9358e-02, -4.6172e-02,  3.7553e-01,
          4.0562e-01,  1.2995e-01,  1.4397e-01,  7.2682e-02,  1.9931e-01,
          1.8387e-01, -3.3452e-01,  2.8571e-01, -1.0793e-01,  9.9655e-02,
         -1.8791e-01],
        [-3.5285e-02, -1.3438e-02,  2.0090e-01,  1.0326e-01, -3.8079e-01,
         -6.6035e-02, -2.6202e-01, -4.0780e-01, -4.1950e-01, -1.0876e-01,
         -1.2869e-01,  5.1200e-01, -3.8718e-01, -3.1815e-02, -3.4818e-02,
          1.3867e-01],
        [ 3.3915e-01,  3.3151e-01,  2.1734e-01, -3.5912e-01, -3.8885e-01,
         -5.9765e-02, -1.4310e-01, -4.2749e-02, -4.8684e-01, -2.1747e-01,
          7.3740e-02,  3.2804e-01,  6.0096e-03,  3.0721e-01, -1.8536e-01,
          1.5009e-02],
        [-3.0163e-01, -5.3090e-02, -2.4560e-01,  1.3090e-01,  1.4220e-01,
          3.0718e-01,  3.1325e-01,  3.0141e-01,  2.4317e-01,  3.0044e-01,
         -6.4329e-04, -2.7026e-01,  1.3731e-01, -2.0518e-01,  3.2484e-01,
         -1.9593e-01],
        [ 2.3730e-01,  1.4768e-01,  1.3963e-01, -2.6260e-01, -2.2201e-01,
         -3.7194e-01, -3.5282e-01, -1.7661e-02, -5.8631e-01, -1.2798e-01,
         -1.0451e-01, -3.7937e-02, -1.8851e-01,  2.8924e-01, -9.6045e-02,
          2.2161e-01],
        [ 3.7799e-01,  1.7601e-01,  2.7082e-01, -8.1239e-02, -3.0995e-01,
         -2.2746e-01, -3.8130e-01,  1.3190e-02, -1.4924e-01, -2.9124e-01,
         -1.6112e-01,  2.6025e-01, -4.2902e-01,  1.0088e-01,  6.3414e-03,
          2.2351e-01],
        [-1.9615e-01,  8.1815e-03, -5.5576e-02, -7.5980e-02,  2.9530e-01,
         -1.4925e-02,  3.3864e-01,  4.0814e-01,  2.9229e-01,  9.6562e-02,
          2.8323e-03, -3.1413e-01,  1.5900e-01, -2.0504e-01,  4.3519e-01,
         -2.8442e-01],
        [-9.4832e-02, -4.1479e-01, -6.2710e-02,  3.9266e-01, -1.5085e-03,
          1.2130e-01,  2.9971e-01, -2.7951e-02,  1.3762e-01,  2.8977e-01,
          4.0238e-01, -2.8993e-01,  2.2282e-01, -3.8006e-01, -2.3260e-02,
          1.2535e-02],
        [ 3.7146e-01,  7.3458e-02,  5.4930e-02, -1.5703e-01, -3.3691e-04,
         -3.9857e-01, -3.1863e-01, -2.4670e-01, -3.4770e-01, -1.7199e-01,
          6.3956e-02,  2.2950e-01, -4.1599e-01,  3.1012e-01,  6.4039e-02,
          2.4452e-01],
        [ 2.6199e-01,  2.2739e-01,  3.4181e-01, -3.5969e-01, -2.3735e-01,
         -1.7086e-01, -1.9774e-01, -3.0125e-01, -4.4668e-01, -3.3763e-01,
         -1.2483e-01,  3.5978e-01, -4.8356e-03,  1.2006e-01, -2.1189e-01,
          4.5429e-02],
        [ 2.4149e-01, -4.5638e-02,  1.8650e-01, -1.2148e-01,  2.4117e-02,
         -2.9458e-01, -1.7872e-02, -2.4220e-01, -5.2024e-01,  1.4165e-02,
          4.7707e-02,  6.2448e-02, -4.0986e-01,  2.6789e-01, -3.8712e-01,
          3.9123e-01],
        [ 5.7255e-02,  7.8152e-02,  9.3392e-02,  8.6500e-02, -2.3679e-01,
         -2.2163e-01, -5.7601e-02, -3.7509e-01, -2.8006e-01, -3.7755e-01,
         -3.5724e-01,  1.5029e-01, -1.9199e-01,  3.1151e-01, -4.3669e-01,
          1.1180e-01],
        [ 2.3744e-01,  2.5393e-01,  3.1102e-01, -3.4984e-01, -1.8990e-01,
         -1.0406e-01, -3.9468e-01, -4.6734e-02, -4.9775e-01, -1.9202e-02,
         -5.2461e-02,  1.1119e-01, -1.1304e-01,  3.0548e-01,  5.9169e-02,
          3.2962e-01],
        [-3.3772e-01, -1.0451e-01,  3.8389e-03,  2.0874e-01,  3.2282e-01,
          3.2866e-02,  4.0662e-01,  1.9340e-01,  4.9379e-02,  1.2850e-01,
          3.7747e-01, -2.9490e-01,  1.7178e-01, -2.2575e-01,  3.1695e-02,
         -1.5406e-01],
        [ 3.2472e-01,  1.9481e-01,  1.5237e-01, -1.3801e-01, -3.1950e-01,
         -2.9885e-01, -1.8844e-01, -3.7462e-01, -1.2948e-01, -1.3853e-01,
         -1.0058e-01,  1.7025e-01,  4.6952e-03,  3.3174e-01, -4.1458e-02,
          3.0504e-01],
        [-2.7058e-01, -3.2883e-02, -3.1253e-01,  2.3641e-01, -7.6998e-02,
          1.4629e-01,  3.5117e-01,  3.2048e-01,  4.4731e-01,  2.4225e-01,
          2.1622e-01, -9.7530e-02,  3.5155e-01,  7.5801e-02,  1.6670e-01,
         -2.4099e-01],
        [-3.1180e-01, -2.3466e-01, -6.2749e-02,  2.6891e-02,  2.2054e-01,
          4.0692e-01,  4.3037e-01,  1.7444e-02,  3.5215e-01,  3.5704e-01,
         -8.9543e-02, -5.1329e-02,  6.3475e-02, -3.0011e-01,  7.2240e-02,
         -2.9125e-01],
        [ 4.8350e-02,  2.1823e-01,  2.3632e-01, -2.0892e-02,  1.2997e-02,
         -3.1296e-01, -4.2609e-01, -3.8820e-01, -4.4170e-01, -2.7504e-01,
         -2.0903e-02,  4.6661e-03, -3.8414e-01,  2.5428e-01, -2.8350e-01,
          2.0438e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0828, -0.0211, -0.0445, -0.0282,  0.0066, -0.2271,  0.0848,  0.1053,
        -0.0742,  0.0016,  0.0424,  0.0901,  0.1283,  0.0579,  0.0748,  0.0029,
        -0.0382, -0.0351,  0.0637, -0.0468, -0.1123, -0.0379, -0.0364,  0.0277,
        -0.0391,  0.1323,  0.1340,  0.0607, -0.1185, -0.1802,  0.0397,  0.0227],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2642,  0.3589, -0.2763, -0.3079,  0.3576,  0.4283, -0.3185, -0.4065,
         -0.3584,  0.4051,  0.3159,  0.4251, -0.3164, -0.4355,  0.3227, -0.3523,
         -0.3653,  0.3678, -0.2840, -0.2705,  0.4658,  0.3641, -0.4114, -0.4061,
         -0.3712, -0.3842, -0.3566,  0.3903, -0.3879,  0.4158,  0.3479, -0.2783]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0126,  0.1649,  0.0610,  ...,  0.2064, -0.3328, -0.1137],
        [-0.0600, -0.0669,  0.1179,  ...,  0.1032, -0.3025,  0.0871],
        [-0.1271,  0.2355,  0.0833,  ...,  0.2118, -0.0313,  0.0345],
        ...,
        [ 0.0872, -0.1230, -0.0377,  ..., -0.1687, -0.0059, -0.1180],
        [ 0.0288, -0.1955, -0.0375,  ..., -0.2639,  0.1078,  0.1557],
        [-0.1709,  0.1430,  0.0450,  ...,  0.0759, -0.2702, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0595,  0.0290, -0.0879, -0.1551, -0.0816, -0.0077, -0.1012,  0.0455,
        -0.0366,  0.0588,  0.0333, -0.0092,  0.0182,  0.1023, -0.0421, -0.0198,
         0.0535, -0.1667,  0.0074,  0.0828, -0.0654,  0.0162,  0.1105,  0.0250,
        -0.1078,  0.0979,  0.0441, -0.1059,  0.0506,  0.2078,  0.1690, -0.1260],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0411, -0.1653, -0.1956,  ...,  0.0356, -0.0419,  0.0654],
        [-0.2245, -0.0198, -0.0211,  ...,  0.1416, -0.0233,  0.0489],
        [ 0.1590, -0.0455, -0.0318,  ..., -0.1437, -0.0028,  0.1895],
        ...,
        [ 0.1732,  0.0508,  0.2407,  ...,  0.1131, -0.1758,  0.2518],
        [-0.0148, -0.1499, -0.0397,  ...,  0.2508,  0.2260, -0.1779],
        [-0.0040, -0.1181,  0.1309,  ...,  0.2294,  0.1346, -0.0453]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0998,  0.1498, -0.0475, -0.1073, -0.0988, -0.1798, -0.0729, -0.0189,
         0.1497, -0.1796,  0.1400, -0.1341,  0.2065,  0.1034, -0.1004,  0.1346,
        -0.1304, -0.1867,  0.0823,  0.0130, -0.0216,  0.0722, -0.2058,  0.2265,
        -0.0407, -0.0160,  0.0762, -0.0475, -0.1610, -0.0502,  0.1324,  0.0360],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4476,  0.3724, -0.4158, -0.4430, -0.3069, -0.2961, -0.3536,  0.3306,
          0.3404, -0.3577, -0.3236,  0.3366,  0.3392,  0.2926,  0.3581,  0.3376,
         -0.4394, -0.4397,  0.2946,  0.3469, -0.4020, -0.3482, -0.4542,  0.2872,
          0.4157,  0.4652, -0.4198,  0.4443, -0.3537, -0.4464,  0.4063,  0.4461]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1828], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.9678e-02,  3.1188e-01,  3.1993e-01, -3.4655e-01, -6.3171e-02,
         -1.8718e-01, -9.2897e-02, -4.4032e-01, -1.9345e-01, -6.0819e-02,
          3.3493e-02,  2.0206e-01,  9.5702e-02, -6.4672e-02,  3.6823e-01,
          3.3584e-01],
        [-2.9255e-01, -3.0151e-01, -1.3437e-01,  2.4246e-02, -1.2066e-01,
          3.0459e-01,  2.2126e-01,  2.2353e-01,  4.2699e-01,  1.2413e-01,
          2.1822e-01, -3.0655e-01, -4.3928e-02, -4.3812e-02, -5.8467e-02,
         -6.5820e-02],
        [ 9.7598e-02,  2.0701e-01,  3.9354e-01, -1.3160e-01,  1.0884e-01,
         -3.7433e-01, -8.3004e-02, -4.5186e-01,  4.6840e-02, -5.4387e-02,
         -8.7813e-02, -4.3344e-02,  4.2317e-01,  2.9472e-01,  4.7238e-01,
          2.3554e-01],
        [ 2.9455e-01,  2.5479e-02,  1.0059e-01, -8.9545e-02,  5.7306e-02,
         -2.3612e-01, -1.9051e-01, -1.4814e-01, -4.2685e-01, -3.7729e-01,
         -9.3284e-02,  3.9593e-01,  3.2213e-01, -1.4549e-01,  1.8179e-01,
          1.2909e-01],
        [-1.4085e-01,  1.6693e-01, -1.9989e-01,  1.3311e-02,  1.0859e-01,
          1.5344e-01,  1.0805e-01,  4.2163e-01,  2.0250e-01,  2.7926e-01,
          2.1564e-01, -2.4166e-01, -1.1005e-01, -2.2846e-01, -1.6054e-01,
         -1.1267e-01],
        [-3.8839e-02,  1.9090e-01, -3.8241e-01,  4.2683e-01,  2.1640e-01,
          2.8812e-02,  3.0537e-01,  4.6536e-02,  2.9714e-01,  1.9415e-01,
         -1.6118e-01, -1.5090e-01, -3.0735e-01,  1.3006e-01, -2.7762e-02,
         -4.7814e-02],
        [ 3.9988e-01,  1.6488e-01,  4.3174e-01, -2.0378e-01,  9.4869e-02,
         -2.5909e-01, -2.3433e-01, -2.8357e-01, -2.6615e-01, -1.0020e-02,
         -1.4139e-02,  9.0195e-02,  2.0932e-04,  2.1928e-01,  3.2367e-02,
          1.4040e-01],
        [-4.2528e-02,  2.8102e-01,  3.7159e-01, -3.6069e-01, -1.7765e-01,
         -3.3516e-01, -1.2481e-01, -2.8633e-01, -1.9177e-01, -1.9644e-01,
         -6.5443e-02,  4.2316e-02,  2.8357e-01, -9.5481e-02,  1.9364e-01,
          3.4566e-01],
        [ 7.5776e-02,  2.7081e-01,  3.3459e-01, -2.8137e-01, -6.6244e-03,
         -4.0287e-01, -2.1790e-01, -1.6407e-01,  1.7611e-02, -3.0482e-01,
         -1.1484e-01,  1.0867e-01, -4.1015e-02,  1.3495e-01,  7.6827e-02,
          7.9935e-02],
        [-3.2368e-01, -4.3477e-02, -1.2355e-01,  1.4378e-02,  5.8564e-03,
          2.1079e-01,  1.0099e-01,  3.1432e-01,  3.0460e-01, -1.9823e-02,
          2.2818e-01, -6.5319e-02, -3.1012e-01, -6.5189e-02, -2.4960e-01,
         -1.6723e-01],
        [-3.7064e-01,  1.1095e-01, -7.3570e-02, -3.0949e-02, -1.4208e-01,
          4.5791e-01,  2.6504e-01,  1.6059e-01,  3.4842e-01,  2.2477e-01,
          6.2286e-02, -1.3330e-02, -1.9292e-01,  1.4897e-01, -4.2927e-01,
         -3.0258e-01],
        [-1.5453e-01, -1.0662e-01, -4.4037e-02,  1.0722e-01,  1.5230e-01,
          1.6361e-01,  4.1838e-01,  2.1180e-01,  1.8804e-01,  3.2382e-01,
          1.4902e-01,  1.8994e-02, -4.3779e-01, -1.8169e-01, -3.0969e-01,
         -1.7397e-01],
        [ 3.8530e-01,  1.7493e-01,  2.0684e-01, -2.1348e-01,  2.9448e-02,
         -5.0577e-02, -1.5105e-01, -4.0133e-01, -3.7193e-01, -1.0294e-01,
         -1.1156e-01,  8.4954e-02,  2.3831e-02,  1.9375e-01,  2.4203e-01,
          7.0716e-03],
        [ 2.5517e-01,  3.2133e-01,  4.0660e-01, -4.7810e-02, -2.1802e-01,
         -8.4393e-02, -1.0589e-01, -1.4124e-01, -2.5167e-01, -1.6716e-01,
         -2.1385e-01,  1.6228e-01,  1.7835e-01,  7.3981e-02,  2.4115e-02,
          2.3806e-01],
        [-4.0236e-01, -2.6765e-01, -9.0173e-02, -2.5289e-02,  2.3867e-01,
          4.5412e-01,  1.4208e-01,  1.6525e-01, -2.1456e-02,  1.6809e-01,
          1.2374e-01, -3.3997e-01, -1.2012e-01, -1.0986e-01, -3.2602e-01,
         -1.4959e-01],
        [-5.5471e-02, -2.2230e-01,  1.8694e-01,  6.0695e-02, -2.7832e-01,
         -5.8528e-02, -1.9851e-01, -3.8787e-01, -2.3546e-01,  2.9674e-03,
          4.1911e-02,  5.1416e-01,  2.0540e-01, -7.3182e-02,  5.2608e-01,
         -3.2023e-03],
        [ 3.3373e-01,  2.2942e-01,  2.1331e-01, -3.6361e-01, -2.5550e-01,
         -7.5884e-02, -1.3834e-01, -5.7879e-02, -3.7924e-01, -1.6040e-01,
          1.5710e-01,  3.2265e-01,  3.8310e-01,  2.5790e-01,  1.6227e-01,
         -4.7639e-02],
        [-3.1541e-01,  1.5809e-02, -2.6122e-01,  1.5057e-01,  2.3127e-02,
          3.3867e-01,  3.2663e-01,  3.1776e-01,  1.4643e-01,  2.6439e-01,
         -4.6749e-02, -2.7010e-01, -1.9721e-01, -2.0632e-01,  1.1451e-02,
         -1.6286e-01],
        [ 2.4716e-01,  9.0891e-02,  1.6542e-01, -3.0160e-01, -3.8984e-02,
         -4.0946e-01, -3.2460e-01, -8.2649e-03, -3.9372e-01, -1.0648e-01,
         -3.6612e-02, -6.2303e-02,  2.2115e-01,  2.3914e-01,  4.0632e-01,
          1.7747e-01],
        [ 3.9356e-01,  1.0337e-01,  2.8835e-01, -1.0370e-01, -1.9897e-01,
         -2.6930e-01, -3.9498e-01, -4.2047e-03, -4.3058e-02, -2.5742e-01,
         -6.7580e-02,  2.6456e-01, -4.8273e-02,  9.6072e-02,  3.7139e-01,
          1.8346e-01],
        [-2.1888e-01,  1.1989e-01, -7.5530e-02, -3.5509e-02,  2.0428e-01,
          2.4819e-02,  3.5887e-01,  4.5748e-01,  2.3568e-01,  6.5770e-02,
         -8.9965e-02, -3.5395e-01, -2.6299e-01, -2.1317e-01, -1.7464e-02,
         -2.3388e-01],
        [-9.1670e-02, -3.0563e-01, -6.2239e-02,  3.9474e-01, -1.1801e-01,
          1.5088e-01,  2.7904e-01, -2.4263e-02,  2.3071e-02,  2.3813e-01,
          2.5046e-01, -2.8239e-01, -1.8466e-01, -3.2841e-01, -4.9918e-01,
          7.9674e-02],
        [ 3.7588e-01,  6.3039e-04,  6.2016e-02, -1.6358e-01,  1.3178e-01,
         -4.2155e-01, -3.2189e-01, -2.4288e-01, -2.3566e-01, -1.3109e-01,
          1.2225e-01,  2.1493e-01, -8.7359e-02,  2.9688e-01,  4.0843e-01,
          2.0589e-01],
        [ 2.7094e-01,  1.6679e-01,  3.5115e-01, -3.7329e-01, -1.1718e-01,
         -1.9670e-01, -2.1093e-01, -3.0304e-01, -3.4882e-01, -3.0068e-01,
         -9.6538e-02,  3.5206e-01,  2.7900e-01,  1.2878e-01,  2.8767e-02,
          1.9049e-02],
        [ 2.4924e-01, -1.8427e-01,  1.9852e-01, -1.5809e-01,  1.2776e-01,
         -3.1788e-01, -1.6820e-02, -2.7207e-01, -4.0964e-01,  7.4228e-02,
          1.9053e-01,  7.0748e-02,  1.0623e-01,  2.2249e-01,  1.4780e-01,
          3.0005e-01],
        [ 9.3902e-02, -2.6236e-02,  1.3079e-01,  3.8683e-02, -1.2931e-01,
         -2.8974e-01, -9.2207e-02, -4.3044e-01, -2.2447e-01, -3.5581e-01,
         -2.8155e-01,  1.8906e-01,  2.5324e-01,  3.3873e-01,  4.8282e-02,
          6.6083e-02],
        [ 2.3049e-01,  1.7310e-01,  3.0834e-01, -3.4840e-01, -3.1651e-02,
         -1.2241e-01, -3.8643e-01, -3.1470e-02, -3.6316e-01,  3.1115e-02,
          8.3982e-03,  8.6242e-02,  2.2227e-01,  2.8181e-01,  3.9349e-01,
          2.8182e-01],
        [-3.4143e-01, -1.0844e-03,  9.0669e-04,  2.1914e-01,  2.4051e-01,
          5.9060e-02,  4.0290e-01,  2.1846e-01, -4.0121e-02,  7.7845e-02,
          2.0996e-01, -3.0268e-01, -2.4617e-01, -1.7582e-01, -3.8837e-01,
         -8.5216e-02],
        [ 3.2166e-01,  1.1039e-01,  1.5132e-01, -1.3672e-01, -2.1624e-01,
         -3.2020e-01, -1.7705e-01, -3.8028e-01, -2.1071e-02, -8.8785e-02,
          9.6956e-03,  1.6135e-01,  3.4166e-01,  2.9024e-01,  3.3008e-01,
          2.5096e-01],
        [-2.8802e-01,  3.0287e-02, -3.3205e-01,  2.5890e-01, -2.1097e-01,
          1.8093e-01,  3.6790e-01,  3.2477e-01,  3.4911e-01,  2.1467e-01,
          1.8375e-01, -9.1629e-02,  2.4160e-02,  5.6013e-02, -1.3607e-01,
         -2.1698e-01],
        [-3.0349e-01, -1.4372e-01, -5.8802e-02,  2.7278e-02,  8.7163e-02,
          4.1893e-01,  4.1878e-01,  1.0750e-02,  2.2432e-01,  2.9943e-01,
         -1.9812e-01, -3.0387e-02, -3.1586e-01, -2.4840e-01, -3.3876e-01,
         -2.2974e-01],
        [ 8.9992e-02,  1.6968e-01,  2.8305e-01, -8.6975e-02,  1.4574e-01,
         -3.6629e-01, -4.6196e-01, -4.2152e-01, -3.1318e-01, -2.7278e-01,
          3.4677e-02,  2.0882e-02,  2.0539e-02,  2.5100e-01,  9.6880e-02,
          1.8667e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-7.7105e-02, -7.9067e-02,  2.0632e-01, -1.9598e-05, -1.3053e-01,
        -8.3291e-02,  9.4364e-02,  8.3124e-02, -6.4901e-03, -9.1160e-02,
        -4.8213e-02,  2.9417e-02,  1.5460e-01,  1.2172e-01, -3.6227e-02,
         6.1824e-03, -1.0053e-01, -2.2818e-03,  1.3765e-01,  3.2180e-02,
        -5.4734e-02, -1.9973e-01,  5.0479e-03, -3.2190e-02,  2.1772e-02,
         2.6440e-01,  1.4391e-01, -7.8074e-03, -2.7141e-02, -1.6265e-01,
        -1.1090e-02,  5.2307e-02], device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2289,  0.3258, -0.2446, -0.2807,  0.3465,  0.3799, -0.2912, -0.3912,
         -0.3162,  0.3730,  0.2856,  0.4050, -0.2787, -0.3965,  0.3220, -0.2789,
         -0.3181,  0.3534, -0.2445, -0.2585,  0.4268,  0.3798, -0.3906, -0.3912,
         -0.3255, -0.3603, -0.3332,  0.3847, -0.3855,  0.3992,  0.3149, -0.2527]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0093,  0.0020,  0.0250,  ...,  0.2106, -0.3871, -0.1137],
        [-0.0793, -0.1837,  0.0813,  ...,  0.1477, -0.3537,  0.0871],
        [-0.0568,  0.1512,  0.0935,  ...,  0.0066,  0.2682,  0.0345],
        ...,
        [ 0.0438, -0.1504,  0.0115,  ...,  0.0696, -0.3178, -0.1180],
        [ 0.0294, -0.0793,  0.0112,  ..., -0.3095,  0.1516,  0.1557],
        [-0.0870,  0.1559,  0.0135,  ..., -0.1750,  0.1043, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0505,  0.0546, -0.0943, -0.1208, -0.0567,  0.0466, -0.1304,  0.0617,
        -0.0453,  0.0925,  0.0354,  0.0057,  0.0101,  0.0637, -0.0777, -0.0192,
         0.0455, -0.1420, -0.0332, -0.0147, -0.1084,  0.0512,  0.0815, -0.0068,
        -0.0856,  0.0670,  0.0248, -0.0951,  0.0637,  0.1474,  0.1324, -0.0660],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0236, -0.2062, -0.0718,  ..., -0.1561, -0.0041,  0.2734],
        [-0.2532, -0.0530,  0.1106,  ..., -0.0861,  0.0051,  0.2804],
        [ 0.1783, -0.0091, -0.1863,  ...,  0.0973, -0.0359, -0.0787],
        ...,
        [ 0.1658,  0.1210,  0.0727,  ...,  0.2791, -0.2359,  0.0461],
        [-0.0689, -0.1851,  0.0868,  ..., -0.0136,  0.2605,  0.0980],
        [-0.0324, -0.1301,  0.2188,  ...,  0.0358,  0.1514,  0.1405]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0906,  0.1265, -0.0376, -0.0577, -0.0319, -0.0371, -0.0338, -0.0630,
         0.1113, -0.1794,  0.1235, -0.1330,  0.1661, -0.0208, -0.1435,  0.1090,
        -0.1292, -0.1555,  0.0149, -0.0299,  0.0075,  0.1068, -0.1932,  0.2059,
        -0.0667, -0.0275,  0.0879, -0.0335, -0.1135, -0.0618,  0.1152,  0.0034],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.6129,  0.5374, -0.6182, -0.6188,  0.4651,  0.4746, -0.5211,  0.5314,
          0.5283, -0.5539, -0.5434,  0.5030,  0.5249, -0.4668,  0.5468,  0.4960,
         -0.6237, -0.6142,  0.4910,  0.5096, -0.5788, -0.5512, -0.6140,  0.4482,
          0.5891,  0.6138, -0.5894,  0.6581, -0.5243, -0.6057,  0.5924,  0.6047]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.3255], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.9663e-02,  3.1176e-01,  3.1986e-01, -3.4650e-01, -6.3266e-02,
         -1.8718e-01, -9.2902e-02, -4.4042e-01, -1.9346e-01, -6.0733e-02,
          3.3519e-02,  2.0212e-01,  9.5798e-02, -6.4730e-02,  3.6831e-01,
          3.3574e-01],
        [-2.9254e-01, -3.0139e-01, -1.3431e-01,  2.4206e-02, -1.2057e-01,
          3.0460e-01,  2.2127e-01,  2.2362e-01,  4.2700e-01,  1.2406e-01,
          2.1819e-01, -3.0660e-01, -4.4019e-02, -4.3752e-02, -5.8530e-02,
         -6.5731e-02],
        [ 9.7581e-02,  2.0689e-01,  3.9346e-01, -1.3155e-01,  1.0876e-01,
         -3.7433e-01, -8.3008e-02, -4.5195e-01,  4.6828e-02, -5.4305e-02,
         -8.7789e-02, -4.3288e-02,  4.2327e-01,  2.9466e-01,  4.7245e-01,
          2.3544e-01],
        [ 2.9454e-01,  2.5360e-02,  1.0053e-01, -8.9503e-02,  5.7209e-02,
         -2.3612e-01, -1.9051e-01, -1.4823e-01, -4.2687e-01, -3.7722e-01,
         -9.3251e-02,  3.9599e-01,  3.2223e-01, -1.4555e-01,  1.8186e-01,
          1.2900e-01],
        [-1.4083e-01,  1.6705e-01, -1.9981e-01,  1.3265e-02,  1.0870e-01,
          1.5345e-01,  1.0805e-01,  4.2173e-01,  2.0252e-01,  2.7917e-01,
          2.1560e-01, -2.4173e-01, -1.1015e-01, -2.2840e-01, -1.6063e-01,
         -1.1257e-01],
        [-3.8829e-02,  1.9100e-01, -3.8236e-01,  4.2680e-01,  2.1650e-01,
          2.8814e-02,  3.0537e-01,  4.6620e-02,  2.9716e-01,  1.9408e-01,
         -1.6121e-01, -1.5097e-01, -3.0744e-01,  1.3011e-01, -2.7824e-02,
         -4.7733e-02],
        [ 3.9987e-01,  1.6477e-01,  4.3168e-01, -2.0374e-01,  9.4782e-02,
         -2.5909e-01, -2.3433e-01, -2.8366e-01, -2.6616e-01, -9.9481e-03,
         -1.4112e-02,  9.0250e-02,  3.0022e-04,  2.1922e-01,  3.2426e-02,
          1.4031e-01],
        [-4.2539e-02,  2.8091e-01,  3.7154e-01, -3.6066e-01, -1.7773e-01,
         -3.3516e-01, -1.2482e-01, -2.8641e-01, -1.9178e-01, -1.9637e-01,
         -6.5418e-02,  4.2367e-02,  2.8365e-01, -9.5531e-02,  1.9369e-01,
          3.4559e-01],
        [ 7.5774e-02,  2.7070e-01,  3.3454e-01, -2.8134e-01, -6.7097e-03,
         -4.0288e-01, -2.1790e-01, -1.6416e-01,  1.7601e-02, -3.0475e-01,
         -1.1483e-01,  1.0872e-01, -4.0924e-02,  1.3490e-01,  7.6902e-02,
          7.9854e-02],
        [-3.2367e-01, -4.3357e-02, -1.2349e-01,  1.4337e-02,  5.9619e-03,
          2.1079e-01,  1.0100e-01,  3.1442e-01,  3.0461e-01, -1.9900e-02,
          2.2815e-01, -6.5383e-02, -3.1022e-01, -6.5128e-02, -2.4967e-01,
         -1.6713e-01],
        [-3.7063e-01,  1.1107e-01, -7.3502e-02, -3.0993e-02, -1.4198e-01,
          4.5791e-01,  2.6504e-01,  1.6068e-01,  3.4843e-01,  2.2469e-01,
          6.2259e-02, -1.3388e-02, -1.9302e-01,  1.4903e-01, -4.2934e-01,
         -3.0248e-01],
        [-1.5452e-01, -1.0650e-01, -4.3979e-02,  1.0718e-01,  1.5240e-01,
          1.6362e-01,  4.1839e-01,  2.1190e-01,  1.8805e-01,  3.2375e-01,
          1.4900e-01,  1.8935e-02, -4.3789e-01, -1.8162e-01, -3.0977e-01,
         -1.7388e-01],
        [ 3.8528e-01,  1.7480e-01,  2.0675e-01, -2.1342e-01,  2.9341e-02,
         -5.0577e-02, -1.5105e-01, -4.0143e-01, -3.7195e-01, -1.0284e-01,
         -1.1152e-01,  8.5024e-02,  2.3928e-02,  1.9369e-01,  2.4210e-01,
          6.9593e-03],
        [ 2.5516e-01,  3.2122e-01,  4.0656e-01, -4.7778e-02, -2.1811e-01,
         -8.4396e-02, -1.0590e-01, -1.4133e-01, -2.5169e-01, -1.6710e-01,
         -2.1382e-01,  1.6233e-01,  1.7844e-01,  7.3919e-02,  2.4169e-02,
          2.3798e-01],
        [-4.0234e-01, -2.6754e-01, -9.0114e-02, -2.5329e-02,  2.3876e-01,
          4.5412e-01,  1.4208e-01,  1.6534e-01, -2.1443e-02,  1.6802e-01,
          1.2372e-01, -3.4003e-01, -1.2021e-01, -1.0980e-01, -3.2608e-01,
         -1.4950e-01],
        [-5.5486e-02, -2.2244e-01,  1.8684e-01,  6.0742e-02, -2.7841e-01,
         -5.8518e-02, -1.9848e-01, -3.8796e-01, -2.3544e-01,  3.0595e-03,
          4.1891e-02,  5.1422e-01,  2.0551e-01, -7.3204e-02,  5.2622e-01,
         -3.3136e-03],
        [ 3.3372e-01,  2.2930e-01,  2.1326e-01, -3.6357e-01, -2.5560e-01,
         -7.5889e-02, -1.3835e-01, -5.7976e-02, -3.7926e-01, -1.6033e-01,
          1.5714e-01,  3.2272e-01,  3.8320e-01,  2.5784e-01,  1.6233e-01,
         -4.7725e-02],
        [-3.1540e-01,  1.5915e-02, -2.6117e-01,  1.5054e-01,  2.3212e-02,
          3.3867e-01,  3.2663e-01,  3.1785e-01,  1.4644e-01,  2.6433e-01,
         -4.6776e-02, -2.7015e-01, -1.9730e-01, -2.0627e-01,  1.1392e-02,
         -1.6279e-01],
        [ 2.4715e-01,  9.0772e-02,  1.6535e-01, -3.0155e-01, -3.9068e-02,
         -4.0946e-01, -3.2461e-01, -8.3542e-03, -3.9374e-01, -1.0639e-01,
         -3.6588e-02, -6.2247e-02,  2.2125e-01,  2.3909e-01,  4.0639e-01,
          1.7738e-01],
        [ 3.9355e-01,  1.0326e-01,  2.8829e-01, -1.0366e-01, -1.9905e-01,
         -2.6930e-01, -3.9499e-01, -4.2906e-03, -4.3068e-02, -2.5734e-01,
         -6.7564e-02,  2.6462e-01, -4.8179e-02,  9.6022e-02,  3.7147e-01,
          1.8337e-01],
        [-2.1887e-01,  1.1999e-01, -7.5475e-02, -3.5539e-02,  2.0436e-01,
          2.4819e-02,  3.5887e-01,  4.5755e-01,  2.3569e-01,  6.5710e-02,
         -8.9982e-02, -3.5400e-01, -2.6307e-01, -2.1314e-01, -1.7533e-02,
         -2.3380e-01],
        [-9.1663e-02, -3.0551e-01, -6.2187e-02,  3.9470e-01, -1.1792e-01,
          1.5088e-01,  2.7905e-01, -2.4176e-02,  2.3081e-02,  2.3806e-01,
          2.5044e-01, -2.8245e-01, -1.8475e-01, -3.2835e-01, -4.9925e-01,
          7.9754e-02],
        [ 3.7587e-01,  5.2523e-04,  6.1964e-02, -1.6355e-01,  1.3170e-01,
         -4.2155e-01, -3.2189e-01, -2.4296e-01, -2.3567e-01, -1.3103e-01,
          1.2227e-01,  2.1498e-01, -8.7267e-02,  2.9683e-01,  4.0849e-01,
          2.0581e-01],
        [ 2.7093e-01,  1.6669e-01,  3.5110e-01, -3.7325e-01, -1.1726e-01,
         -1.9670e-01, -2.1093e-01, -3.0312e-01, -3.4884e-01, -3.0061e-01,
         -9.6515e-02,  3.5211e-01,  2.7909e-01,  1.2874e-01,  2.8824e-02,
          1.8978e-02],
        [ 2.4923e-01, -1.8440e-01,  1.9844e-01, -1.5804e-01,  1.2764e-01,
         -3.1789e-01, -1.6824e-02, -2.7219e-01, -4.0967e-01,  7.4314e-02,
          1.9058e-01,  7.0824e-02,  1.0634e-01,  2.2242e-01,  1.4788e-01,
          2.9994e-01],
        [ 9.3889e-02, -2.6350e-02,  1.3072e-01,  3.8722e-02, -1.2941e-01,
         -2.8974e-01, -9.2207e-02, -4.3053e-01, -2.2448e-01, -3.5574e-01,
         -2.8151e-01,  1.8913e-01,  2.5333e-01,  3.3868e-01,  4.8349e-02,
          6.5993e-02],
        [ 2.3048e-01,  1.7299e-01,  3.0828e-01, -3.4836e-01, -3.1729e-02,
         -1.2241e-01, -3.8643e-01, -3.1550e-02, -3.6318e-01,  3.1182e-02,
          8.4201e-03,  8.6292e-02,  2.2236e-01,  2.8176e-01,  3.9355e-01,
          2.8174e-01],
        [-3.4142e-01, -9.6611e-04,  9.7060e-04,  2.1910e-01,  2.4061e-01,
          5.9062e-02,  4.0291e-01,  2.1856e-01, -4.0106e-02,  7.7768e-02,
          2.0993e-01, -3.0274e-01, -2.4627e-01, -1.7576e-01, -3.8844e-01,
         -8.5121e-02],
        [ 3.2165e-01,  1.1028e-01,  1.5127e-01, -1.3668e-01, -2.1632e-01,
         -3.2021e-01, -1.7706e-01, -3.8036e-01, -2.1085e-02, -8.8719e-02,
          9.7220e-03,  1.6140e-01,  3.4176e-01,  2.9019e-01,  3.3015e-01,
          2.5088e-01],
        [-2.8801e-01,  3.0388e-02, -3.3200e-01,  2.5886e-01, -2.1089e-01,
          1.8093e-01,  3.6790e-01,  3.2485e-01,  3.4912e-01,  2.1461e-01,
          1.8373e-01, -9.1675e-02,  2.4077e-02,  5.6060e-02, -1.3612e-01,
         -2.1691e-01],
        [-3.0348e-01, -1.4360e-01, -5.8743e-02,  2.7238e-02,  8.7250e-02,
          4.1894e-01,  4.1878e-01,  1.0839e-02,  2.2434e-01,  2.9936e-01,
         -1.9815e-01, -3.0445e-02, -3.1596e-01, -2.4835e-01, -3.3883e-01,
         -2.2966e-01],
        [ 8.9979e-02,  1.6956e-01,  2.8299e-01, -8.6929e-02,  1.4565e-01,
         -3.6629e-01, -4.6197e-01, -4.2161e-01, -3.1320e-01, -2.7270e-01,
          3.4703e-02,  2.0938e-02,  2.0635e-02,  2.5094e-01,  9.6952e-02,
          1.8658e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-7.7144e-02, -7.9037e-02,  2.0629e-01, -5.2803e-05, -1.3047e-01,
        -8.3246e-02,  9.4343e-02,  8.3105e-02, -6.5353e-03, -9.1113e-02,
        -4.8176e-02,  2.9445e-02,  1.5457e-01,  1.2171e-01, -3.6194e-02,
         5.9515e-03, -1.0055e-01, -2.2569e-03,  1.3762e-01,  3.2145e-02,
        -5.4619e-02, -1.9969e-01,  5.0167e-03, -3.2216e-02,  2.1748e-02,
         2.6436e-01,  1.4388e-01, -7.7672e-03, -2.7173e-02, -1.6263e-01,
        -1.1068e-02,  5.2284e-02], device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2289,  0.3258, -0.2446, -0.2807,  0.3465,  0.3799, -0.2912, -0.3911,
         -0.3162,  0.3730,  0.2856,  0.4050, -0.2787, -0.3964,  0.3220, -0.2790,
         -0.3181,  0.3534, -0.2445, -0.2585,  0.4268,  0.3798, -0.3906, -0.3912,
         -0.3255, -0.3603, -0.3332,  0.3848, -0.3855,  0.3991,  0.3149, -0.2527]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0093,  0.0020,  0.0250,  ...,  0.2106, -0.3871, -0.1137],
        [-0.0793, -0.1837,  0.0813,  ...,  0.1477, -0.3537,  0.0871],
        [-0.0568,  0.1512,  0.0935,  ...,  0.0066,  0.2682,  0.0345],
        ...,
        [ 0.0438, -0.1504,  0.0115,  ...,  0.0696, -0.3178, -0.1180],
        [ 0.0294, -0.0793,  0.0112,  ..., -0.3095,  0.1516,  0.1557],
        [-0.0870,  0.1559,  0.0135,  ..., -0.1750,  0.1043, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0505,  0.0546, -0.0943, -0.1208, -0.0567,  0.0466, -0.1304,  0.0617,
        -0.0453,  0.0925,  0.0354,  0.0057,  0.0101,  0.0637, -0.0777, -0.0192,
         0.0455, -0.1420, -0.0332, -0.0147, -0.1084,  0.0512,  0.0815, -0.0068,
        -0.0856,  0.0670,  0.0248, -0.0951,  0.0637,  0.1474,  0.1324, -0.0660],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0236, -0.2062, -0.0718,  ..., -0.1561, -0.0041,  0.2734],
        [-0.2532, -0.0530,  0.1106,  ..., -0.0861,  0.0051,  0.2804],
        [ 0.1783, -0.0091, -0.1863,  ...,  0.0973, -0.0359, -0.0787],
        ...,
        [ 0.1658,  0.1210,  0.0727,  ...,  0.2791, -0.2359,  0.0461],
        [-0.0689, -0.1851,  0.0868,  ..., -0.0136,  0.2605,  0.0980],
        [-0.0324, -0.1301,  0.2188,  ...,  0.0358,  0.1514,  0.1405]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0906,  0.1265, -0.0376, -0.0577, -0.0319, -0.0371, -0.0338, -0.0630,
         0.1113, -0.1794,  0.1235, -0.1330,  0.1661, -0.0208, -0.1435,  0.1090,
        -0.1292, -0.1555,  0.0149, -0.0299,  0.0075,  0.1068, -0.1932,  0.2059,
        -0.0667, -0.0275,  0.0879, -0.0335, -0.1135, -0.0617,  0.1152,  0.0034],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.6129,  0.5374, -0.6182, -0.6188,  0.4651,  0.4746, -0.5211,  0.5314,
          0.5283, -0.5539, -0.5434,  0.5030,  0.5249, -0.4668,  0.5468,  0.4960,
         -0.6237, -0.6142,  0.4910,  0.5096, -0.5788, -0.5512, -0.6140,  0.4482,
          0.5891,  0.6138, -0.5894,  0.6581, -0.5243, -0.6057,  0.5924,  0.6047]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.3255], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.3101e-02,  2.9721e-01,  2.8810e-01, -2.7056e-01, -4.1665e-01,
         -2.1322e-01, -8.3875e-02, -5.3039e-01, -2.9161e-01, -5.9453e-02,
          1.0986e-02,  2.8075e-01,  1.3551e-01, -6.7766e-02,  1.1727e-01,
          3.2533e-01],
        [-2.4139e-01, -2.8568e-01, -9.4478e-02, -4.3520e-02,  1.5056e-01,
          2.9555e-01,  1.9417e-01,  2.7015e-01,  4.8675e-01,  1.3471e-01,
          2.5274e-01, -3.3986e-01, -4.8694e-02, -5.0051e-02,  1.8004e-01,
         -5.3628e-02],
        [ 5.7474e-02,  1.8717e-01,  3.5982e-01, -6.7520e-02, -2.6925e-01,
         -3.8621e-01, -6.9679e-02, -5.4199e-01, -5.9554e-02, -5.5492e-02,
         -1.0130e-01,  1.8590e-02,  4.5558e-01,  3.2499e-01,  2.3916e-01,
          2.2405e-01],
        [ 2.5620e-01,  1.7080e-02,  7.1369e-02, -3.1759e-02, -2.3795e-01,
         -2.4341e-01, -1.7884e-01, -2.1711e-01, -5.1858e-01, -4.0041e-01,
         -8.2623e-02,  4.4932e-01,  3.2992e-01, -1.1109e-01, -4.2394e-02,
          1.2397e-01],
        [-7.6753e-02,  1.4527e-01, -1.5492e-01, -7.0573e-02,  3.5263e-01,
          1.3497e-01,  7.0406e-02,  4.4614e-01,  2.3950e-01,  2.9222e-01,
          2.8239e-01, -2.4459e-01, -1.0361e-01, -2.4063e-01,  1.0611e-01,
         -1.2145e-01],
        [ 4.0111e-03,  1.7956e-01, -3.5246e-01,  3.6636e-01,  5.2535e-01,
          2.5701e-02,  2.9470e-01,  8.7681e-02,  3.4841e-01,  2.1535e-01,
         -1.2505e-01, -1.6831e-01, -3.0190e-01,  1.1923e-01,  2.3122e-01,
         -5.2729e-02],
        [ 3.6322e-01,  6.6207e-02,  4.0276e-01, -1.5405e-01, -2.2851e-01,
         -2.6037e-01, -2.0984e-01, -3.4991e-01, -3.5014e-01, -2.9262e-02,
         -2.5367e-02,  1.4223e-01, -1.4868e-02,  2.3940e-01, -1.0584e-01,
          1.3272e-01],
        [-7.2626e-02,  2.2056e-01,  3.4765e-01, -3.2325e-01, -4.8143e-01,
         -3.3206e-01, -1.0562e-01, -3.4998e-01, -2.6835e-01, -2.1390e-01,
         -7.2640e-02,  8.9919e-02,  2.8196e-01, -7.9217e-02,  8.0742e-02,
          3.3643e-01],
        [ 3.6628e-02,  2.6117e-01,  3.0751e-01, -2.1837e-01, -2.1986e-01,
         -4.0437e-01, -2.0671e-01, -2.1636e-01, -5.3115e-02, -3.2903e-01,
         -2.3456e-01,  1.4235e-01, -1.2234e-03,  1.8882e-01, -1.7659e-01,
          7.9227e-02],
        [-2.7664e-01, -4.9207e-02, -9.0213e-02, -5.1955e-02,  2.6390e-01,
          2.1211e-01,  8.5923e-02,  3.6602e-01,  3.7066e-01,  2.6711e-03,
          2.9538e-01, -9.3663e-02, -3.3259e-01, -9.3325e-02,  9.9479e-03,
         -1.7127e-01],
        [-3.4470e-01,  1.0256e-01, -5.5869e-02, -7.1280e-02,  1.4845e-01,
          4.8075e-01,  2.6455e-01,  2.4914e-01,  4.5202e-01,  2.5858e-01,
          9.6998e-02, -8.3319e-02, -2.1304e-01,  1.0312e-01, -1.6302e-01,
         -3.0684e-01],
        [-1.1812e-01, -1.1267e-01, -2.0521e-02,  5.7386e-02,  3.3756e-01,
          1.7193e-01,  4.0137e-01,  2.6691e-01,  2.5751e-01,  3.5728e-01,
          2.1331e-01, -1.9286e-02, -4.3329e-01, -2.5378e-01, -9.2696e-02,
         -1.8293e-01],
        [ 3.1544e-01,  1.8184e-01,  1.5191e-01, -1.2535e-01, -3.4859e-01,
         -4.9506e-02, -1.2830e-01, -4.9754e-01, -4.4739e-01, -1.1053e-01,
         -1.2345e-01,  1.4336e-01,  2.0892e-02,  1.8123e-01, -7.9109e-02,
         -3.0643e-03],
        [ 2.0492e-01,  2.8744e-01,  3.6712e-01,  1.4453e-02, -4.6837e-01,
         -6.7783e-02, -7.2075e-02, -1.7257e-01, -2.9996e-01, -1.7382e-01,
         -2.4249e-01,  1.8221e-01,  1.7146e-01,  7.9574e-02, -1.7337e-01,
          2.2333e-01],
        [-3.6317e-01, -2.4502e-01, -5.8685e-02, -7.8387e-02,  5.3778e-01,
          4.5318e-01,  1.2350e-01,  2.2772e-01,  5.4583e-02,  1.8349e-01,
          1.5088e-01, -3.8553e-01, -1.3204e-01, -1.2608e-01, -1.3339e-01,
         -1.3927e-01],
        [-1.1005e-01, -1.4883e-01,  1.6568e-01,  1.5019e-01, -5.5866e-01,
         -9.4781e-02, -2.2657e-01, -4.9152e-01, -3.3086e-01, -5.0168e-02,
         -8.1358e-02,  5.1737e-01,  2.3866e-01, -2.2580e-02,  2.3596e-01,
          1.9359e-02],
        [ 3.0713e-01,  2.2077e-01,  1.9529e-01, -3.2305e-01, -5.2755e-01,
         -8.5719e-02, -1.3064e-01, -1.0836e-01, -4.5866e-01, -1.9452e-01,
          1.3410e-01,  3.6785e-01,  4.1105e-01,  3.0373e-01,  7.8252e-03,
         -4.3821e-02],
        [-2.8461e-01,  3.8881e-02, -2.3735e-01,  1.1145e-01,  2.8703e-01,
          3.3558e-01,  3.0503e-01,  3.6564e-01,  2.1873e-01,  2.8498e-01,
         -3.3886e-02, -3.0943e-01, -1.9675e-01, -2.3748e-01,  1.3128e-01,
         -1.5770e-01],
        [ 1.9216e-01,  5.3581e-02,  1.1613e-01, -2.2231e-01, -4.1098e-01,
         -4.1380e-01, -3.0355e-01, -9.8062e-02, -5.0725e-01, -9.0927e-02,
         -6.7478e-02, -2.2803e-03,  2.7992e-01,  2.7260e-01,  1.9646e-01,
          1.4331e-01],
        [ 3.6159e-01,  8.1434e-02,  2.6356e-01, -5.4210e-02, -4.9432e-01,
         -2.8159e-01, -3.8580e-01, -9.0631e-02, -1.4339e-01, -2.8015e-01,
         -1.1317e-01,  3.3182e-01, -1.1327e-02,  1.2502e-01,  1.8776e-01,
          1.7500e-01],
        [-1.6649e-01,  1.0634e-01, -3.7175e-02, -1.0364e-01,  4.3596e-01,
          8.9519e-04,  3.2698e-01,  4.5957e-01,  2.5139e-01,  7.1105e-02,
         -4.5446e-02, -3.3779e-01, -2.3483e-01, -2.1160e-01,  2.1955e-01,
         -2.3317e-01],
        [-6.9403e-02, -2.8485e-01, -4.7851e-02,  3.5076e-01,  1.5593e-01,
          1.7511e-01,  2.9599e-01,  6.3896e-02,  1.2434e-01,  2.7762e-01,
          3.5702e-01, -3.4460e-01, -2.5952e-01, -3.8631e-01, -2.5241e-01,
          7.2770e-02],
        [ 3.5957e-01, -1.2881e-02,  5.1007e-02, -1.3689e-01, -1.5446e-01,
         -4.3957e-01, -3.2427e-01, -3.2298e-01, -3.3454e-01, -1.6414e-01,
          9.6716e-02,  2.8068e-01, -4.5480e-02,  3.3803e-01,  2.6390e-01,
          2.0752e-01],
        [ 2.4759e-01,  1.5977e-01,  3.3409e-01, -3.4426e-01, -3.6966e-01,
         -1.9679e-01, -1.9685e-01, -3.6282e-01, -4.2856e-01, -3.2412e-01,
         -6.5994e-02,  4.0059e-01,  2.7820e-01,  1.5735e-01, -8.1254e-02,
          1.1649e-02],
        [ 2.0456e-01, -1.6681e-01,  1.6951e-01, -8.7535e-02, -1.3027e-01,
         -3.2330e-01, -2.3214e-03, -3.0760e-01, -4.7776e-01,  4.0419e-02,
          1.0612e-01,  9.7808e-02,  1.3478e-01,  2.6513e-01, -1.4962e-01,
          3.1935e-01],
        [ 2.5605e-02, -2.5832e-02,  7.6109e-02,  1.1884e-01, -3.9001e-01,
         -2.5138e-01, -3.9081e-02, -4.3267e-01, -2.3806e-01, -3.5042e-01,
         -3.2118e-01,  1.7593e-01,  2.1703e-01,  3.2361e-01, -1.9744e-01,
          5.5829e-02],
        [ 2.1181e-01,  1.4776e-01,  2.9483e-01, -3.2017e-01, -3.2866e-01,
         -1.3862e-01, -3.8464e-01, -1.1445e-01, -4.6441e-01,  1.3426e-03,
         -7.9198e-03,  1.5318e-01,  2.6054e-01,  3.1376e-01,  2.7228e-01,
          2.7958e-01],
        [-3.0573e-01, -2.4877e-04,  2.5613e-02,  1.6842e-01,  4.8293e-01,
          7.2082e-02,  3.9474e-01,  2.8871e-01,  3.7928e-02,  1.0815e-01,
          2.5649e-01, -3.5093e-01, -2.6884e-01, -2.1480e-01, -1.8073e-01,
         -8.9228e-02],
        [ 2.9562e-01,  1.2016e-01,  1.3246e-01, -1.0261e-01, -4.5714e-01,
         -3.2956e-01, -1.6925e-01, -4.4173e-01, -1.0064e-01, -1.1567e-01,
          3.0508e-02,  2.1303e-01,  3.3468e-01,  3.3015e-01,  1.4561e-01,
          2.5013e-01],
        [-2.6457e-01,  6.7060e-02, -3.1401e-01,  2.2729e-01,  7.2731e-02,
          1.8481e-01,  3.5766e-01,  3.9368e-01,  4.3163e-01,  2.3708e-01,
          2.0842e-01, -1.4429e-01,  1.0361e-02,  3.1788e-02, -1.7675e-02,
         -2.1360e-01],
        [-2.7621e-01, -1.3426e-01, -3.8867e-02, -1.2440e-02,  3.6262e-01,
          4.3219e-01,  4.0857e-01,  8.0172e-02,  3.1724e-01,  3.2858e-01,
         -1.6475e-01, -8.8359e-02, -3.5277e-01, -2.9210e-01, -1.6501e-01,
         -2.2849e-01],
        [ 4.2569e-02,  1.2193e-01,  2.4344e-01, -1.2202e-02, -1.6733e-01,
         -3.6640e-01, -4.3089e-01, -4.9118e-01, -4.0788e-01, -2.7002e-01,
          3.0313e-03,  7.1729e-02,  3.4881e-02,  2.8323e-01, -8.4001e-02,
          1.6808e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-3.4316e-02, -2.7504e-02,  1.3246e-01, -2.6022e-02, -9.4890e-02,
        -1.3127e-01,  8.5072e-02,  9.9810e-02, -1.2592e-02, -9.4213e-02,
        -3.2872e-02,  4.4573e-02,  1.7808e-01,  9.5321e-02,  1.5450e-04,
        -1.7566e-02, -4.5676e-02, -4.6889e-03,  1.1534e-01,  1.8933e-02,
        -7.5386e-02, -1.6394e-01, -1.1465e-02, -1.0079e-02,  3.3078e-02,
         1.9146e-01,  1.3669e-01, -1.1822e-02, -5.5874e-02, -1.5975e-01,
         1.7300e-02, -4.0568e-02], device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2714,  0.3556, -0.2605, -0.2979,  0.3749,  0.4166, -0.3063, -0.4117,
         -0.3372,  0.3991,  0.3015,  0.4091, -0.3125, -0.4268,  0.3394, -0.3989,
         -0.3525,  0.3556, -0.2639, -0.2770,  0.4525,  0.3445, -0.4001, -0.3998,
         -0.3831, -0.3843, -0.3378,  0.3967, -0.3900,  0.4055,  0.3195, -0.2640]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0067, -0.0056,  0.0451,  ...,  0.2363, -0.3838, -0.1137],
        [-0.0804, -0.1896,  0.0903,  ...,  0.1467, -0.3681,  0.0871],
        [-0.0459,  0.1741,  0.0706,  ..., -0.0052,  0.2962,  0.0345],
        ...,
        [ 0.0320, -0.1883,  0.0443,  ...,  0.0665, -0.3212, -0.1180],
        [ 0.0434, -0.0531, -0.0202,  ..., -0.3058,  0.1738,  0.1557],
        [-0.2010,  0.0500,  0.0060,  ...,  0.0399, -0.2723, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0557,  0.0549, -0.0859, -0.1214, -0.0599,  0.0542, -0.1259,  0.0588,
        -0.0477,  0.0813,  0.0294,  0.0116,  0.0276,  0.0751, -0.0761, -0.0177,
         0.0464, -0.1515, -0.0315, -0.0253, -0.0735,  0.0501,  0.0903, -0.0048,
        -0.0885,  0.0884,  0.0328, -0.0876,  0.0478,  0.1372,  0.1479, -0.1088],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0320, -0.1888, -0.0862,  ..., -0.1062, -0.0276,  0.0756],
        [-0.2498, -0.0432,  0.1097,  ..., -0.0379, -0.0059,  0.0635],
        [ 0.1737, -0.0278, -0.1740,  ...,  0.0454, -0.0101,  0.1658],
        ...,
        [ 0.1505,  0.0941,  0.0970,  ...,  0.2164, -0.1987,  0.2369],
        [-0.0698, -0.1683,  0.0783,  ...,  0.0402,  0.2397, -0.1666],
        [-0.0334, -0.1219,  0.2072,  ...,  0.0825,  0.1327, -0.0257]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0867,  0.1248, -0.0279, -0.0608, -0.0320, -0.0635, -0.0294, -0.0598,
         0.0980, -0.1408,  0.1368, -0.1257,  0.1548,  0.0605, -0.1341,  0.0920,
        -0.1215, -0.1504,  0.0048, -0.0129,  0.0040,  0.1072, -0.1882,  0.1777,
        -0.0626, -0.0295,  0.0882, -0.0410, -0.1124, -0.0566,  0.1013,  0.0053],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.6595,  0.5834, -0.6593, -0.6608,  0.5270,  0.5186, -0.5737,  0.5674,
          0.5912, -0.5994, -0.5524,  0.5514,  0.5499,  0.5619,  0.5889,  0.5470,
         -0.6597, -0.6649,  0.5271,  0.5544, -0.6156, -0.5930, -0.6615,  0.5203,
          0.6451,  0.6653, -0.6431,  0.6928, -0.5723, -0.6556,  0.6406,  0.6585]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.3680], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 5.7703e-03, -4.1395e-02,  2.5501e-01, -2.9157e-01, -3.4106e-01,
         -1.0899e-01, -4.3560e-02, -4.8332e-01, -2.6725e-01, -1.0405e-02,
          1.6570e-01,  1.6908e-01,  6.6595e-03, -1.0438e-01, -2.2386e-01,
          3.0931e-01],
        [-2.6715e-01,  1.5889e-02, -8.2371e-02, -5.9749e-03,  8.1104e-02,
          2.2575e-01,  1.5625e-01,  2.2928e-01,  4.8806e-01,  1.1263e-01,
          9.4511e-02, -2.6509e-01,  2.1027e-02, -2.8615e-02,  5.0221e-01,
         -4.8226e-02],
        [ 7.4972e-02, -9.5837e-02,  3.4148e-01, -9.9259e-02, -1.8613e-01,
         -3.2007e-01, -4.4412e-02, -4.8141e-01, -5.5258e-03, -3.9049e-02,
         -6.1060e-02, -7.5376e-02,  3.8035e-01,  3.0340e-01, -9.8816e-02,
          2.3346e-01],
        [ 2.7621e-01, -1.2787e-01,  4.7532e-02, -5.5751e-02, -1.4179e-01,
         -1.5010e-01, -1.1606e-01, -1.5573e-01, -5.0515e-01, -3.5714e-01,
          5.1566e-03,  3.4846e-01,  2.5126e-01, -1.5609e-01, -3.2896e-01,
          9.9541e-02],
        [-8.8658e-02,  4.4396e-01, -1.3011e-01, -3.7909e-02,  2.6183e-01,
          4.9855e-02,  2.4744e-02,  3.7634e-01,  2.0008e-01,  2.6581e-01,
          6.0632e-02, -1.3907e-01, -9.6320e-03, -2.0980e-01,  4.0409e-01,
         -1.1594e-01],
        [ 7.0849e-03,  3.9699e-01, -3.2389e-01,  3.8798e-01,  4.0302e-01,
         -6.8772e-02,  2.4179e-01,  6.1061e-03,  2.9176e-01,  1.8526e-01,
         -1.1898e-01, -6.5882e-02, -1.9728e-01,  1.4230e-01,  4.7445e-01,
         -4.5907e-02],
        [ 3.6638e-01, -7.7947e-02,  3.7207e-01, -1.7018e-01, -1.3613e-01,
         -1.7567e-01, -1.5153e-01, -2.8598e-01, -3.1095e-01,  7.3054e-03,
         -8.5924e-03,  4.5795e-02, -1.0173e-01,  1.4599e-01, -3.8322e-01,
          1.1199e-01],
        [-7.3424e-02,  7.0918e-02,  3.2525e-01, -3.4400e-01, -4.0684e-01,
         -2.7426e-01, -7.5352e-02, -3.0558e-01, -2.3315e-01, -1.9808e-01,
         -4.4318e-02,  1.8232e-02,  2.2861e-01, -1.1770e-01, -1.6338e-01,
          3.3059e-01],
        [ 4.8802e-02, -8.9155e-02,  2.8408e-01, -2.5217e-01, -1.6992e-01,
         -3.3757e-01, -1.7107e-01, -1.8327e-01, -3.0842e-02, -3.0339e-01,
          2.4790e-02,  6.4350e-02, -6.0800e-02,  1.6532e-01, -4.8659e-01,
          7.7233e-02],
        [-3.0270e-01,  2.6816e-01, -8.2192e-02, -6.4655e-03,  1.8337e-01,
          1.3933e-01,  4.8256e-02,  3.0898e-01,  3.4879e-01, -1.1957e-02,
          1.2235e-01, -1.3379e-02, -2.5245e-01, -8.3859e-02,  3.2080e-01,
         -1.7826e-01],
        [-3.6159e-01,  3.0546e-01, -3.3434e-02, -4.3332e-02,  6.6270e-02,
          3.9898e-01,  2.2081e-01,  1.9379e-01,  4.2941e-01,  2.2703e-01,
          8.4745e-03,  1.0237e-02, -1.7921e-01,  1.1619e-01,  1.3174e-01,
         -2.9704e-01],
        [-1.2420e-01,  1.1535e-01,  6.4754e-03,  8.5429e-02,  2.5470e-01,
          1.0381e-01,  3.4667e-01,  2.0687e-01,  2.1320e-01,  3.2413e-01,
          7.3100e-02,  7.3284e-02, -4.0555e-01, -2.0995e-01,  1.7479e-01,
         -1.7402e-01],
        [ 3.3680e-01, -1.1266e-01,  1.1881e-01, -1.5364e-01, -2.3816e-01,
          6.9304e-02, -6.8104e-02, -4.1186e-01, -4.2188e-01, -6.6468e-02,
         -1.1318e-01,  1.8224e-02, -8.4790e-02,  1.5247e-01, -4.3265e-01,
         -2.0378e-02],
        [ 2.1459e-01,  2.2248e-02,  3.4801e-01, -1.3621e-02, -3.9400e-01,
         -6.2624e-03, -3.0532e-02, -1.2717e-01, -2.8206e-01, -1.5141e-01,
         -1.1387e-01,  1.0958e-01,  1.1047e-01,  4.0545e-02, -4.6632e-01,
          2.1568e-01],
        [-3.7920e-01,  3.1434e-02, -4.3360e-02, -4.3756e-02,  4.7187e-01,
          3.9458e-01,  9.6597e-02,  1.8745e-01,  3.3187e-02,  1.6963e-01,
          2.7924e-02, -3.0954e-01, -8.1711e-02, -1.1012e-01,  1.9183e-01,
         -1.4016e-01],
        [-6.5532e-02, -5.4045e-01,  1.2577e-01,  9.9370e-02, -5.0842e-01,
          4.7667e-02, -1.6890e-01, -4.3123e-01, -3.2323e-01,  1.0356e-03,
         -4.5797e-02,  3.8007e-01,  8.4528e-02, -9.8307e-02, -1.3878e-01,
          1.9680e-02],
        [ 3.1911e-01,  3.5695e-02,  1.7091e-01, -3.4158e-01, -4.1503e-01,
         -5.4612e-03, -6.3886e-02, -5.1250e-02, -4.4909e-01, -1.5299e-01,
          1.7321e-01,  2.8053e-01,  3.1674e-01,  2.2705e-01, -2.3571e-01,
         -6.8918e-02],
        [-2.6964e-01,  1.6860e-01, -1.9713e-01,  1.1406e-01,  1.5563e-01,
          2.5091e-01,  2.4356e-01,  2.8642e-01,  1.5757e-01,  2.4335e-01,
         -5.8920e-02, -2.0218e-01, -1.0149e-01, -1.5449e-01,  2.9000e-01,
         -1.3001e-01],
        [ 2.2556e-01, -1.8309e-01,  1.0712e-01, -2.5887e-01, -2.8904e-01,
         -3.4541e-01, -2.5816e-01, -3.6519e-02, -4.6398e-01, -7.1138e-02,
          2.5067e-02, -9.7979e-02,  1.6522e-01,  2.1093e-01, -1.1042e-01,
          1.5059e-01],
        [ 3.6650e-01, -1.6242e-01,  2.2782e-01, -7.4691e-02, -4.2043e-01,
         -2.0854e-01, -3.4012e-01, -4.4038e-02, -1.0807e-01, -2.4415e-01,
          1.0866e-01,  2.3098e-01, -6.5687e-02,  7.5192e-02, -1.4386e-01,
          1.5880e-01],
        [-1.5962e-01,  3.1031e-01, -7.4097e-03, -8.6637e-02,  3.1417e-01,
         -7.7333e-02,  2.8143e-01,  3.7793e-01,  1.9594e-01,  4.4846e-02,
         -1.1646e-01, -2.3870e-01, -1.5114e-01, -1.7299e-01,  4.1591e-01,
         -2.2073e-01],
        [-1.0489e-01,  1.4310e-01, -3.8947e-02,  4.0028e-01,  1.3648e-01,
          1.2457e-01,  2.7741e-01,  6.0566e-02,  1.3456e-01,  2.6839e-01,
          1.9557e-01, -2.9790e-01, -2.2405e-01, -3.7885e-01,  8.3646e-02,
          6.2559e-02],
        [ 3.6420e-01, -2.2707e-01,  2.6392e-02, -1.5968e-01, -7.4791e-02,
         -3.7856e-01, -2.8269e-01, -2.8043e-01, -3.0586e-01, -1.4054e-01,
          2.1259e-01,  2.0455e-01, -9.2958e-02,  2.9179e-01, -2.7839e-03,
          1.9519e-01],
        [ 2.4158e-01,  7.9972e-02,  2.9823e-01, -3.4326e-01, -2.2250e-01,
         -1.1571e-01, -1.2407e-01, -2.9616e-01, -4.0409e-01, -2.7252e-01,
         -2.0637e-04,  3.0939e-01,  2.1183e-01,  7.0505e-02, -2.3070e-01,
         -3.1142e-02],
        [ 2.2115e-01, -4.6140e-01,  1.5323e-01, -1.2819e-01, -3.0538e-02,
         -2.3154e-01,  5.4379e-02, -2.3059e-01, -4.3307e-01,  6.7582e-02,
          1.7520e-01,  2.7885e-04,  3.1451e-02,  2.4568e-01, -4.4991e-01,
          3.1954e-01],
        [ 2.6154e-02, -2.6647e-01,  5.1379e-02,  9.4783e-02, -2.8177e-01,
         -1.8031e-01, -1.1352e-02, -3.6002e-01, -1.8723e-01, -3.3278e-01,
         -2.4828e-01,  8.0709e-02,  1.5244e-01,  3.0742e-01, -4.7257e-01,
          5.1692e-02],
        [ 2.1134e-01, -8.9598e-02,  2.6061e-01, -3.3481e-01, -2.4608e-01,
         -7.7951e-02, -3.3565e-01, -7.1704e-02, -4.2434e-01,  3.0922e-02,
          6.2493e-02,  6.7901e-02,  2.1097e-01,  2.3393e-01,  2.8181e-03,
          2.6052e-01],
        [-3.2476e-01,  2.7211e-01,  4.4235e-02,  2.0500e-01,  4.0697e-01,
          6.4837e-03,  3.5087e-01,  2.3667e-01,  5.5148e-03,  8.5665e-02,
          6.0458e-02, -2.6294e-01, -2.1212e-01, -1.7883e-01,  1.1423e-01,
         -8.8494e-02],
        [ 2.9134e-01, -2.0950e-02,  9.9706e-02, -1.1745e-01, -3.5137e-01,
         -2.5969e-01, -1.2098e-01, -3.7742e-01, -5.5865e-02, -8.1078e-02,
          1.1994e-01,  1.1648e-01,  3.2545e-01,  2.8828e-01, -6.8749e-02,
          2.2988e-01],
        [-2.5968e-01,  2.1863e-01, -2.8433e-01,  2.4036e-01, -1.6405e-02,
          1.1862e-01,  3.1110e-01,  3.3916e-01,  3.9360e-01,  2.0946e-01,
          1.4290e-01, -6.3655e-02,  7.8247e-02,  8.6122e-02,  2.2061e-01,
         -1.9589e-01],
        [-2.7667e-01,  9.8829e-02, -6.1974e-03,  5.6758e-03,  2.7392e-01,
          3.5768e-01,  3.6038e-01,  2.8381e-02,  2.7500e-01,  2.9531e-01,
         -2.4867e-01,  9.8046e-03, -2.8857e-01, -2.4391e-01,  1.1698e-01,
         -2.1347e-01],
        [ 4.4487e-02, -9.5226e-02,  2.0590e-01, -2.8719e-02, -6.6610e-02,
         -2.7582e-01, -3.6701e-01, -4.0574e-01, -3.4930e-01, -2.2492e-01,
          1.0047e-01, -5.2441e-02, -8.4146e-02,  1.7822e-01, -3.6143e-01,
          1.4805e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0845, -0.0231,  0.1367, -0.1160, -0.0502, -0.0291,  0.0606,  0.1478,
        -0.0408, -0.0425,  0.0403,  0.0595,  0.1621,  0.0931, -0.0561,  0.0967,
        -0.1890, -0.0025,  0.0206,  0.0091, -0.0220, -0.1235, -0.0630, -0.0610,
        -0.1902,  0.2741,  0.1115,  0.0197, -0.0845, -0.2232,  0.1514, -0.0330],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.3290,  0.4154, -0.3012, -0.3171,  0.4275,  0.4537, -0.3493, -0.4254,
         -0.3966,  0.4751,  0.3231,  0.4519, -0.3754, -0.4854,  0.3801, -0.4408,
         -0.3779,  0.3684, -0.2899, -0.3064,  0.4868,  0.4251, -0.4206, -0.4121,
         -0.4662, -0.4304, -0.3621,  0.4374, -0.3918,  0.4308,  0.3361, -0.2918]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0313,  0.0972,  0.0518,  ...,  0.2247, -0.3801, -0.1137],
        [-0.0972, -0.0660,  0.1118,  ...,  0.1587, -0.3649,  0.0871],
        [-0.0144, -0.0203,  0.0240,  ...,  0.0229,  0.2833,  0.0345],
        ...,
        [ 0.0205, -0.0012,  0.0525,  ...,  0.0886, -0.3771, -0.1180],
        [ 0.0744, -0.1943, -0.0483,  ..., -0.3321,  0.1956,  0.1557],
        [-0.1926,  0.1346,  0.0323,  ...,  0.1011, -0.3320, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0426,  0.0409, -0.0669, -0.1335, -0.0719,  0.0585, -0.1109,  0.0465,
        -0.0396,  0.0813,  0.0191,  0.0113,  0.0291,  0.0779, -0.0529, -0.0195,
         0.0593, -0.1526,  0.0012,  0.0276, -0.0524,  0.0348,  0.1081,  0.0059,
        -0.0930,  0.1034,  0.0471, -0.0962,  0.0550,  0.1398,  0.1666, -0.1226],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0682, -0.1989, -0.1005,  ..., -0.1611, -0.0095,  0.0714],
        [-0.2129, -0.0555,  0.1018,  ..., -0.0942,  0.0142,  0.0456],
        [ 0.1463, -0.0080, -0.1791,  ...,  0.1109, -0.0390,  0.1948],
        ...,
        [ 0.1260,  0.1109,  0.1072,  ...,  0.2831, -0.2330,  0.2488],
        [-0.0125, -0.1679,  0.0581,  ..., -0.0117,  0.2455, -0.1733],
        [-0.0103, -0.1513,  0.2154,  ...,  0.0079,  0.1725, -0.0552]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1056,  0.1500, -0.0628, -0.0858,  0.0008, -0.0453, -0.0598, -0.0426,
         0.1257, -0.1712,  0.1303, -0.1160,  0.1744,  0.0873, -0.1208,  0.1300,
        -0.1388, -0.1750, -0.0545, -0.0020, -0.0049,  0.0828, -0.2137,  0.2162,
        -0.0449, -0.0040,  0.0726, -0.0277, -0.1371, -0.0739,  0.1255,  0.0454],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.6290,  0.5529, -0.6458, -0.6280,  0.5124,  0.4918, -0.5544,  0.5324,
          0.5459, -0.5757, -0.5194,  0.5396,  0.5179,  0.5002,  0.5690,  0.5671,
         -0.6248, -0.6384, -0.4992,  0.5461, -0.5896, -0.5710, -0.6425,  0.4805,
          0.6132,  0.6390, -0.6250,  0.6347, -0.5564, -0.6261,  0.6152,  0.6413]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.3657], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-3.4121e-02,  2.6119e-01,  2.2506e-01, -2.5379e-01, -3.9262e-01,
         -7.9698e-02,  1.0124e-02, -4.8424e-01, -2.6984e-01,  3.0825e-02,
          1.7568e-01,  1.7357e-01, -4.3511e-03, -1.5335e-01, -2.5128e-01,
          2.7129e-01],
        [-2.2839e-01, -2.6487e-01, -4.3357e-02, -4.5154e-02,  1.2155e-01,
          1.9641e-01,  1.1654e-01,  2.1285e-01,  4.7376e-01,  7.0372e-02,
          6.5424e-02, -2.5177e-01,  4.7672e-02,  2.3162e-02,  5.1949e-01,
         -7.7406e-03],
        [ 6.3497e-02,  1.9709e-01,  3.1842e-01, -8.0409e-02, -2.3854e-01,
         -3.2291e-01, -3.4124e-02, -5.1903e-01, -1.7574e-02, -1.6456e-02,
         -3.1217e-02, -5.5603e-02,  4.1732e-01,  2.9343e-01, -1.4093e-01,
          2.2472e-01],
        [ 2.3507e-01, -2.2358e-02,  1.1868e-02, -2.1213e-02, -2.0668e-01,
         -1.2123e-01, -7.7027e-02, -1.3798e-01, -5.0453e-01, -3.1758e-01,
          2.7012e-02,  3.4307e-01,  2.2143e-01, -2.0485e-01, -3.5615e-01,
          5.5376e-02],
        [-7.6691e-02,  1.7332e-01, -1.0865e-01, -6.3781e-02,  3.4680e-01,
          3.1641e-02, -2.8313e-03,  4.0482e-01,  2.4436e-01,  2.3133e-01,
          7.6236e-02, -1.6034e-01, -1.4661e-02, -1.7780e-01,  4.7925e-01,
         -8.1326e-02],
        [ 1.5141e-02,  2.0513e-01, -3.0996e-01,  3.6782e-01,  4.6936e-01,
         -7.8713e-02,  2.1517e-01,  1.3694e-02,  3.2306e-01,  1.5705e-01,
         -1.1674e-01, -8.0629e-02, -1.9686e-01,  1.7657e-01,  5.5936e-01,
         -1.6900e-02],
        [ 3.3867e-01,  4.9344e-02,  3.4356e-01, -1.4350e-01, -1.9070e-01,
         -1.6327e-01, -1.2878e-01, -2.8481e-01, -3.0095e-01,  3.6611e-02,
          2.3013e-02,  4.7627e-02, -1.0401e-01,  1.1325e-01, -4.2361e-01,
          8.4735e-02],
        [-9.0290e-02,  2.2704e-01,  3.0334e-01, -3.2212e-01, -4.3327e-01,
         -2.6817e-01, -5.7280e-02, -3.0794e-01, -2.2378e-01, -1.7534e-01,
         -3.1861e-02,  1.9971e-02,  2.3405e-01, -1.3913e-01, -1.9352e-01,
          3.1454e-01],
        [ 2.8630e-02,  2.5659e-01,  2.5534e-01, -2.2696e-01, -2.0470e-01,
         -3.2438e-01, -1.4801e-01, -1.8434e-01, -3.2605e-02, -2.7214e-01,
          4.8374e-02,  7.1175e-02, -5.8146e-02,  1.3417e-01, -5.1840e-01,
          5.1458e-02],
        [-2.8058e-01, -3.3724e-02, -5.3144e-02, -3.7785e-02,  2.4475e-01,
          1.1897e-01,  1.8102e-02,  3.1929e-01,  3.6426e-01, -4.8604e-02,
          1.1646e-01, -1.7443e-02, -2.4558e-01, -4.2650e-02,  3.7001e-01,
         -1.4415e-01],
        [-3.4318e-01,  1.1988e-01, -1.1445e-02, -6.1565e-02,  1.3545e-01,
          3.8872e-01,  1.9939e-01,  2.0754e-01,  4.4620e-01,  2.0092e-01,
         -3.2848e-02, -5.9083e-03, -1.8038e-01,  1.4124e-01,  1.8892e-01,
         -2.7157e-01],
        [-1.0751e-01, -9.2760e-02,  3.0393e-02,  6.4329e-02,  3.0076e-01,
          8.8688e-02,  3.3105e-01,  2.1679e-01,  2.2163e-01,  2.9823e-01,
          7.1278e-02,  6.2396e-02, -4.0249e-01, -1.9194e-01,  2.1268e-01,
         -1.5093e-01],
        [ 2.9695e-01,  1.4589e-01,  8.4202e-02, -1.1377e-01, -3.1375e-01,
          1.0259e-01, -2.2503e-02, -4.2149e-01, -4.3447e-01, -2.2413e-02,
         -9.1619e-02,  1.8354e-02, -9.6260e-02,  1.0595e-01, -4.6930e-01,
         -6.2584e-02],
        [ 1.8709e-01,  2.7425e-01,  3.1640e-01,  1.6274e-02, -4.2392e-01,
          1.3359e-02, -4.7412e-03, -1.1699e-01, -2.6790e-01, -1.1809e-01,
         -8.9658e-02,  1.0259e-01,  9.6489e-02,  3.4074e-03, -4.8699e-01,
          1.8626e-01],
        [-3.5777e-01, -2.4573e-01, -1.7674e-02, -6.8893e-02,  5.0912e-01,
          3.8037e-01,  7.2764e-02,  1.8808e-01,  3.1091e-02,  1.4089e-01,
          5.8641e-03, -3.1161e-01, -7.8714e-02, -8.0174e-02,  2.1673e-01,
         -1.1584e-01],
        [-2.6826e-01, -1.1632e-01,  8.8351e-02,  1.9845e-01,  2.8684e-01,
          1.0630e-01,  5.1541e-02,  1.5003e-01,  2.6449e-01,  4.8961e-02,
          1.9870e-02,  1.4698e-01, -9.9989e-02, -1.9928e-01,  6.8909e-01,
         -4.7672e-03],
        [ 2.8151e-01,  1.5557e-01,  1.3849e-01, -3.0877e-01, -4.6649e-01,
          2.2165e-02, -3.2925e-02, -2.2952e-02, -4.3958e-01, -1.1707e-01,
          1.7629e-01,  2.7239e-01,  2.8303e-01,  1.8732e-01, -2.3558e-01,
         -1.0734e-01],
        [-2.5216e-01,  1.0530e-01, -1.7700e-01,  9.3606e-02,  2.1281e-01,
          2.4658e-01,  2.2747e-01,  2.9354e-01,  1.6069e-01,  2.2177e-01,
         -7.8072e-02, -2.1136e-01, -1.1115e-01, -1.2483e-01,  3.3875e-01,
         -1.0892e-01],
        [ 2.0355e-01,  3.8251e-02,  8.2880e-02, -2.3560e-01, -3.5396e-01,
         -3.3083e-01, -2.3415e-01, -4.8497e-02, -4.8819e-01, -4.0713e-02,
          5.2275e-02, -8.0669e-02,  1.6646e-01,  1.8135e-01, -1.3886e-01,
          1.1810e-01],
        [ 3.5055e-01,  6.7910e-02,  2.0665e-01, -5.6225e-02, -4.7596e-01,
         -1.9401e-01, -3.2088e-01, -5.2402e-02, -1.2970e-01, -2.1636e-01,
          1.2198e-01,  2.5106e-01, -6.4229e-02,  5.5024e-02, -1.8062e-01,
          1.3056e-01],
        [-1.4659e-01,  1.3627e-01,  1.1217e-02, -1.1077e-01,  3.6518e-01,
         -8.7703e-02,  2.6142e-01,  3.8970e-01,  2.1019e-01,  1.7789e-02,
         -1.0616e-01, -2.4556e-01, -1.5588e-01, -1.4773e-01,  5.0073e-01,
         -1.9692e-01],
        [-8.9978e-02, -2.7743e-01, -1.6457e-02,  3.7927e-01,  1.6617e-01,
          1.1533e-01,  2.6012e-01,  6.3088e-02,  1.4005e-01,  2.4096e-01,
          1.7944e-01, -3.1076e-01, -2.3493e-01, -3.5719e-01,  1.1159e-01,
          8.0939e-02],
        [ 3.5364e-01, -3.5326e-02,  1.0797e-02, -1.4497e-01, -1.3000e-01,
         -3.7423e-01, -2.7486e-01, -2.9101e-01, -3.1911e-01, -1.2213e-01,
          2.1892e-01,  2.2123e-01, -8.2336e-02,  2.7641e-01, -4.3797e-02,
          1.7883e-01],
        [ 2.0375e-01,  1.0120e-01,  2.6613e-01, -3.1184e-01, -2.7238e-01,
         -9.6944e-02, -9.9950e-02, -2.7177e-01, -3.7958e-01, -2.4303e-01,
          2.1361e-02,  2.9773e-01,  1.9510e-01,  3.4784e-02, -2.3444e-01,
         -5.9747e-02],
        [ 2.0655e-01, -1.7377e-01,  1.3272e-01, -1.0519e-01, -1.0069e-01,
         -2.1920e-01,  7.6239e-02, -2.4326e-01, -4.5588e-01,  9.6407e-02,
          2.0571e-01,  1.3633e-02,  3.1826e-02,  2.1462e-01, -5.0835e-01,
          2.9235e-01],
        [ 1.5184e-02, -2.3194e-02,  3.1882e-02,  1.1593e-01, -3.3526e-01,
         -1.7384e-01,  1.1766e-02, -3.8302e-01, -2.0210e-01, -3.0762e-01,
         -2.4412e-01,  9.1258e-02,  1.6494e-01,  2.8371e-01, -5.4796e-01,
          3.2973e-02],
        [ 1.9599e-01,  1.0859e-01,  2.4052e-01, -3.1751e-01, -2.9107e-01,
         -6.8219e-02, -3.2646e-01, -7.7463e-02, -4.3009e-01,  5.2809e-02,
          7.0795e-02,  8.1870e-02,  2.1494e-01,  2.2745e-01, -2.8754e-02,
          2.4336e-01],
        [-3.1243e-01,  1.7201e-02,  6.1793e-02,  1.8555e-01,  4.6464e-01,
         -9.1847e-03,  3.3219e-01,  2.4849e-01,  2.8630e-02,  6.0578e-02,
          6.9090e-02, -2.8020e-01, -2.1003e-01, -1.6242e-01,  1.6595e-01,
         -6.3417e-02],
        [ 2.7120e-01,  1.0192e-01,  7.6606e-02, -9.7026e-02, -3.9475e-01,
         -2.4729e-01, -1.0699e-01, -3.8102e-01, -5.0916e-02, -5.8197e-02,
          1.3174e-01,  1.2200e-01,  3.2391e-01,  2.7100e-01, -9.9532e-02,
          2.1166e-01],
        [-2.4796e-01,  7.6746e-02, -2.6774e-01,  2.2429e-01,  3.6914e-02,
          1.1695e-01,  3.0183e-01,  3.5124e-01,  4.0066e-01,  1.9169e-01,
          1.2124e-01, -7.6767e-02,  6.3138e-02,  1.0051e-01,  2.7752e-01,
         -1.8131e-01],
        [-2.6048e-01, -1.0344e-01,  1.5111e-02, -1.3262e-02,  3.2442e-01,
          3.4841e-01,  3.4496e-01,  3.3904e-02,  2.8560e-01,  2.7052e-01,
         -2.6149e-01, -5.1197e-03, -2.9423e-01, -2.2052e-01,  1.4335e-01,
         -1.9034e-01],
        [ 1.7131e-02,  6.2152e-02,  1.7700e-01, -3.8972e-04, -1.2869e-01,
         -2.6055e-01, -3.4132e-01, -4.2482e-01, -3.6128e-01, -1.9333e-01,
          1.2511e-01, -3.9777e-02, -8.2269e-02,  1.4530e-01, -3.9577e-01,
          1.1715e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-9.5209e-02, -2.6470e-03,  1.7411e-01, -1.1928e-01, -2.5041e-02,
         9.9719e-03,  8.0458e-02,  1.6927e-01, -3.0509e-02, -2.4629e-02,
         9.5141e-03,  6.9785e-02,  1.2772e-01,  8.6544e-02, -5.0526e-02,
        -4.7192e-02, -2.1380e-01, -1.0083e-02,  1.6257e-02,  2.2745e-04,
        -9.2257e-04, -1.2636e-01, -5.8356e-02, -5.1269e-02, -1.6914e-01,
         2.7735e-01,  1.1157e-01,  4.4026e-02, -7.9099e-02, -2.3991e-01,
         1.5766e-01, -3.0987e-02], device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.3314,  0.4150, -0.3015, -0.3310,  0.4709,  0.4902, -0.3570, -0.4246,
         -0.4041,  0.4917,  0.3367,  0.4472, -0.3935, -0.4910,  0.3796,  0.4386,
         -0.3811,  0.3757, -0.2924, -0.3079,  0.5062,  0.3982, -0.4229, -0.4131,
         -0.5149, -0.4476, -0.3605,  0.4429, -0.3955,  0.4352,  0.3371, -0.2967]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0104,  0.1005,  0.0754,  ...,  0.1620, -0.3477, -0.1137],
        [-0.1061, -0.0466,  0.1160,  ...,  0.1330, -0.3603,  0.0871],
        [-0.0092, -0.0357,  0.0331,  ...,  0.0238,  0.3041,  0.0345],
        ...,
        [ 0.0113,  0.0227,  0.0523,  ...,  0.0711, -0.3954, -0.1180],
        [ 0.0866, -0.2166, -0.0510,  ..., -0.3068,  0.2057,  0.1557],
        [-0.1880,  0.1531,  0.0377,  ...,  0.0674, -0.3471, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0465,  0.0399, -0.0695, -0.1357, -0.0738,  0.0495, -0.1101,  0.0502,
        -0.0413,  0.0784,  0.0248,  0.0118,  0.0241,  0.0757, -0.0504, -0.0209,
         0.0574, -0.1563, -0.0642,  0.0379, -0.0579,  0.0317,  0.1052,  0.0080,
        -0.0877,  0.0524,  0.0435, -0.1169,  0.0550,  0.1431,  0.1668, -0.1280],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0455, -0.1929, -0.0945,  ..., -0.1349,  0.0054,  0.0649],
        [-0.2301, -0.0490,  0.1208,  ..., -0.0613,  0.0158,  0.0382],
        [ 0.1553, -0.0145, -0.1850,  ...,  0.0781, -0.0315,  0.1944],
        ...,
        [ 0.1303,  0.0881,  0.1140,  ...,  0.2453, -0.2331,  0.2385],
        [-0.0228, -0.1644,  0.0703,  ...,  0.0283,  0.2372, -0.1795],
        [-0.0154, -0.1353,  0.2096,  ...,  0.0487,  0.1645, -0.0467]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1093,  0.1639, -0.0661, -0.0846, -0.0032, -0.0438, -0.0600, -0.0402,
         0.1378, -0.1816,  0.1171, -0.1276,  0.1964,  0.1062, -0.1219,  0.1414,
        -0.1385, -0.1752,  0.0485, -0.0109, -0.0085,  0.0845, -0.2033,  0.2438,
        -0.0414, -0.0058,  0.0714, -0.0272, -0.1378, -0.0698,  0.1350,  0.0402],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.6565,  0.5871, -0.6654, -0.6380,  0.5273,  0.5364, -0.5733,  0.5455,
          0.5529, -0.6058, -0.5516,  0.5450,  0.5411,  0.5322,  0.5772,  0.5941,
         -0.6406, -0.6519,  0.5027,  0.5567, -0.6105, -0.5914, -0.6529,  0.4939,
          0.6371,  0.6517, -0.6338,  0.6517, -0.5717, -0.6391,  0.6338,  0.6484]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.3746], device='cuda:0', requires_grad=True)

