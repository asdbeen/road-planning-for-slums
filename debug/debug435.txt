Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 8.9968e-03,  3.9129e-01,  3.0410e-01, -3.0850e-01, -1.9433e-01,
         -1.5276e-01, -1.0304e-01, -4.1092e-01, -3.2961e-01, -7.9896e-02,
         -1.7940e-02,  2.1534e-01, -3.4468e-01, -7.2842e-02, -6.8607e-02,
          3.9685e-01],
        [-2.5149e-01, -3.7933e-01, -9.3539e-02, -2.9984e-02, -2.6279e-02,
          2.4912e-01,  1.7765e-01,  1.7725e-01,  4.8949e-01,  1.3685e-01,
          2.8653e-01, -2.7784e-01,  3.8986e-01, -1.9047e-02,  3.6934e-01,
         -9.3937e-02],
        [ 1.1009e-01,  2.9579e-01,  3.9211e-01, -1.2008e-01, -1.1579e-01,
         -3.4684e-01, -1.2628e-01, -4.7759e-01, -1.4359e-01, -9.9333e-02,
         -1.5321e-01, -5.4032e-03, -2.8699e-02,  3.5251e-01, -6.5761e-02,
          3.0372e-01],
        [ 2.8856e-01,  1.0859e-01,  8.9305e-02, -6.5498e-02, -6.9030e-02,
         -2.1919e-01, -1.9377e-01, -1.4252e-01, -5.3974e-01, -4.2928e-01,
         -2.0482e-01,  4.0663e-01, -1.1022e-01, -1.2474e-01, -2.4206e-01,
          1.8459e-01],
        [-1.0393e-01,  4.1297e-02, -1.6860e-01, -4.0184e-02,  1.7328e-01,
          9.5568e-02,  6.7343e-02,  3.5400e-01,  2.4876e-01,  3.0898e-01,
          3.3964e-01, -1.9220e-01,  3.6047e-01, -2.2757e-01,  3.2848e-01,
         -1.8053e-01],
        [-3.5399e-02,  6.1566e-02, -3.7696e-01,  4.0581e-01,  3.7485e-01,
          1.3746e-03,  3.1906e-01,  2.9193e-02,  3.9136e-01,  2.4572e-01,
         -7.6619e-02, -1.4276e-01,  1.7179e-01,  1.1383e-01,  4.8253e-01,
         -1.1915e-01],
        [ 3.6924e-01,  2.3866e-01,  3.9984e-01, -1.6668e-01, -5.5529e-02,
         -2.0560e-01, -2.0152e-01, -2.5224e-01, -3.5615e-01, -3.0836e-02,
         -3.3309e-02,  7.7011e-02, -3.8534e-01,  1.9439e-01, -3.2886e-01,
          1.6629e-01],
        [-5.2070e-02,  3.5994e-01,  3.6009e-01, -3.5071e-01, -3.5305e-01,
         -2.9909e-01, -1.2261e-01, -2.9021e-01, -3.0192e-01, -2.3237e-01,
         -8.8267e-02,  5.7236e-02, -6.9720e-02, -1.0002e-01, -1.5835e-01,
          3.7804e-01],
        [ 4.1480e-02,  3.5781e-01,  3.0360e-01, -2.3642e-01, -5.6570e-02,
         -3.4574e-01, -1.8195e-01, -1.1462e-01, -4.9078e-02, -3.2361e-01,
         -2.7932e-01,  6.8982e-02, -4.4671e-01,  1.6066e-01, -3.2960e-01,
          1.1862e-01],
        [-3.1426e-01, -1.6633e-01, -1.1442e-01, -9.4020e-03,  1.0588e-01,
          1.7876e-01,  1.0321e-01,  2.8620e-01,  3.9154e-01,  2.8024e-02,
          3.6335e-01, -5.1740e-02,  1.5807e-01, -9.8739e-02,  2.4685e-01,
         -2.4131e-01],
        [-3.7806e-01,  2.1122e-02, -7.4533e-02, -3.6172e-02, -2.2672e-02,
          4.4958e-01,  2.8479e-01,  1.7553e-01,  4.7776e-01,  2.8521e-01,
          2.1963e-01, -4.1825e-02,  2.3287e-01,  1.0581e-01,  5.8130e-02,
         -3.6994e-01],
        [-1.5295e-01, -2.0887e-01, -4.4181e-02,  9.6259e-02,  2.0046e-01,
          1.4207e-01,  4.1896e-01,  1.8864e-01,  2.7794e-01,  3.7870e-01,
          4.0934e-01,  2.7846e-02, -2.7381e-02, -2.7326e-01,  8.0799e-02,
         -2.5062e-01],
        [ 3.4144e-01,  2.8249e-01,  1.6139e-01, -1.5309e-01, -1.0732e-01,
          2.0489e-02, -1.0719e-01, -3.5163e-01, -4.3127e-01, -1.1862e-01,
         -1.6579e-01,  6.2096e-02, -4.7311e-01,  1.4727e-01, -2.8029e-01,
          5.8742e-02],
        [ 2.1563e-01,  4.0060e-01,  3.7034e-01, -3.3809e-03, -3.1730e-01,
         -2.3012e-02, -5.8799e-02, -8.8895e-02, -3.0470e-01, -1.7706e-01,
         -2.7563e-01,  1.2565e-01, -2.2724e-01,  5.8351e-02, -3.6350e-01,
          2.6091e-01],
        [-3.8380e-01, -3.4942e-01, -6.9252e-02, -4.6506e-02,  3.7576e-01,
          4.0587e-01,  1.3022e-01,  1.4452e-01,  7.2597e-02,  1.9923e-01,
          1.8422e-01, -3.3449e-01,  2.8594e-01, -1.0761e-01,  9.9129e-02,
         -1.8782e-01],
        [-3.5504e-02, -1.4174e-02,  2.0047e-01,  1.0419e-01, -3.8122e-01,
         -6.6599e-02, -2.6253e-01, -4.0889e-01, -4.1927e-01, -1.0840e-01,
         -1.2940e-01,  5.1191e-01, -3.8761e-01, -3.2404e-02, -3.4105e-02,
          1.3828e-01],
        [ 3.3916e-01,  3.3134e-01,  2.1731e-01, -3.5877e-01, -3.8912e-01,
         -5.9976e-02, -1.4360e-01, -4.3253e-02, -4.8673e-01, -2.1744e-01,
          7.3222e-02,  3.2798e-01,  5.7244e-03,  3.0696e-01, -1.8466e-01,
          1.4985e-02],
        [-3.0159e-01, -5.2828e-02, -2.4549e-01,  1.3055e-01,  1.4241e-01,
          3.0743e-01,  3.1349e-01,  3.0192e-01,  2.4309e-01,  3.0037e-01,
         -3.3342e-04, -2.7029e-01,  1.3753e-01, -2.0485e-01,  3.2426e-01,
         -1.9583e-01],
        [ 2.3723e-01,  1.4734e-01,  1.3946e-01, -2.6207e-01, -2.2231e-01,
         -3.7224e-01, -3.5328e-01, -1.8367e-02, -5.8623e-01, -1.2785e-01,
         -1.0501e-01, -3.8014e-02, -1.8884e-01,  2.8884e-01, -9.5379e-02,
          2.2147e-01],
        [ 3.7789e-01,  1.7574e-01,  2.7066e-01, -8.0803e-02, -3.1010e-01,
         -2.2761e-01, -3.8160e-01,  1.2746e-02, -1.4906e-01, -2.9109e-01,
         -1.6148e-01,  2.6011e-01, -4.2919e-01,  1.0047e-01,  7.0158e-03,
          2.2336e-01],
        [-1.9608e-01,  8.5143e-03, -5.5423e-02, -7.6400e-02,  2.9547e-01,
         -1.4754e-02,  3.3891e-01,  4.0861e-01,  2.9215e-01,  9.6445e-02,
          3.1441e-03, -3.1408e-01,  1.5916e-01, -2.0468e-01,  4.3463e-01,
         -2.8428e-01],
        [-9.4799e-02, -4.1459e-01, -6.2617e-02,  3.9234e-01, -1.3084e-03,
          1.2137e-01,  3.0010e-01, -2.7564e-02,  1.3756e-01,  2.8968e-01,
          4.0275e-01, -2.8981e-01,  2.2301e-01, -3.7978e-01, -2.3706e-02,
          1.2601e-02],
        [ 3.7144e-01,  7.3244e-02,  5.4854e-02, -1.5672e-01, -5.4725e-04,
         -3.9881e-01, -3.1888e-01, -2.4717e-01, -3.4765e-01, -1.7193e-01,
          6.3631e-02,  2.2951e-01, -4.1622e-01,  3.0986e-01,  6.4561e-02,
          2.4446e-01],
        [ 2.6196e-01,  2.2716e-01,  3.4172e-01, -3.5936e-01, -2.3756e-01,
         -1.7109e-01, -1.9798e-01, -3.0171e-01, -4.4659e-01, -3.3757e-01,
         -1.2515e-01,  3.5979e-01, -5.0428e-03,  1.1975e-01, -2.1132e-01,
          4.5346e-02],
        [ 2.4151e-01, -4.5984e-02,  1.8640e-01, -1.2092e-01,  2.3725e-02,
         -2.9503e-01, -1.8454e-02, -2.4304e-01, -5.2017e-01,  1.4232e-02,
          4.7048e-02,  6.2445e-02, -4.1032e-01,  2.6756e-01, -3.8640e-01,
          3.9115e-01],
        [ 5.7206e-02,  7.7828e-02,  9.3244e-02,  8.6879e-02, -2.3703e-01,
         -2.2192e-01, -5.7827e-02, -3.7569e-01, -2.8003e-01, -3.7747e-01,
         -3.5753e-01,  1.5035e-01, -1.9223e-01,  3.1118e-01, -4.3627e-01,
          1.1168e-01],
        [ 2.3741e-01,  2.5373e-01,  3.1093e-01, -3.4951e-01, -1.9009e-01,
         -1.0419e-01, -3.9500e-01, -4.7119e-02, -4.9770e-01, -1.9133e-02,
         -5.2784e-02,  1.1114e-01, -1.1324e-01,  3.0522e-01,  5.9699e-02,
          3.2956e-01],
        [-3.3759e-01, -1.0422e-01,  4.0232e-03,  2.0830e-01,  3.2289e-01,
          3.2848e-02,  4.0695e-01,  1.9369e-01,  4.9119e-02,  1.2832e-01,
          3.7778e-01, -2.9467e-01,  1.7185e-01, -2.2532e-01,  3.1052e-02,
         -1.5388e-01],
        [ 3.2467e-01,  1.9460e-01,  1.5227e-01, -1.3768e-01, -3.1968e-01,
         -2.9899e-01, -1.8876e-01, -3.7503e-01, -1.2934e-01, -1.3844e-01,
         -1.0094e-01,  1.7016e-01,  4.5233e-03,  3.3142e-01, -4.0846e-02,
          3.0495e-01],
        [-2.7053e-01, -3.2632e-02, -3.1241e-01,  2.3609e-01, -7.6830e-02,
          1.4647e-01,  3.5134e-01,  3.2089e-01,  4.4728e-01,  2.4218e-01,
          2.1643e-01, -9.7544e-02,  3.5172e-01,  7.6081e-02,  1.6627e-01,
         -2.4088e-01],
        [-3.1177e-01, -2.3443e-01, -6.2661e-02,  2.6513e-02,  2.2076e-01,
          4.0708e-01,  4.3078e-01,  1.7913e-02,  3.5204e-01,  3.5696e-01,
         -8.9120e-02, -5.1236e-02,  6.3704e-02, -2.9981e-01,  7.1602e-02,
         -2.9117e-01],
        [ 4.8239e-02,  2.1788e-01,  2.3613e-01, -2.0376e-02,  1.2805e-02,
         -3.1321e-01, -4.2640e-01, -3.8878e-01, -4.4155e-01, -2.7489e-01,
         -2.1272e-02,  4.5898e-03, -3.8436e-01,  2.5386e-01, -2.8279e-01,
          2.0420e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0817, -0.0223, -0.0435, -0.0269,  0.0054, -0.2285,  0.0858,  0.1062,
        -0.0734,  0.0004,  0.0412,  0.0894,  0.1295,  0.0588,  0.0738,  0.0045,
        -0.0370, -0.0361,  0.0648, -0.0459, -0.1136, -0.0387, -0.0353,  0.0286,
        -0.0373,  0.1334,  0.1348,  0.0599, -0.1175, -0.1810,  0.0386,  0.0238],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2644,  0.3591, -0.2764, -0.3081,  0.3578,  0.4285, -0.3186, -0.4066,
         -0.3585,  0.4054,  0.3161,  0.4253, -0.3166, -0.4356,  0.3228, -0.3528,
         -0.3654,  0.3679, -0.2842, -0.2706,  0.4661,  0.3642, -0.4115, -0.4061,
         -0.3713, -0.3845, -0.3567,  0.3905, -0.3881,  0.4160,  0.3480, -0.2784]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0131,  0.1659,  0.0610,  ...,  0.2063, -0.3330, -0.1137],
        [-0.0604, -0.0662,  0.1180,  ...,  0.1030, -0.3027,  0.0871],
        [-0.1277,  0.2368,  0.0833,  ...,  0.2118, -0.0318,  0.0345],
        ...,
        [ 0.0875, -0.1236, -0.0377,  ..., -0.1687, -0.0058, -0.1180],
        [ 0.0292, -0.1962, -0.0376,  ..., -0.2638,  0.1080,  0.1557],
        [-0.1713,  0.1437,  0.0451,  ...,  0.0758, -0.2704, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0594,  0.0289, -0.0879, -0.1553, -0.0818, -0.0080, -0.1010,  0.0453,
        -0.0364,  0.0586,  0.0332, -0.0091,  0.0182,  0.1025, -0.0419, -0.0197,
         0.0533, -0.1669,  0.0076,  0.0830, -0.0652,  0.0161,  0.1107,  0.0252,
        -0.1080,  0.0981,  0.0443, -0.1059,  0.0505,  0.2079,  0.1692, -0.1261],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0415, -0.1655, -0.1952,  ...,  0.0358, -0.0416,  0.0652],
        [-0.2242, -0.0200, -0.0208,  ...,  0.1418, -0.0230,  0.0487],
        [ 0.1586, -0.0453, -0.0321,  ..., -0.1439, -0.0031,  0.1897],
        ...,
        [ 0.1728,  0.0508,  0.2406,  ...,  0.1130, -0.1758,  0.2518],
        [-0.0146, -0.1501, -0.0395,  ...,  0.2510,  0.2263, -0.1781],
        [-0.0037, -0.1183,  0.1312,  ...,  0.2296,  0.1349, -0.0456]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1000,  0.1500, -0.0477, -0.1074, -0.0989, -0.1800, -0.0731, -0.0187,
         0.1498, -0.1798,  0.1400, -0.1339,  0.2067,  0.1035, -0.1002,  0.1347,
        -0.1305, -0.1869,  0.0825,  0.0132, -0.0218,  0.0720, -0.2059,  0.2267,
        -0.0405, -0.0159,  0.0760, -0.0475, -0.1611, -0.0502,  0.1325,  0.0362],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4480,  0.3728, -0.4163, -0.4435, -0.3073, -0.2966, -0.3541,  0.3312,
          0.3409, -0.3582, -0.3239,  0.3370,  0.3397,  0.2930,  0.3586,  0.3381,
         -0.4397, -0.4401,  0.2951,  0.3475, -0.4025, -0.3487, -0.4546,  0.2876,
          0.4162,  0.4655, -0.4202,  0.4446, -0.3542, -0.4467,  0.4068,  0.4466]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1832], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.9841e-02,  3.1190e-01,  3.2026e-01, -3.4664e-01, -6.3310e-02,
         -1.8735e-01, -9.3671e-02, -4.4064e-01, -1.9325e-01, -6.0846e-02,
          3.3384e-02,  2.0211e-01,  9.5123e-02, -6.5346e-02,  3.6886e-01,
          3.3573e-01],
        [-2.9273e-01, -3.0154e-01, -1.3468e-01,  2.4369e-02, -1.2053e-01,
          3.0479e-01,  2.2195e-01,  2.2383e-01,  4.2684e-01,  1.2422e-01,
          2.1835e-01, -3.0662e-01, -4.3399e-02, -4.3205e-02, -5.9047e-02,
         -6.5743e-02],
        [ 9.7644e-02,  2.0693e-01,  3.9373e-01, -1.3159e-01,  1.0862e-01,
         -3.7436e-01, -8.3635e-02, -4.5225e-01,  4.7005e-02, -5.4277e-02,
         -8.7822e-02, -4.3214e-02,  4.2264e-01,  2.9393e-01,  4.7288e-01,
          2.3533e-01],
        [ 2.9479e-01,  2.5662e-02,  1.0101e-01, -8.9725e-02,  5.7379e-02,
         -2.3636e-01, -1.9133e-01, -1.4819e-01, -4.2652e-01, -3.7752e-01,
         -9.3577e-02,  3.9575e-01,  3.2146e-01, -1.4581e-01,  1.8242e-01,
          1.2915e-01],
        [-1.4133e-01,  1.6663e-01, -2.0053e-01,  1.3699e-02,  1.0840e-01,
          1.5392e-01,  1.0906e-01,  4.2163e-01,  2.0217e-01,  2.7971e-01,
          2.1613e-01, -2.4147e-01, -1.0938e-01, -2.2834e-01, -1.6145e-01,
         -1.1288e-01],
        [-3.9254e-02,  1.9056e-01, -3.8298e-01,  4.2723e-01,  2.1619e-01,
          2.9245e-02,  3.0618e-01,  4.6420e-02,  2.9687e-01,  1.9463e-01,
         -1.6079e-01, -1.5071e-01, -3.0672e-01,  1.2999e-01, -2.8487e-02,
         -4.8062e-02],
        [ 3.9990e-01,  1.6476e-01,  4.3189e-01, -2.0375e-01,  9.4568e-02,
         -2.5913e-01, -2.3485e-01, -2.8402e-01, -2.6606e-01, -9.8854e-03,
         -1.4068e-02,  9.0391e-02, -2.6467e-04,  2.1843e-01,  3.2785e-02,
          1.4016e-01],
        [-4.2485e-02,  2.8097e-01,  3.7176e-01, -3.6071e-01, -1.7787e-01,
         -3.3522e-01, -1.2531e-01, -2.8667e-01, -1.9165e-01, -1.9639e-01,
         -6.5420e-02,  4.2431e-02,  2.8307e-01, -9.6158e-02,  1.9402e-01,
          3.4552e-01],
        [ 7.5786e-02,  2.7048e-01,  3.3464e-01, -2.8129e-01, -7.2271e-03,
         -4.0293e-01, -2.1828e-01, -1.6482e-01,  1.7470e-02, -3.0446e-01,
         -1.1451e-01,  1.0913e-01, -4.1246e-02,  1.3372e-01,  7.7190e-02,
          7.9501e-02],
        [-3.2404e-01, -4.3697e-02, -1.2405e-01,  1.4666e-02,  5.7325e-03,
          2.1114e-01,  1.0188e-01,  3.1440e-01,  3.0432e-01, -1.9492e-02,
          2.2861e-01, -6.5193e-02, -3.0950e-01, -6.4954e-02, -2.5039e-01,
         -1.6736e-01],
        [-3.7075e-01,  1.1098e-01, -7.3805e-02, -3.0903e-02, -1.4191e-01,
          4.5802e-01,  2.6573e-01,  1.6093e-01,  3.4825e-01,  2.2474e-01,
          6.2373e-02, -1.3411e-02, -1.9237e-01,  1.4968e-01, -4.2984e-01,
         -3.0243e-01],
        [-1.5464e-01, -1.0650e-01, -4.4233e-02,  1.0724e-01,  1.5259e-01,
          1.6374e-01,  4.1903e-01,  2.1231e-01,  1.8799e-01,  3.2370e-01,
          1.4904e-01,  1.8774e-02, -4.3737e-01, -1.8080e-01, -3.1024e-01,
         -1.7374e-01],
        [ 3.8562e-01,  1.7507e-01,  2.0735e-01, -2.1371e-01,  2.9421e-02,
         -5.0903e-02, -1.5199e-01, -4.0151e-01, -3.7167e-01, -1.0317e-01,
         -1.1178e-01,  8.4913e-02,  2.3188e-02,  1.9328e-01,  2.4281e-01,
          7.0829e-03],
        [ 2.5530e-01,  3.2129e-01,  4.0684e-01, -4.7903e-02, -2.1827e-01,
         -8.4559e-02, -1.0645e-01, -1.4166e-01, -2.5164e-01, -1.6717e-01,
         -2.1384e-01,  1.6248e-01,  1.7792e-01,  7.3252e-02,  2.4610e-02,
          2.3793e-01],
        [-4.0246e-01, -2.6764e-01, -9.0403e-02, -2.5238e-02,  2.3884e-01,
          4.5423e-01,  1.4269e-01,  1.6558e-01, -2.1616e-02,  1.6809e-01,
          1.2381e-01, -3.4005e-01, -1.1958e-01, -1.0919e-01, -3.2652e-01,
         -1.4946e-01],
        [-5.5009e-02, -2.2212e-01,  1.8747e-01,  6.0250e-02, -2.7811e-01,
         -5.8929e-02, -1.9923e-01, -3.8769e-01, -2.3514e-01,  2.4983e-03,
          4.1582e-02,  5.1408e-01,  2.0486e-01, -7.3009e-02,  5.2693e-01,
         -3.0067e-03],
        [ 3.3389e-01,  2.2950e-01,  2.1363e-01, -3.6373e-01, -2.5559e-01,
         -7.6081e-02, -1.3905e-01, -5.8097e-02, -3.7904e-01, -1.6050e-01,
          1.5699e-01,  3.2262e-01,  3.8252e-01,  2.5740e-01,  1.6280e-01,
         -4.7685e-02],
        [-3.1547e-01,  1.5811e-02, -2.6142e-01,  1.5060e-01,  2.3279e-02,
          3.3876e-01,  3.2721e-01,  3.1804e-01,  1.4625e-01,  2.6439e-01,
         -4.6692e-02, -2.7014e-01, -1.9666e-01, -2.0571e-01,  1.1021e-02,
         -1.6275e-01],
        [ 2.4713e-01,  9.0717e-02,  1.6551e-01, -3.0151e-01, -3.9312e-02,
         -4.0943e-01, -3.2515e-01, -8.7638e-03, -3.9363e-01, -1.0623e-01,
         -3.6520e-02, -6.2081e-02,  2.2066e-01,  2.3822e-01,  4.0676e-01,
          1.7717e-01],
        [ 3.9352e-01,  1.0311e-01,  2.8839e-01, -1.0359e-01, -1.9941e-01,
         -2.6927e-01, -3.9544e-01, -4.8171e-03, -4.3073e-02, -2.5708e-01,
         -6.7365e-02,  2.6490e-01, -4.8662e-02,  9.5039e-02,  3.7178e-01,
          1.8307e-01],
        [-2.1927e-01,  1.1961e-01, -7.6025e-02, -3.5132e-02,  2.0405e-01,
          2.5205e-02,  3.5959e-01,  4.5736e-01,  2.3543e-01,  6.6212e-02,
         -8.9555e-02, -3.5380e-01, -2.6241e-01, -2.1329e-01, -1.8194e-02,
         -2.3411e-01],
        [-9.1695e-02, -3.0539e-01, -6.2333e-02,  3.9469e-01, -1.1754e-01,
          1.5092e-01,  2.7947e-01, -2.3636e-02,  2.3114e-02,  2.3787e-01,
          2.5025e-01, -2.8275e-01, -1.8431e-01, -3.2733e-01, -4.9958e-01,
          8.0011e-02],
        [ 3.7589e-01,  5.0875e-04,  6.2118e-02, -1.6355e-01,  1.3151e-01,
         -4.2156e-01, -3.2236e-01, -2.4330e-01, -2.3556e-01, -1.3094e-01,
          1.2229e-01,  2.1509e-01, -8.7838e-02,  2.9607e-01,  4.0882e-01,
          2.0567e-01],
        [ 2.7098e-01,  1.6680e-01,  3.5132e-01, -3.7329e-01, -1.1730e-01,
         -1.9675e-01, -2.1148e-01, -3.0327e-01, -3.4861e-01, -3.0067e-01,
         -9.6618e-02,  3.5204e-01,  2.7844e-01,  1.2824e-01,  2.9165e-02,
          1.8948e-02],
        [ 2.4964e-01, -1.8408e-01,  1.9907e-01, -1.5841e-01,  1.2778e-01,
         -3.1831e-01, -1.7764e-02, -2.7223e-01, -4.0943e-01,  7.3907e-02,
          1.9024e-01,  7.0698e-02,  1.0564e-01,  2.2217e-01,  1.4861e-01,
          3.0013e-01],
        [ 9.4314e-02, -2.5961e-02,  1.3137e-01,  3.8315e-02, -1.2917e-01,
         -2.9017e-01, -9.3102e-02, -4.3045e-01, -2.2421e-01, -3.5624e-01,
         -2.8193e-01,  1.8894e-01,  2.5261e-01,  3.3862e-01,  4.9077e-02,
          6.6267e-02],
        [ 2.3047e-01,  1.7295e-01,  3.0842e-01, -3.4834e-01, -3.1950e-02,
         -1.2239e-01, -3.8687e-01, -3.1905e-02, -3.6307e-01,  3.1298e-02,
          8.4840e-03,  8.6432e-02,  2.2179e-01,  2.8097e-01,  3.9385e-01,
          2.8158e-01],
        [-3.4167e-01, -1.1961e-03,  5.3930e-04,  2.1930e-01,  2.4050e-01,
          5.9288e-02,  4.0370e-01,  2.1865e-01, -4.0367e-02,  7.8006e-02,
          2.1025e-01, -3.0263e-01, -2.4557e-01, -1.7537e-01, -3.8905e-01,
         -8.5222e-02],
        [ 3.2178e-01,  1.1042e-01,  1.5156e-01, -1.3678e-01, -2.1632e-01,
         -3.2032e-01, -1.7769e-01, -3.8052e-01, -2.0868e-02, -8.8824e-02,
          9.5417e-03,  1.6134e-01,  3.4110e-01,  2.8968e-01,  3.3059e-01,
          2.5089e-01],
        [-2.8802e-01,  3.0394e-02, -3.3216e-01,  2.5887e-01, -2.1070e-01,
          1.8095e-01,  3.6834e-01,  3.2515e-01,  3.4902e-01,  2.1456e-01,
          1.8368e-01, -9.1789e-02,  2.4629e-02,  5.6760e-02, -1.3643e-01,
         -2.1679e-01],
        [-3.0350e-01, -1.4356e-01, -5.8914e-02,  2.7228e-02,  8.7500e-02,
          4.1896e-01,  4.1930e-01,  1.1262e-02,  2.2426e-01,  2.9923e-01,
         -1.9821e-01, -3.0628e-02, -3.1541e-01, -2.4749e-01, -3.3918e-01,
         -2.2947e-01],
        [ 8.9980e-02,  1.6948e-01,  2.8316e-01, -8.6900e-02,  1.4536e-01,
         -3.6630e-01, -4.6251e-01, -4.2207e-01, -3.1315e-01, -2.7253e-01,
          3.4819e-02,  2.1170e-02,  2.0110e-02,  2.5003e-01,  9.7304e-02,
          1.8634e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0764, -0.0798,  0.2070,  0.0005, -0.1311, -0.0838,  0.0952,  0.0838,
        -0.0054, -0.0916, -0.0488,  0.0287,  0.1553,  0.1227, -0.0370,  0.0065,
        -0.0999, -0.0029,  0.1384,  0.0331, -0.0551, -0.2007,  0.0057, -0.0317,
         0.0226,  0.2650,  0.1446, -0.0083, -0.0266, -0.1634, -0.0119,  0.0531],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2293,  0.3264, -0.2449, -0.2811,  0.3472,  0.3804, -0.2916, -0.3915,
         -0.3166,  0.3736,  0.2860,  0.4054, -0.2794, -0.3969,  0.3224, -0.2793,
         -0.3183,  0.3538, -0.2448, -0.2589,  0.4272,  0.3802, -0.3910, -0.3914,
         -0.3259, -0.3609, -0.3335,  0.3853, -0.3858,  0.3996,  0.3152, -0.2531]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0095,  0.0018,  0.0250,  ...,  0.2106, -0.3875, -0.1137],
        [-0.0794, -0.1838,  0.0813,  ...,  0.1477, -0.3540,  0.0871],
        [-0.0566,  0.1514,  0.0935,  ...,  0.0066,  0.2686,  0.0345],
        ...,
        [ 0.0437, -0.1506,  0.0115,  ...,  0.0696, -0.3182, -0.1180],
        [ 0.0296, -0.0791,  0.0112,  ..., -0.3095,  0.1519,  0.1557],
        [-0.0868,  0.1560,  0.0135,  ..., -0.1750,  0.1048, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0505,  0.0546, -0.0943, -0.1208, -0.0567,  0.0466, -0.1304,  0.0617,
        -0.0453,  0.0925,  0.0355,  0.0056,  0.0101,  0.0637, -0.0777, -0.0192,
         0.0455, -0.1420, -0.0332, -0.0147, -0.1084,  0.0513,  0.0815, -0.0068,
        -0.0856,  0.0670,  0.0248, -0.0951,  0.0637,  0.1474,  0.1324, -0.0660],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0234, -0.2062, -0.0719,  ..., -0.1561, -0.0043,  0.2734],
        [-0.2535, -0.0531,  0.1104,  ..., -0.0862,  0.0048,  0.2805],
        [ 0.1786, -0.0090, -0.1862,  ...,  0.0974, -0.0357, -0.0788],
        ...,
        [ 0.1660,  0.1211,  0.0728,  ...,  0.2792, -0.2357,  0.0461],
        [-0.0692, -0.1852,  0.0867,  ..., -0.0137,  0.2603,  0.0981],
        [-0.0326, -0.1302,  0.2187,  ...,  0.0357,  0.1512,  0.1405]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0907,  0.1266, -0.0376, -0.0577, -0.0319, -0.0372, -0.0339, -0.0629,
         0.1113, -0.1795,  0.1236, -0.1330,  0.1661, -0.0208, -0.1435,  0.1090,
        -0.1292, -0.1556,  0.0149, -0.0299,  0.0075,  0.1068, -0.1932,  0.2059,
        -0.0667, -0.0275,  0.0879, -0.0335, -0.1135, -0.0618,  0.1152,  0.0034],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.6140,  0.5384, -0.6192, -0.6198,  0.4661,  0.4756, -0.5221,  0.5325,
          0.5293, -0.5549, -0.5445,  0.5040,  0.5259, -0.4678,  0.5478,  0.4971,
         -0.6247, -0.6152,  0.4920,  0.5106, -0.5798, -0.5523, -0.6150,  0.4492,
          0.5901,  0.6148, -0.5904,  0.6592, -0.5254, -0.6067,  0.5934,  0.6058]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.3264], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.9827e-02,  3.1178e-01,  3.2018e-01, -3.4659e-01, -6.3407e-02,
         -1.8735e-01, -9.3675e-02, -4.4075e-01, -1.9327e-01, -6.0758e-02,
          3.3411e-02,  2.0217e-01,  9.5222e-02, -6.5404e-02,  3.6894e-01,
          3.3563e-01],
        [-2.9272e-01, -3.0143e-01, -1.3462e-01,  2.4329e-02, -1.2043e-01,
          3.0479e-01,  2.2196e-01,  2.2393e-01,  4.2686e-01,  1.2414e-01,
          2.1831e-01, -3.0668e-01, -4.3493e-02, -4.3145e-02, -5.9112e-02,
         -6.5651e-02],
        [ 9.7628e-02,  2.0680e-01,  3.9365e-01, -1.3154e-01,  1.0853e-01,
         -3.7436e-01, -8.3640e-02, -4.5234e-01,  4.6992e-02, -5.4194e-02,
         -8.7797e-02, -4.3156e-02,  4.2274e-01,  2.9387e-01,  4.7295e-01,
          2.3523e-01],
        [ 2.9478e-01,  2.5540e-02,  1.0094e-01, -8.9682e-02,  5.7280e-02,
         -2.3636e-01, -1.9133e-01, -1.4829e-01, -4.2654e-01, -3.7744e-01,
         -9.3543e-02,  3.9581e-01,  3.2156e-01, -1.4586e-01,  1.8249e-01,
          1.2906e-01],
        [-1.4131e-01,  1.6676e-01, -2.0045e-01,  1.3652e-02,  1.0851e-01,
          1.5392e-01,  1.0907e-01,  4.2173e-01,  2.0219e-01,  2.7963e-01,
          2.1609e-01, -2.4154e-01, -1.0948e-01, -2.2828e-01, -1.6153e-01,
         -1.1277e-01],
        [-3.9244e-02,  1.9067e-01, -3.8292e-01,  4.2720e-01,  2.1629e-01,
          2.9247e-02,  3.0618e-01,  4.6506e-02,  2.9689e-01,  1.9456e-01,
         -1.6083e-01, -1.5078e-01, -3.0681e-01,  1.3003e-01, -2.8550e-02,
         -4.7978e-02],
        [ 3.9989e-01,  1.6464e-01,  4.3182e-01, -2.0371e-01,  9.4478e-02,
         -2.5913e-01, -2.3485e-01, -2.8411e-01, -2.6608e-01, -9.8115e-03,
         -1.4040e-02,  9.0447e-02, -1.7059e-04,  2.1838e-01,  3.2847e-02,
          1.4008e-01],
        [-4.2496e-02,  2.8087e-01,  3.7170e-01, -3.6067e-01, -1.7795e-01,
         -3.3522e-01, -1.2531e-01, -2.8675e-01, -1.9166e-01, -1.9632e-01,
         -6.5394e-02,  4.2484e-02,  2.8316e-01, -9.6208e-02,  1.9408e-01,
          3.4544e-01],
        [ 7.5784e-02,  2.7037e-01,  3.3459e-01, -2.8126e-01, -7.3153e-03,
         -4.0293e-01, -2.1829e-01, -1.6491e-01,  1.7459e-02, -3.0440e-01,
         -1.1450e-01,  1.0918e-01, -4.1152e-02,  1.3367e-01,  7.7268e-02,
          7.9418e-02],
        [-3.2403e-01, -4.3573e-02, -1.2398e-01,  1.4624e-02,  5.8406e-03,
          2.1115e-01,  1.0188e-01,  3.1450e-01,  3.0434e-01, -1.9571e-02,
          2.2857e-01, -6.5259e-02, -3.0960e-01, -6.4893e-02, -2.5046e-01,
         -1.6726e-01],
        [-3.7074e-01,  1.1110e-01, -7.3736e-02, -3.0947e-02, -1.4181e-01,
          4.5802e-01,  2.6573e-01,  1.6102e-01,  3.4826e-01,  2.2466e-01,
          6.2346e-02, -1.3470e-02, -1.9247e-01,  1.4973e-01, -4.2992e-01,
         -3.0233e-01],
        [-1.5464e-01, -1.0638e-01, -4.4173e-02,  1.0720e-01,  1.5268e-01,
          1.6374e-01,  4.1904e-01,  2.1241e-01,  1.8801e-01,  3.2362e-01,
          1.4901e-01,  1.8713e-02, -4.3748e-01, -1.8074e-01, -3.1032e-01,
         -1.7364e-01],
        [ 3.8560e-01,  1.7494e-01,  2.0726e-01, -2.1366e-01,  2.9312e-02,
         -5.0904e-02, -1.5199e-01, -4.0161e-01, -3.7169e-01, -1.0307e-01,
         -1.1174e-01,  8.4985e-02,  2.3288e-02,  1.9322e-01,  2.4289e-01,
          6.9680e-03],
        [ 2.5530e-01,  3.2118e-01,  4.0679e-01, -4.7870e-02, -2.1837e-01,
         -8.4563e-02, -1.0646e-01, -1.4175e-01, -2.5166e-01, -1.6711e-01,
         -2.1381e-01,  1.6253e-01,  1.7801e-01,  7.3189e-02,  2.4667e-02,
          2.3785e-01],
        [-4.0245e-01, -2.6753e-01, -9.0343e-02, -2.5278e-02,  2.3893e-01,
          4.5423e-01,  1.4270e-01,  1.6567e-01, -2.1602e-02,  1.6801e-01,
          1.2378e-01, -3.4011e-01, -1.1967e-01, -1.0913e-01, -3.2659e-01,
         -1.4937e-01],
        [-5.5024e-02, -2.2226e-01,  1.8736e-01,  6.0298e-02, -2.7821e-01,
         -5.8918e-02, -1.9920e-01, -3.8778e-01, -2.3513e-01,  2.5937e-03,
          4.1562e-02,  5.1414e-01,  2.0497e-01, -7.3031e-02,  5.2706e-01,
         -3.1215e-03],
        [ 3.3388e-01,  2.2938e-01,  2.1357e-01, -3.6369e-01, -2.5569e-01,
         -7.6087e-02, -1.3905e-01, -5.8196e-02, -3.7906e-01, -1.6043e-01,
          1.5702e-01,  3.2269e-01,  3.8262e-01,  2.5734e-01,  1.6286e-01,
         -4.7773e-02],
        [-3.1546e-01,  1.5920e-02, -2.6137e-01,  1.5057e-01,  2.3367e-02,
          3.3876e-01,  3.2721e-01,  3.1813e-01,  1.4626e-01,  2.6432e-01,
         -4.6720e-02, -2.7019e-01, -1.9675e-01, -2.0565e-01,  1.0960e-02,
         -1.6267e-01],
        [ 2.4712e-01,  9.0595e-02,  1.6544e-01, -3.0146e-01, -3.9398e-02,
         -4.0943e-01, -3.2516e-01, -8.8556e-03, -3.9365e-01, -1.0615e-01,
         -3.6496e-02, -6.2022e-02,  2.2077e-01,  2.3817e-01,  4.0683e-01,
          1.7707e-01],
        [ 3.9351e-01,  1.0299e-01,  2.8833e-01, -1.0354e-01, -1.9950e-01,
         -2.6928e-01, -3.9545e-01, -4.9055e-03, -4.3084e-02, -2.5701e-01,
         -6.7347e-02,  2.6496e-01, -4.8564e-02,  9.4989e-02,  3.7186e-01,
          1.8298e-01],
        [-2.1926e-01,  1.1971e-01, -7.5968e-02, -3.5163e-02,  2.0413e-01,
          2.5205e-02,  3.5959e-01,  4.5744e-01,  2.3544e-01,  6.6149e-02,
         -8.9573e-02, -3.5385e-01, -2.6250e-01, -2.1325e-01, -1.8265e-02,
         -2.3403e-01],
        [-9.1689e-02, -3.0528e-01, -6.2280e-02,  3.9466e-01, -1.1746e-01,
          1.5093e-01,  2.7948e-01, -2.3547e-02,  2.3125e-02,  2.3780e-01,
          2.5023e-01, -2.8280e-01, -1.8440e-01, -3.2727e-01, -4.9965e-01,
          8.0094e-02],
        [ 3.7588e-01,  4.0051e-04,  6.2065e-02, -1.6351e-01,  1.3142e-01,
         -4.2157e-01, -3.2236e-01, -2.4339e-01, -2.3557e-01, -1.3088e-01,
          1.2231e-01,  2.1514e-01, -8.7743e-02,  2.9602e-01,  4.0888e-01,
          2.0560e-01],
        [ 2.7097e-01,  1.6669e-01,  3.5127e-01, -3.7326e-01, -1.1738e-01,
         -1.9675e-01, -2.1149e-01, -3.0335e-01, -3.4862e-01, -3.0060e-01,
         -9.6594e-02,  3.5210e-01,  2.7854e-01,  1.2819e-01,  2.9225e-02,
          1.8876e-02],
        [ 2.4962e-01, -1.8421e-01,  1.9900e-01, -1.5836e-01,  1.2766e-01,
         -3.1832e-01, -1.7768e-02, -2.7235e-01, -4.0946e-01,  7.3996e-02,
          1.9029e-01,  7.0776e-02,  1.0574e-01,  2.2210e-01,  1.4869e-01,
          3.0002e-01],
        [ 9.4302e-02, -2.6078e-02,  1.3130e-01,  3.8356e-02, -1.2927e-01,
         -2.9017e-01, -9.3103e-02, -4.3055e-01, -2.2423e-01, -3.5616e-01,
         -2.8189e-01,  1.8901e-01,  2.5270e-01,  3.3856e-01,  4.9145e-02,
          6.6174e-02],
        [ 2.3046e-01,  1.7284e-01,  3.0837e-01, -3.4830e-01, -3.2031e-02,
         -1.2239e-01, -3.8687e-01, -3.1987e-02, -3.6308e-01,  3.1367e-02,
          8.5064e-03,  8.6485e-02,  2.2189e-01,  2.8092e-01,  3.9391e-01,
          2.8150e-01],
        [-3.4166e-01, -1.0745e-03,  6.0484e-04,  2.1926e-01,  2.4060e-01,
          5.9291e-02,  4.0370e-01,  2.1875e-01, -4.0351e-02,  7.7928e-02,
          2.1022e-01, -3.0269e-01, -2.4567e-01, -1.7531e-01, -3.8912e-01,
         -8.5125e-02],
        [ 3.2177e-01,  1.1031e-01,  1.5150e-01, -1.3675e-01, -2.1641e-01,
         -3.2032e-01, -1.7769e-01, -3.8061e-01, -2.0883e-02, -8.8755e-02,
          9.5688e-03,  1.6140e-01,  3.4120e-01,  2.8963e-01,  3.3066e-01,
          2.5080e-01],
        [-2.8801e-01,  3.0497e-02, -3.3211e-01,  2.5884e-01, -2.1062e-01,
          1.8095e-01,  3.6835e-01,  3.2523e-01,  3.4903e-01,  2.1449e-01,
          1.8366e-01, -9.1837e-02,  2.4543e-02,  5.6807e-02, -1.3648e-01,
         -2.1671e-01],
        [-3.0349e-01, -1.4344e-01, -5.8854e-02,  2.7188e-02,  8.7589e-02,
          4.1896e-01,  4.1931e-01,  1.1354e-02,  2.2428e-01,  2.9915e-01,
         -1.9823e-01, -3.0687e-02, -3.1551e-01, -2.4743e-01, -3.3925e-01,
         -2.2938e-01],
        [ 8.9967e-02,  1.6936e-01,  2.8309e-01, -8.6854e-02,  1.4527e-01,
         -3.6631e-01, -4.6252e-01, -4.2216e-01, -3.1317e-01, -2.7245e-01,
          3.4845e-02,  2.1228e-02,  2.0210e-02,  2.4997e-01,  9.7379e-02,
          1.8625e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0764, -0.0798,  0.2070,  0.0004, -0.1310, -0.0838,  0.0951,  0.0838,
        -0.0055, -0.0916, -0.0488,  0.0288,  0.1553,  0.1227, -0.0369,  0.0062,
        -0.0999, -0.0029,  0.1384,  0.0330, -0.0550, -0.2007,  0.0057, -0.0317,
         0.0226,  0.2650,  0.1446, -0.0083, -0.0267, -0.1633, -0.0118,  0.0531],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2293,  0.3263, -0.2449, -0.2811,  0.3472,  0.3804, -0.2916, -0.3915,
         -0.3166,  0.3736,  0.2860,  0.4054, -0.2794, -0.3969,  0.3224, -0.2794,
         -0.3183,  0.3538, -0.2448, -0.2589,  0.4273,  0.3802, -0.3910, -0.3914,
         -0.3259, -0.3609, -0.3335,  0.3854, -0.3858,  0.3996,  0.3152, -0.2530]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0095,  0.0018,  0.0250,  ...,  0.2106, -0.3875, -0.1137],
        [-0.0794, -0.1838,  0.0813,  ...,  0.1477, -0.3540,  0.0871],
        [-0.0566,  0.1514,  0.0935,  ...,  0.0066,  0.2686,  0.0345],
        ...,
        [ 0.0437, -0.1506,  0.0115,  ...,  0.0696, -0.3182, -0.1180],
        [ 0.0296, -0.0791,  0.0112,  ..., -0.3095,  0.1519,  0.1557],
        [-0.0868,  0.1560,  0.0135,  ..., -0.1750,  0.1048, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0505,  0.0546, -0.0943, -0.1208, -0.0567,  0.0466, -0.1304,  0.0617,
        -0.0453,  0.0925,  0.0355,  0.0056,  0.0101,  0.0637, -0.0777, -0.0192,
         0.0455, -0.1420, -0.0332, -0.0147, -0.1084,  0.0513,  0.0815, -0.0068,
        -0.0856,  0.0670,  0.0248, -0.0951,  0.0637,  0.1474,  0.1324, -0.0660],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0234, -0.2062, -0.0719,  ..., -0.1561, -0.0043,  0.2734],
        [-0.2535, -0.0531,  0.1104,  ..., -0.0862,  0.0049,  0.2805],
        [ 0.1786, -0.0090, -0.1862,  ...,  0.0974, -0.0357, -0.0788],
        ...,
        [ 0.1660,  0.1211,  0.0728,  ...,  0.2792, -0.2357,  0.0461],
        [-0.0692, -0.1852,  0.0867,  ..., -0.0137,  0.2603,  0.0981],
        [-0.0326, -0.1302,  0.2187,  ...,  0.0357,  0.1512,  0.1405]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0907,  0.1266, -0.0376, -0.0577, -0.0319, -0.0372, -0.0339, -0.0629,
         0.1113, -0.1795,  0.1236, -0.1330,  0.1661, -0.0208, -0.1435,  0.1090,
        -0.1292, -0.1556,  0.0149, -0.0299,  0.0075,  0.1068, -0.1932,  0.2059,
        -0.0667, -0.0275,  0.0879, -0.0335, -0.1135, -0.0618,  0.1152,  0.0034],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.6140,  0.5384, -0.6192, -0.6198,  0.4661,  0.4756, -0.5221,  0.5325,
          0.5293, -0.5549, -0.5445,  0.5040,  0.5259, -0.4678,  0.5478,  0.4971,
         -0.6247, -0.6152,  0.4920,  0.5106, -0.5798, -0.5523, -0.6150,  0.4492,
          0.5901,  0.6148, -0.5904,  0.6592, -0.5254, -0.6067,  0.5934,  0.6058]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.3264], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-2.3266e-02,  2.9688e-01,  2.8789e-01, -2.7004e-01, -4.1714e-01,
         -2.1336e-01, -8.4271e-02, -5.3111e-01, -2.9229e-01, -5.9121e-02,
          1.1271e-02,  2.8086e-01,  1.3605e-01, -6.7764e-02,  1.1748e-01,
          3.2510e-01],
        [-2.4126e-01, -2.8536e-01, -9.4312e-02, -4.4003e-02,  1.5103e-01,
          2.9564e-01,  1.9451e-01,  2.7072e-01,  4.8732e-01,  1.3444e-01,
          2.5246e-01, -3.3992e-01, -4.9187e-02, -5.0092e-02,  1.7988e-01,
         -5.3447e-02],
        [ 5.7313e-02,  1.8688e-01,  3.5961e-01, -6.7042e-02, -2.6965e-01,
         -3.8626e-01, -7.0056e-02, -5.4260e-01, -6.0096e-02, -5.5182e-02,
         -1.0107e-01,  1.8595e-02,  4.5597e-01,  3.2497e-01,  2.3943e-01,
          2.2385e-01],
        [ 2.5603e-01,  1.6760e-02,  7.1162e-02, -3.1274e-02, -2.3841e-01,
         -2.4350e-01, -1.7916e-01, -2.1774e-01, -5.1918e-01, -4.0010e-01,
         -8.2337e-02,  4.4941e-01,  3.3041e-01, -1.1111e-01, -4.2231e-02,
          1.2374e-01],
        [-7.6695e-02,  1.4550e-01, -1.5480e-01, -7.0975e-02,  3.5310e-01,
          1.3515e-01,  7.0890e-02,  4.4682e-01,  2.4012e-01,  2.9201e-01,
          2.8222e-01, -2.4472e-01, -1.0410e-01, -2.4072e-01,  1.0601e-01,
         -1.2132e-01],
        [ 4.0105e-03,  1.7974e-01, -3.5240e-01,  3.6606e-01,  5.2584e-01,
          2.5908e-02,  2.9517e-01,  8.8311e-02,  3.4903e-01,  2.1521e-01,
         -1.2517e-01, -1.6851e-01, -3.0240e-01,  1.1914e-01,  2.3112e-01,
         -5.2667e-02],
        [ 3.6308e-01,  6.5882e-02,  4.0258e-01, -1.5356e-01, -2.2895e-01,
         -2.6042e-01, -2.1014e-01, -3.5044e-01, -3.5068e-01, -2.8968e-02,
         -2.5101e-02,  1.4223e-01, -1.4487e-02,  2.3943e-01, -1.0566e-01,
          1.3253e-01],
        [-7.2764e-02,  2.2026e-01,  3.4748e-01, -3.2284e-01, -4.8186e-01,
         -3.3210e-01, -1.0585e-01, -3.5043e-01, -2.6881e-01, -2.1364e-01,
         -7.2383e-02,  8.9945e-02,  2.8231e-01, -7.9281e-02,  8.1006e-02,
          3.3626e-01],
        [ 3.6590e-02,  2.6087e-01,  3.0744e-01, -2.1791e-01, -2.2041e-01,
         -4.0454e-01, -2.0711e-01, -2.1692e-01, -5.3764e-02, -3.2883e-01,
         -2.3430e-01,  1.4243e-01, -6.1853e-04,  1.8907e-01, -1.7654e-01,
          7.9145e-02],
        [-2.7657e-01, -4.8985e-02, -9.0092e-02, -5.2343e-02,  2.6432e-01,
          2.1225e-01,  8.6368e-02,  3.6661e-01,  3.7123e-01,  2.4620e-03,
          2.9521e-01, -9.3761e-02, -3.3304e-01, -9.3390e-02,  9.7919e-03,
         -1.7115e-01],
        [-3.4456e-01,  1.0283e-01, -5.5689e-02, -7.1728e-02,  1.4886e-01,
          4.8082e-01,  2.6491e-01,  2.4971e-01,  4.5255e-01,  2.5830e-01,
          9.6761e-02, -8.3360e-02, -2.1348e-01,  1.0313e-01, -1.6325e-01,
         -3.0665e-01],
        [-1.1800e-01, -1.1237e-01, -2.0363e-02,  5.6901e-02,  3.3799e-01,
          1.7201e-01,  4.0171e-01,  2.6743e-01,  2.5804e-01,  3.5701e-01,
          2.1304e-01, -1.9293e-02, -4.3376e-01, -2.5386e-01, -9.2867e-02,
         -1.8275e-01],
        [ 3.1530e-01,  1.8155e-01,  1.5170e-01, -1.2486e-01, -3.4904e-01,
         -4.9642e-02, -1.2878e-01, -4.9831e-01, -4.4803e-01, -1.1023e-01,
         -1.2324e-01,  1.4345e-01,  2.1344e-02,  1.8122e-01, -7.8898e-02,
         -3.2654e-03],
        [ 2.0482e-01,  2.8715e-01,  3.6699e-01,  1.4884e-02, -4.6884e-01,
         -6.7869e-02, -7.2382e-02, -1.7305e-01, -3.0048e-01, -1.7359e-01,
         -2.4223e-01,  1.8225e-01,  1.7191e-01,  7.9631e-02, -1.7319e-01,
          2.2319e-01],
        [-3.6303e-01, -2.4471e-01, -5.8511e-02, -7.8844e-02,  5.3824e-01,
          4.5325e-01,  1.2382e-01,  2.2827e-01,  5.5119e-02,  1.8321e-01,
          1.5061e-01, -3.8558e-01, -1.3249e-01, -1.2608e-01, -1.3359e-01,
         -1.3908e-01],
        [-1.0984e-01, -1.4876e-01,  1.6579e-01,  1.5034e-01, -5.5894e-01,
         -9.5240e-02, -2.2743e-01, -4.9229e-01, -3.3153e-01, -5.0189e-02,
         -8.1430e-02,  5.1757e-01,  2.3907e-01, -2.2113e-02,  2.3582e-01,
          1.9477e-02],
        [ 3.0699e-01,  2.2046e-01,  1.9512e-01, -3.2259e-01, -5.2799e-01,
         -8.5781e-02, -1.3089e-01, -1.0885e-01, -4.5921e-01, -1.9425e-01,
          1.3438e-01,  3.6790e-01,  4.1150e-01,  3.0375e-01,  7.9642e-03,
         -4.4012e-02],
        [-2.8445e-01,  3.9198e-02, -2.3716e-01,  1.1098e-01,  2.8744e-01,
          3.3559e-01,  3.0526e-01,  3.6610e-01,  2.1920e-01,  2.8469e-01,
         -3.4167e-02, -3.0940e-01, -1.9711e-01, -2.3749e-01,  1.3114e-01,
         -1.5750e-01],
        [ 1.9197e-01,  5.3269e-02,  1.1589e-01, -2.2180e-01, -4.1137e-01,
         -4.1384e-01, -3.0389e-01, -9.8650e-02, -5.0780e-01, -9.0588e-02,
         -6.7219e-02, -2.2922e-03,  2.8031e-01,  2.7256e-01,  1.9675e-01,
          1.4309e-01],
        [ 3.6141e-01,  8.1074e-02,  2.6335e-01, -5.3661e-02, -4.9480e-01,
         -2.8165e-01, -3.8613e-01, -9.1209e-02, -1.4396e-01, -2.7981e-01,
         -1.1286e-01,  3.3180e-01, -1.0846e-02,  1.2504e-01,  1.8800e-01,
          1.7478e-01],
        [-1.6648e-01,  1.0646e-01, -3.7121e-02, -1.0390e-01,  4.3628e-01,
          1.0100e-03,  3.2737e-01,  4.6003e-01,  2.5186e-01,  7.0987e-02,
         -4.5540e-02, -3.3788e-01, -2.3517e-01, -2.1173e-01,  2.1958e-01,
         -2.3310e-01],
        [-6.9300e-02, -2.8449e-01, -4.7689e-02,  3.5024e-01,  1.5652e-01,
          1.7525e-01,  2.9639e-01,  6.4540e-02,  1.2497e-01,  2.7734e-01,
          3.5675e-01, -3.4469e-01, -2.6008e-01, -3.8633e-01, -2.5274e-01,
          7.2919e-02],
        [ 3.5944e-01, -1.3167e-02,  5.0857e-02, -1.3646e-01, -1.5486e-01,
         -4.3961e-01, -3.2453e-01, -3.2342e-01, -3.3501e-01, -1.6389e-01,
          9.6976e-02,  2.8068e-01, -4.5080e-02,  3.3806e-01,  2.6407e-01,
          2.0736e-01],
        [ 2.4741e-01,  1.5943e-01,  3.3389e-01, -3.4377e-01, -3.7007e-01,
         -1.9677e-01, -1.9703e-01, -3.6323e-01, -4.2901e-01, -3.2382e-01,
         -6.5684e-02,  4.0054e-01,  2.7855e-01,  1.5735e-01, -8.1132e-02,
          1.1438e-02],
        [ 2.0456e-01, -1.6700e-01,  1.6944e-01, -8.7178e-02, -1.3074e-01,
         -3.2353e-01, -2.8018e-03, -3.0822e-01, -4.7844e-01,  4.0576e-02,
          1.0627e-01,  9.7977e-02,  1.3534e-01,  2.6531e-01, -1.4960e-01,
          3.1928e-01],
        [ 2.5536e-02, -2.6048e-02,  7.5988e-02,  1.1920e-01, -3.9042e-01,
         -2.5148e-01, -3.9484e-02, -4.3324e-01, -2.3857e-01, -3.5022e-01,
         -3.2102e-01,  1.7602e-01,  2.1741e-01,  3.2365e-01, -1.9732e-01,
          5.5713e-02],
        [ 2.1164e-01,  1.4743e-01,  2.9463e-01, -3.1969e-01, -3.2905e-01,
         -1.3862e-01, -3.8487e-01, -1.1488e-01, -4.6486e-01,  1.6487e-03,
         -7.6355e-03,  1.5314e-01,  2.6090e-01,  3.1371e-01,  2.7259e-01,
          2.7938e-01],
        [-3.0560e-01,  5.0244e-05,  2.5792e-02,  1.6795e-01,  4.8338e-01,
          7.2174e-02,  3.9512e-01,  2.8931e-01,  3.8475e-02,  1.0786e-01,
          2.5623e-01, -3.5099e-01, -2.6932e-01, -2.1479e-01, -1.8098e-01,
         -8.9032e-02],
        [ 2.9549e-01,  1.1989e-01,  1.3230e-01, -1.0218e-01, -4.5752e-01,
         -3.2960e-01, -1.6951e-01, -4.4218e-01, -1.0111e-01, -1.1541e-01,
          3.0765e-02,  2.1303e-01,  3.3509e-01,  3.3019e-01,  1.4573e-01,
          2.4996e-01],
        [-2.6442e-01,  6.7386e-02, -3.1383e-01,  2.2683e-01,  7.3163e-02,
          1.8483e-01,  3.5790e-01,  3.9413e-01,  4.3207e-01,  2.3679e-01,
          2.0814e-01, -1.4428e-01,  1.0010e-02,  3.1855e-02, -1.7955e-02,
         -2.1341e-01],
        [-2.7606e-01, -1.3396e-01, -3.8689e-02, -1.2907e-02,  3.6300e-01,
          4.3222e-01,  4.0884e-01,  8.0638e-02,  3.1773e-01,  3.2830e-01,
         -1.6501e-01, -8.8337e-02, -3.5316e-01, -2.9212e-01, -1.6521e-01,
         -2.2830e-01],
        [ 4.2390e-02,  1.2159e-01,  2.4323e-01, -1.1650e-02, -1.6774e-01,
         -3.6644e-01, -4.3122e-01, -4.9175e-01, -4.0843e-01, -2.6970e-01,
          3.3125e-03,  7.1690e-02,  3.5293e-02,  2.8331e-01, -8.3874e-02,
          1.6786e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-3.4268e-02, -2.7464e-02,  1.3232e-01, -2.6061e-02, -9.4811e-02,
        -1.3115e-01,  8.4924e-02,  9.9827e-02, -1.2708e-02, -9.4132e-02,
        -3.2865e-02,  4.4630e-02,  1.7798e-01,  9.5245e-02,  1.4943e-04,
        -1.8003e-02, -4.5812e-02, -4.5075e-03,  1.1523e-01,  1.8898e-02,
        -7.5099e-02, -1.6397e-01, -1.1530e-02, -1.0277e-02,  3.2898e-02,
         1.9127e-01,  1.3661e-01, -1.1924e-02, -5.6004e-02, -1.5976e-01,
         1.7453e-02, -4.0765e-02], device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2719,  0.3560, -0.2609, -0.2983,  0.3755,  0.4172, -0.3067, -0.4120,
         -0.3375,  0.3998,  0.3020,  0.4096, -0.3131, -0.4272,  0.3398, -0.3998,
         -0.3528,  0.3559, -0.2643, -0.2773,  0.4531,  0.3448, -0.4004, -0.4000,
         -0.3838, -0.3848, -0.3381,  0.3972, -0.3904,  0.4058,  0.3199, -0.2644]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0068, -0.0056,  0.0452,  ...,  0.2364, -0.3847, -0.1137],
        [-0.0804, -0.1896,  0.0903,  ...,  0.1468, -0.3690,  0.0871],
        [-0.0458,  0.1741,  0.0706,  ..., -0.0053,  0.2973,  0.0345],
        ...,
        [ 0.0320, -0.1883,  0.0443,  ...,  0.0666, -0.3225, -0.1180],
        [ 0.0435, -0.0531, -0.0202,  ..., -0.3058,  0.1748,  0.1557],
        [-0.2010,  0.0500,  0.0060,  ...,  0.0399, -0.2736, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0557,  0.0549, -0.0859, -0.1214, -0.0599,  0.0542, -0.1259,  0.0588,
        -0.0477,  0.0814,  0.0294,  0.0116,  0.0276,  0.0751, -0.0761, -0.0177,
         0.0464, -0.1515, -0.0315, -0.0253, -0.0735,  0.0501,  0.0903, -0.0048,
        -0.0885,  0.0884,  0.0328, -0.0876,  0.0478,  0.1372,  0.1479, -0.1088],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0316, -0.1891, -0.0856,  ..., -0.1068, -0.0267,  0.0755],
        [-0.2502, -0.0436,  0.1104,  ..., -0.0386, -0.0050,  0.0633],
        [ 0.1740, -0.0275, -0.1746,  ...,  0.0460, -0.0109,  0.1659],
        ...,
        [ 0.1508,  0.0944,  0.0965,  ...,  0.2171, -0.1996,  0.2370],
        [-0.0702, -0.1686,  0.0788,  ...,  0.0396,  0.2406, -0.1667],
        [-0.0338, -0.1222,  0.2078,  ...,  0.0819,  0.1336, -0.0258]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0867,  0.1248, -0.0279, -0.0608, -0.0319, -0.0635, -0.0294, -0.0598,
         0.0980, -0.1408,  0.1367, -0.1256,  0.1547,  0.0605, -0.1341,  0.0920,
        -0.1215, -0.1504,  0.0048, -0.0129,  0.0040,  0.1072, -0.1882,  0.1777,
        -0.0625, -0.0295,  0.0882, -0.0410, -0.1124, -0.0566,  0.1013,  0.0053],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.6605,  0.5844, -0.6603, -0.6619,  0.5280,  0.5196, -0.5748,  0.5685,
          0.5922, -0.6004, -0.5534,  0.5524,  0.5509,  0.5630,  0.5899,  0.5480,
         -0.6607, -0.6659,  0.5281,  0.5554, -0.6167, -0.5940, -0.6625,  0.5213,
          0.6461,  0.6663, -0.6441,  0.6938, -0.5733, -0.6566,  0.6416,  0.6595]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.3689], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 5.7942e-03, -4.1087e-02,  2.5521e-01, -2.9171e-01, -3.4099e-01,
         -1.0876e-01, -4.3895e-02, -4.8296e-01, -2.6717e-01, -1.0605e-02,
          1.6533e-01,  1.6892e-01,  6.2246e-03, -1.0429e-01, -2.2312e-01,
          3.0934e-01],
        [-2.6727e-01,  1.5541e-02, -8.2528e-02, -5.8387e-03,  8.1083e-02,
          2.2565e-01,  1.5640e-01,  2.2910e-01,  4.8819e-01,  1.1275e-01,
          9.4995e-02, -2.6510e-01,  2.1257e-02, -2.8666e-02,  5.0167e-01,
         -4.8237e-02],
        [ 7.4832e-02, -9.5606e-02,  3.4161e-01, -9.9398e-02, -1.8603e-01,
         -3.1996e-01, -4.4821e-02, -4.8100e-01, -5.1127e-03, -3.9292e-02,
         -6.1145e-02, -7.5582e-02,  3.8020e-01,  3.0366e-01, -9.8051e-02,
          2.3361e-01],
        [ 2.7639e-01, -1.2743e-01,  4.7715e-02, -5.5931e-02, -1.4167e-01,
         -1.4998e-01, -1.1618e-01, -1.5546e-01, -5.0535e-01, -3.5725e-01,
          4.6852e-03,  3.4850e-01,  2.5100e-01, -1.5604e-01, -3.2835e-01,
          9.9551e-02],
        [-8.8564e-02,  4.4381e-01, -1.3017e-01, -3.7880e-02,  2.6178e-01,
          4.9672e-02,  2.4955e-02,  3.7606e-01,  1.9985e-01,  2.6591e-01,
          6.0775e-02, -1.3885e-01, -9.2540e-03, -2.0980e-01,  4.0340e-01,
         -1.1593e-01],
        [ 7.1713e-03,  3.9678e-01, -3.2396e-01,  3.8802e-01,  4.0293e-01,
         -6.8930e-02,  2.4200e-01,  5.8216e-03,  2.9154e-01,  1.8538e-01,
         -1.1880e-01, -6.5708e-02, -1.9700e-01,  1.4222e-01,  4.7366e-01,
         -4.5931e-02],
        [ 3.6639e-01, -7.7619e-02,  3.7217e-01, -1.7027e-01, -1.3597e-01,
         -1.7552e-01, -1.5166e-01, -2.8566e-01, -3.1089e-01,  7.2153e-03,
         -8.9222e-03,  4.5689e-02, -1.0201e-01,  1.4603e-01, -3.8251e-01,
          1.1199e-01],
        [-7.3539e-02,  7.1182e-02,  3.2530e-01, -3.4405e-01, -4.0663e-01,
         -2.7412e-01, -7.5525e-02, -3.0522e-01, -2.3283e-01, -1.9819e-01,
         -4.4435e-02,  1.8038e-02,  2.2843e-01, -1.1760e-01, -1.6258e-01,
          3.3062e-01],
        [ 4.8776e-02, -8.8875e-02,  2.8420e-01, -2.5230e-01, -1.6985e-01,
         -3.3748e-01, -1.7131e-01, -1.8300e-01, -3.0681e-02, -3.0355e-01,
          2.4607e-02,  6.4240e-02, -6.0942e-02,  1.6548e-01, -4.8601e-01,
          7.7317e-02],
        [-3.0276e-01,  2.6788e-01, -8.2336e-02, -6.3455e-03,  1.8338e-01,
          1.3923e-01,  4.8462e-02,  3.0880e-01,  3.4880e-01, -1.1816e-02,
          1.2275e-01, -1.3339e-02, -2.5222e-01, -8.3944e-02,  3.2023e-01,
         -1.7830e-01],
        [-3.6164e-01,  3.0512e-01, -3.3576e-02, -4.3191e-02,  6.6171e-02,
          3.9886e-01,  2.2100e-01,  1.9348e-01,  4.2937e-01,  2.2717e-01,
          8.7892e-03,  1.0307e-02, -1.7897e-01,  1.1610e-01,  1.3108e-01,
         -2.9708e-01],
        [-1.2417e-01,  1.1509e-01,  6.3761e-03,  8.5564e-02,  2.5462e-01,
          1.0376e-01,  3.4687e-01,  2.0660e-01,  2.1303e-01,  3.2427e-01,
          7.3153e-02,  7.3386e-02, -4.0546e-01, -2.1009e-01,  1.7431e-01,
         -1.7411e-01],
        [ 3.3682e-01, -1.1247e-01,  1.1894e-01, -1.5370e-01, -2.3817e-01,
          6.9552e-02, -6.8334e-02, -4.1161e-01, -4.2184e-01, -6.6588e-02,
         -1.1355e-01,  1.8059e-02, -8.5317e-02,  1.5245e-01, -4.3198e-01,
         -2.0419e-02],
        [ 2.1460e-01,  2.2555e-02,  3.4811e-01, -1.3718e-02, -3.9392e-01,
         -6.1783e-03, -3.0682e-02, -1.2696e-01, -2.8200e-01, -1.5152e-01,
         -1.1416e-01,  1.0951e-01,  1.1030e-01,  4.0626e-02, -4.6576e-01,
          2.1571e-01],
        [-3.7916e-01,  3.1146e-02, -4.3461e-02, -4.3660e-02,  4.7177e-01,
          3.9447e-01,  9.6804e-02,  1.8716e-01,  3.3022e-02,  1.6977e-01,
          2.8163e-02, -3.0941e-01, -8.1508e-02, -1.1023e-01,  1.9116e-01,
         -1.4021e-01],
        [-6.5710e-02, -5.4059e-01,  1.2582e-01,  9.9386e-02, -5.0866e-01,
          4.8004e-02, -1.6924e-01, -4.3108e-01, -3.2293e-01,  9.0107e-04,
         -4.5835e-02,  3.7970e-01,  8.3811e-02, -9.8414e-02, -1.3819e-01,
          1.9619e-02],
        [ 3.1924e-01,  3.6114e-02,  1.7105e-01, -3.4174e-01, -4.1487e-01,
         -5.3715e-03, -6.3958e-02, -5.0994e-02, -4.4923e-01, -1.5308e-01,
          1.7281e-01,  2.8056e-01,  3.1655e-01,  2.2708e-01, -2.3515e-01,
         -6.8904e-02],
        [-2.6953e-01,  1.6829e-01, -1.9718e-01,  1.1410e-01,  1.5529e-01,
          2.5072e-01,  2.4368e-01,  2.8596e-01,  1.5727e-01,  2.4341e-01,
         -5.8763e-02, -2.0196e-01, -1.0120e-01, -1.5452e-01,  2.8919e-01,
         -1.3000e-01],
        [ 2.2553e-01, -1.8276e-01,  1.0726e-01, -2.5902e-01, -2.8887e-01,
         -3.4527e-01, -2.5842e-01, -3.6103e-02, -4.6378e-01, -7.1311e-02,
          2.4840e-02, -9.8120e-02,  1.6499e-01,  2.1107e-01, -1.0969e-01,
          1.5067e-01],
        [ 3.6641e-01, -1.6215e-01,  2.2792e-01, -7.4794e-02, -4.2027e-01,
         -2.0841e-01, -3.4036e-01, -4.3655e-02, -1.0780e-01, -2.4429e-01,
          1.0853e-01,  2.3079e-01, -6.5892e-02,  7.5312e-02, -1.4321e-01,
          1.5886e-01],
        [-1.5949e-01,  3.1015e-01, -7.4325e-03, -8.6641e-02,  3.1406e-01,
         -7.7501e-02,  2.8159e-01,  3.7766e-01,  1.9566e-01,  4.4916e-02,
         -1.1636e-01, -2.3848e-01, -1.5082e-01, -1.7299e-01,  4.1512e-01,
         -2.2071e-01],
        [-1.0490e-01,  1.4289e-01, -3.9139e-02,  4.0053e-01,  1.3652e-01,
          1.2458e-01,  2.7776e-01,  6.0334e-02,  1.3440e-01,  2.6867e-01,
          1.9567e-01, -2.9786e-01, -2.2404e-01, -3.7913e-01,  8.3207e-02,
          6.2351e-02],
        [ 3.6417e-01, -2.2677e-01,  2.6468e-02, -1.5976e-01, -7.4644e-02,
         -3.7846e-01, -2.8283e-01, -2.8014e-01, -3.0572e-01, -1.4063e-01,
          2.1239e-01,  2.0443e-01, -9.3133e-02,  2.9186e-01, -2.1661e-03,
          1.9522e-01],
        [ 2.4163e-01,  8.0371e-02,  2.9830e-01, -3.4334e-01, -2.2213e-01,
         -1.1554e-01, -1.2405e-01, -2.9577e-01, -4.0410e-01, -2.7253e-01,
         -5.2171e-04,  3.0930e-01,  2.1153e-01,  7.0446e-02, -2.3005e-01,
         -3.1193e-02],
        [ 2.2125e-01, -4.6106e-01,  1.5338e-01, -1.2831e-01, -3.0540e-02,
         -2.3145e-01,  5.4201e-02, -2.3042e-01, -4.3317e-01,  6.7449e-02,
          1.7467e-01,  2.8069e-04,  3.1232e-02,  2.4576e-01, -4.4934e-01,
          3.1956e-01],
        [ 2.5987e-02, -2.6635e-01,  5.1410e-02,  9.4773e-02, -2.8169e-01,
         -1.8014e-01, -1.1582e-02, -3.5971e-01, -1.8685e-01, -3.3289e-01,
         -2.4831e-01,  8.0449e-02,  1.5212e-01,  3.0748e-01, -4.7175e-01,
          5.1713e-02],
        [ 2.1126e-01, -8.9313e-02,  2.6069e-01, -3.3491e-01, -2.4590e-01,
         -7.7853e-02, -3.3585e-01, -7.1342e-02, -4.2407e-01,  3.0786e-02,
          6.2366e-02,  6.7741e-02,  2.1083e-01,  2.3407e-01,  3.4571e-03,
          2.6059e-01],
        [-3.2473e-01,  2.7188e-01,  4.4121e-02,  2.0513e-01,  4.0693e-01,
          6.4092e-03,  3.5111e-01,  2.3640e-01,  5.3560e-03,  8.5818e-02,
          6.0574e-02, -2.6283e-01, -2.1198e-01, -1.7897e-01,  1.1371e-01,
         -8.8575e-02],
        [ 2.9128e-01, -2.0625e-02,  9.9783e-02, -1.1754e-01, -3.5115e-01,
         -2.5958e-01, -1.2114e-01, -3.7704e-01, -5.5651e-02, -8.1181e-02,
          1.1978e-01,  1.1633e-01,  3.2526e-01,  2.8838e-01, -6.8054e-02,
          2.2991e-01],
        [-2.5960e-01,  2.1837e-01, -2.8437e-01,  2.4039e-01, -1.6617e-02,
          1.1847e-01,  3.1121e-01,  3.3883e-01,  3.9336e-01,  2.0952e-01,
          1.4307e-01, -6.3467e-02,  7.8500e-02,  8.6101e-02,  2.1989e-01,
         -1.9588e-01],
        [-2.7661e-01,  9.8527e-02, -6.2946e-03,  5.7995e-03,  2.7375e-01,
          3.5758e-01,  3.6059e-01,  2.8001e-02,  2.7476e-01,  2.9545e-01,
         -2.4854e-01,  9.9484e-03, -2.8842e-01, -2.4406e-01,  1.1629e-01,
         -2.1355e-01],
        [ 4.4389e-02, -9.4958e-02,  2.0597e-01, -2.8793e-02, -6.6414e-02,
         -2.7563e-01, -3.6723e-01, -4.0531e-01, -3.4901e-01, -2.2503e-01,
          1.0033e-01, -5.2677e-02, -8.4489e-02,  1.7827e-01, -3.6065e-01,
          1.4807e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0847, -0.0227,  0.1369, -0.1164, -0.0503, -0.0292,  0.0604,  0.1479,
        -0.0407, -0.0423,  0.0405,  0.0594,  0.1619,  0.0929, -0.0560,  0.0969,
        -0.1893, -0.0024,  0.0206,  0.0091, -0.0221, -0.1237, -0.0630, -0.0613,
        -0.1905,  0.2744,  0.1116,  0.0196, -0.0845, -0.2232,  0.1513, -0.0330],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.3294,  0.4158, -0.3016, -0.3174,  0.4280,  0.4541, -0.3497, -0.4258,
         -0.3970,  0.4756,  0.3235,  0.4523, -0.3759, -0.4857,  0.3805, -0.4414,
         -0.3782,  0.3686, -0.2902, -0.3067,  0.4871,  0.4258, -0.4209, -0.4124,
         -0.4666, -0.4308, -0.3625,  0.4378, -0.3921,  0.4311,  0.3365, -0.2921]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0314,  0.0974,  0.0518,  ...,  0.2247, -0.3802, -0.1137],
        [-0.0973, -0.0658,  0.1118,  ...,  0.1587, -0.3650,  0.0871],
        [-0.0143, -0.0205,  0.0240,  ...,  0.0229,  0.2835,  0.0345],
        ...,
        [ 0.0204, -0.0010,  0.0525,  ...,  0.0886, -0.3773, -0.1180],
        [ 0.0745, -0.1945, -0.0483,  ..., -0.3321,  0.1957,  0.1557],
        [-0.1927,  0.1348,  0.0323,  ...,  0.1011, -0.3322, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0426,  0.0409, -0.0669, -0.1335, -0.0719,  0.0586, -0.1108,  0.0465,
        -0.0396,  0.0813,  0.0191,  0.0113,  0.0292,  0.0779, -0.0529, -0.0195,
         0.0593, -0.1526,  0.0012,  0.0276, -0.0523,  0.0348,  0.1081,  0.0059,
        -0.0930,  0.1034,  0.0471, -0.0961,  0.0550,  0.1398,  0.1667, -0.1226],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0681, -0.1991, -0.1004,  ..., -0.1614, -0.0091,  0.0712],
        [-0.2131, -0.0556,  0.1019,  ..., -0.0945,  0.0146,  0.0455],
        [ 0.1464, -0.0078, -0.1792,  ...,  0.1111, -0.0393,  0.1949],
        ...,
        [ 0.1261,  0.1110,  0.1071,  ...,  0.2833, -0.2333,  0.2490],
        [-0.0127, -0.1680,  0.0582,  ..., -0.0120,  0.2458, -0.1735],
        [-0.0104, -0.1515,  0.2155,  ...,  0.0077,  0.1729, -0.0554]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1056,  0.1500, -0.0628, -0.0858,  0.0008, -0.0453, -0.0598, -0.0426,
         0.1257, -0.1712,  0.1302, -0.1160,  0.1744,  0.0873, -0.1208,  0.1300,
        -0.1388, -0.1750, -0.0546, -0.0020, -0.0050,  0.0828, -0.2137,  0.2162,
        -0.0449, -0.0040,  0.0726, -0.0276, -0.1371, -0.0739,  0.1255,  0.0454],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.6300,  0.5539, -0.6469, -0.6290,  0.5135,  0.4928, -0.5554,  0.5335,
          0.5469, -0.5767, -0.5204,  0.5407,  0.5189,  0.5013,  0.5700,  0.5681,
         -0.6259, -0.6395, -0.5002,  0.5471, -0.5906, -0.5721, -0.6436,  0.4815,
          0.6142,  0.6400, -0.6260,  0.6357, -0.5575, -0.6271,  0.6162,  0.6424]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.3665], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-3.3804e-02,  2.6127e-01,  2.2543e-01, -2.5405e-01, -3.9230e-01,
         -7.9613e-02,  9.8133e-03, -4.8358e-01, -2.7014e-01,  3.0686e-02,
          1.7494e-01,  1.7333e-01, -4.8759e-03, -1.5313e-01, -2.5061e-01,
          2.7151e-01],
        [-2.2861e-01, -2.6492e-01, -4.3660e-02, -4.4953e-02,  1.2129e-01,
          1.9635e-01,  1.1674e-01,  2.1234e-01,  4.7406e-01,  7.0475e-02,
          6.6235e-02, -2.5166e-01,  4.8074e-02,  2.3002e-02,  5.1882e-01,
         -7.8728e-03],
        [ 6.3646e-02,  1.9746e-01,  3.1872e-01, -8.0661e-02, -2.3804e-01,
         -3.2305e-01, -3.4727e-02, -5.1864e-01, -1.7409e-02, -1.6747e-02,
         -3.1564e-02, -5.5947e-02,  4.1724e-01,  2.9406e-01, -1.4031e-01,
          2.2520e-01],
        [ 2.3541e-01, -2.2314e-02,  1.2241e-02, -2.1469e-02, -2.0649e-01,
         -1.2116e-01, -7.7252e-02, -1.3741e-01, -5.0502e-01, -3.1771e-01,
          2.6125e-02,  3.4306e-01,  2.2094e-01, -2.0471e-01, -3.5548e-01,
          5.5499e-02],
        [-7.6919e-02,  1.7330e-01, -1.0893e-01, -6.3603e-02,  3.4661e-01,
          3.1570e-02, -2.6273e-03,  4.0432e-01,  2.4469e-01,  2.3139e-01,
          7.6926e-02, -1.6019e-01, -1.4277e-02, -1.7793e-01,  4.7866e-01,
         -8.1464e-02],
        [ 1.4987e-02,  2.0515e-01, -3.1018e-01,  3.6797e-01,  4.6913e-01,
         -7.8834e-02,  2.1528e-01,  1.3208e-02,  3.2329e-01,  1.5709e-01,
         -1.1604e-01, -8.0473e-02, -1.9640e-01,  1.7652e-01,  5.5869e-01,
         -1.6973e-02],
        [ 3.3882e-01,  4.9415e-02,  3.4381e-01, -1.4367e-01, -1.9031e-01,
         -1.6318e-01, -1.2898e-01, -2.8427e-01, -3.0107e-01,  3.6514e-02,
          2.2371e-02,  4.7399e-02, -1.0444e-01,  1.1341e-01, -4.2290e-01,
          8.4873e-02],
        [-9.0241e-02,  2.2722e-01,  3.0351e-01, -3.2226e-01, -4.3276e-01,
         -2.6814e-01, -5.7520e-02, -3.0752e-01, -2.2363e-01, -1.7547e-01,
         -3.2231e-02,  1.9668e-02,  2.3379e-01, -1.3887e-01, -1.9283e-01,
          3.1473e-01],
        [ 2.8787e-02,  2.5675e-01,  2.5558e-01, -2.2714e-01, -2.0441e-01,
         -3.2437e-01, -1.4829e-01, -1.8402e-01, -3.2670e-02, -2.7227e-01,
          4.7897e-02,  7.1026e-02, -5.8368e-02,  1.3440e-01, -5.1788e-01,
          5.1667e-02],
        [-2.8081e-01, -3.3789e-02, -5.3442e-02, -3.7582e-02,  2.4455e-01,
          1.1894e-01,  1.8339e-02,  3.1886e-01,  3.6456e-01, -4.8497e-02,
          1.1721e-01, -1.7344e-02, -2.4526e-01, -4.2843e-02,  3.6942e-01,
         -1.4432e-01],
        [-3.4343e-01,  1.1976e-01, -1.1763e-02, -6.1335e-02,  1.3518e-01,
          3.8872e-01,  1.9970e-01,  2.0708e-01,  4.4645e-01,  2.0107e-01,
         -3.2175e-02, -5.7890e-03, -1.8004e-01,  1.4098e-01,  1.8831e-01,
         -2.7178e-01],
        [-1.0766e-01, -9.2889e-02,  3.0176e-02,  6.4486e-02,  3.0051e-01,
          8.8694e-02,  3.3132e-01,  2.1651e-01,  2.2173e-01,  2.9834e-01,
          7.1686e-02,  6.2513e-02, -4.0231e-01, -1.9216e-01,  2.1219e-01,
         -1.5110e-01],
        [ 2.9719e-01,  1.4586e-01,  8.4488e-02, -1.1394e-01, -3.1351e-01,
          1.0275e-01, -2.2673e-02, -4.2082e-01, -4.3483e-01, -2.2443e-02,
         -9.2364e-02,  1.8098e-02, -9.6824e-02,  1.0602e-01, -4.6865e-01,
         -6.2474e-02],
        [ 1.8721e-01,  2.7432e-01,  3.1662e-01,  1.6127e-02, -4.2360e-01,
          1.3425e-02, -4.9002e-03, -1.1657e-01, -2.6800e-01, -1.1817e-01,
         -9.0291e-02,  1.0242e-01,  9.6163e-02,  3.5507e-03, -4.8634e-01,
          1.8638e-01],
        [-3.5790e-01, -2.4587e-01, -1.7933e-02, -6.8708e-02,  5.0871e-01,
          3.8034e-01,  7.3038e-02,  1.8761e-01,  3.1151e-02,  1.4104e-01,
          6.4633e-03, -3.1138e-01, -7.8405e-02, -8.0447e-02,  2.1604e-01,
         -1.1605e-01],
        [-2.6860e-01, -1.1637e-01,  8.8009e-02,  1.9867e-01,  2.8658e-01,
          1.0622e-01,  5.1885e-02,  1.4940e-01,  2.6483e-01,  4.9061e-02,
          2.0528e-02,  1.4736e-01, -9.9524e-02, -1.9949e-01,  6.8847e-01,
         -5.0201e-03],
        [ 2.8175e-01,  1.5556e-01,  1.3877e-01, -3.0895e-01, -4.6631e-01,
          2.2267e-02, -3.3060e-02, -2.2501e-02, -4.3997e-01, -1.1714e-01,
          1.7551e-01,  2.7238e-01,  2.8257e-01,  1.8736e-01, -2.3497e-01,
         -1.0729e-01],
        [-2.5224e-01,  1.0519e-01, -1.7721e-01,  9.3744e-02,  2.1231e-01,
          2.4650e-01,  2.2768e-01,  2.9300e-01,  1.6068e-01,  2.2186e-01,
         -7.7577e-02, -2.1105e-01, -1.1078e-01, -1.2503e-01,  3.3799e-01,
         -1.0906e-01],
        [ 2.0376e-01,  3.8338e-02,  8.3143e-02, -2.3579e-01, -3.5367e-01,
         -3.3077e-01, -2.3445e-01, -4.8059e-02, -4.8838e-01, -4.0815e-02,
          5.1718e-02, -8.0857e-02,  1.6607e-01,  1.8154e-01, -1.3829e-01,
          1.1828e-01],
        [ 3.5073e-01,  6.8006e-02,  2.0692e-01, -5.6413e-02, -4.7563e-01,
         -1.9394e-01, -3.2114e-01, -5.1957e-02, -1.2983e-01, -2.1647e-01,
          1.2141e-01,  2.5088e-01, -6.4604e-02,  5.5196e-02, -1.8003e-01,
          1.3073e-01],
        [-1.4659e-01,  1.3632e-01,  1.1141e-02, -1.1076e-01,  3.6482e-01,
         -8.7843e-02,  2.6148e-01,  3.8927e-01,  2.1020e-01,  1.7730e-02,
         -1.0576e-01, -2.4525e-01, -1.5552e-01, -1.4774e-01,  5.0000e-01,
         -1.9696e-01],
        [-9.0175e-02, -2.7758e-01, -1.6687e-02,  3.7946e-01,  1.6599e-01,
          1.1535e-01,  2.6043e-01,  6.2930e-02,  1.4015e-01,  2.4110e-01,
          1.7984e-01, -3.1069e-01, -2.3478e-01, -3.5737e-01,  1.1123e-01,
          8.0717e-02],
        [ 3.5376e-01, -3.5219e-02,  1.0999e-02, -1.4511e-01, -1.2971e-01,
         -3.7421e-01, -2.7508e-01, -2.9070e-01, -3.1921e-01, -1.2223e-01,
          2.1843e-01,  2.2109e-01, -8.2574e-02,  2.7660e-01, -4.3253e-02,
          1.7898e-01],
        [ 2.0385e-01,  1.0120e-01,  2.6633e-01, -3.1196e-01, -2.7196e-01,
         -9.6772e-02, -1.0003e-01, -2.7119e-01, -3.7971e-01, -2.4306e-01,
          2.0765e-02,  2.9749e-01,  1.9457e-01,  3.4791e-02, -2.3371e-01,
         -5.9734e-02],
        [ 2.0680e-01, -1.7373e-01,  1.3301e-01, -1.0539e-01, -1.0059e-01,
         -2.1918e-01,  7.6031e-02, -2.4290e-01, -4.5624e-01,  9.6316e-02,
          2.0494e-01,  1.3609e-02,  3.1534e-02,  2.1477e-01, -5.0785e-01,
          2.9249e-01],
        [ 1.5198e-02, -2.3120e-02,  3.2021e-02,  1.1586e-01, -3.3478e-01,
         -1.7376e-01,  1.1577e-02, -3.8254e-01, -2.0202e-01, -3.0766e-01,
         -2.4452e-01,  9.0887e-02,  1.6463e-01,  2.8390e-01, -5.4722e-01,
          3.3134e-02],
        [ 1.9607e-01,  1.0868e-01,  2.4066e-01, -3.1761e-01, -2.9072e-01,
         -6.8158e-02, -3.2667e-01, -7.7132e-02, -4.3006e-01,  5.2748e-02,
          7.0432e-02,  8.1632e-02,  2.1466e-01,  2.2758e-01, -2.8222e-02,
          2.4350e-01],
        [-3.1268e-01,  1.7072e-02,  6.1465e-02,  1.8578e-01,  4.6440e-01,
         -9.1794e-03,  3.3249e-01,  2.4808e-01,  2.8891e-02,  6.0736e-02,
          6.9771e-02, -2.8013e-01, -2.0976e-01, -1.6268e-01,  1.6537e-01,
         -6.3622e-02],
        [ 2.7129e-01,  1.0207e-01,  7.6809e-02, -9.7171e-02, -3.9432e-01,
         -2.4727e-01, -1.0726e-01, -3.8059e-01, -5.0903e-02, -5.8316e-02,
          1.3131e-01,  1.2174e-01,  3.2365e-01,  2.7127e-01, -9.8872e-02,
          2.1184e-01],
        [-2.4805e-01,  7.6624e-02, -2.6794e-01,  2.2444e-01,  3.6480e-02,
          1.1689e-01,  3.0202e-01,  3.5078e-01,  4.0065e-01,  1.9180e-01,
          1.2177e-01, -7.6535e-02,  6.3466e-02,  1.0032e-01,  2.7683e-01,
         -1.8146e-01],
        [-2.6059e-01, -1.0355e-01,  1.4940e-02, -1.3145e-02,  3.2412e-01,
          3.4838e-01,  3.4522e-01,  3.3585e-02,  2.8565e-01,  2.7060e-01,
         -2.6112e-01, -4.9171e-03, -2.9398e-01, -2.2071e-01,  1.4284e-01,
         -1.9050e-01],
        [ 1.7309e-02,  6.2300e-02,  1.7728e-01, -5.8524e-04, -1.2827e-01,
         -2.6052e-01, -3.4167e-01, -4.2425e-01, -3.6137e-01, -1.9347e-01,
          1.2457e-01, -4.0064e-02, -8.2624e-02,  1.4562e-01, -3.9507e-01,
          1.1739e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0959, -0.0019,  0.1740, -0.1201, -0.0244,  0.0107,  0.0799,  0.1690,
        -0.0309, -0.0239,  0.0101,  0.0701,  0.1270,  0.0860, -0.0500, -0.0466,
        -0.2146, -0.0097,  0.0158, -0.0003, -0.0006, -0.1261, -0.0588, -0.0519,
        -0.1698,  0.2771,  0.1113,  0.0446, -0.0794, -0.2395,  0.1579, -0.0314],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.3319,  0.4155, -0.3020, -0.3314,  0.4715,  0.4907, -0.3574, -0.4249,
         -0.4046,  0.4924,  0.3372,  0.4477, -0.3941, -0.4915,  0.3801,  0.4394,
         -0.3815,  0.3760, -0.2928, -0.3084,  0.5066,  0.3988, -0.4234, -0.4134,
         -0.5155, -0.4480, -0.3609,  0.4435, -0.3959,  0.4355,  0.3375, -0.2971]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0099,  0.0993,  0.0754,  ...,  0.1620, -0.3479, -0.1137],
        [-0.1057, -0.0477,  0.1160,  ...,  0.1330, -0.3605,  0.0871],
        [-0.0096, -0.0345,  0.0331,  ...,  0.0238,  0.3043,  0.0345],
        ...,
        [ 0.0118,  0.0215,  0.0522,  ...,  0.0711, -0.3955, -0.1180],
        [ 0.0861, -0.2154, -0.0510,  ..., -0.3068,  0.2060,  0.1557],
        [-0.1876,  0.1521,  0.0378,  ...,  0.0673, -0.3473, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0465,  0.0399, -0.0694, -0.1357, -0.0739,  0.0495, -0.1101,  0.0502,
        -0.0414,  0.0783,  0.0247,  0.0119,  0.0241,  0.0757, -0.0503, -0.0208,
         0.0573, -0.1563, -0.0643,  0.0379, -0.0579,  0.0316,  0.1052,  0.0082,
        -0.0877,  0.0524,  0.0435, -0.1173,  0.0550,  0.1431,  0.1668, -0.1282],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0456, -0.1927, -0.0948,  ..., -0.1352,  0.0045,  0.0652],
        [-0.2299, -0.0489,  0.1206,  ..., -0.0616,  0.0148,  0.0385],
        [ 0.1551, -0.0144, -0.1849,  ...,  0.0783, -0.0308,  0.1943],
        ...,
        [ 0.1302,  0.0879,  0.1143,  ...,  0.2457, -0.2320,  0.2381],
        [-0.0226, -0.1644,  0.0702,  ...,  0.0281,  0.2364, -0.1793],
        [-0.0153, -0.1352,  0.2094,  ...,  0.0484,  0.1635, -0.0464]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1093,  0.1639, -0.0662, -0.0845, -0.0031, -0.0439, -0.0600, -0.0401,
         0.1379, -0.1816,  0.1172, -0.1276,  0.1965,  0.1063, -0.1218,  0.1415,
        -0.1385, -0.1753,  0.0486, -0.0109, -0.0085,  0.0845, -0.2033,  0.2440,
        -0.0415, -0.0058,  0.0713, -0.0273, -0.1378, -0.0698,  0.1351,  0.0403],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.6579,  0.5886, -0.6668, -0.6394,  0.5287,  0.5379, -0.5748,  0.5469,
          0.5543, -0.6073, -0.5529,  0.5464,  0.5424,  0.5336,  0.5785,  0.5955,
         -0.6420, -0.6532,  0.5041,  0.5581, -0.6120, -0.5929, -0.6544,  0.4952,
          0.6385,  0.6531, -0.6351,  0.6531, -0.5732, -0.6405,  0.6352,  0.6498]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.3758], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-5.2378e-01,  7.0633e-01, -1.7782e-01, -3.2844e-01,  2.7039e-01,
         -2.9473e-01,  5.9385e-01,  5.6293e-02,  2.7318e-01,  1.5805e-01,
          1.8911e-01, -2.4533e-01, -1.9129e-01,  5.9020e-02,  3.0682e-01,
         -1.3679e-01],
        [-3.7108e-01,  1.1839e-01, -2.1028e-01, -2.9577e-01,  1.6469e-01,
         -1.6971e-01,  3.3618e-01,  3.0600e-01,  5.3356e-01,  3.1657e-02,
          1.3475e-01, -3.9241e-01,  1.1989e-01,  3.2608e-01,  5.0954e-01,
         -1.8945e-01],
        [-3.5900e-01,  4.1450e-01, -5.6921e-02, -6.8429e-02,  4.1332e-01,
         -3.6042e-01,  5.0668e-01,  7.1675e-02,  5.0911e-01,  1.1399e-01,
          2.7248e-02, -5.3265e-01,  1.3384e-01,  3.3661e-01,  4.4995e-01,
         -1.7165e-01],
        [ 3.9310e-01, -3.8235e-01,  1.7476e-01,  1.8567e-01, -1.8070e-01,
          1.5942e-01, -3.2710e-01, -1.9390e-01, -5.0002e-01, -2.9180e-01,
         -2.4433e-02,  4.3810e-01,  1.3580e-01, -4.1782e-01, -2.8651e-01,
          2.6237e-01],
        [-2.3675e-01,  5.3344e-01, -2.6795e-01, -3.1513e-01,  2.8593e-01,
         -2.9331e-01,  1.8482e-01,  4.0917e-01,  2.2315e-01,  1.8801e-01,
          1.8179e-01, -2.4446e-01,  1.0249e-01,  9.5880e-02,  3.8175e-01,
         -2.6768e-01],
        [-1.3319e-01,  5.6171e-01, -4.4629e-01,  7.5301e-02,  4.2377e-01,
         -4.1663e-01,  3.8688e-01,  3.1709e-02,  3.0484e-01,  2.0728e-02,
         -1.5160e-01, -1.5915e-01, -2.0026e-01,  4.6557e-01,  4.1951e-01,
         -1.8280e-01],
        [ 4.1637e-01, -2.9020e-01,  5.2250e-01,  1.8152e-01, -2.1392e-01,
          2.6458e-01, -3.7347e-01, -3.5071e-01, -3.5240e-01,  2.1861e-01,
         -4.3732e-02,  1.5047e-01, -6.1416e-02, -1.7361e-01, -3.1636e-01,
          2.8929e-01],
        [ 5.4210e-02, -1.2300e-01,  4.5730e-01, -2.1702e-02, -4.9507e-01,
          1.0676e-01, -2.5040e-01, -3.8440e-01, -2.9449e-01, -2.0592e-02,
         -7.8195e-02,  1.4251e-01,  2.7847e-01, -4.2751e-01, -1.9378e-01,
          4.7765e-01],
        [ 1.9228e-01, -2.2321e-01,  4.6939e-01,  1.1113e-01, -3.2734e-01,
          1.7686e-01, -4.3116e-01, -3.2968e-01, -1.8131e-01, -2.0966e-01,
         -1.9543e-01,  2.4590e-01, -1.3112e-01, -3.0088e-01, -5.7087e-01,
          2.5956e-01],
        [-4.6783e-01,  3.5750e-01, -2.2859e-01, -2.5008e-01,  2.1374e-01,
         -1.8930e-01,  2.2026e-01,  3.4124e-01,  3.6806e-01,  7.7408e-03,
          1.0622e-01, -1.0723e-01, -1.9362e-02,  2.4165e-01,  2.9561e-01,
         -3.4761e-01],
        [-5.7778e-01,  6.0867e-01, -2.0668e-01, -3.3966e-01,  5.4943e-02,
          2.1383e-02,  4.4226e-01,  1.9437e-01,  4.2661e-01,  2.0744e-01,
          5.3169e-02, -7.2851e-02, -1.0614e-02,  4.7996e-01,  4.1825e-02,
         -5.1746e-01],
        [-3.2715e-01,  2.9181e-01, -1.6085e-01, -1.4161e-01,  3.2126e-01,
         -2.0608e-01,  5.3645e-01,  2.6314e-01,  2.7553e-01,  3.7028e-01,
          1.6077e-01, -4.4198e-02, -1.7277e-01,  7.3923e-02,  2.3634e-01,
         -3.5920e-01],
        [ 4.6925e-01, -2.8823e-01,  2.8051e-01,  1.8728e-01, -2.4916e-01,
          5.0393e-01, -2.5569e-01, -4.2801e-01, -4.1438e-01,  7.3646e-02,
         -1.3198e-01,  1.3922e-01, -9.7251e-02, -2.5763e-01, -3.0950e-01,
          1.6244e-01],
        [ 3.3739e-01, -7.9951e-02,  4.6706e-01,  2.4995e-01, -4.3088e-01,
          3.3711e-01, -1.8680e-01, -1.6161e-01, -2.9035e-01, -5.6291e-02,
         -1.4744e-01,  1.8668e-01,  2.3336e-02, -2.4993e-01, -4.3381e-01,
          3.5359e-01],
        [-5.4494e-01,  2.2318e-01, -2.0070e-01, -3.5060e-01,  5.3215e-01,
         -2.8467e-02,  3.0530e-01,  2.5186e-01,  8.6723e-02,  8.4003e-02,
          8.8431e-02, -4.2096e-01,  2.1112e-04,  2.9088e-01,  1.6503e-01,
         -3.1680e-01],
        [ 9.3513e-02, -3.8610e-01,  3.4337e-01,  2.9239e-01, -4.2165e-01,
          2.6285e-01, -3.1639e-01, -3.8674e-01, -2.8601e-01,  1.6804e-02,
          6.9211e-02,  5.2101e-01, -5.0843e-02, -2.6767e-01, -2.9781e-02,
          2.2403e-01],
        [ 4.4747e-01, -1.7630e-01,  3.4638e-01, -6.1971e-02, -6.2008e-01,
          3.5461e-01, -3.1903e-01, -2.1727e-01, -5.7565e-01, -8.3640e-02,
          2.0074e-01,  4.8344e-01,  2.7403e-01, -1.0062e-01, -3.7697e-01,
          1.2281e-01],
        [-3.2501e-01,  3.7806e-01, -3.2564e-01, -1.5280e-01,  2.9380e-01,
         -7.2382e-02,  4.4825e-01,  3.9557e-01,  2.2599e-01,  7.8461e-02,
          3.4593e-04, -3.3708e-01, -1.7270e-01,  8.2574e-02,  3.0455e-01,
         -2.8251e-01],
        [-2.4565e-01,  3.1756e-01, -2.9160e-01, -2.4750e-01,  2.6576e-01,
         -4.1314e-01,  2.5165e-01,  4.9144e-01,  4.6983e-02,  8.7474e-02,
          1.5308e-02, -5.3128e-01, -9.8122e-03,  3.0370e-01,  4.1357e-01,
         -2.4258e-01],
        [ 5.5375e-01, -4.1229e-01,  3.9879e-01,  2.2104e-01, -4.2132e-01,
          1.7877e-01, -5.5848e-01, -5.0773e-02, -1.1243e-01, -1.5802e-01,
         -9.9542e-02,  3.0703e-01, -1.3904e-01, -2.7066e-01, -3.8131e-02,
          3.6996e-01],
        [-2.4400e-01,  3.4673e-01, -1.0886e-01, -2.8217e-01,  3.8116e-01,
         -2.9944e-01,  4.1071e-01,  4.4964e-01,  2.5083e-01, -4.5499e-02,
         -1.6327e-01, -3.5104e-01, -7.9347e-02, -7.1954e-03,  4.4632e-01,
         -3.1625e-01],
        [ 3.6332e-01, -3.5630e-01,  2.5482e-01,  3.1268e-01, -2.9303e-01,
          1.0921e-01, -2.4263e-02, -2.9538e-01, -3.3281e-01, -8.8050e-02,
          2.4795e-01,  1.3669e-01,  2.3256e-02, -3.2827e-01, -6.0117e-01,
          2.8921e-01],
        [ 4.9468e-01, -4.6466e-01,  1.7709e-01,  1.7501e-01, -1.6170e-01,
          4.6245e-02, -4.8439e-01, -3.5107e-01, -3.5600e-01, -1.2577e-02,
          5.2140e-02,  3.1638e-01, -1.0189e-01, -9.2200e-02,  3.0998e-02,
          3.7932e-01],
        [ 2.9472e-01, -1.5986e-01,  4.3279e-01, -1.1052e-01, -4.5101e-01,
          1.6122e-01, -3.5343e-01, -4.5093e-01, -4.9537e-01, -1.6558e-01,
         -9.1258e-02,  4.8727e-01,  2.6574e-01, -1.2936e-01, -3.0664e-01,
          1.3621e-01],
        [ 3.7012e-01, -6.3780e-01,  3.0439e-01,  1.9474e-01, -1.1009e-01,
          1.9359e-01, -1.5934e-01, -3.0776e-01, -4.9130e-01,  1.2468e-01,
          2.0996e-01,  1.2072e-01, -1.0619e-01, -2.0055e-01, -4.3474e-01,
          4.9332e-01],
        [ 1.5822e-01, -4.0214e-01,  1.8018e-01,  3.8613e-01, -3.7090e-01,
          1.8805e-01, -1.7509e-01, -4.5279e-01, -2.6054e-01, -2.1190e-01,
         -2.8452e-01,  2.1517e-01,  1.4260e-01, -1.6985e-02, -4.9554e-01,
          1.8462e-01],
        [ 3.8826e-01, -2.9076e-01,  4.3535e-01, -5.3551e-02, -3.1686e-01,
          2.9347e-01, -5.5372e-01, -1.2598e-01, -4.7699e-01,  1.0578e-01,
          2.6839e-03,  1.8276e-01,  1.6784e-01, -5.9361e-02,  8.6560e-03,
          4.6326e-01],
        [-5.2245e-01,  4.0204e-01, -1.2486e-01, -2.5976e-02,  4.3564e-01,
         -3.0528e-01,  5.2493e-01,  2.6413e-01,  4.8749e-02,  1.1232e-01,
          1.4056e-01, -3.6772e-01,  1.2697e-02,  1.0278e-01,  1.4178e-01,
         -2.6954e-01],
        [ 4.6270e-01, -2.9338e-01,  2.5951e-01,  1.1806e-01, -4.6909e-01,
          4.9688e-02, -3.2194e-01, -4.7945e-01, -1.3922e-01, -6.0578e-02,
          4.4646e-02,  2.5811e-01,  2.2662e-01, -6.3191e-03, -1.4195e-01,
          4.0330e-01],
        [-3.6539e-01,  4.2477e-01, -4.0881e-01, -6.5798e-02,  2.1976e-02,
         -2.3778e-01,  4.8274e-01,  3.6845e-01,  3.9472e-01,  4.2501e-02,
          2.3308e-01, -1.4160e-01,  3.4668e-02,  3.5035e-01,  1.1724e-01,
         -3.5927e-01],
        [-4.6766e-01,  3.5312e-01, -1.8053e-01, -2.8197e-01,  3.5948e-01,
         -3.3617e-02,  5.9067e-01,  1.0375e-01,  3.3939e-01,  2.4845e-01,
         -1.7863e-01, -1.1783e-01, -2.1258e-01,  1.4494e-01,  1.3596e-01,
         -4.1357e-01],
        [ 1.2673e-01, -2.7370e-01,  3.5500e-01,  2.8217e-01, -1.6756e-01,
          9.4586e-02, -6.0871e-01, -5.2460e-01, -4.2124e-01, -7.7735e-02,
         -9.6722e-04,  1.1911e-01, -4.1778e-02, -1.1636e-01, -3.6073e-01,
          3.1816e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.2417,  0.0795,  0.1801, -0.0885,  0.0010, -0.0998,  0.0624,  0.1045,
        -0.2177, -0.0741,  0.0262,  0.0583,  0.1126,  0.0858,  0.0106,  0.0852,
        -0.1228,  0.0689, -0.0398, -0.0942, -0.0353, -0.0056, -0.1306, -0.1365,
        -0.1291,  0.1826,  0.1137,  0.0430, -0.0816, -0.1286,  0.1420, -0.1691],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5281,  0.5568,  0.4863, -0.5140,  0.6138,  0.6509, -0.5043, -0.6207,
         -0.5604,  0.6614,  0.5390,  0.6718, -0.5599, -0.6246,  0.5535, -0.5424,
         -0.5361,  0.5712,  0.4941, -0.5104,  0.6150, -0.4286, -0.6227, -0.5934,
         -0.5680, -0.6379, -0.5336,  0.6231, -0.6122,  0.6206,  0.5588, -0.4756]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.2314,  0.1617, -0.0087,  ...,  0.0795, -0.1024, -0.1137],
        [-0.1281, -0.2100,  0.1749,  ..., -0.0082, -0.3804,  0.0871],
        [-0.0368,  0.1241,  0.0890,  ...,  0.1316,  0.1787,  0.0345],
        ...,
        [-0.0236, -0.1668,  0.0620,  ..., -0.1228, -0.2022, -0.1180],
        [ 0.0053, -0.1074, -0.0156,  ..., -0.1635,  0.0428,  0.1557],
        [-0.0977,  0.1276, -0.0215,  ..., -0.0642,  0.0427, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0513,  0.0650, -0.1597, -0.0554, -0.0546,  0.0357, -0.1284,  0.1106,
        -0.0562,  0.1540,  0.0223, -0.0520, -0.0500,  0.0612, -0.0741, -0.0445,
         0.1044, -0.1400, -0.0442,  0.0479, -0.0817,  0.1337,  0.0986, -0.0593,
        -0.0044,  0.1187,  0.0182, -0.1361,  0.0819,  0.1834,  0.0925, -0.1391],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.2017, -0.1882, -0.1067,  ..., -0.0558, -0.1169,  0.1668],
        [ 0.0189,  0.0049,  0.1465,  ..., -0.0367, -0.0366,  0.2479],
        [-0.0682, -0.0946, -0.1844,  ...,  0.0226,  0.0412,  0.0032],
        ...,
        [-0.0463,  0.0302,  0.0774,  ...,  0.1944, -0.1512,  0.1311],
        [ 0.2015, -0.1017,  0.0881,  ...,  0.0602,  0.1886,  0.0220],
        [ 0.1860, -0.0571,  0.2498,  ...,  0.0808,  0.1051,  0.1094]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0573,  0.0219,  0.0618,  0.0233, -0.0784, -0.1300,  0.0627, -0.1830,
         0.0234, -0.0619,  0.2338, -0.1865,  0.0763,  0.1045, -0.2232, -0.0210,
        -0.0518, -0.1122, -0.0692, -0.1112,  0.1009,  0.2011, -0.1040,  0.2107,
        -0.1507, -0.0643,  0.1436, -0.1466, -0.0446, -0.0015, -0.0025, -0.0623],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3343,  0.2472, -0.3472, -0.3051,  0.2077,  0.2017, -0.2383,  0.2704,
          0.2425, -0.2451, -0.2297,  0.2252,  0.2331, -0.2040,  0.2709,  0.2196,
         -0.3269, -0.3351,  0.1951,  0.2279, -0.2918, -0.2720, -0.3418, -0.1602,
          0.3063,  0.3356, -0.3183,  0.3212, -0.2439, -0.3177,  0.3165,  0.3144]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.1473], device='cuda:0', requires_grad=True)

