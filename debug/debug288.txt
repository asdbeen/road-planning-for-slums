Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.4053e-03,  3.9278e-01,  3.0545e-01, -3.2508e-01, -1.9128e-01,
         -1.5281e-01, -7.7464e-02, -3.9255e-01, -2.6261e-01, -7.7014e-02,
         -2.5603e-02,  1.9803e-01, -3.0950e-01, -6.9809e-02, -4.0297e-02,
          3.8560e-01],
        [-2.4786e-01, -3.8658e-01, -9.8487e-02, -1.2247e-02, -2.5971e-02,
          2.4707e-01,  1.6377e-01,  1.6187e-01,  4.3753e-01,  1.3679e-01,
          2.9550e-01, -2.6344e-01,  3.6409e-01, -2.8262e-02,  3.4772e-01,
         -9.0751e-02],
        [ 9.3650e-02,  2.9377e-01,  3.8904e-01, -1.3034e-01, -1.0265e-01,
         -3.4695e-01, -9.2872e-02, -4.4997e-01, -6.9488e-02, -8.9656e-02,
         -1.5531e-01, -3.1466e-02,  1.5969e-02,  3.5041e-01, -2.5650e-02,
          2.8819e-01],
        [ 2.8394e-01,  1.1689e-01,  9.5108e-02, -8.6535e-02, -6.9019e-02,
         -2.1569e-01, -1.7753e-01, -1.2321e-01, -4.8193e-01, -4.2909e-01,
         -2.1501e-01,  3.8883e-01, -8.0899e-02, -1.1499e-01, -2.1897e-01,
          1.8071e-01],
        [-9.6411e-02,  3.5529e-02, -1.7117e-01, -2.3859e-02,  1.6722e-01,
          8.9166e-02,  4.8215e-02,  3.3023e-01,  1.9081e-01,  3.0505e-01,
          3.4557e-01, -1.7007e-01,  3.2750e-01, -2.3341e-01,  3.0055e-01,
         -1.7444e-01],
        [-2.0776e-02,  6.1424e-02, -3.7358e-01,  4.1662e-01,  3.5899e-01,
         -8.4330e-03,  2.8910e-01, -1.1518e-03,  3.2141e-01,  2.3493e-01,
         -7.7146e-02, -1.1289e-01,  1.3044e-01,  1.1683e-01,  4.3840e-01,
         -1.0641e-01],
        [ 3.6618e-01,  2.4488e-01,  4.0513e-01, -1.8264e-01, -5.7932e-02,
         -2.0892e-01, -1.8679e-01, -2.4114e-01, -3.0222e-01, -3.1940e-02,
         -4.3109e-02,  6.6565e-02, -3.6091e-01,  2.0427e-01, -3.0421e-01,
          1.6294e-01],
        [-5.8134e-02,  3.6224e-01,  3.6133e-01, -3.6045e-01, -3.4825e-01,
         -2.9993e-01, -1.0481e-01, -2.7570e-01, -2.4959e-01, -2.2893e-01,
         -9.2377e-02,  4.2441e-02, -4.2573e-02, -9.5082e-02, -1.2972e-01,
          3.7215e-01],
        [ 3.2687e-02,  3.5583e-01,  3.0189e-01, -2.4476e-01, -5.0715e-02,
         -3.4540e-01, -1.5906e-01, -1.0139e-01,  6.4986e-03, -3.1940e-01,
         -2.8201e-01,  5.5505e-02, -4.2014e-01,  1.5938e-01, -3.0012e-01,
          1.0888e-01],
        [-3.0106e-01, -1.6556e-01, -1.1115e-01,  4.8388e-04,  9.2765e-02,
          1.7032e-01,  7.5947e-02,  2.5988e-01,  3.2758e-01,  1.9011e-02,
          3.6328e-01, -2.6417e-02,  1.2098e-01, -9.5430e-02,  2.0978e-01,
         -2.2929e-01],
        [-3.7016e-01,  1.5974e-02, -7.7026e-02, -1.9491e-02, -2.8233e-02,
          4.4372e-01,  2.6429e-01,  1.5231e-01,  4.1758e-01,  2.8111e-01,
          2.2537e-01, -2.0226e-02,  1.9912e-01,  9.9941e-02,  3.0555e-02,
         -3.6302e-01],
        [-1.3999e-01, -2.0336e-01, -3.8627e-02,  1.0136e-01,  1.8893e-01,
          1.3736e-01,  3.8975e-01,  1.7030e-01,  2.1877e-01,  3.7122e-01,
          4.0774e-01,  4.5448e-02, -5.6303e-02, -2.6541e-01,  4.5716e-02,
         -2.3695e-01],
        [ 3.3478e-01,  2.8967e-01,  1.6629e-01, -1.7197e-01, -1.0470e-01,
          2.2841e-02, -8.7555e-02, -3.2973e-01, -3.6961e-01, -1.1651e-01,
         -1.7455e-01,  4.2272e-02, -4.3866e-01,  1.5634e-01, -2.5269e-01,
          5.3010e-02],
        [ 2.0910e-01,  4.0102e-01,  3.7039e-01, -1.2509e-02, -3.1336e-01,
         -2.3108e-02, -4.0596e-02, -7.6910e-02, -2.5391e-01, -1.7437e-01,
         -2.7960e-01,  1.1357e-01, -2.0351e-01,  5.9279e-02, -3.3519e-01,
          2.5400e-01],
        [-3.7856e-01, -3.5375e-01, -7.2351e-02, -3.3599e-02,  3.7351e-01,
          4.0628e-01,  1.1421e-01,  1.2821e-01,  2.0943e-02,  1.9740e-01,
          1.9098e-01, -3.1855e-01,  2.5756e-01, -1.1500e-01,  7.5235e-02,
         -1.8286e-01],
        [-4.9285e-02,  6.8354e-03,  2.1480e-01,  5.8226e-02, -3.7257e-01,
         -4.5717e-02, -2.3198e-01, -3.5604e-01, -3.1920e-01, -1.0182e-01,
         -1.4732e-01,  4.6454e-01, -3.0392e-01, -1.4437e-02,  1.3870e-03,
          1.3045e-01],
        [ 3.2931e-01,  3.2875e-01,  2.1509e-01, -3.6646e-01, -3.8337e-01,
         -5.9632e-02, -1.2054e-01, -2.9924e-02, -4.2768e-01, -2.1355e-01,
          6.9482e-02,  3.1366e-01,  3.1652e-02,  3.0225e-01, -1.4938e-01,
          4.2998e-03],
        [-3.0017e-01, -6.1101e-02, -2.5176e-01,  1.4720e-01,  1.4521e-01,
          3.0923e-01,  3.0185e-01,  2.9002e-01,  1.9401e-01,  3.0199e-01,
          1.0124e-02, -2.5914e-01,  1.1559e-01, -2.1714e-01,  3.0241e-01,
         -1.9475e-01],
        [ 2.2487e-01,  1.5049e-01,  1.4162e-01, -2.8033e-01, -2.1690e-01,
         -3.7295e-01, -3.2395e-01,  4.6224e-03, -5.1106e-01, -1.2344e-01,
         -1.1304e-01, -5.9110e-02, -1.4733e-01,  2.9268e-01, -6.0047e-02,
          2.0927e-01],
        [ 3.7427e-01,  1.7969e-01,  2.7508e-01, -9.6339e-02, -3.1347e-01,
         -2.3247e-01, -3.6453e-01,  2.1873e-02, -9.6313e-02, -2.9267e-01,
         -1.7115e-01,  2.5204e-01, -4.0516e-01,  1.0885e-01,  2.7524e-02,
          2.1842e-01],
        [-1.9030e-01,  1.4635e-03, -5.8521e-02, -6.0406e-02,  2.8980e-01,
         -2.0335e-02,  3.2211e-01,  3.8768e-01,  2.3806e-01,  9.3246e-02,
          9.0737e-03, -2.9420e-01,  1.3058e-01, -2.1105e-01,  4.0336e-01,
         -2.8017e-01],
        [-7.8941e-02, -4.0754e-01, -5.5303e-02,  3.9505e-01, -1.7627e-02,
          1.1593e-01,  2.6901e-01, -5.0923e-02,  7.3259e-02,  2.7818e-01,
          3.9872e-01, -2.6569e-01,  1.8544e-01, -3.7044e-01, -6.3763e-02,
          2.8259e-02],
        [ 3.6856e-01,  7.8914e-02,  5.8965e-02, -1.7030e-01, -1.0959e-03,
         -3.9891e-01, -3.0698e-01, -2.3502e-01, -3.0093e-01, -1.7191e-01,
          5.5889e-02,  2.1752e-01, -3.9344e-01,  3.1841e-01,  8.5650e-02,
          2.4175e-01],
        [ 2.6182e-01,  2.3417e-01,  3.4804e-01, -3.7498e-01, -2.4384e-01,
         -1.7619e-01, -1.8754e-01, -2.9575e-01, -4.0125e-01, -3.4095e-01,
         -1.3689e-01,  3.5433e-01,  1.2095e-02,  1.3189e-01, -1.9388e-01,
          4.4597e-02],
        [ 2.2452e-01, -4.5050e-02,  1.8390e-01, -1.3712e-01,  3.6899e-02,
         -2.8301e-01,  1.1975e-02, -2.1108e-01, -4.4002e-01,  2.4176e-02,
          4.3790e-02,  3.0979e-02, -3.6209e-01,  2.6443e-01, -3.4562e-01,
          3.7604e-01],
        [ 5.1144e-02,  8.6330e-02,  9.7748e-02,  7.0162e-02, -2.3059e-01,
         -2.1687e-01, -4.0584e-02, -3.5021e-01, -2.2293e-01, -3.7332e-01,
         -3.6416e-01,  1.2593e-01, -1.5663e-01,  3.2200e-01, -4.0799e-01,
          1.0766e-01],
        [ 2.3007e-01,  2.5363e-01,  3.1108e-01, -3.5885e-01, -1.8625e-01,
         -1.0692e-01, -3.7337e-01, -3.5575e-02, -4.4010e-01, -1.6301e-02,
         -5.7337e-02,  9.9530e-02, -8.7414e-02,  3.0603e-01,  9.2553e-02,
          3.2136e-01],
        [-3.2672e-01, -1.0184e-01,  7.1251e-03,  2.1606e-01,  3.1320e-01,
          2.9371e-02,  3.8084e-01,  1.7526e-01, -7.6926e-03,  1.2215e-01,
          3.7838e-01, -2.7716e-01,  1.4307e-01, -2.2172e-01, -2.3082e-03,
         -1.4285e-01],
        [ 3.1739e-01,  1.9459e-01,  1.5205e-01, -1.4641e-01, -3.1483e-01,
         -3.0005e-01, -1.6795e-01, -3.6166e-01, -7.5767e-02, -1.3536e-01,
         -1.0497e-01,  1.5677e-01,  2.8886e-02,  3.3170e-01, -9.9848e-03,
          2.9725e-01],
        [-2.6950e-01, -4.1300e-02, -3.1862e-01,  2.5250e-01, -7.4476e-02,
          1.4703e-01,  3.4088e-01,  3.0878e-01,  4.0074e-01,  2.4316e-01,
          2.2569e-01, -8.6463e-02,  3.2910e-01,  6.2154e-02,  1.4792e-01,
         -2.4023e-01],
        [-3.0208e-01, -2.3399e-01, -6.1409e-02,  3.6388e-02,  2.1382e-01,
          4.0505e-01,  4.0728e-01,  7.8206e-04,  2.9203e-01,  3.5222e-01,
         -8.5897e-02, -3.4145e-02,  3.4577e-02, -2.9808e-01,  3.6864e-02,
         -2.8132e-01],
        [ 4.7258e-02,  2.2912e-01,  2.4565e-01, -4.4996e-02,  6.6224e-03,
         -3.1492e-01, -4.1294e-01, -3.7490e-01, -3.8364e-01, -2.7863e-01,
         -3.5474e-02, -6.9497e-03, -3.5808e-01,  2.6922e-01, -2.6282e-01,
          2.0333e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0710, -0.0183, -0.0170, -0.0341,  0.0123, -0.2324,  0.0954,  0.1208,
        -0.0594, -0.0031,  0.0452,  0.0804,  0.1316,  0.0712,  0.0660, -0.0200,
        -0.0222, -0.0389,  0.0800, -0.0342, -0.1045, -0.0645, -0.0326,  0.0360,
        -0.0414,  0.1322,  0.1552,  0.0500, -0.1021, -0.1812,  0.0268,  0.0225],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2209,  0.3147, -0.2312, -0.2628,  0.3064,  0.3633, -0.2841, -0.3762,
         -0.3243,  0.3445,  0.2681,  0.3796, -0.2676, -0.3992,  0.2871, -0.2446,
         -0.3234,  0.3350, -0.2341, -0.2391,  0.4064,  0.3201, -0.3748, -0.3779,
         -0.2930, -0.3342, -0.3219,  0.3461, -0.3530,  0.3835,  0.3053, -0.2390]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0060,  0.1154,  0.0698,  ...,  0.1973, -0.3108, -0.1137],
        [-0.0735, -0.0664,  0.1194,  ...,  0.1022, -0.2871,  0.0871],
        [-0.1080,  0.1597,  0.0931,  ...,  0.1986,  0.0255,  0.0345],
        ...,
        [ 0.0967, -0.1198, -0.0373,  ..., -0.1703, -0.0240, -0.1180],
        [ 0.0388, -0.1838, -0.0410,  ..., -0.2614,  0.0927,  0.1557],
        [-0.1840,  0.1343,  0.0508,  ...,  0.0709, -0.2449, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0534,  0.0307, -0.0953, -0.1551, -0.0812, -0.0072, -0.1021,  0.0407,
        -0.0328,  0.0578,  0.0280, -0.0028,  0.0082,  0.1020, -0.0439, -0.0123,
         0.0480, -0.1664,  0.0045,  0.0820, -0.0626,  0.0177,  0.1110,  0.0235,
        -0.1106,  0.0984,  0.0442, -0.0980,  0.0457,  0.2039,  0.1690, -0.1283],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0501, -0.1641, -0.1887,  ...,  0.0356, -0.0452,  0.0650],
        [-0.2196, -0.0157, -0.0192,  ...,  0.1389, -0.0286,  0.0481],
        [ 0.1499, -0.0493, -0.0380,  ..., -0.1417,  0.0028,  0.1873],
        ...,
        [ 0.1448,  0.0586,  0.2100,  ...,  0.1044, -0.1763,  0.2463],
        [-0.0158, -0.1375, -0.0460,  ...,  0.2400,  0.2148, -0.1736],
        [-0.0042, -0.1102,  0.1274,  ...,  0.2225,  0.1271, -0.0449]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1009,  0.1483, -0.0468, -0.1007, -0.1070, -0.1766, -0.0642, -0.0263,
         0.1414, -0.1701,  0.1328, -0.1278,  0.1987,  0.0932, -0.1088,  0.1240,
        -0.1368, -0.1793,  0.0774,  0.0111, -0.0157,  0.0806, -0.2079,  0.2181,
        -0.0451, -0.0101,  0.0760, -0.0414, -0.1513, -0.0592,  0.1239,  0.0308],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3818,  0.3056, -0.3450, -0.3756, -0.2301, -0.2244, -0.2896,  0.2569,
          0.2823, -0.2992, -0.2526,  0.2679,  0.2765,  0.2327,  0.2928,  0.2755,
         -0.3737, -0.3792,  0.2259,  0.2716, -0.3318, -0.2818, -0.3838,  0.2283,
          0.3462,  0.3981, -0.3538,  0.3709, -0.2899, -0.3785,  0.3428,  0.3828]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1358], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.2961e-02,  3.4673e-01,  3.2227e-01, -3.4667e-01, -3.3791e-02,
         -1.8015e-01, -6.9895e-02, -3.9552e-01, -1.8027e-01, -8.2716e-02,
          3.4005e-02,  1.8012e-01,  6.5794e-02, -5.4543e-02,  3.2146e-01,
          3.5963e-01],
        [-2.7754e-01, -3.3289e-01, -1.2813e-01,  1.4868e-02, -1.5263e-01,
          2.8786e-01,  1.9185e-01,  1.7440e-01,  4.0467e-01,  1.3433e-01,
          2.1626e-01, -2.7819e-01, -5.8436e-03, -4.4561e-02, -4.4824e-03,
         -8.1352e-02],
        [ 9.9221e-02,  2.4023e-01,  4.0084e-01, -1.3924e-01,  1.3385e-01,
         -3.7557e-01, -6.6026e-02, -4.1852e-01,  5.0225e-02, -7.8784e-02,
         -8.9888e-02, -5.6380e-02,  4.0135e-01,  3.0635e-01,  4.3661e-01,
          2.6057e-01],
        [ 2.9313e-01,  6.3022e-02,  1.0668e-01, -9.2770e-02,  9.3322e-02,
         -2.3258e-01, -1.7396e-01, -1.0209e-01, -4.1090e-01, -4.0190e-01,
         -1.0250e-01,  3.7056e-01,  2.9002e-01, -1.2836e-01,  1.4587e-01,
          1.5668e-01],
        [-1.1963e-01,  1.2631e-01, -1.9129e-01, -8.4061e-04,  6.1354e-02,
          1.2782e-01,  7.1258e-02,  3.5321e-01,  1.6526e-01,  2.9283e-01,
          2.2570e-01, -1.9594e-01, -6.0576e-02, -2.2911e-01, -9.1085e-02,
         -1.3510e-01],
        [-2.4038e-02,  1.4939e-01, -3.7711e-01,  4.1501e-01,  1.6538e-01,
          7.4604e-03,  2.7887e-01, -1.7336e-02,  2.5601e-01,  2.0657e-01,
         -1.4109e-01, -1.0188e-01, -2.5323e-01,  1.2886e-01,  2.6925e-02,
         -6.9551e-02],
        [ 3.9390e-01,  1.9561e-01,  4.3218e-01, -2.0325e-01,  1.2154e-01,
         -2.5206e-01, -2.1303e-01, -2.4473e-01, -2.5479e-01, -2.6127e-02,
         -1.4738e-02,  7.1330e-02, -2.7497e-02,  2.2655e-01, -8.4044e-03,
          1.5871e-01],
        [-4.4357e-02,  3.1020e-01,  3.7443e-01, -3.6273e-01, -1.5264e-01,
         -3.3218e-01, -1.1035e-01, -2.5149e-01, -1.8211e-01, -2.1300e-01,
         -6.8393e-02,  2.5552e-02,  2.5902e-01, -8.6115e-02,  1.6399e-01,
          3.6246e-01],
        [ 5.7019e-02,  2.9833e-01,  3.2559e-01, -2.6947e-01,  2.3355e-02,
         -3.8416e-01, -1.8562e-01, -1.1752e-01,  3.7272e-02, -3.1265e-01,
         -1.0743e-01,  8.1155e-02, -7.5015e-02,  1.3869e-01,  1.7881e-02,
          9.2033e-02],
        [-3.0778e-01, -7.9321e-02, -1.1755e-01,  4.1498e-03, -3.5185e-02,
          1.9219e-01,  7.0288e-02,  2.5707e-01,  2.7646e-01, -7.2560e-03,
          2.3292e-01, -2.9516e-02, -2.6785e-01, -6.9112e-02, -1.9251e-01,
         -1.8659e-01],
        [-3.6904e-01,  7.7944e-02, -7.8749e-02, -2.6799e-02, -1.6861e-01,
          4.5615e-01,  2.4701e-01,  1.2477e-01,  3.4092e-01,  2.4651e-01,
          6.2598e-02,  2.9453e-03, -1.6676e-01,  1.3726e-01, -3.9200e-01,
         -3.2631e-01],
        [-1.4512e-01, -1.3845e-01, -4.3063e-02,  1.0574e-01,  1.2022e-01,
          1.5402e-01,  3.9082e-01,  1.6720e-01,  1.7381e-01,  3.4218e-01,
          1.4946e-01,  4.2339e-02, -4.0800e-01, -1.9929e-01, -2.6270e-01,
         -1.9572e-01],
        [ 3.6947e-01,  2.1409e-01,  2.0262e-01, -2.0549e-01,  6.6713e-02,
         -3.1035e-02, -1.1780e-01, -3.4459e-01, -3.4579e-01, -1.2087e-01,
         -1.1627e-01,  5.1369e-02, -1.7351e-02,  1.9513e-01,  1.7769e-01,
          3.1647e-02],
        [ 2.3826e-01,  3.4956e-01,  3.9771e-01, -3.5787e-02, -1.8602e-01,
         -6.5530e-02, -7.5676e-02, -9.2364e-02, -2.2717e-01, -1.7248e-01,
         -2.1076e-01,  1.3277e-01,  1.3865e-01,  7.1860e-02, -2.9902e-02,
          2.4887e-01],
        [-3.9616e-01, -2.9794e-01, -9.0328e-02, -2.6539e-02,  2.1143e-01,
          4.4724e-01,  1.2192e-01,  1.2628e-01, -3.3544e-02,  1.8368e-01,
          1.2341e-01, -3.2058e-01, -9.1362e-02, -1.1645e-01, -2.8621e-01,
         -1.6742e-01],
        [-8.4176e-02, -1.5989e-01,  1.8127e-01,  8.5843e-02, -2.0366e-01,
         -2.1745e-02, -1.6054e-01, -2.9679e-01, -1.7358e-01, -1.0497e-02,
          1.1628e-02,  4.3614e-01,  1.2486e-01, -8.7994e-02,  4.2474e-01,
          2.8359e-02],
        [ 3.3333e-01,  2.6823e-01,  2.1939e-01, -3.6782e-01, -2.1328e-01,
         -7.2512e-02, -1.2330e-01, -7.0210e-03, -3.6048e-01, -1.8646e-01,
          1.4201e-01,  2.9324e-01,  3.5136e-01,  2.8480e-01,  1.3135e-01,
         -1.9921e-02],
        [-3.1648e-01, -1.6219e-02, -2.6700e-01,  1.5562e-01, -6.0290e-03,
          3.3848e-01,  3.1391e-01,  2.8162e-01,  1.3750e-01,  2.8538e-01,
         -4.0296e-02, -2.5253e-01, -1.7250e-01, -2.2190e-01,  3.8635e-02,
         -1.8428e-01],
        [ 2.5097e-01,  1.2432e-01,  1.7533e-01, -3.1220e-01, -1.4742e-02,
         -4.1362e-01, -3.0992e-01,  2.3432e-02, -3.9280e-01, -1.3351e-01,
         -3.8607e-02, -7.4291e-02,  2.0159e-01,  2.5462e-01,  3.7406e-01,
          2.0371e-01],
        [ 3.8972e-01,  1.3228e-01,  2.9153e-01, -1.0673e-01, -1.7867e-01,
         -2.6664e-01, -3.7529e-01,  2.6754e-02, -3.9928e-02, -2.7639e-01,
         -6.3113e-02,  2.5242e-01, -7.0173e-02,  1.0292e-01,  3.3148e-01,
          2.0285e-01],
        [-2.0408e-01,  7.9123e-02, -7.0917e-02, -4.8217e-02,  1.5480e-01,
          4.8964e-03,  3.3445e-01,  3.9743e-01,  1.9634e-01,  7.6076e-02,
         -7.2281e-02, -3.0673e-01, -2.0862e-01, -2.1051e-01,  3.8137e-02,
         -2.5368e-01],
        [-8.0399e-02, -3.3351e-01, -5.8355e-02,  3.8972e-01, -1.4549e-01,
          1.3955e-01,  2.5363e-01, -6.4827e-02,  1.0247e-02,  2.5080e-01,
          2.4660e-01, -2.6127e-01, -1.5746e-01, -3.3584e-01, -4.5122e-01,
          6.4298e-02],
        [ 3.7637e-01,  2.8362e-02,  6.7104e-02, -1.6869e-01,  1.5374e-01,
         -4.2255e-01, -3.0944e-01, -2.1401e-01, -2.3312e-01, -1.4967e-01,
          1.2282e-01,  2.0361e-01, -1.0631e-01,  3.0857e-01,  3.8122e-01,
          2.2384e-01],
        [ 2.7610e-01,  1.9768e-01,  3.6076e-01, -3.8208e-01, -9.2572e-02,
         -2.0170e-01, -2.0427e-01, -2.7347e-01, -3.4501e-01, -3.2390e-01,
         -1.0149e-01,  3.3888e-01,  2.5900e-01,  1.4560e-01,  9.1395e-03,
          4.0304e-02],
        [ 2.3015e-01, -1.4079e-01,  1.9152e-01, -1.4614e-01,  1.8352e-01,
         -2.9326e-01,  1.9001e-02, -1.9762e-01, -3.7098e-01,  5.6739e-02,
          1.7479e-01,  2.2064e-02,  5.6690e-02,  2.3618e-01,  8.2948e-02,
          3.2668e-01],
        [ 7.5388e-02,  1.1346e-02,  1.2209e-01,  5.2705e-02, -8.5821e-02,
         -2.6605e-01, -5.9635e-02, -3.6823e-01, -1.8822e-01, -3.6561e-01,
         -2.9090e-01,  1.4632e-01,  2.0416e-01,  3.3577e-01, -1.3595e-02,
          8.4647e-02],
        [ 2.3364e-01,  2.0273e-01,  3.1588e-01, -3.5636e-01, -9.1858e-03,
         -1.2580e-01, -3.7550e-01, -3.3864e-03, -3.6218e-01,  9.4729e-03,
          6.1633e-03,  7.5531e-02,  2.0463e-01,  2.9521e-01,  3.6755e-01,
          3.0250e-01],
        [-3.3513e-01, -3.4733e-02, -1.5737e-04,  2.1834e-01,  2.0711e-01,
          5.1883e-02,  3.8126e-01,  1.7389e-01, -5.5564e-02,  9.6725e-02,
          2.1376e-01, -2.7880e-01, -2.1438e-01, -1.8756e-01, -3.4659e-01,
         -1.0770e-01],
        [ 3.2254e-01,  1.4137e-01,  1.5722e-01, -1.4189e-01, -1.8800e-01,
         -3.2067e-01, -1.6424e-01, -3.4605e-01, -1.4119e-02, -1.0959e-01,
          5.4313e-03,  1.4535e-01,  3.1830e-01,  3.0688e-01,  3.0217e-01,
          2.7287e-01],
        [-2.8701e-01,  3.5534e-03, -3.3530e-01,  2.6160e-01, -2.3099e-01,
          1.7972e-01,  3.5443e-01,  2.9715e-01,  3.4435e-01,  2.2960e-01,
          1.8287e-01, -8.0285e-02,  4.5934e-02,  5.1546e-02, -1.0712e-01,
         -2.3239e-01],
        [-3.0208e-01, -1.7518e-01, -6.3376e-02,  3.2352e-02,  5.9406e-02,
          4.1702e-01,  4.0043e-01, -2.5848e-02,  2.1756e-01,  3.2113e-01,
         -1.9508e-01, -1.3757e-02, -2.9290e-01, -2.6549e-01, -3.0428e-01,
         -2.5227e-01],
        [ 8.6229e-02,  2.0179e-01,  2.8638e-01, -9.0353e-02,  1.7172e-01,
         -3.6189e-01, -4.3932e-01, -3.8416e-01, -3.0520e-01, -2.9386e-01,
          3.3845e-02,  4.1567e-03, -5.2097e-03,  2.6200e-01,  5.4881e-02,
          2.0944e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0924, -0.0626,  0.1880, -0.0253, -0.0882, -0.0398,  0.0770,  0.0661,
        -0.0229, -0.0605, -0.0342,  0.0523,  0.1318,  0.1042, -0.0198, -0.0090,
        -0.1386,  0.0196,  0.1206,  0.0221, -0.0193, -0.1802, -0.0087, -0.0467,
        -0.0346,  0.2297,  0.1276,  0.0156, -0.0465, -0.1524,  0.0112,  0.0340],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1962,  0.2876, -0.2129, -0.2451,  0.2703,  0.3200, -0.2642, -0.3666,
         -0.2889,  0.3100,  0.2504,  0.3626, -0.2255, -0.3654,  0.2874, -0.1611,
         -0.2860,  0.3259, -0.2170, -0.2312,  0.3476,  0.3430, -0.3626, -0.3681,
         -0.2656, -0.2962, -0.3081,  0.3308, -0.3525,  0.3733,  0.2870, -0.2253]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0122, -0.0045,  0.0257,  ...,  0.2093, -0.3546, -0.1137],
        [-0.0830, -0.1910,  0.0827,  ...,  0.1457, -0.3307,  0.0871],
        [-0.0529,  0.1589,  0.0913,  ...,  0.0103,  0.2376,  0.0345],
        ...,
        [ 0.0406, -0.1572,  0.0127,  ...,  0.0675, -0.2823, -0.1180],
        [ 0.0357, -0.0692,  0.0064,  ..., -0.3034,  0.1290,  0.1557],
        [-0.0839,  0.1625,  0.0125,  ..., -0.1729,  0.0656, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0511,  0.0543, -0.0931, -0.1202, -0.0574,  0.0456, -0.1293,  0.0622,
        -0.0464,  0.0924,  0.0332,  0.0079,  0.0094,  0.0628, -0.0785, -0.0205,
         0.0467, -0.1420, -0.0322, -0.0149, -0.1091,  0.0481,  0.0818, -0.0067,
        -0.0849,  0.0669,  0.0240, -0.0961,  0.0642,  0.1475,  0.1365, -0.0661],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0367, -0.1982, -0.0791,  ..., -0.1421, -0.0143,  0.2643],
        [-0.2380, -0.0469,  0.1062,  ..., -0.0727, -0.0013,  0.2727],
        [ 0.1664, -0.0176, -0.1779,  ...,  0.0847, -0.0252, -0.0703],
        ...,
        [ 0.1537,  0.1138,  0.0799,  ...,  0.2656, -0.2240,  0.0534],
        [-0.0546, -0.1757,  0.0782,  ...,  0.0006,  0.2506,  0.0880],
        [-0.0200, -0.1237,  0.2127,  ...,  0.0489,  0.1412,  0.1331]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0870,  0.1225, -0.0354, -0.0549, -0.0315, -0.0354, -0.0325, -0.0625,
         0.1100, -0.1753,  0.1224, -0.1329,  0.1650, -0.0183, -0.1429,  0.1054,
        -0.1273, -0.1538,  0.0133, -0.0296,  0.0086,  0.1086, -0.1892,  0.2023,
        -0.0697, -0.0287,  0.0880, -0.0372, -0.1121, -0.0601,  0.1110,  0.0009],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5212,  0.4455, -0.5237, -0.5268,  0.3719,  0.3801, -0.4281,  0.4368,
          0.4367, -0.4596, -0.4497,  0.4106,  0.4327, -0.3737,  0.4537,  0.4021,
         -0.5315, -0.5226,  0.3996,  0.4168, -0.4847, -0.4577, -0.5212,  0.3566,
          0.4959,  0.5222, -0.4962,  0.5643, -0.4318, -0.5135,  0.4984,  0.5133]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2425], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.2961e-02,  3.4673e-01,  3.2227e-01, -3.4667e-01, -3.3792e-02,
         -1.8015e-01, -6.9895e-02, -3.9552e-01, -1.8028e-01, -8.2715e-02,
          3.4005e-02,  1.8012e-01,  6.5795e-02, -5.4543e-02,  3.2146e-01,
          3.5963e-01],
        [-2.7754e-01, -3.3289e-01, -1.2813e-01,  1.4868e-02, -1.5263e-01,
          2.8786e-01,  1.9185e-01,  1.7440e-01,  4.0467e-01,  1.3433e-01,
          2.1626e-01, -2.7819e-01, -5.8444e-03, -4.4560e-02, -4.4825e-03,
         -8.1352e-02],
        [ 9.9221e-02,  2.4023e-01,  4.0084e-01, -1.3924e-01,  1.3385e-01,
         -3.7557e-01, -6.6026e-02, -4.1852e-01,  5.0225e-02, -7.8783e-02,
         -8.9887e-02, -5.6379e-02,  4.0136e-01,  3.0635e-01,  4.3661e-01,
          2.6057e-01],
        [ 2.9313e-01,  6.3021e-02,  1.0668e-01, -9.2770e-02,  9.3320e-02,
         -2.3258e-01, -1.7396e-01, -1.0209e-01, -4.1090e-01, -4.0190e-01,
         -1.0250e-01,  3.7056e-01,  2.9003e-01, -1.2836e-01,  1.4587e-01,
          1.5667e-01],
        [-1.1963e-01,  1.2631e-01, -1.9129e-01, -8.4102e-04,  6.1355e-02,
          1.2782e-01,  7.1258e-02,  3.5321e-01,  1.6526e-01,  2.9283e-01,
          2.2570e-01, -1.9595e-01, -6.0577e-02, -2.2911e-01, -9.1085e-02,
         -1.3510e-01],
        [-2.4038e-02,  1.4939e-01, -3.7711e-01,  4.1501e-01,  1.6538e-01,
          7.4602e-03,  2.7887e-01, -1.7335e-02,  2.5601e-01,  2.0657e-01,
         -1.4109e-01, -1.0188e-01, -2.5323e-01,  1.2886e-01,  2.6925e-02,
         -6.9550e-02],
        [ 3.9390e-01,  1.9560e-01,  4.3218e-01, -2.0325e-01,  1.2154e-01,
         -2.5206e-01, -2.1303e-01, -2.4473e-01, -2.5479e-01, -2.6126e-02,
         -1.4737e-02,  7.1330e-02, -2.7496e-02,  2.2655e-01, -8.4044e-03,
          1.5871e-01],
        [-4.4357e-02,  3.1020e-01,  3.7443e-01, -3.6273e-01, -1.5264e-01,
         -3.3218e-01, -1.1035e-01, -2.5149e-01, -1.8211e-01, -2.1300e-01,
         -6.8393e-02,  2.5553e-02,  2.5902e-01, -8.6116e-02,  1.6399e-01,
          3.6246e-01],
        [ 5.7019e-02,  2.9833e-01,  3.2559e-01, -2.6947e-01,  2.3354e-02,
         -3.8416e-01, -1.8562e-01, -1.1752e-01,  3.7272e-02, -3.1265e-01,
         -1.0743e-01,  8.1156e-02, -7.5014e-02,  1.3869e-01,  1.7881e-02,
          9.2032e-02],
        [-3.0778e-01, -7.9320e-02, -1.1755e-01,  4.1494e-03, -3.5184e-02,
          1.9219e-01,  7.0288e-02,  2.5707e-01,  2.7646e-01, -7.2567e-03,
          2.3292e-01, -2.9516e-02, -2.6785e-01, -6.9111e-02, -1.9251e-01,
         -1.8659e-01],
        [-3.6904e-01,  7.7945e-02, -7.8748e-02, -2.6799e-02, -1.6861e-01,
          4.5615e-01,  2.4701e-01,  1.2477e-01,  3.4092e-01,  2.4651e-01,
          6.2598e-02,  2.9447e-03, -1.6677e-01,  1.3726e-01, -3.9200e-01,
         -3.2631e-01],
        [-1.4512e-01, -1.3845e-01, -4.3062e-02,  1.0574e-01,  1.2022e-01,
          1.5402e-01,  3.9082e-01,  1.6720e-01,  1.7381e-01,  3.4218e-01,
          1.4946e-01,  4.2339e-02, -4.0800e-01, -1.9929e-01, -2.6270e-01,
         -1.9572e-01],
        [ 3.6947e-01,  2.1409e-01,  2.0262e-01, -2.0549e-01,  6.6712e-02,
         -3.1035e-02, -1.1780e-01, -3.4459e-01, -3.4579e-01, -1.2086e-01,
         -1.1627e-01,  5.1370e-02, -1.7350e-02,  1.9513e-01,  1.7769e-01,
          3.1646e-02],
        [ 2.3826e-01,  3.4956e-01,  3.9771e-01, -3.5787e-02, -1.8602e-01,
         -6.5530e-02, -7.5676e-02, -9.2365e-02, -2.2717e-01, -1.7248e-01,
         -2.1076e-01,  1.3277e-01,  1.3865e-01,  7.1860e-02, -2.9902e-02,
          2.4887e-01],
        [-3.9616e-01, -2.9794e-01, -9.0327e-02, -2.6540e-02,  2.1143e-01,
          4.4724e-01,  1.2192e-01,  1.2628e-01, -3.3544e-02,  1.8368e-01,
          1.2341e-01, -3.2058e-01, -9.1363e-02, -1.1645e-01, -2.8621e-01,
         -1.6742e-01],
        [-8.4177e-02, -1.5989e-01,  1.8127e-01,  8.5843e-02, -2.0366e-01,
         -2.1744e-02, -1.6054e-01, -2.9679e-01, -1.7358e-01, -1.0497e-02,
          1.1628e-02,  4.3614e-01,  1.2486e-01, -8.7995e-02,  4.2474e-01,
          2.8358e-02],
        [ 3.3333e-01,  2.6823e-01,  2.1939e-01, -3.6782e-01, -2.1328e-01,
         -7.2512e-02, -1.2330e-01, -7.0217e-03, -3.6048e-01, -1.8646e-01,
          1.4201e-01,  2.9324e-01,  3.5136e-01,  2.8480e-01,  1.3135e-01,
         -1.9921e-02],
        [-3.1648e-01, -1.6218e-02, -2.6700e-01,  1.5562e-01, -6.0281e-03,
          3.3848e-01,  3.1391e-01,  2.8162e-01,  1.3750e-01,  2.8538e-01,
         -4.0297e-02, -2.5253e-01, -1.7250e-01, -2.2190e-01,  3.8635e-02,
         -1.8428e-01],
        [ 2.5097e-01,  1.2432e-01,  1.7533e-01, -3.1220e-01, -1.4743e-02,
         -4.1362e-01, -3.0992e-01,  2.3432e-02, -3.9280e-01, -1.3351e-01,
         -3.8607e-02, -7.4291e-02,  2.0159e-01,  2.5462e-01,  3.7406e-01,
          2.0371e-01],
        [ 3.8972e-01,  1.3228e-01,  2.9153e-01, -1.0673e-01, -1.7868e-01,
         -2.6664e-01, -3.7529e-01,  2.6753e-02, -3.9928e-02, -2.7639e-01,
         -6.3113e-02,  2.5242e-01, -7.0172e-02,  1.0292e-01,  3.3148e-01,
          2.0285e-01],
        [-2.0408e-01,  7.9125e-02, -7.0916e-02, -4.8217e-02,  1.5480e-01,
          4.8962e-03,  3.3445e-01,  3.9743e-01,  1.9634e-01,  7.6075e-02,
         -7.2281e-02, -3.0673e-01, -2.0862e-01, -2.1051e-01,  3.8137e-02,
         -2.5368e-01],
        [-8.0398e-02, -3.3351e-01, -5.8354e-02,  3.8972e-01, -1.4549e-01,
          1.3955e-01,  2.5363e-01, -6.4826e-02,  1.0247e-02,  2.5080e-01,
          2.4660e-01, -2.6127e-01, -1.5746e-01, -3.3584e-01, -4.5122e-01,
          6.4299e-02],
        [ 3.7637e-01,  2.8361e-02,  6.7104e-02, -1.6869e-01,  1.5374e-01,
         -4.2255e-01, -3.0944e-01, -2.1401e-01, -2.3312e-01, -1.4967e-01,
          1.2282e-01,  2.0361e-01, -1.0631e-01,  3.0857e-01,  3.8122e-01,
          2.2384e-01],
        [ 2.7610e-01,  1.9768e-01,  3.6076e-01, -3.8208e-01, -9.2573e-02,
         -2.0170e-01, -2.0427e-01, -2.7347e-01, -3.4501e-01, -3.2390e-01,
         -1.0149e-01,  3.3888e-01,  2.5900e-01,  1.4560e-01,  9.1395e-03,
          4.0303e-02],
        [ 2.3015e-01, -1.4079e-01,  1.9152e-01, -1.4614e-01,  1.8352e-01,
         -2.9326e-01,  1.9001e-02, -1.9762e-01, -3.7099e-01,  5.6740e-02,
          1.7479e-01,  2.2065e-02,  5.6690e-02,  2.3618e-01,  8.2948e-02,
          3.2668e-01],
        [ 7.5388e-02,  1.1345e-02,  1.2209e-01,  5.2705e-02, -8.5822e-02,
         -2.6605e-01, -5.9635e-02, -3.6824e-01, -1.8822e-01, -3.6561e-01,
         -2.9090e-01,  1.4632e-01,  2.0416e-01,  3.3577e-01, -1.3595e-02,
          8.4646e-02],
        [ 2.3364e-01,  2.0273e-01,  3.1588e-01, -3.5636e-01, -9.1866e-03,
         -1.2579e-01, -3.7550e-01, -3.3869e-03, -3.6218e-01,  9.4733e-03,
          6.1637e-03,  7.5532e-02,  2.0463e-01,  2.9521e-01,  3.6755e-01,
          3.0250e-01],
        [-3.3513e-01, -3.4732e-02, -1.5687e-04,  2.1834e-01,  2.0711e-01,
          5.1883e-02,  3.8126e-01,  1.7389e-01, -5.5563e-02,  9.6724e-02,
          2.1376e-01, -2.7880e-01, -2.1438e-01, -1.8755e-01, -3.4659e-01,
         -1.0770e-01],
        [ 3.2254e-01,  1.4136e-01,  1.5721e-01, -1.4189e-01, -1.8800e-01,
         -3.2066e-01, -1.6424e-01, -3.4605e-01, -1.4119e-02, -1.0959e-01,
          5.4318e-03,  1.4535e-01,  3.1830e-01,  3.0688e-01,  3.0217e-01,
          2.7286e-01],
        [-2.8701e-01,  3.5544e-03, -3.3530e-01,  2.6160e-01, -2.3099e-01,
          1.7972e-01,  3.5443e-01,  2.9715e-01,  3.4435e-01,  2.2960e-01,
          1.8287e-01, -8.0286e-02,  4.5933e-02,  5.1547e-02, -1.0712e-01,
         -2.3239e-01],
        [-3.0208e-01, -1.7518e-01, -6.3375e-02,  3.2352e-02,  5.9407e-02,
          4.1702e-01,  4.0043e-01, -2.5847e-02,  2.1756e-01,  3.2113e-01,
         -1.9508e-01, -1.3758e-02, -2.9290e-01, -2.6549e-01, -3.0428e-01,
         -2.5227e-01],
        [ 8.6229e-02,  2.0179e-01,  2.8638e-01, -9.0353e-02,  1.7172e-01,
         -3.6189e-01, -4.3932e-01, -3.8416e-01, -3.0520e-01, -2.9386e-01,
          3.3845e-02,  4.1572e-03, -5.2087e-03,  2.6200e-01,  5.4881e-02,
          2.0944e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0924, -0.0626,  0.1880, -0.0253, -0.0882, -0.0398,  0.0770,  0.0661,
        -0.0229, -0.0605, -0.0342,  0.0523,  0.1318,  0.1042, -0.0198, -0.0090,
        -0.1386,  0.0196,  0.1206,  0.0221, -0.0193, -0.1802, -0.0087, -0.0467,
        -0.0346,  0.2297,  0.1276,  0.0156, -0.0465, -0.1524,  0.0112,  0.0340],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1962,  0.2876, -0.2129, -0.2451,  0.2703,  0.3200, -0.2642, -0.3666,
         -0.2889,  0.3100,  0.2504,  0.3626, -0.2255, -0.3654,  0.2874, -0.1611,
         -0.2860,  0.3259, -0.2170, -0.2312,  0.3476,  0.3430, -0.3626, -0.3681,
         -0.2656, -0.2962, -0.3081,  0.3308, -0.3525,  0.3733,  0.2870, -0.2253]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0122, -0.0045,  0.0257,  ...,  0.2093, -0.3546, -0.1137],
        [-0.0830, -0.1910,  0.0827,  ...,  0.1457, -0.3307,  0.0871],
        [-0.0529,  0.1589,  0.0913,  ...,  0.0103,  0.2376,  0.0345],
        ...,
        [ 0.0406, -0.1572,  0.0127,  ...,  0.0675, -0.2823, -0.1180],
        [ 0.0357, -0.0692,  0.0064,  ..., -0.3034,  0.1290,  0.1557],
        [-0.0839,  0.1625,  0.0125,  ..., -0.1729,  0.0656, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0511,  0.0543, -0.0931, -0.1202, -0.0574,  0.0456, -0.1293,  0.0622,
        -0.0464,  0.0924,  0.0332,  0.0079,  0.0094,  0.0628, -0.0785, -0.0205,
         0.0467, -0.1420, -0.0322, -0.0149, -0.1091,  0.0481,  0.0818, -0.0067,
        -0.0849,  0.0669,  0.0240, -0.0961,  0.0642,  0.1475,  0.1365, -0.0661],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0367, -0.1982, -0.0791,  ..., -0.1421, -0.0143,  0.2643],
        [-0.2380, -0.0469,  0.1062,  ..., -0.0727, -0.0013,  0.2727],
        [ 0.1664, -0.0176, -0.1779,  ...,  0.0847, -0.0252, -0.0703],
        ...,
        [ 0.1537,  0.1138,  0.0799,  ...,  0.2656, -0.2240,  0.0534],
        [-0.0546, -0.1757,  0.0782,  ...,  0.0006,  0.2506,  0.0880],
        [-0.0200, -0.1237,  0.2127,  ...,  0.0489,  0.1412,  0.1331]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0870,  0.1225, -0.0354, -0.0549, -0.0315, -0.0354, -0.0325, -0.0625,
         0.1100, -0.1753,  0.1224, -0.1329,  0.1650, -0.0183, -0.1429,  0.1054,
        -0.1273, -0.1538,  0.0133, -0.0296,  0.0086,  0.1086, -0.1892,  0.2023,
        -0.0697, -0.0287,  0.0880, -0.0372, -0.1121, -0.0601,  0.1110,  0.0009],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5212,  0.4455, -0.5237, -0.5268,  0.3719,  0.3801, -0.4281,  0.4368,
          0.4367, -0.4596, -0.4497,  0.4106,  0.4327, -0.3737,  0.4537,  0.4021,
         -0.5315, -0.5226,  0.3996,  0.4168, -0.4847, -0.4577, -0.5212,  0.3566,
          0.4959,  0.5222, -0.4962,  0.5643, -0.4318, -0.5135,  0.4984,  0.5133]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2425], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 7.6509e-03,  3.5843e-01,  3.2066e-01, -3.1454e-01, -3.2486e-01,
         -2.0437e-01, -9.0915e-02, -4.8300e-01, -2.5852e-01, -8.7287e-02,
         -2.3711e-02,  2.5431e-01,  1.0751e-01, -3.2264e-02,  3.7176e-02,
          3.6897e-01],
        [-2.6031e-01, -3.3605e-01, -1.1483e-01, -1.1571e-02,  6.9043e-02,
          2.8674e-01,  1.9684e-01,  2.3255e-01,  4.5810e-01,  1.5279e-01,
          2.8315e-01, -3.1602e-01, -2.1956e-02, -7.7377e-02,  2.5301e-01,
         -8.2415e-02],
        [ 8.9350e-02,  2.4649e-01,  3.9268e-01, -1.0926e-01, -1.8308e-01,
         -3.8391e-01, -8.1451e-02, -5.0279e-01, -3.6572e-02, -8.5625e-02,
         -1.3635e-01, -6.8374e-05,  4.3632e-01,  3.6522e-01,  1.4805e-01,
          2.6523e-01],
        [ 2.8444e-01,  7.1348e-02,  1.0116e-01, -7.1496e-02, -1.5484e-01,
         -2.4098e-01, -1.9050e-01, -1.8014e-01, -4.9403e-01, -4.2726e-01,
         -1.1797e-01,  4.2960e-01,  3.1007e-01, -7.6098e-02, -1.1892e-01,
          1.6183e-01],
        [-1.0294e-01,  8.7313e-02, -1.8276e-01, -3.1113e-02,  2.6314e-01,
          1.2693e-01,  7.6195e-02,  4.0178e-01,  2.1072e-01,  3.1717e-01,
          3.1806e-01, -2.1956e-01, -7.5511e-02, -2.7745e-01,  1.8725e-01,
         -1.5860e-01],
        [-1.7509e-02,  1.2626e-01, -3.7517e-01,  4.0125e-01,  4.3701e-01,
          1.7025e-02,  2.9627e-01,  4.6903e-02,  3.1962e-01,  2.3607e-01,
         -9.5035e-02, -1.4525e-01, -2.7383e-01,  9.0088e-02,  3.0372e-01,
         -8.2987e-02],
        [ 3.8433e-01,  1.1605e-01,  4.2440e-01, -1.8616e-01, -1.4728e-01,
         -2.5452e-01, -2.1585e-01, -3.1605e-01, -3.2451e-01, -4.9715e-02,
         -5.3852e-02,  1.2178e-01, -3.3011e-02,  2.6846e-01, -1.8124e-01,
          1.6225e-01],
        [-5.1555e-02,  2.6653e-01,  3.6869e-01, -3.5361e-01, -4.0780e-01,
         -3.3147e-01, -1.1414e-01, -3.2540e-01, -2.5248e-01, -2.3521e-01,
         -1.0055e-01,  7.7366e-02,  2.7171e-01, -4.9328e-02,  9.4798e-03,
          3.6281e-01],
        [ 4.7052e-02,  3.0404e-01,  3.1892e-01, -2.4349e-01, -1.4514e-01,
         -3.9101e-01, -2.0182e-01, -1.7993e-01, -2.1619e-02, -3.3820e-01,
         -2.5562e-01,  1.1639e-01, -3.3979e-02,  2.0514e-01, -2.3983e-01,
          1.0027e-01],
        [-2.9955e-01, -1.0484e-01, -1.1475e-01, -1.5457e-02,  1.7653e-01,
          2.0216e-01,  8.8120e-02,  3.2282e-01,  3.3991e-01,  2.4360e-02,
          3.2846e-01, -6.8491e-02, -3.0121e-01, -1.2574e-01,  8.7160e-02,
         -2.0492e-01],
        [-3.7083e-01,  4.8498e-02, -8.3472e-02, -3.3492e-02,  6.4983e-02,
          4.7555e-01,  2.7236e-01,  2.1074e-01,  4.2679e-01,  2.8343e-01,
          1.3143e-01, -6.2309e-02, -1.8848e-01,  6.7898e-02, -8.2974e-02,
         -3.4301e-01],
        [-1.3838e-01, -1.5965e-01, -4.2056e-02,  8.9876e-02,  2.6532e-01,
          1.6553e-01,  4.0716e-01,  2.3415e-01,  2.3271e-01,  3.7641e-01,
          2.4677e-01,  1.4943e-03, -4.0749e-01, -2.8474e-01, -1.9071e-02,
         -2.1370e-01],
        [ 3.5123e-01,  2.4756e-01,  1.8975e-01, -1.7286e-01, -2.5165e-01,
         -4.1292e-02, -1.3707e-01, -4.4321e-01, -4.1462e-01, -1.4328e-01,
         -1.5987e-01,  1.1640e-01, -7.7525e-03,  2.2275e-01, -1.6547e-01,
          4.4864e-02],
        [ 2.2082e-01,  3.3310e-01,  3.8381e-01, -1.3117e-02, -3.9423e-01,
         -6.0779e-02, -7.4333e-02, -1.4206e-01, -2.7557e-01, -1.8944e-01,
         -2.7095e-01,  1.6243e-01,  1.4922e-01,  1.0451e-01, -2.4543e-01,
          2.4724e-01],
        [-3.8664e-01, -2.9622e-01, -8.3129e-02, -4.3471e-02,  4.5746e-01,
          4.4988e-01,  1.3189e-01,  1.9440e-01,  3.3352e-02,  2.0647e-01,
          1.8348e-01, -3.6705e-01, -1.1429e-01, -1.5904e-01, -5.5128e-02,
         -1.7099e-01],
        [-6.2352e-02, -7.5106e-02,  2.1543e-01,  9.1882e-02, -4.5382e-01,
         -9.1114e-02, -2.4004e-01, -4.2692e-01, -2.9898e-01, -9.2440e-02,
         -1.2120e-01,  4.9260e-01,  2.0943e-01,  2.4744e-02,  1.6198e-01,
          7.9598e-02],
        [ 3.2798e-01,  2.6860e-01,  2.1702e-01, -3.5528e-01, -4.5201e-01,
         -8.1647e-02, -1.3879e-01, -7.9153e-02, -4.3346e-01, -2.1493e-01,
          1.0123e-01,  3.4920e-01,  3.8989e-01,  3.3156e-01, -6.2344e-02,
         -1.5456e-02],
        [-3.0624e-01, -7.0005e-03, -2.5967e-01,  1.4288e-01,  2.1182e-01,
          3.3489e-01,  3.1667e-01,  3.3875e-01,  1.9960e-01,  3.0690e-01,
         -2.5311e-03, -2.9361e-01, -1.8434e-01, -2.6771e-01,  2.0191e-01,
         -1.8540e-01],
        [ 2.2763e-01,  1.1557e-01,  1.5256e-01, -2.6725e-01, -3.2692e-01,
         -4.1312e-01, -3.1834e-01, -6.0815e-02, -4.8357e-01, -1.2410e-01,
         -1.0636e-01, -1.9958e-02,  2.6057e-01,  3.1610e-01,  1.0206e-01,
          1.8901e-01],
        [ 3.8657e-01,  1.3459e-01,  2.8950e-01, -9.0590e-02, -4.1488e-01,
         -2.7792e-01, -3.9541e-01, -5.6759e-02, -1.2109e-01, -3.0436e-01,
         -1.4700e-01,  3.1231e-01, -2.9690e-02,  1.6019e-01,  1.0224e-01,
          2.0972e-01],
        [-1.8979e-01,  5.5220e-02, -6.1848e-02, -6.8791e-02,  3.5551e-01,
         -1.4747e-03,  3.3586e-01,  4.2690e-01,  2.3103e-01,  9.4753e-02,
         -1.1452e-02, -3.2046e-01, -2.1628e-01, -2.4458e-01,  2.8943e-01,
         -2.6377e-01],
        [-8.2575e-02, -3.3324e-01, -6.2237e-02,  3.7862e-01,  7.1051e-02,
          1.5958e-01,  2.8908e-01,  2.1618e-02,  9.0176e-02,  2.8949e-01,
          3.7974e-01, -3.1646e-01, -2.2391e-01, -4.0741e-01, -1.8029e-01,
          4.9277e-02],
        [ 3.7736e-01,  3.1675e-02,  6.9605e-02, -1.6555e-01, -7.8592e-02,
         -4.3457e-01, -3.2969e-01, -2.9340e-01, -3.1218e-01, -1.8199e-01,
          6.8005e-02,  2.6200e-01, -6.5090e-02,  3.6515e-01,  1.9479e-01,
          2.3228e-01],
        [ 2.6768e-01,  2.0110e-01,  3.5494e-01, -3.7369e-01, -3.0131e-01,
         -1.9786e-01, -2.0988e-01, -3.4070e-01, -4.1158e-01, -3.4473e-01,
         -9.5286e-02,  3.8746e-01,  2.6976e-01,  1.8410e-01, -1.4184e-01,
          3.6787e-02],
        [ 2.2209e-01, -1.1189e-01,  1.8908e-01, -1.2139e-01, -3.6780e-02,
         -3.0560e-01,  2.2934e-03, -2.5838e-01, -4.3576e-01,  2.4316e-02,
          7.5547e-02,  6.4575e-02,  9.0960e-02,  2.9081e-01, -2.1930e-01,
          3.4909e-01],
        [ 5.1765e-02,  2.8805e-02,  1.0336e-01,  8.1635e-02, -3.0606e-01,
         -2.4943e-01, -4.9041e-02, -3.9745e-01, -2.1801e-01, -3.7640e-01,
         -3.5524e-01,  1.5835e-01,  2.0000e-01,  3.6024e-01, -2.7847e-01,
          8.9653e-02],
        [ 2.3390e-01,  1.9578e-01,  3.1722e-01, -3.5175e-01, -2.5653e-01,
         -1.3699e-01, -3.9374e-01, -8.8866e-02, -4.4554e-01, -2.0885e-02,
         -3.9569e-02,  1.3910e-01,  2.4530e-01,  3.4594e-01,  1.9133e-01,
          3.0821e-01],
        [-3.3053e-01, -5.3224e-02, -5.6856e-04,  2.0542e-01,  4.0183e-01,
          6.6436e-02,  4.0184e-01,  2.5097e-01,  1.3677e-02,  1.3195e-01,
          2.9203e-01, -3.2965e-01, -2.4480e-01, -2.5131e-01, -9.8821e-02,
         -1.2460e-01],
        [ 3.1643e-01,  1.6406e-01,  1.5467e-01, -1.3407e-01, -3.8441e-01,
         -3.2728e-01, -1.7944e-01, -4.1312e-01, -8.0207e-02, -1.3659e-01,
         -2.2318e-03,  1.9574e-01,  3.1666e-01,  3.6135e-01,  7.9043e-02,
          2.7833e-01],
        [-2.8344e-01,  2.2824e-02, -3.3324e-01,  2.5571e-01, -1.0403e-03,
          1.8225e-01,  3.6422e-01,  3.6689e-01,  4.1420e-01,  2.5634e-01,
          2.3594e-01, -1.2932e-01,  2.3886e-02,  2.6099e-03,  5.5152e-02,
         -2.3849e-01],
        [-2.9936e-01, -1.8482e-01, -6.2904e-02,  2.1401e-02,  2.8608e-01,
          4.2874e-01,  4.1832e-01,  4.9864e-02,  2.9398e-01,  3.5120e-01,
         -1.3017e-01, -6.9888e-02, -3.3210e-01, -3.2476e-01, -8.5576e-02,
         -2.5982e-01],
        [ 6.8119e-02,  1.7646e-01,  2.7022e-01, -4.9017e-02, -8.5045e-02,
         -3.6102e-01, -4.4120e-01, -4.5379e-01, -3.8041e-01, -2.9391e-01,
         -3.1409e-02,  4.9055e-02,  1.2927e-02,  3.1648e-01, -1.6415e-01,
          2.0425e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0498, -0.0153,  0.1109, -0.0329, -0.0639, -0.0964,  0.0765,  0.0841,
        -0.0174, -0.0632, -0.0098,  0.0566,  0.1516,  0.0820,  0.0164, -0.0425,
        -0.0484, -0.0064,  0.0942,  0.0083, -0.0480, -0.1414, -0.0260,  0.0017,
         0.0008,  0.1652,  0.1208,  0.0154, -0.0628, -0.1434,  0.0283, -0.0412],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2369,  0.3271, -0.2330, -0.2674,  0.3296,  0.3682, -0.2868, -0.3892,
         -0.3193,  0.3531,  0.2694,  0.3795, -0.2707, -0.4036,  0.3094, -0.2962,
         -0.3260,  0.3364, -0.2339, -0.2551,  0.4068,  0.3178, -0.3767, -0.3833,
         -0.3365, -0.3455, -0.3184,  0.3575, -0.3648,  0.3876,  0.2949, -0.2422]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0139, -0.0093,  0.0440,  ...,  0.2362, -0.3707, -0.1137],
        [-0.0867, -0.1926,  0.0881,  ...,  0.1477, -0.3510,  0.0871],
        [-0.0398,  0.1767,  0.0726,  ..., -0.0051,  0.2715,  0.0345],
        ...,
        [ 0.0254, -0.1914,  0.0429,  ...,  0.0660, -0.2977, -0.1180],
        [ 0.0513, -0.0487, -0.0198,  ..., -0.3044,  0.1563,  0.1557],
        [-0.2051,  0.0491,  0.0026,  ...,  0.0416, -0.2431, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0566,  0.0571, -0.0876, -0.1193, -0.0578,  0.0531, -0.1275,  0.0606,
        -0.0487,  0.0815,  0.0309,  0.0097,  0.0262,  0.0737, -0.0778, -0.0170,
         0.0494, -0.1501, -0.0290, -0.0243, -0.0746,  0.0445,  0.0890, -0.0067,
        -0.0874,  0.0871,  0.0331, -0.0873,  0.0484,  0.1381,  0.1479, -0.1056],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0170, -0.1918, -0.0775,  ..., -0.1182, -0.0250,  0.0701],
        [-0.2666, -0.0459,  0.1186,  ..., -0.0503, -0.0038,  0.0580],
        [ 0.1851, -0.0280, -0.1792,  ...,  0.0559, -0.0111,  0.1679],
        ...,
        [ 0.1670,  0.0978,  0.0871,  ...,  0.2296, -0.2028,  0.2426],
        [-0.0800, -0.1657,  0.0808,  ...,  0.0306,  0.2393, -0.1664],
        [-0.0499, -0.1265,  0.2181,  ...,  0.0696,  0.1368, -0.0326]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0836,  0.1216, -0.0230, -0.0590, -0.0343, -0.0627, -0.0261, -0.0596,
         0.0944, -0.1349,  0.1350, -0.1268,  0.1515,  0.0575, -0.1342,  0.0873,
        -0.1178, -0.1455,  0.0029, -0.0138,  0.0070,  0.1096, -0.1836,  0.1727,
        -0.0640, -0.0311,  0.0908, -0.0422, -0.1091, -0.0534,  0.0950,  0.0032],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5320,  0.4543, -0.5312, -0.5339,  0.3989,  0.3898, -0.4458,  0.4403,
          0.4650, -0.4695, -0.4289,  0.4253,  0.4243,  0.4346,  0.4631,  0.4170,
         -0.5325, -0.5379,  0.4020,  0.4278, -0.4876, -0.4658, -0.5321,  0.3927,
          0.5162,  0.5399, -0.5157,  0.5650, -0.4443, -0.5292,  0.5110,  0.5319]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2499], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.2770e-02,  5.1567e-02,  2.9348e-01, -3.3033e-01, -2.9209e-01,
         -1.5054e-01, -5.7192e-02, -4.5893e-01, -2.1189e-01, -5.3632e-02,
          1.8159e-01,  2.0034e-01,  6.3412e-02, -5.7901e-02, -1.9194e-01,
          3.6707e-01],
        [-2.6371e-01, -6.1882e-02, -9.9915e-02,  1.4526e-02,  4.7094e-02,
          2.4766e-01,  1.6636e-01,  2.0934e-01,  4.4171e-01,  1.3791e-01,
          6.5944e-02, -2.7657e-01, -1.0985e-02, -5.9529e-02,  4.7035e-01,
         -8.2779e-02],
        [ 9.0311e-02, -6.6025e-03,  3.6990e-01, -1.2572e-01, -1.4202e-01,
         -3.4093e-01, -3.9198e-02, -4.6459e-01,  7.6531e-03, -6.0726e-02,
         -7.7987e-02, -4.8096e-02,  4.0435e-01,  3.2305e-01, -6.6273e-02,
          2.6081e-01],
        [ 2.7232e-01, -6.7532e-02,  6.9057e-02, -8.2027e-02, -1.1143e-01,
         -1.8058e-01, -1.3666e-01, -1.3375e-01, -4.4717e-01, -3.9198e-01,
          3.3613e-02,  3.6284e-01,  2.9512e-01, -1.1712e-01, -2.9742e-01,
          1.4295e-01],
        [-1.0255e-01,  3.4956e-01, -1.6198e-01, -6.5142e-03,  2.3105e-01,
          8.0532e-02,  3.7100e-02,  3.6868e-01,  1.8034e-01,  2.9786e-01,
          6.4332e-02, -1.7179e-01, -5.6607e-02, -2.4932e-01,  3.8604e-01,
         -1.5625e-01],
        [-5.4867e-03,  3.2515e-01, -3.4824e-01,  4.1419e-01,  3.7799e-01,
         -4.2119e-02,  2.4803e-01,  1.9875e-05,  2.7968e-01,  2.0870e-01,
         -1.1445e-01, -9.1733e-02, -2.3518e-01,  1.1963e-01,  4.5516e-01,
         -7.3575e-02],
        [ 3.7453e-01, -1.8847e-02,  3.9719e-01, -1.9862e-01, -1.1553e-01,
         -2.0476e-01, -1.6780e-01, -2.7702e-01, -2.8162e-01, -2.3694e-02,
          6.2970e-03,  6.9870e-02, -6.0618e-02,  1.8349e-01, -3.6528e-01,
          1.4950e-01],
        [-5.9249e-02,  1.2692e-01,  3.4768e-01, -3.6817e-01, -3.8650e-01,
         -2.9500e-01, -8.0270e-02, -3.0159e-01, -2.2890e-01, -2.1930e-01,
         -5.5302e-02,  4.3751e-02,  2.5398e-01, -9.6608e-02, -1.4902e-01,
          3.5369e-01],
        [ 5.1871e-02,  6.5196e-03,  3.0486e-01, -2.7318e-01, -1.2911e-01,
         -3.5156e-01, -1.7220e-01, -1.5902e-01, -1.2800e-03, -3.2495e-01,
          1.7295e-02,  7.8217e-02, -4.3806e-02,  1.8975e-01, -4.4723e-01,
          1.0441e-01],
        [-3.0246e-01,  1.7936e-01, -1.0021e-01,  1.2929e-02,  1.4618e-01,
          1.5908e-01,  5.2571e-02,  2.9052e-01,  3.1186e-01,  9.3122e-03,
          1.0491e-01, -2.6828e-02, -2.8162e-01, -1.0849e-01,  2.8861e-01,
         -2.0824e-01],
        [-3.6537e-01,  2.2816e-01, -5.7530e-02, -1.7424e-02,  3.1494e-02,
          4.2434e-01,  2.3205e-01,  1.7453e-01,  3.9178e-01,  2.5636e-01,
         -2.4663e-04, -9.0782e-03, -2.1481e-01,  8.3725e-02,  9.9462e-02,
         -3.3367e-01],
        [-1.2912e-01,  3.2764e-02, -1.5452e-02,  1.0707e-01,  2.1959e-01,
          1.1710e-01,  3.5233e-01,  1.8575e-01,  1.8839e-01,  3.4829e-01,
          8.4887e-02,  5.7285e-02, -4.2106e-01, -2.3865e-01,  1.4215e-01,
         -2.0199e-01],
        [ 3.4894e-01, -1.6745e-02,  1.5923e-01, -1.9435e-01, -1.9993e-01,
          2.1892e-02, -9.0131e-02, -3.9687e-01, -3.7802e-01, -1.1107e-01,
         -9.2951e-02,  5.4981e-02, -1.2231e-02,  2.0465e-01, -4.0694e-01,
          3.6695e-02],
        [ 2.1725e-01,  9.7459e-02,  3.6541e-01, -3.3031e-02, -3.6648e-01,
         -2.2665e-02, -3.7051e-02, -1.1278e-01, -2.5493e-01, -1.7231e-01,
         -1.0448e-01,  1.2353e-01,  1.3269e-01,  6.6825e-02, -4.3940e-01,
          2.4202e-01],
        [-3.8726e-01, -4.9996e-02, -6.5990e-02, -2.0246e-02,  4.4061e-01,
          4.1468e-01,  1.0155e-01,  1.7382e-01,  1.2031e-02,  1.9255e-01,
          2.9932e-02, -3.3037e-01, -1.0851e-01, -1.3609e-01,  1.6461e-01,
         -1.6852e-01],
        [-3.2454e-02, -4.1557e-01,  1.9806e-01,  3.7532e-02, -4.5328e-01,
         -2.4112e-02, -2.0099e-01, -4.1555e-01, -2.8360e-01, -6.8906e-02,
         -5.0963e-02,  4.4780e-01,  1.9104e-01, -2.3098e-02, -1.0970e-01,
          9.8288e-02],
        [ 3.1739e-01,  8.9359e-02,  1.9061e-01, -3.6633e-01, -3.9234e-01,
         -2.9623e-02, -8.3949e-02, -3.1225e-02, -4.0124e-01, -1.8524e-01,
          1.9762e-01,  2.9318e-01,  3.4975e-01,  2.6699e-01, -2.0342e-01,
         -3.1544e-02],
        [-2.8995e-01,  1.2589e-01, -2.2812e-01,  1.4859e-01,  1.5449e-01,
          2.8471e-01,  2.6329e-01,  2.9385e-01,  1.5437e-01,  2.7849e-01,
         -5.6312e-02, -2.4068e-01, -1.4660e-01, -1.9119e-01,  2.9434e-01,
         -1.6643e-01],
        [ 2.3838e-01, -1.0141e-01,  1.4070e-01, -2.9306e-01, -2.5430e-01,
         -3.7457e-01, -2.7335e-01, -1.6918e-02, -4.3516e-01, -1.0764e-01,
          2.1852e-02, -6.8704e-02,  2.0339e-01,  2.5331e-01, -7.6432e-02,
          1.9313e-01],
        [ 3.8012e-01, -7.5824e-02,  2.6055e-01, -1.0684e-01, -3.8540e-01,
         -2.3121e-01, -3.5116e-01, -2.5018e-02, -8.7382e-02, -2.7716e-01,
          9.7390e-02,  2.5950e-01, -3.6975e-02,  1.1578e-01, -1.1184e-01,
          1.9684e-01],
        [-1.7817e-01,  2.4707e-01, -3.4952e-02, -5.7767e-02,  3.0532e-01,
         -4.7909e-02,  2.9291e-01,  3.8752e-01,  1.9816e-01,  7.1073e-02,
         -1.1025e-01, -2.7374e-01, -1.9538e-01, -2.0324e-01,  4.2643e-01,
         -2.5163e-01],
        [-9.7104e-02,  2.6688e-02, -5.5857e-02,  4.1650e-01,  7.0639e-02,
          1.2715e-01,  2.6632e-01,  1.1431e-02,  8.4582e-02,  2.8518e-01,
          2.0915e-01, -2.9643e-01, -2.2230e-01, -3.9432e-01,  1.3242e-02,
          4.1951e-02],
        [ 3.7247e-01, -1.6053e-01,  4.8442e-02, -1.8359e-01, -5.0510e-02,
         -3.9729e-01, -2.9173e-01, -2.6866e-01, -2.8698e-01, -1.6499e-01,
          2.1119e-01,  2.2500e-01, -6.8195e-02,  3.2173e-01,  2.1068e-02,
          2.2292e-01],
        [ 2.5091e-01,  1.0878e-01,  3.2526e-01, -3.7804e-01, -2.3139e-01,
         -1.5110e-01, -1.5658e-01, -2.9623e-01, -3.7233e-01, -3.1424e-01,
          2.1323e-02,  3.3882e-01,  2.6096e-01,  1.1797e-01, -2.2957e-01,
          1.2123e-02],
        [ 2.1836e-01, -3.7938e-01,  1.6877e-01, -1.4603e-01,  4.8382e-03,
         -2.5070e-01,  4.8843e-02, -2.1154e-01, -3.9304e-01,  4.6863e-02,
          1.9853e-01,  1.0637e-02,  6.0423e-02,  2.6927e-01, -4.1601e-01,
          3.4867e-01],
        [ 4.7431e-02, -1.8788e-01,  8.1687e-02,  6.4664e-02, -2.6470e-01,
         -2.1029e-01, -1.9391e-02, -3.6633e-01, -1.9188e-01, -3.5865e-01,
         -2.6448e-01,  1.1816e-01,  1.9716e-01,  3.3625e-01, -4.7434e-01,
          8.2624e-02],
        [ 2.2407e-01, -1.7879e-02,  2.8766e-01, -3.6254e-01, -2.1845e-01,
         -9.6262e-02, -3.4396e-01, -5.7496e-02, -4.1035e-01,  3.7307e-03,
          5.2628e-02,  9.2384e-02,  2.3213e-01,  2.6792e-01,  3.0643e-02,
          2.9022e-01],
        [-3.3020e-01,  1.8058e-01,  1.9704e-02,  2.2887e-01,  3.6718e-01,
          2.2913e-02,  3.5616e-01,  2.1417e-01, -2.3064e-02,  1.1156e-01,
          6.9041e-02, -2.8127e-01, -2.3273e-01, -2.1035e-01,  7.9443e-02,
         -1.2049e-01],
        [ 3.0356e-01,  3.8021e-02,  1.2476e-01, -1.4423e-01, -3.3352e-01,
         -2.8203e-01, -1.3263e-01, -3.7195e-01, -4.2666e-02, -1.0849e-01,
          1.1621e-01,  1.4338e-01,  3.5488e-01,  3.1943e-01, -5.5327e-02,
          2.6044e-01],
        [-2.7328e-01,  1.6391e-01, -3.0929e-01,  2.6808e-01, -3.0213e-02,
          1.4359e-01,  3.2397e-01,  3.3724e-01,  3.8361e-01,  2.3672e-01,
          1.4361e-01, -9.1776e-02,  4.3638e-02,  5.4455e-02,  2.1126e-01,
         -2.2590e-01],
        [-2.8854e-01,  2.4927e-02, -3.3184e-02,  3.3220e-02,  2.4342e-01,
          3.7838e-01,  3.6959e-01,  1.2767e-02,  2.5750e-01,  3.2367e-01,
         -2.3541e-01, -1.4964e-02, -3.1410e-01, -2.7566e-01,  8.5552e-02,
         -2.4418e-01],
        [ 6.3057e-02, -2.3569e-02,  2.4228e-01, -6.5396e-02, -4.3530e-02,
         -3.1119e-01, -3.8651e-01, -4.0139e-01, -3.3048e-01, -2.6405e-01,
          9.8577e-02, -1.3436e-02, -3.3741e-02,  2.2444e-01, -3.4899e-01,
          1.9444e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0627, -0.0597,  0.1193, -0.0757, -0.0514, -0.0277,  0.0854,  0.1389,
        -0.0448, -0.0646,  0.0241,  0.0676,  0.1908,  0.1088, -0.0585,  0.0975,
        -0.1516, -0.0069,  0.0248,  0.0031, -0.0192, -0.1114, -0.0582, -0.0245,
        -0.1606,  0.2592,  0.1065,  0.0244, -0.0826, -0.2293,  0.1597, -0.0283],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2592,  0.3461, -0.2511, -0.2656,  0.3495,  0.3888, -0.3030, -0.3872,
         -0.3381,  0.3940,  0.2702,  0.3972, -0.2937, -0.4293,  0.3272, -0.3257,
         -0.3322,  0.3327, -0.2425, -0.2619,  0.4267,  0.3470, -0.3784, -0.3793,
         -0.3899, -0.3656, -0.3239,  0.3726, -0.3525,  0.3906,  0.2941, -0.2448]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0532,  0.1280,  0.0571,  ...,  0.2206, -0.3330, -0.1137],
        [-0.1218, -0.0307,  0.1167,  ...,  0.1557, -0.3320,  0.0871],
        [ 0.0117, -0.0586,  0.0188,  ...,  0.0275,  0.2353,  0.0345],
        ...,
        [-0.0039,  0.0336,  0.0576,  ...,  0.0853, -0.3231, -0.1180],
        [ 0.0983, -0.2285, -0.0531,  ..., -0.3287,  0.1550,  0.1557],
        [-0.2175,  0.1703,  0.0372,  ...,  0.0984, -0.2818, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0412,  0.0407, -0.0664, -0.1339, -0.0720,  0.0600, -0.1104,  0.0456,
        -0.0386,  0.0800,  0.0173,  0.0116,  0.0300,  0.0788, -0.0527, -0.0185,
         0.0586, -0.1550,  0.0024,  0.0280, -0.0498,  0.0328,  0.1091,  0.0057,
        -0.0936,  0.1045,  0.0473, -0.0937,  0.0538,  0.1392,  0.1670, -0.1228],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0758, -0.1830, -0.1160,  ..., -0.1343, -0.0151,  0.0739],
        [-0.2049, -0.0390,  0.0846,  ..., -0.0672,  0.0085,  0.0482],
        [ 0.1364, -0.0246, -0.1597,  ...,  0.0853, -0.0277,  0.1886],
        ...,
        [ 0.1166,  0.0961,  0.1207,  ...,  0.2559, -0.2262,  0.2466],
        [-0.0052, -0.1503,  0.0388,  ...,  0.0146,  0.2372, -0.1683],
        [-0.0023, -0.1357,  0.1989,  ...,  0.0332,  0.1648, -0.0513]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1030,  0.1473, -0.0585, -0.0834, -0.0004, -0.0434, -0.0577, -0.0440,
         0.1236, -0.1692,  0.1276, -0.1171,  0.1719,  0.0867, -0.1230,  0.1250,
        -0.1388, -0.1724, -0.0581, -0.0033, -0.0026,  0.0851, -0.2103,  0.2129,
        -0.0458, -0.0047,  0.0747, -0.0287, -0.1358, -0.0728,  0.1203,  0.0420],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4697,  0.3898, -0.4751, -0.4643,  0.3425,  0.3245, -0.3879,  0.3606,
          0.3888, -0.4120, -0.3585,  0.3754,  0.3584,  0.3383,  0.4026,  0.3976,
         -0.4654, -0.4786, -0.3332,  0.3789, -0.4234, -0.4020, -0.4757,  0.3217,
          0.4456,  0.4796, -0.4633,  0.4687, -0.3897, -0.4667,  0.4513,  0.4767]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2301], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-9.4905e-03,  3.5192e-01,  2.8314e-01, -3.0039e-01, -2.8358e-01,
         -1.2932e-01, -3.8975e-02, -4.4365e-01, -2.0171e-01, -3.6046e-02,
          1.5695e-01,  1.7615e-01,  4.6755e-02, -6.4732e-02, -1.7673e-01,
          3.4643e-01],
        [-2.4407e-01, -3.4371e-01, -8.4729e-02, -9.9668e-03,  3.5157e-02,
          2.3261e-01,  1.5582e-01,  1.9387e-01,  4.2361e-01,  1.2275e-01,
          7.0246e-02, -2.5549e-01,  1.2022e-03, -5.2288e-02,  4.5722e-01,
         -6.3949e-02],
        [ 6.9887e-02,  2.4104e-01,  3.5589e-01, -1.0135e-01, -1.4071e-01,
         -3.2798e-01, -3.1223e-02, -4.5812e-01,  1.3885e-02, -4.5698e-02,
         -8.4051e-02, -6.6077e-02,  3.9787e-01,  3.2389e-01, -5.5664e-02,
          2.4264e-01],
        [ 2.5598e-01,  6.6587e-02,  6.0779e-02, -6.4081e-02, -1.0861e-01,
         -1.7147e-01, -1.3416e-01, -1.2199e-01, -4.3920e-01, -3.8258e-01,
          2.8025e-02,  3.4924e-01,  2.9148e-01, -1.1376e-01, -2.9409e-01,
          1.2757e-01],
        [-9.5615e-02,  8.7445e-02, -1.5739e-01, -2.3170e-02,  2.4596e-01,
          7.4403e-02,  4.2503e-02,  3.7774e-01,  1.8621e-01,  2.9169e-01,
          8.6768e-02, -1.6447e-01, -6.6657e-02, -2.6201e-01,  4.0640e-01,
         -1.4607e-01],
        [ 5.9024e-04,  1.2671e-01, -3.4612e-01,  4.0177e-01,  3.8849e-01,
         -4.1179e-02,  2.5116e-01, -1.3068e-03,  2.7922e-01,  2.0500e-01,
         -1.1846e-01, -8.5765e-02, -2.4771e-01,  1.1170e-01,  4.9703e-01,
         -6.6326e-02],
        [ 3.5659e-01,  1.2087e-01,  3.8538e-01, -1.7797e-01, -1.0956e-01,
         -1.9616e-01, -1.6304e-01, -2.6373e-01, -2.6307e-01, -1.2424e-02,
          5.3949e-03,  5.4577e-02, -6.6071e-02,  1.8380e-01, -3.6369e-01,
          1.3380e-01],
        [-7.7181e-02,  2.7292e-01,  3.3508e-01, -3.4643e-01, -3.6767e-01,
         -2.8482e-01, -7.0884e-02, -2.8299e-01, -2.0944e-01, -2.0705e-01,
         -6.8698e-02,  2.5570e-02,  2.4437e-01, -9.9938e-02, -1.3562e-01,
          3.3870e-01],
        [ 3.4257e-02,  3.1723e-01,  2.9194e-01, -2.5129e-01, -1.1336e-01,
         -3.3849e-01, -1.6293e-01, -1.4188e-01,  1.2810e-02, -3.1144e-01,
          1.0146e-02,  5.9792e-02, -5.3361e-02,  1.8532e-01, -4.3653e-01,
          8.6162e-02],
        [-2.9217e-01, -1.1043e-01, -9.2350e-02, -5.4338e-03,  1.5007e-01,
          1.5085e-01,  5.1512e-02,  2.9054e-01,  3.0975e-01,  6.8428e-04,
          1.2591e-01, -1.5114e-02, -2.8346e-01, -1.1163e-01,  2.9558e-01,
         -1.9621e-01],
        [-3.5547e-01,  4.7304e-02, -5.3670e-02, -2.9223e-02,  3.6125e-02,
          4.1894e-01,  2.3201e-01,  1.7166e-01,  3.9152e-01,  2.5102e-01,
         -9.5995e-03, -1.5110e-03, -2.1258e-01,  7.3286e-02,  1.1154e-01,
         -3.2311e-01],
        [-1.1647e-01, -1.5128e-01, -7.7773e-03,  9.0369e-02,  2.1312e-01,
          1.0635e-01,  3.5219e-01,  1.8057e-01,  1.8046e-01,  3.4055e-01,
          1.0674e-01,  6.8878e-02, -4.1485e-01, -2.4849e-01,  1.3837e-01,
         -1.8959e-01],
        [ 3.2810e-01,  2.4501e-01,  1.4451e-01, -1.6660e-01, -2.0770e-01,
          4.0202e-02, -8.2263e-02, -3.9486e-01, -3.6965e-01, -9.4352e-02,
         -9.4500e-02,  3.2606e-02, -2.0132e-02,  2.0241e-01, -4.0252e-01,
          1.8164e-02],
        [ 1.9899e-01,  3.3829e-01,  3.5043e-01, -1.1250e-02, -3.5273e-01,
         -9.7376e-03, -2.9275e-02, -9.7455e-02, -2.3509e-01, -1.5847e-01,
         -1.0792e-01,  1.0531e-01,  1.2220e-01,  6.2862e-02, -4.2836e-01,
          2.2513e-01],
        [-3.6993e-01, -3.0532e-01, -5.3477e-02, -4.1589e-02,  4.2920e-01,
          4.0232e-01,  9.3650e-02,  1.5931e-01, -1.7357e-03,  1.7972e-01,
          3.4362e-02, -3.1285e-01, -9.9244e-02, -1.3317e-01,  1.5094e-01,
         -1.5203e-01],
        [-3.0175e-01, -2.2396e-01,  1.7428e-02,  2.5789e-01,  1.5318e-01,
          1.7831e-01,  1.0311e-01,  8.7735e-02,  1.7088e-01,  1.3122e-01,
          3.9577e-02,  1.4464e-01, -1.5615e-01, -2.9947e-01,  6.0280e-01,
         -9.2260e-02],
        [ 2.9890e-01,  2.3782e-01,  1.8093e-01, -3.4684e-01, -3.8174e-01,
         -1.8571e-02, -8.0098e-02, -1.0623e-02, -3.8491e-01, -1.7481e-01,
          1.7724e-01,  2.7760e-01,  3.3830e-01,  2.7224e-01, -1.7936e-01,
         -4.6938e-02],
        [-2.7444e-01,  4.1981e-02, -2.1936e-01,  1.2933e-01,  1.4896e-01,
          2.7932e-01,  2.6120e-01,  2.8134e-01,  1.4237e-01,  2.7000e-01,
         -5.1999e-02, -2.2753e-01, -1.4828e-01, -1.9050e-01,  2.9358e-01,
         -1.5227e-01],
        [ 2.2027e-01,  1.1397e-01,  1.3222e-01, -2.7243e-01, -2.5306e-01,
         -3.6390e-01, -2.7043e-01, -8.1962e-03, -4.3307e-01, -9.6244e-02,
          2.4903e-02, -8.3018e-02,  1.9849e-01,  2.5890e-01, -6.3303e-02,
          1.7467e-01],
        [ 3.6489e-01,  1.3955e-01,  2.5356e-01, -9.0112e-02, -3.7983e-01,
         -2.2054e-01, -3.5092e-01, -1.2717e-02, -8.0408e-02, -2.6814e-01,
          9.0722e-02,  2.4736e-01, -4.2319e-02,  1.2699e-01, -1.0512e-01,
          1.8111e-01],
        [-1.6774e-01,  6.4969e-02, -2.7393e-02, -7.4448e-02,  3.0968e-01,
         -5.2984e-02,  2.9458e-01,  3.8563e-01,  1.9255e-01,  6.3916e-02,
         -9.4747e-02, -2.6371e-01, -2.0103e-01, -2.1220e-01,  4.5897e-01,
         -2.4131e-01],
        [-8.4693e-02, -3.3757e-01, -5.0547e-02,  3.9832e-01,  5.4378e-02,
          1.1846e-01,  2.6290e-01, -2.1835e-03,  7.5101e-02,  2.7670e-01,
          2.2548e-01, -2.8027e-01, -2.1821e-01, -3.9775e-01,  6.2706e-03,
          5.3733e-02],
        [ 3.6213e-01,  2.1997e-02,  4.3728e-02, -1.6937e-01, -4.7451e-02,
         -3.9190e-01, -2.9409e-01, -2.6045e-01, -2.8134e-01, -1.5988e-01,
          1.9040e-01,  2.1685e-01, -6.7794e-02,  3.2926e-01,  2.7194e-02,
          2.1245e-01],
        [ 2.3016e-01,  1.7716e-01,  3.1363e-01, -3.5565e-01, -2.1453e-01,
         -1.3985e-01, -1.5006e-01, -2.7043e-01, -3.5224e-01, -3.0293e-01,
          9.1545e-03,  3.1955e-01,  2.4979e-01,  1.1646e-01, -2.0074e-01,
         -3.5706e-03],
        [ 2.1439e-01, -9.6782e-02,  1.6766e-01, -1.3474e-01, -5.1865e-03,
         -2.4937e-01,  4.3760e-02, -2.1555e-01, -3.9649e-01,  4.9153e-02,
          2.0466e-01,  7.0130e-03,  6.9507e-02,  2.8140e-01, -4.3091e-01,
          3.4333e-01],
        [ 3.4251e-02,  3.9150e-02,  7.1044e-02,  8.3151e-02, -2.6716e-01,
         -2.0219e-01, -1.3248e-02, -3.6379e-01, -1.8471e-01, -3.4885e-01,
         -2.7355e-01,  1.0464e-01,  1.9644e-01,  3.3952e-01, -4.9137e-01,
          7.0460e-02],
        [ 2.0773e-01,  1.6558e-01,  2.7916e-01, -3.4476e-01, -2.0878e-01,
         -8.5382e-02, -3.4418e-01, -4.1865e-02, -3.9819e-01,  1.2724e-02,
          3.3877e-02,  7.9927e-02,  2.2390e-01,  2.8311e-01,  4.1704e-02,
          2.7661e-01],
        [-3.2164e-01, -5.1165e-02,  2.2724e-02,  2.1416e-01,  3.6960e-01,
          1.5373e-02,  3.6005e-01,  2.1340e-01, -2.4296e-02,  1.0713e-01,
          9.1540e-02, -2.7323e-01, -2.3454e-01, -2.2752e-01,  9.0272e-02,
         -1.1117e-01],
        [ 2.8676e-01,  1.5648e-01,  1.1453e-01, -1.2595e-01, -3.2362e-01,
         -2.6939e-01, -1.2995e-01, -3.5717e-01, -2.9339e-02, -9.8470e-02,
          9.7741e-02,  1.2892e-01,  3.4496e-01,  3.2464e-01, -4.2735e-02,
          2.4647e-01],
        [-2.6111e-01,  1.9719e-02, -3.0186e-01,  2.5148e-01, -3.4600e-02,
          1.3858e-01,  3.2372e-01,  3.2907e-01,  3.7441e-01,  2.3002e-01,
          1.4891e-01, -8.1061e-02,  4.2321e-02,  4.7786e-02,  2.1830e-01,
         -2.1491e-01],
        [-2.7329e-01, -1.6326e-01, -2.5734e-02,  1.6060e-02,  2.3508e-01,
          3.6967e-01,  3.6810e-01, -2.9114e-03,  2.4828e-01,  3.1476e-01,
         -2.2198e-01, -2.9903e-03, -3.0975e-01, -2.7988e-01,  6.8396e-02,
         -2.2913e-01],
        [ 4.1099e-02,  1.3520e-01,  2.2938e-01, -4.0201e-02, -3.6733e-02,
         -2.9782e-01, -3.8189e-01, -3.9398e-01, -3.2186e-01, -2.5044e-01,
          9.3355e-02, -3.0292e-02, -4.2631e-02,  2.2444e-01, -3.3018e-01,
          1.7408e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0831, -0.0347,  0.1186, -0.0762, -0.0530, -0.0291,  0.0884,  0.1378,
        -0.0537, -0.0513,  0.0048,  0.0888,  0.1643,  0.0931, -0.0400, -0.0591,
        -0.1748, -0.0020,  0.0131, -0.0102, -0.0188, -0.0893, -0.0682, -0.0369,
        -0.1282,  0.2670,  0.0871,  0.0410, -0.0993, -0.2292,  0.1814, -0.0412],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2592,  0.3438, -0.2514, -0.2703,  0.3720,  0.4046, -0.3061, -0.3847,
         -0.3511,  0.3983,  0.2775,  0.3950, -0.3012, -0.4325,  0.3251,  0.3120,
         -0.3308,  0.3355, -0.2439, -0.2625,  0.4312,  0.3418, -0.3800, -0.3785,
         -0.4177, -0.3736, -0.3234,  0.3726, -0.3540,  0.3924,  0.2963, -0.2478]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0166,  0.1037,  0.0777,  ...,  0.1580, -0.2644, -0.1137],
        [-0.1137, -0.0398,  0.1178,  ...,  0.1305, -0.3126,  0.0871],
        [-0.0022, -0.0408,  0.0313,  ...,  0.0276,  0.2329,  0.0345],
        ...,
        [ 0.0072,  0.0222,  0.0544,  ...,  0.0663, -0.3133, -0.1180],
        [ 0.0935, -0.2211, -0.0538,  ..., -0.3022,  0.1404,  0.1557],
        [-0.1973,  0.1629,  0.0398,  ...,  0.0653, -0.2725, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0465,  0.0408, -0.0703, -0.1356, -0.0731,  0.0517, -0.1108,  0.0500,
        -0.0401,  0.0779,  0.0233,  0.0121,  0.0252,  0.0751, -0.0514, -0.0202,
         0.0573, -0.1579, -0.0618,  0.0365, -0.0557,  0.0301,  0.1057,  0.0067,
        -0.0889,  0.0533,  0.0430, -0.1134,  0.0542,  0.1429,  0.1672, -0.1271],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0638, -0.1809, -0.1070,  ..., -0.1217, -0.0238,  0.0742],
        [-0.2148, -0.0370,  0.1065,  ..., -0.0509, -0.0075,  0.0472],
        [ 0.1404, -0.0286, -0.1675,  ...,  0.0670, -0.0115,  0.1835],
        ...,
        [ 0.1132,  0.0790,  0.1236,  ...,  0.2335, -0.2043,  0.2315],
        [-0.0104, -0.1494,  0.0520,  ...,  0.0372,  0.2192, -0.1681],
        [-0.0016, -0.1239,  0.1964,  ...,  0.0583,  0.1429, -0.0382]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1061,  0.1594, -0.0596, -0.0822, -0.0064, -0.0423, -0.0570, -0.0429,
         0.1338, -0.1772,  0.1140, -0.1295,  0.1917,  0.1028, -0.1264,  0.1335,
        -0.1376, -0.1718,  0.0440, -0.0117, -0.0055,  0.0871, -0.1992,  0.2354,
        -0.0438, -0.0076,  0.0771, -0.0274, -0.1345, -0.0683,  0.1273,  0.0359],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4893,  0.4151, -0.4919, -0.4685,  0.3538,  0.3575, -0.4018,  0.3688,
          0.3897, -0.4343, -0.3817,  0.3780,  0.3748,  0.3639,  0.4096,  0.4214,
         -0.4754, -0.4879,  0.3384,  0.3863, -0.4370, -0.4170, -0.4847,  0.3331,
          0.4613,  0.4879, -0.4704,  0.4800, -0.4014, -0.4748,  0.4657,  0.4809]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2384], device='cuda:0', requires_grad=True)

