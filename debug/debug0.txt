Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.5118e-01,  2.3700e-01,  1.6103e-01, -1.7770e-01, -1.4512e-03,
         -3.8530e-03,  1.2072e-01, -2.1556e-01,  5.2829e-03,  8.3151e-02,
          1.2566e-01,  2.4582e-02, -1.2549e-01, -2.3850e-01,  1.3359e-01,
          2.2665e-01],
        [-7.7076e-02, -2.2183e-01,  7.1551e-02, -1.7369e-01, -1.6493e-01,
          6.9730e-02, -2.2154e-02, -1.8536e-02,  2.2583e-01, -4.4154e-02,
          1.5059e-01, -7.9393e-02,  1.8444e-01,  7.7829e-02,  2.2120e-01,
          8.5599e-02],
        [-9.0114e-02,  1.1047e-01,  2.1144e-01,  4.8896e-02,  1.1372e-01,
         -1.7438e-01,  1.3696e-01, -2.3758e-01,  2.2252e-01,  1.0302e-01,
          1.4946e-02, -2.3549e-01,  2.2581e-01,  1.6081e-01,  2.2900e-01,
          9.6708e-02],
        [ 8.5732e-02, -6.6215e-02, -1.0093e-01,  9.7643e-02,  8.8203e-02,
         -9.5511e-03,  3.8322e-02,  8.6988e-02, -2.4305e-01, -2.2094e-01,
         -6.5100e-02,  1.7170e-01,  1.2346e-01, -2.3990e-01, -7.3668e-02,
         -2.4870e-02],
        [ 8.0514e-02,  2.0612e-01,  3.8716e-03, -1.9300e-01,  1.3750e-02,
         -9.4954e-02, -1.5119e-01,  1.3706e-01, -3.1995e-02,  1.1689e-01,
          1.9308e-01,  2.2982e-02,  1.3922e-01, -1.1650e-01,  1.3797e-01,
          8.3907e-03],
        [ 1.6453e-01,  2.4061e-01, -1.9071e-01,  2.3892e-01,  1.8925e-01,
         -1.9980e-01,  7.4879e-02, -2.0501e-01,  8.2691e-02,  3.7579e-02,
         -2.4024e-01,  8.9163e-02, -7.0265e-02,  2.5077e-01,  2.4242e-01,
          8.4704e-02],
        [ 1.9865e-01,  8.8716e-02,  2.3811e-01, -2.4660e-02,  6.3367e-02,
         -4.2869e-02, -5.9561e-03, -7.6341e-02, -1.0051e-01,  1.4594e-01,
          1.0883e-01, -1.0879e-01, -2.1874e-01,  1.2069e-01, -2.2839e-01,
         -9.4693e-03],
        [-2.1351e-01,  2.0774e-01,  2.0517e-01, -2.0706e-01, -2.3084e-01,
         -1.4940e-01,  6.7390e-02, -1.2360e-01, -6.1132e-02, -6.2071e-02,
          4.7448e-02, -1.1666e-01,  1.1530e-01, -1.8048e-01, -2.0666e-02,
          2.1115e-01],
        [-1.3645e-01,  1.9022e-01,  1.3171e-01, -8.2345e-02,  8.8280e-02,
         -1.7048e-01,  1.8529e-02,  7.2233e-02,  2.1465e-01, -1.3869e-01,
         -1.4060e-01, -1.2319e-01, -2.4195e-01,  4.8987e-02, -2.0536e-01,
         -6.5514e-02],
        [-1.1314e-01,  1.5568e-02,  7.4240e-02, -1.8008e-01, -7.5394e-02,
         -2.2447e-02, -1.4293e-01,  5.6260e-02,  9.4143e-02, -1.7928e-01,
          1.9499e-01,  1.7606e-01, -7.6700e-02,  3.8771e-02,  2.8857e-02,
         -3.6090e-02],
        [-1.6936e-01,  2.0751e-01,  1.2146e-01, -2.0739e-01, -1.9531e-01,
          2.3926e-01,  4.1240e-02, -5.8921e-02,  1.7098e-01,  7.2975e-02,
          8.8185e-02,  1.9680e-01, -2.1038e-02,  2.3956e-01, -1.7691e-01,
         -1.5370e-01],
        [ 4.0763e-02, -2.8762e-02,  1.4107e-01, -6.6390e-02,  3.7723e-02,
         -5.0361e-02,  1.8928e-01, -1.6957e-02,  5.4293e-03,  1.8179e-01,
          2.4146e-01,  2.3763e-01, -2.4602e-01, -1.3969e-01, -5.5870e-02,
         -5.3208e-02],
        [ 1.4620e-01,  1.1134e-01, -1.8972e-02,  4.3426e-03,  5.5148e-02,
          2.1394e-01,  1.2800e-01, -1.2455e-01, -1.2965e-01,  7.7665e-02,
         -2.3702e-02, -1.5881e-01, -2.4039e-01,  3.4292e-02, -7.1482e-02,
         -1.4387e-01],
        [ 4.8625e-02,  2.4185e-01,  2.0924e-01,  1.4095e-01, -1.8696e-01,
          1.4109e-01,  1.2771e-01,  8.4955e-02, -6.3871e-02, -4.4005e-03,
         -1.3401e-01, -5.4722e-02, -3.9558e-02, -3.6989e-02, -2.4721e-01,
          8.9795e-02],
        [-2.0614e-01, -1.8538e-01,  1.0000e-01, -2.0306e-01,  2.3691e-01,
          2.4096e-01, -7.7864e-02, -4.4559e-02, -1.8968e-01,  1.4671e-02,
          4.4131e-02, -1.3872e-01,  7.6810e-02, -8.0720e-03, -7.5263e-02,
         -2.4588e-03],
        [-2.4074e-01, -1.7769e-01,  3.4686e-02,  2.3984e-01, -1.4659e-01,
          1.5869e-01,  2.1291e-02, -1.0640e-01, -1.3141e-03,  1.2115e-01,
          3.1321e-02,  2.2289e-01, -4.5724e-02, -1.6851e-01,  2.2749e-01,
         -6.9805e-02],
        [ 1.6022e-01,  1.6331e-01,  4.5873e-02, -2.0678e-01, -2.4385e-01,
          1.1710e-01,  5.9530e-02,  1.4691e-01, -2.2194e-01, -3.3485e-02,
          2.1759e-01,  1.3293e-01,  2.0935e-01,  1.9471e-01, -5.9759e-02,
         -1.6865e-01],
        [-1.5067e-01,  8.6498e-02, -1.0083e-01,  2.5842e-03,  3.8306e-02,
          1.5678e-01,  1.4102e-01,  1.4137e-01,  1.1754e-02,  1.3984e-01,
         -1.1862e-01, -1.0165e-01, -4.1178e-02, -1.4361e-01,  2.2141e-01,
         -3.9907e-02],
        [ 7.1118e-02, -6.2559e-03, -4.9763e-03, -1.3173e-01, -1.9894e-02,
         -2.2211e-01, -1.1804e-01,  1.9110e-01, -2.3296e-01,  4.0845e-02,
          3.8314e-02, -2.4079e-01,  4.7293e-02,  1.1749e-01,  1.7959e-01,
          4.5222e-02],
        [ 1.9699e-01,  7.8717e-03,  9.6825e-02,  7.2263e-02, -1.8278e-01,
         -5.6410e-02, -1.7759e-01,  1.9558e-01,  1.1772e-01, -1.0569e-01,
         -4.4214e-02,  6.8270e-02, -2.1643e-01,  5.6069e-03,  1.2076e-01,
          3.2908e-02],
        [-2.4601e-02,  1.6232e-01,  1.0715e-01, -2.2065e-01,  1.4554e-01,
         -1.9559e-01,  1.4203e-01,  2.0899e-01,  2.4637e-02, -8.5499e-02,
         -1.3073e-01, -1.1260e-01, -4.7679e-02, -1.0207e-01,  2.4659e-01,
         -1.0943e-01],
        [ 1.0220e-01, -2.3024e-01,  1.2512e-01,  2.1432e-01, -1.8081e-01,
         -6.2196e-02,  6.1180e-02, -2.4065e-01, -1.5658e-01,  8.5609e-02,
          2.3382e-01, -7.6278e-02, -3.8724e-03, -2.3976e-01, -2.4155e-01,
          2.1582e-01],
        [ 2.1375e-01, -7.7784e-02, -9.7257e-02, -1.7778e-02,  1.1759e-01,
         -2.4319e-01, -1.4007e-01, -8.0886e-02, -1.1041e-01, -5.7296e-03,
          1.8394e-01,  5.6177e-02, -2.2465e-01,  2.2965e-01,  2.0288e-01,
          8.0312e-02],
        [ 1.2397e-01,  9.1864e-02,  2.0651e-01, -2.4204e-01, -1.5404e-01,
         -3.3338e-02, -4.9149e-02, -1.6450e-01, -2.4135e-01, -1.9007e-01,
         -3.7236e-02,  2.1381e-01,  1.6734e-01,  7.0484e-02, -1.5196e-01,
         -9.8976e-02],
        [ 2.5680e-02, -2.3332e-01, -9.8168e-03,  4.9248e-02,  2.2761e-01,
         -6.7210e-02,  2.4380e-01,  1.9688e-02, -1.7504e-01,  2.3761e-01,
          2.1833e-01, -1.9595e-01, -1.4343e-01,  1.1797e-01, -1.5224e-01,
          1.7158e-01],
        [-1.1769e-01, -7.9180e-02, -7.0170e-02,  2.3692e-01, -8.2949e-02,
         -5.0198e-02,  1.4968e-01, -1.6948e-01, -2.7997e-03, -1.9456e-01,
         -2.2915e-01, -5.5486e-02,  2.9229e-02,  2.1163e-01, -2.3819e-01,
         -7.0339e-02],
        [ 6.7386e-02,  9.2813e-02,  1.4766e-01, -2.0261e-01, -5.9529e-02,
          5.6222e-02, -2.0199e-01,  1.2734e-01, -2.4013e-01,  1.5725e-01,
          8.2864e-02, -6.9424e-02,  8.2698e-02,  2.1017e-01,  1.8549e-01,
          1.5324e-01],
        [-1.4713e-01,  7.3428e-02,  1.8602e-01,  4.5682e-02,  1.6393e-01,
         -1.5346e-01,  1.7730e-01, -6.8764e-03, -2.2271e-01, -6.6222e-02,
          2.1939e-01, -8.8921e-02, -4.4891e-02, -9.8438e-02, -1.3752e-01,
          4.1716e-02],
        [ 1.5326e-01,  2.7974e-02, -1.3823e-02,  1.2871e-02, -1.8588e-01,
         -1.3331e-01,  1.0927e-02, -1.9826e-01,  1.2223e-01,  3.6930e-02,
          4.2250e-03, -1.4453e-02,  2.1274e-01,  2.2660e-01,  1.2363e-01,
          1.2576e-01],
        [-1.2282e-01,  1.0379e-01, -1.7069e-01,  1.0964e-01, -1.7911e-01,
          2.2307e-04,  1.8279e-01,  1.6533e-01,  2.2265e-01,  8.3859e-02,
          9.5455e-02,  6.5449e-02,  1.8096e-01,  1.3277e-01,  7.2179e-02,
         -8.8828e-02],
        [-1.2258e-01, -6.0228e-02,  1.1772e-01, -1.3450e-01,  6.6716e-02,
          2.2030e-01,  2.1327e-01, -1.8558e-01,  7.2844e-02,  1.6340e-01,
         -2.2866e-01,  1.5820e-01, -1.5736e-01, -1.7922e-01, -1.0754e-01,
         -9.5629e-02],
        [-1.0490e-01,  7.3450e-02,  9.5320e-02,  9.8637e-02,  1.7110e-01,
         -1.5672e-01, -2.3591e-01, -2.0161e-01, -1.3593e-01, -1.1477e-01,
          1.0840e-01, -1.8237e-01, -1.8429e-01,  1.3522e-01, -1.6050e-01,
          4.5335e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1921,  0.0938,  0.1551, -0.2093,  0.0866, -0.1298,  0.1571,  0.2233,
        -0.2124,  0.0949,  0.1673,  0.2289,  0.1904,  0.0507,  0.0133,  0.0500,
        -0.1504, -0.0474, -0.0050, -0.1570, -0.0123, -0.0316, -0.0860, -0.0753,
        -0.2505,  0.2398,  0.1217,  0.1823, -0.2112, -0.2432,  0.1844, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0260,  0.0870,  0.0097, -0.0075,  0.1034,  0.1428, -0.0509, -0.1525,
         -0.0953,  0.1247,  0.0170,  0.1498, -0.0602, -0.1659,  0.0533, -0.0737,
         -0.1072,  0.1118,  0.0107, -0.0167,  0.1707,  0.1524, -0.1460, -0.1641,
         -0.0890, -0.1357, -0.0945,  0.1177, -0.1192,  0.1637,  0.0568,  0.0061]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0259,  0.0352,  0.0528,  ...,  0.0355, -0.1569, -0.1137],
        [-0.0427, -0.1213,  0.0865,  ..., -0.0269, -0.1526,  0.0871],
        [-0.0900,  0.0712,  0.1115,  ...,  0.1530,  0.0678,  0.0345],
        ...,
        [ 0.0819, -0.0804,  0.0098,  ..., -0.1161, -0.0683, -0.1180],
        [ 0.0102, -0.1229, -0.0090,  ..., -0.1362, -0.0364,  0.1557],
        [-0.1353,  0.0646,  0.0394,  ..., -0.0273, -0.1457, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0573,  0.0679, -0.1061, -0.1142, -0.0469,  0.0088, -0.1304,  0.0724,
        -0.0286,  0.0917,  0.0463, -0.0241, -0.0134,  0.0479, -0.0819, -0.0402,
         0.0719, -0.1443, -0.0332,  0.0348, -0.0813,  0.0772,  0.0807, -0.0218,
        -0.0502,  0.0763,  0.0104, -0.1224,  0.0937,  0.1563,  0.1384, -0.0870],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1629, -0.0727, -0.1354,  ..., -0.0177, -0.1342,  0.1712],
        [-0.0968,  0.0934,  0.0393,  ...,  0.0677, -0.1336,  0.1683],
        [ 0.0232, -0.1653, -0.1006,  ..., -0.0598,  0.1153,  0.0571],
        ...,
        [ 0.0242, -0.0153,  0.1384,  ...,  0.1377, -0.1005,  0.1477],
        [ 0.0972, -0.0192, -0.0069,  ...,  0.1535,  0.1027, -0.0480],
        [ 0.0999, -0.0122,  0.1658,  ...,  0.1605,  0.0333,  0.0629]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0705,  0.1044,  0.0013, -0.0469, -0.0596, -0.1148, -0.0082, -0.0979,
         0.1069, -0.1279,  0.1523, -0.1547,  0.1486,  0.0187, -0.1653,  0.0544,
        -0.1152, -0.1414,  0.0106, -0.0489,  0.0422,  0.1384, -0.1635,  0.1772,
        -0.0967, -0.0336,  0.1132, -0.0725, -0.0905, -0.0427,  0.0705, -0.0063],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1626,  0.0778, -0.1597, -0.1257,  0.0155, -0.0069, -0.0522,  0.0566,
          0.0754, -0.1040, -0.0339,  0.0618,  0.0654, -0.0143,  0.0875,  0.0646,
         -0.1673, -0.1678,  0.0045,  0.0591, -0.1273, -0.0925, -0.1701,  0.0348,
          0.1296,  0.1582, -0.1425,  0.1380, -0.0697, -0.1545,  0.1120,  0.1471]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0077], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.5118e-01,  2.3700e-01,  1.6103e-01, -1.7770e-01, -1.4512e-03,
         -3.8530e-03,  1.2072e-01, -2.1556e-01,  5.2829e-03,  8.3151e-02,
          1.2566e-01,  2.4582e-02, -1.2549e-01, -2.3850e-01,  1.3359e-01,
          2.2665e-01],
        [-7.7076e-02, -2.2183e-01,  7.1551e-02, -1.7369e-01, -1.6493e-01,
          6.9730e-02, -2.2154e-02, -1.8536e-02,  2.2583e-01, -4.4154e-02,
          1.5059e-01, -7.9393e-02,  1.8444e-01,  7.7829e-02,  2.2120e-01,
          8.5599e-02],
        [-9.0114e-02,  1.1047e-01,  2.1144e-01,  4.8896e-02,  1.1372e-01,
         -1.7438e-01,  1.3696e-01, -2.3758e-01,  2.2252e-01,  1.0302e-01,
          1.4946e-02, -2.3549e-01,  2.2581e-01,  1.6081e-01,  2.2900e-01,
          9.6708e-02],
        [ 8.5732e-02, -6.6215e-02, -1.0093e-01,  9.7643e-02,  8.8203e-02,
         -9.5511e-03,  3.8322e-02,  8.6988e-02, -2.4305e-01, -2.2094e-01,
         -6.5100e-02,  1.7170e-01,  1.2346e-01, -2.3990e-01, -7.3668e-02,
         -2.4870e-02],
        [ 8.0514e-02,  2.0612e-01,  3.8716e-03, -1.9300e-01,  1.3750e-02,
         -9.4954e-02, -1.5119e-01,  1.3706e-01, -3.1995e-02,  1.1689e-01,
          1.9308e-01,  2.2982e-02,  1.3922e-01, -1.1650e-01,  1.3797e-01,
          8.3907e-03],
        [ 1.6453e-01,  2.4061e-01, -1.9071e-01,  2.3892e-01,  1.8925e-01,
         -1.9980e-01,  7.4879e-02, -2.0501e-01,  8.2691e-02,  3.7579e-02,
         -2.4024e-01,  8.9163e-02, -7.0265e-02,  2.5077e-01,  2.4242e-01,
          8.4704e-02],
        [ 1.9865e-01,  8.8716e-02,  2.3811e-01, -2.4660e-02,  6.3367e-02,
         -4.2869e-02, -5.9561e-03, -7.6341e-02, -1.0051e-01,  1.4594e-01,
          1.0883e-01, -1.0879e-01, -2.1874e-01,  1.2069e-01, -2.2839e-01,
         -9.4693e-03],
        [-2.1351e-01,  2.0774e-01,  2.0517e-01, -2.0706e-01, -2.3084e-01,
         -1.4940e-01,  6.7390e-02, -1.2360e-01, -6.1132e-02, -6.2071e-02,
          4.7448e-02, -1.1666e-01,  1.1530e-01, -1.8048e-01, -2.0666e-02,
          2.1115e-01],
        [-1.3645e-01,  1.9022e-01,  1.3171e-01, -8.2345e-02,  8.8280e-02,
         -1.7048e-01,  1.8529e-02,  7.2233e-02,  2.1465e-01, -1.3869e-01,
         -1.4060e-01, -1.2319e-01, -2.4195e-01,  4.8987e-02, -2.0536e-01,
         -6.5514e-02],
        [-1.1314e-01,  1.5568e-02,  7.4240e-02, -1.8008e-01, -7.5394e-02,
         -2.2447e-02, -1.4293e-01,  5.6260e-02,  9.4143e-02, -1.7928e-01,
          1.9499e-01,  1.7606e-01, -7.6700e-02,  3.8771e-02,  2.8857e-02,
         -3.6090e-02],
        [-1.6936e-01,  2.0751e-01,  1.2146e-01, -2.0739e-01, -1.9531e-01,
          2.3926e-01,  4.1240e-02, -5.8921e-02,  1.7098e-01,  7.2975e-02,
          8.8185e-02,  1.9680e-01, -2.1038e-02,  2.3956e-01, -1.7691e-01,
         -1.5370e-01],
        [ 4.0763e-02, -2.8762e-02,  1.4107e-01, -6.6390e-02,  3.7723e-02,
         -5.0361e-02,  1.8928e-01, -1.6957e-02,  5.4293e-03,  1.8179e-01,
          2.4146e-01,  2.3763e-01, -2.4602e-01, -1.3969e-01, -5.5870e-02,
         -5.3208e-02],
        [ 1.4620e-01,  1.1134e-01, -1.8972e-02,  4.3426e-03,  5.5148e-02,
          2.1394e-01,  1.2800e-01, -1.2455e-01, -1.2965e-01,  7.7665e-02,
         -2.3702e-02, -1.5881e-01, -2.4039e-01,  3.4292e-02, -7.1482e-02,
         -1.4387e-01],
        [ 4.8625e-02,  2.4185e-01,  2.0924e-01,  1.4095e-01, -1.8696e-01,
          1.4109e-01,  1.2771e-01,  8.4955e-02, -6.3871e-02, -4.4005e-03,
         -1.3401e-01, -5.4722e-02, -3.9558e-02, -3.6989e-02, -2.4721e-01,
          8.9795e-02],
        [-2.0614e-01, -1.8538e-01,  1.0000e-01, -2.0306e-01,  2.3691e-01,
          2.4096e-01, -7.7864e-02, -4.4559e-02, -1.8968e-01,  1.4671e-02,
          4.4131e-02, -1.3872e-01,  7.6810e-02, -8.0720e-03, -7.5263e-02,
         -2.4588e-03],
        [-2.4074e-01, -1.7769e-01,  3.4686e-02,  2.3984e-01, -1.4659e-01,
          1.5869e-01,  2.1291e-02, -1.0640e-01, -1.3141e-03,  1.2115e-01,
          3.1321e-02,  2.2289e-01, -4.5724e-02, -1.6851e-01,  2.2749e-01,
         -6.9805e-02],
        [ 1.6022e-01,  1.6331e-01,  4.5873e-02, -2.0678e-01, -2.4385e-01,
          1.1710e-01,  5.9530e-02,  1.4691e-01, -2.2194e-01, -3.3485e-02,
          2.1759e-01,  1.3293e-01,  2.0935e-01,  1.9471e-01, -5.9759e-02,
         -1.6865e-01],
        [-1.5067e-01,  8.6498e-02, -1.0083e-01,  2.5842e-03,  3.8306e-02,
          1.5678e-01,  1.4102e-01,  1.4137e-01,  1.1754e-02,  1.3984e-01,
         -1.1862e-01, -1.0165e-01, -4.1178e-02, -1.4361e-01,  2.2141e-01,
         -3.9907e-02],
        [ 7.1118e-02, -6.2559e-03, -4.9763e-03, -1.3173e-01, -1.9894e-02,
         -2.2211e-01, -1.1804e-01,  1.9110e-01, -2.3296e-01,  4.0845e-02,
          3.8314e-02, -2.4079e-01,  4.7293e-02,  1.1749e-01,  1.7959e-01,
          4.5222e-02],
        [ 1.9699e-01,  7.8717e-03,  9.6825e-02,  7.2263e-02, -1.8278e-01,
         -5.6410e-02, -1.7759e-01,  1.9558e-01,  1.1772e-01, -1.0569e-01,
         -4.4214e-02,  6.8270e-02, -2.1643e-01,  5.6069e-03,  1.2076e-01,
          3.2908e-02],
        [-2.4601e-02,  1.6232e-01,  1.0715e-01, -2.2065e-01,  1.4554e-01,
         -1.9559e-01,  1.4203e-01,  2.0899e-01,  2.4637e-02, -8.5499e-02,
         -1.3073e-01, -1.1260e-01, -4.7679e-02, -1.0207e-01,  2.4659e-01,
         -1.0943e-01],
        [ 1.0220e-01, -2.3024e-01,  1.2512e-01,  2.1432e-01, -1.8081e-01,
         -6.2196e-02,  6.1180e-02, -2.4065e-01, -1.5658e-01,  8.5609e-02,
          2.3382e-01, -7.6278e-02, -3.8724e-03, -2.3976e-01, -2.4155e-01,
          2.1582e-01],
        [ 2.1375e-01, -7.7784e-02, -9.7257e-02, -1.7778e-02,  1.1759e-01,
         -2.4319e-01, -1.4007e-01, -8.0886e-02, -1.1041e-01, -5.7296e-03,
          1.8394e-01,  5.6177e-02, -2.2465e-01,  2.2965e-01,  2.0288e-01,
          8.0312e-02],
        [ 1.2397e-01,  9.1864e-02,  2.0651e-01, -2.4204e-01, -1.5404e-01,
         -3.3338e-02, -4.9149e-02, -1.6450e-01, -2.4135e-01, -1.9007e-01,
         -3.7236e-02,  2.1381e-01,  1.6734e-01,  7.0484e-02, -1.5196e-01,
         -9.8976e-02],
        [ 2.5680e-02, -2.3332e-01, -9.8168e-03,  4.9248e-02,  2.2761e-01,
         -6.7210e-02,  2.4380e-01,  1.9688e-02, -1.7504e-01,  2.3761e-01,
          2.1833e-01, -1.9595e-01, -1.4343e-01,  1.1797e-01, -1.5224e-01,
          1.7158e-01],
        [-1.1769e-01, -7.9180e-02, -7.0170e-02,  2.3692e-01, -8.2949e-02,
         -5.0198e-02,  1.4968e-01, -1.6948e-01, -2.7997e-03, -1.9456e-01,
         -2.2915e-01, -5.5486e-02,  2.9229e-02,  2.1163e-01, -2.3819e-01,
         -7.0339e-02],
        [ 6.7386e-02,  9.2813e-02,  1.4766e-01, -2.0261e-01, -5.9529e-02,
          5.6222e-02, -2.0199e-01,  1.2734e-01, -2.4013e-01,  1.5725e-01,
          8.2864e-02, -6.9424e-02,  8.2698e-02,  2.1017e-01,  1.8549e-01,
          1.5324e-01],
        [-1.4713e-01,  7.3428e-02,  1.8602e-01,  4.5682e-02,  1.6393e-01,
         -1.5346e-01,  1.7730e-01, -6.8764e-03, -2.2271e-01, -6.6222e-02,
          2.1939e-01, -8.8921e-02, -4.4891e-02, -9.8438e-02, -1.3752e-01,
          4.1716e-02],
        [ 1.5326e-01,  2.7974e-02, -1.3823e-02,  1.2871e-02, -1.8588e-01,
         -1.3331e-01,  1.0927e-02, -1.9826e-01,  1.2223e-01,  3.6930e-02,
          4.2250e-03, -1.4453e-02,  2.1274e-01,  2.2660e-01,  1.2363e-01,
          1.2576e-01],
        [-1.2282e-01,  1.0379e-01, -1.7069e-01,  1.0964e-01, -1.7911e-01,
          2.2307e-04,  1.8279e-01,  1.6533e-01,  2.2265e-01,  8.3859e-02,
          9.5455e-02,  6.5449e-02,  1.8096e-01,  1.3277e-01,  7.2179e-02,
         -8.8828e-02],
        [-1.2258e-01, -6.0228e-02,  1.1772e-01, -1.3450e-01,  6.6716e-02,
          2.2030e-01,  2.1327e-01, -1.8558e-01,  7.2844e-02,  1.6340e-01,
         -2.2866e-01,  1.5820e-01, -1.5736e-01, -1.7922e-01, -1.0754e-01,
         -9.5629e-02],
        [-1.0490e-01,  7.3450e-02,  9.5320e-02,  9.8637e-02,  1.7110e-01,
         -1.5672e-01, -2.3591e-01, -2.0161e-01, -1.3593e-01, -1.1477e-01,
          1.0840e-01, -1.8237e-01, -1.8429e-01,  1.3522e-01, -1.6050e-01,
          4.5335e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1921,  0.0938,  0.1551, -0.2093,  0.0866, -0.1298,  0.1571,  0.2233,
        -0.2124,  0.0949,  0.1673,  0.2289,  0.1904,  0.0507,  0.0133,  0.0500,
        -0.1504, -0.0474, -0.0050, -0.1570, -0.0123, -0.0316, -0.0860, -0.0753,
        -0.2505,  0.2398,  0.1217,  0.1823, -0.2112, -0.2432,  0.1844, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0260,  0.0870,  0.0097, -0.0075,  0.1034,  0.1428, -0.0509, -0.1525,
         -0.0953,  0.1247,  0.0170,  0.1498, -0.0602, -0.1659,  0.0533, -0.0737,
         -0.1072,  0.1118,  0.0107, -0.0167,  0.1707,  0.1524, -0.1460, -0.1641,
         -0.0890, -0.1357, -0.0945,  0.1177, -0.1192,  0.1637,  0.0568,  0.0061]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0259,  0.0352,  0.0528,  ...,  0.0355, -0.1569, -0.1137],
        [-0.0427, -0.1213,  0.0865,  ..., -0.0269, -0.1526,  0.0871],
        [-0.0900,  0.0712,  0.1115,  ...,  0.1530,  0.0678,  0.0345],
        ...,
        [ 0.0819, -0.0804,  0.0098,  ..., -0.1161, -0.0683, -0.1180],
        [ 0.0102, -0.1229, -0.0090,  ..., -0.1362, -0.0364,  0.1557],
        [-0.1353,  0.0646,  0.0394,  ..., -0.0273, -0.1457, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0573,  0.0679, -0.1061, -0.1142, -0.0469,  0.0088, -0.1304,  0.0724,
        -0.0286,  0.0917,  0.0463, -0.0241, -0.0134,  0.0479, -0.0819, -0.0402,
         0.0719, -0.1443, -0.0332,  0.0348, -0.0813,  0.0772,  0.0807, -0.0218,
        -0.0502,  0.0763,  0.0104, -0.1224,  0.0937,  0.1563,  0.1384, -0.0870],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1629, -0.0727, -0.1354,  ..., -0.0177, -0.1342,  0.1712],
        [-0.0968,  0.0934,  0.0393,  ...,  0.0677, -0.1336,  0.1683],
        [ 0.0232, -0.1653, -0.1006,  ..., -0.0598,  0.1153,  0.0571],
        ...,
        [ 0.0242, -0.0153,  0.1384,  ...,  0.1377, -0.1005,  0.1477],
        [ 0.0972, -0.0192, -0.0069,  ...,  0.1535,  0.1027, -0.0480],
        [ 0.0999, -0.0122,  0.1658,  ...,  0.1605,  0.0333,  0.0629]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0705,  0.1044,  0.0013, -0.0469, -0.0596, -0.1148, -0.0082, -0.0979,
         0.1069, -0.1279,  0.1523, -0.1547,  0.1486,  0.0187, -0.1653,  0.0544,
        -0.1152, -0.1414,  0.0106, -0.0489,  0.0422,  0.1384, -0.1635,  0.1772,
        -0.0967, -0.0336,  0.1132, -0.0725, -0.0905, -0.0427,  0.0705, -0.0063],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1626,  0.0778, -0.1597, -0.1257,  0.0155, -0.0069, -0.0522,  0.0566,
          0.0754, -0.1040, -0.0339,  0.0618,  0.0654, -0.0143,  0.0875,  0.0646,
         -0.1673, -0.1678,  0.0045,  0.0591, -0.1273, -0.0925, -0.1701,  0.0348,
          0.1296,  0.1582, -0.1425,  0.1380, -0.0697, -0.1545,  0.1120,  0.1471]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0077], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.5117e-01,  2.3702e-01,  1.6108e-01, -1.7820e-01, -1.3557e-03,
         -3.9014e-03,  1.2073e-01, -2.1255e-01,  5.2733e-03,  8.4580e-02,
          1.2568e-01,  2.4583e-02, -1.2549e-01, -2.3844e-01,  1.3666e-01,
          2.2666e-01],
        [-7.7073e-02, -2.2182e-01,  7.1567e-02, -1.7398e-01, -1.6490e-01,
          6.9713e-02, -2.2154e-02, -1.5415e-02,  2.2583e-01, -4.2366e-02,
          1.5059e-01, -7.9392e-02,  1.8444e-01,  7.7854e-02,  2.2436e-01,
          8.5601e-02],
        [-9.0102e-02,  1.1052e-01,  2.1155e-01,  4.8111e-02,  1.1391e-01,
         -1.7446e-01,  1.3699e-01, -2.3479e-01,  2.2251e-01,  1.0396e-01,
          1.5007e-02, -2.3550e-01,  2.2580e-01,  1.6094e-01,  2.3189e-01,
          9.6714e-02],
        [ 8.5701e-02, -6.6273e-02, -1.0112e-01,  9.8696e-02,  8.7902e-02,
         -9.3682e-03,  3.8319e-02,  8.4409e-02, -2.4303e-01, -2.2194e-01,
         -6.5147e-02,  1.7171e-01,  1.2344e-01, -2.4008e-01, -7.6426e-02,
         -2.4895e-02],
        [ 8.0516e-02,  2.0612e-01,  3.8842e-03, -1.9317e-01,  1.3781e-02,
         -9.4967e-02, -1.5120e-01,  1.4007e-01, -3.1998e-02,  1.1961e-01,
          1.9308e-01,  2.2982e-02,  1.3922e-01, -1.1648e-01,  1.4114e-01,
          8.3920e-03],
        [ 1.6454e-01,  2.4061e-01, -1.9070e-01,  2.3881e-01,  1.8928e-01,
         -1.9981e-01,  7.4879e-02, -2.0193e-01,  8.2688e-02,  3.9598e-02,
         -2.4023e-01,  8.9165e-02, -7.0265e-02,  2.5079e-01,  2.4558e-01,
          8.4705e-02],
        [ 1.9865e-01,  8.8708e-02,  2.3808e-01, -2.4297e-02,  6.3299e-02,
         -4.2836e-02, -5.9514e-03, -7.6998e-02, -1.0051e-01,  1.4343e-01,
          1.0883e-01, -1.0879e-01, -2.1874e-01,  1.2066e-01, -2.3151e-01,
         -9.4732e-03],
        [-2.1351e-01,  2.0774e-01,  2.0516e-01, -2.0693e-01, -2.3087e-01,
         -1.4939e-01,  6.7392e-02, -1.2661e-01, -6.1130e-02, -6.4848e-02,
          4.7447e-02, -1.1666e-01,  1.1530e-01, -1.8049e-01, -2.3841e-02,
          2.1115e-01],
        [-1.3645e-01,  1.9021e-01,  1.3170e-01, -8.2213e-02,  8.8245e-02,
         -1.7047e-01,  1.8530e-02,  6.9223e-02,  2.1465e-01, -1.4132e-01,
         -1.4060e-01, -1.2319e-01, -2.4195e-01,  4.8969e-02, -2.0852e-01,
         -6.5516e-02],
        [-1.1314e-01,  1.5573e-02,  7.4250e-02, -1.8025e-01, -7.5369e-02,
         -2.2457e-02, -1.4293e-01,  5.9347e-02,  9.4142e-02, -1.7670e-01,
          1.9499e-01,  1.7606e-01, -7.6700e-02,  3.8789e-02,  3.2025e-02,
         -3.6090e-02],
        [-1.6934e-01,  2.0756e-01,  1.2155e-01, -2.0966e-01, -1.9517e-01,
          2.3912e-01,  4.1337e-02, -5.5919e-02,  1.7097e-01,  7.3130e-02,
          8.8200e-02,  1.9680e-01, -2.1025e-02,  2.3974e-01, -1.7408e-01,
         -1.5369e-01],
        [ 4.0766e-02, -2.8758e-02,  1.4108e-01, -6.6626e-02,  3.7754e-02,
         -5.0374e-02,  1.8928e-01, -1.4806e-02,  5.4262e-03,  1.8306e-01,
          2.4147e-01,  2.3763e-01, -2.4602e-01, -1.3968e-01, -5.2711e-02,
         -5.3206e-02],
        [ 1.4620e-01,  1.1132e-01, -1.8998e-02,  6.6081e-03,  5.5102e-02,
          2.1398e-01,  1.2799e-01, -1.2768e-01, -1.2965e-01,  7.7561e-02,
         -2.3707e-02, -1.5881e-01, -2.4039e-01,  3.4233e-02, -7.4582e-02,
         -1.4387e-01],
        [ 4.8624e-02,  2.4185e-01,  2.0924e-01,  1.4138e-01, -1.8698e-01,
          1.4110e-01,  1.2771e-01,  8.1816e-02, -6.3870e-02, -5.8959e-03,
         -1.3401e-01, -5.4722e-02, -3.9559e-02, -3.7006e-02, -2.5039e-01,
          8.9794e-02],
        [-2.0614e-01, -1.8537e-01,  1.0003e-01, -2.0340e-01,  2.3696e-01,
          2.4094e-01, -7.7865e-02, -4.1500e-02, -1.8968e-01,  1.6863e-02,
          4.4138e-02, -1.3872e-01,  7.6811e-02, -8.0410e-03, -7.2129e-02,
         -2.4561e-03],
        [-2.4074e-01, -1.7770e-01,  3.4669e-02,  2.4004e-01, -1.4663e-01,
          1.5871e-01,  2.1293e-02, -1.0915e-01, -1.3125e-03,  1.1841e-01,
          3.1321e-02,  2.2289e-01, -4.5725e-02, -1.6853e-01,  2.2433e-01,
         -6.9806e-02],
        [ 1.6022e-01,  1.6331e-01,  4.5859e-02, -2.0654e-01, -2.4388e-01,
          1.1711e-01,  5.9533e-02,  1.4387e-01, -2.2194e-01, -3.5919e-02,
          2.1758e-01,  1.3293e-01,  2.0935e-01,  1.9469e-01, -6.2923e-02,
         -1.6865e-01],
        [-1.5067e-01,  8.6502e-02, -1.0082e-01,  2.4639e-03,  3.8338e-02,
          1.5677e-01,  1.4102e-01,  1.4428e-01,  1.1751e-02,  1.4239e-01,
         -1.1862e-01, -1.0165e-01, -4.1177e-02, -1.4359e-01,  2.2458e-01,
         -3.9905e-02],
        [ 7.1136e-02, -6.2224e-03, -4.8646e-03, -1.3252e-01, -1.9704e-02,
         -2.2221e-01, -1.1803e-01,  1.9392e-01, -2.3298e-01,  4.2108e-02,
          3.8361e-02, -2.4079e-01,  4.7299e-02,  1.1760e-01,  1.8251e-01,
          4.5235e-02],
        [ 1.9697e-01,  7.8512e-03,  9.6727e-02,  7.2923e-02, -1.8295e-01,
         -5.6320e-02, -1.7759e-01,  1.9271e-01,  1.1774e-01, -1.0709e-01,
         -4.4265e-02,  6.8263e-02, -2.1644e-01,  5.5257e-03,  1.1779e-01,
          3.2891e-02],
        [-2.4600e-02,  1.6232e-01,  1.0716e-01, -2.2073e-01,  1.4556e-01,
         -1.9560e-01,  1.4203e-01,  2.1211e-01,  2.4635e-02, -8.2969e-02,
         -1.3073e-01, -1.1260e-01, -4.7679e-02, -1.0205e-01,  2.4977e-01,
         -1.0943e-01],
        [ 1.0220e-01, -2.3024e-01,  1.2512e-01,  2.1426e-01, -1.8078e-01,
         -6.2203e-02,  6.1179e-02, -2.3771e-01, -1.5659e-01,  8.7456e-02,
          2.3383e-01, -7.6277e-02, -3.8719e-03, -2.3974e-01, -2.3838e-01,
          2.1582e-01],
        [ 2.1375e-01, -7.7788e-02, -9.7265e-02, -1.7631e-02,  1.1757e-01,
         -2.4318e-01, -1.4007e-01, -8.4013e-02, -1.1041e-01, -8.1285e-03,
          1.8394e-01,  5.6177e-02, -2.2465e-01,  2.2963e-01,  1.9971e-01,
          8.0311e-02],
        [ 1.2397e-01,  9.1860e-02,  2.0651e-01, -2.4193e-01, -1.5406e-01,
         -3.3330e-02, -4.9148e-02, -1.6763e-01, -2.4134e-01, -1.9245e-01,
         -3.7237e-02,  2.1381e-01,  1.6734e-01,  7.0469e-02, -1.5514e-01,
         -9.8976e-02],
        [ 2.5677e-02, -2.3332e-01, -9.8330e-03,  4.9405e-02,  2.2757e-01,
         -6.7195e-02,  2.4380e-01,  1.7269e-02, -1.7503e-01,  2.3487e-01,
          2.1832e-01, -1.9595e-01, -1.4343e-01,  1.1795e-01, -1.5540e-01,
          1.7158e-01],
        [-1.1769e-01, -7.9186e-02, -7.0179e-02,  2.3718e-01, -8.2973e-02,
         -5.0187e-02,  1.4968e-01, -1.7264e-01, -2.7969e-03, -1.9465e-01,
         -2.2916e-01, -5.5487e-02,  2.9230e-02,  2.1160e-01, -2.4134e-01,
         -7.0340e-02],
        [ 6.7384e-02,  9.2809e-02,  1.4765e-01, -2.0243e-01, -5.9562e-02,
          5.6236e-02, -2.0199e-01,  1.2439e-01, -2.4013e-01,  1.5452e-01,
          8.2862e-02, -6.9424e-02,  8.2697e-02,  2.1016e-01,  1.8233e-01,
          1.5323e-01],
        [-1.4713e-01,  7.3432e-02,  1.8603e-01,  4.5455e-02,  1.6397e-01,
         -1.5348e-01,  1.7730e-01, -6.7016e-03, -2.2271e-01, -6.3634e-02,
          2.1939e-01, -8.8921e-02, -4.4890e-02, -9.8423e-02, -1.3436e-01,
          4.1717e-02],
        [ 1.5325e-01,  2.7968e-02, -1.3836e-02,  1.3890e-02, -1.8591e-01,
         -1.3329e-01,  1.0927e-02, -2.0141e-01,  1.2223e-01,  3.6578e-02,
          4.2223e-03, -1.4454e-02,  2.1274e-01,  2.2657e-01,  1.2048e-01,
          1.2576e-01],
        [-1.2282e-01,  1.0379e-01, -1.7068e-01,  1.0956e-01, -1.7909e-01,
          2.1579e-04,  1.8279e-01,  1.6760e-01,  2.2265e-01,  8.6572e-02,
          9.5459e-02,  6.5449e-02,  1.8096e-01,  1.3278e-01,  7.5352e-02,
         -8.8827e-02],
        [-1.2258e-01, -6.0219e-02,  1.1774e-01, -1.3487e-01,  6.6768e-02,
          2.2028e-01,  2.1327e-01, -1.8248e-01,  7.2840e-02,  1.6490e-01,
         -2.2865e-01,  1.5820e-01, -1.5736e-01, -1.7918e-01, -1.0440e-01,
         -9.5626e-02],
        [-1.0487e-01,  7.3496e-02,  9.5487e-02,  9.7729e-02,  1.7137e-01,
         -1.5686e-01, -2.3591e-01, -1.9907e-01, -1.3595e-01, -1.1357e-01,
          1.0846e-01, -1.8237e-01, -1.8427e-01,  1.3536e-01, -1.5771e-01,
          4.5356e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1917,  0.0939,  0.1572, -0.2093,  0.0863, -0.1295,  0.1573,  0.2233,
        -0.2124,  0.0924,  0.1673,  0.2288,  0.1904,  0.0507,  0.0134,  0.0517,
        -0.1476, -0.0474, -0.0042, -0.1589, -0.0096, -0.0316, -0.0860, -0.0756,
        -0.2505,  0.2398,  0.1223,  0.1823, -0.2112, -0.2432,  0.1845, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0260,  0.0870,  0.0129, -0.0075,  0.1035,  0.1428, -0.0509, -0.1525,
         -0.0953,  0.1279,  0.0170,  0.1498, -0.0602, -0.1659,  0.0533, -0.0767,
         -0.1041,  0.1118,  0.0107, -0.0135,  0.1738,  0.1524, -0.1460, -0.1641,
         -0.0890, -0.1357, -0.0945,  0.1177, -0.1192,  0.1637,  0.0568,  0.0061]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0259,  0.0354,  0.0503,  ...,  0.0354, -0.1588, -0.1137],
        [-0.0427, -0.1212,  0.0834,  ..., -0.0271, -0.1555,  0.0871],
        [-0.0900,  0.0711,  0.1146,  ...,  0.1532,  0.0707,  0.0345],
        ...,
        [ 0.0819, -0.0802,  0.0070,  ..., -0.1163, -0.0709, -0.1180],
        [ 0.0102, -0.1230, -0.0059,  ..., -0.1360, -0.0334,  0.1557],
        [-0.1353,  0.0645,  0.0425,  ..., -0.0271, -0.1428, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0571,  0.0677, -0.1058, -0.1144, -0.0472,  0.0086, -0.1302,  0.0721,
        -0.0285,  0.0916,  0.0461, -0.0240, -0.0140,  0.0476, -0.0816, -0.0399,
         0.0717, -0.1445, -0.0334,  0.0349, -0.0810,  0.0774,  0.0809, -0.0216,
        -0.0499,  0.0760,  0.0106, -0.1222,  0.0939,  0.1561,  0.1386, -0.0867],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1625, -0.0721, -0.1355,  ..., -0.0176, -0.1345,  0.1715],
        [-0.0972,  0.0941,  0.0392,  ...,  0.0679, -0.1339,  0.1686],
        [ 0.0236, -0.1659, -0.1005,  ..., -0.0599,  0.1155,  0.0568],
        ...,
        [ 0.0246, -0.0159,  0.1386,  ...,  0.1376, -0.1002,  0.1474],
        [ 0.0968, -0.0186, -0.0071,  ...,  0.1537,  0.1025, -0.0478],
        [ 0.0995, -0.0116,  0.1657,  ...,  0.1607,  0.0331,  0.0632]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0707,  0.1046,  0.0011, -0.0471, -0.0593, -0.1151, -0.0084, -0.0976,
         0.1071, -0.1282,  0.1521, -0.1545,  0.1488,  0.0184, -0.1650,  0.0546,
        -0.1154, -0.1416,  0.0109, -0.0487,  0.0420,  0.1382, -0.1637,  0.1774,
        -0.0964, -0.0333,  0.1130, -0.0722, -0.0907, -0.0430,  0.0707, -0.0061],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1626,  0.0779, -0.1629, -0.1288,  0.0155, -0.0084, -0.0522,  0.0565,
          0.0758, -0.1042, -0.0337,  0.0618,  0.0657, -0.0175,  0.0873,  0.0648,
         -0.1675, -0.1673,  0.0043,  0.0589, -0.1276, -0.0926, -0.1705,  0.0351,
          0.1297,  0.1572, -0.1424,  0.1381, -0.0692, -0.1541,  0.1119,  0.1470]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0075], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.5117e-01,  2.3702e-01,  1.6108e-01, -1.7820e-01, -1.3557e-03,
         -3.9014e-03,  1.2073e-01, -2.1255e-01,  5.2733e-03,  8.4580e-02,
          1.2568e-01,  2.4583e-02, -1.2549e-01, -2.3844e-01,  1.3666e-01,
          2.2666e-01],
        [-7.7073e-02, -2.2182e-01,  7.1567e-02, -1.7398e-01, -1.6490e-01,
          6.9713e-02, -2.2154e-02, -1.5415e-02,  2.2583e-01, -4.2366e-02,
          1.5059e-01, -7.9392e-02,  1.8444e-01,  7.7854e-02,  2.2436e-01,
          8.5601e-02],
        [-9.0102e-02,  1.1052e-01,  2.1155e-01,  4.8111e-02,  1.1391e-01,
         -1.7446e-01,  1.3699e-01, -2.3479e-01,  2.2251e-01,  1.0396e-01,
          1.5007e-02, -2.3550e-01,  2.2580e-01,  1.6094e-01,  2.3189e-01,
          9.6714e-02],
        [ 8.5701e-02, -6.6273e-02, -1.0112e-01,  9.8696e-02,  8.7902e-02,
         -9.3682e-03,  3.8319e-02,  8.4409e-02, -2.4303e-01, -2.2194e-01,
         -6.5147e-02,  1.7171e-01,  1.2344e-01, -2.4008e-01, -7.6426e-02,
         -2.4895e-02],
        [ 8.0516e-02,  2.0612e-01,  3.8842e-03, -1.9317e-01,  1.3781e-02,
         -9.4967e-02, -1.5120e-01,  1.4007e-01, -3.1998e-02,  1.1961e-01,
          1.9308e-01,  2.2982e-02,  1.3922e-01, -1.1648e-01,  1.4114e-01,
          8.3920e-03],
        [ 1.6454e-01,  2.4061e-01, -1.9070e-01,  2.3881e-01,  1.8928e-01,
         -1.9981e-01,  7.4879e-02, -2.0193e-01,  8.2688e-02,  3.9598e-02,
         -2.4023e-01,  8.9165e-02, -7.0265e-02,  2.5079e-01,  2.4558e-01,
          8.4705e-02],
        [ 1.9865e-01,  8.8708e-02,  2.3808e-01, -2.4297e-02,  6.3299e-02,
         -4.2836e-02, -5.9514e-03, -7.6998e-02, -1.0051e-01,  1.4343e-01,
          1.0883e-01, -1.0879e-01, -2.1874e-01,  1.2066e-01, -2.3151e-01,
         -9.4732e-03],
        [-2.1351e-01,  2.0774e-01,  2.0516e-01, -2.0693e-01, -2.3087e-01,
         -1.4939e-01,  6.7392e-02, -1.2661e-01, -6.1130e-02, -6.4848e-02,
          4.7447e-02, -1.1666e-01,  1.1530e-01, -1.8049e-01, -2.3841e-02,
          2.1115e-01],
        [-1.3645e-01,  1.9021e-01,  1.3170e-01, -8.2213e-02,  8.8245e-02,
         -1.7047e-01,  1.8530e-02,  6.9223e-02,  2.1465e-01, -1.4132e-01,
         -1.4060e-01, -1.2319e-01, -2.4195e-01,  4.8969e-02, -2.0852e-01,
         -6.5516e-02],
        [-1.1314e-01,  1.5573e-02,  7.4250e-02, -1.8025e-01, -7.5369e-02,
         -2.2457e-02, -1.4293e-01,  5.9347e-02,  9.4142e-02, -1.7670e-01,
          1.9499e-01,  1.7606e-01, -7.6700e-02,  3.8789e-02,  3.2025e-02,
         -3.6090e-02],
        [-1.6934e-01,  2.0756e-01,  1.2155e-01, -2.0966e-01, -1.9517e-01,
          2.3912e-01,  4.1337e-02, -5.5919e-02,  1.7097e-01,  7.3130e-02,
          8.8200e-02,  1.9680e-01, -2.1025e-02,  2.3974e-01, -1.7408e-01,
         -1.5369e-01],
        [ 4.0766e-02, -2.8758e-02,  1.4108e-01, -6.6626e-02,  3.7754e-02,
         -5.0374e-02,  1.8928e-01, -1.4806e-02,  5.4262e-03,  1.8306e-01,
          2.4147e-01,  2.3763e-01, -2.4602e-01, -1.3968e-01, -5.2711e-02,
         -5.3206e-02],
        [ 1.4620e-01,  1.1132e-01, -1.8998e-02,  6.6081e-03,  5.5102e-02,
          2.1398e-01,  1.2799e-01, -1.2768e-01, -1.2965e-01,  7.7561e-02,
         -2.3707e-02, -1.5881e-01, -2.4039e-01,  3.4233e-02, -7.4582e-02,
         -1.4387e-01],
        [ 4.8624e-02,  2.4185e-01,  2.0924e-01,  1.4138e-01, -1.8698e-01,
          1.4110e-01,  1.2771e-01,  8.1816e-02, -6.3870e-02, -5.8959e-03,
         -1.3401e-01, -5.4722e-02, -3.9559e-02, -3.7006e-02, -2.5039e-01,
          8.9794e-02],
        [-2.0614e-01, -1.8537e-01,  1.0003e-01, -2.0340e-01,  2.3696e-01,
          2.4094e-01, -7.7865e-02, -4.1500e-02, -1.8968e-01,  1.6863e-02,
          4.4138e-02, -1.3872e-01,  7.6811e-02, -8.0410e-03, -7.2129e-02,
         -2.4561e-03],
        [-2.4074e-01, -1.7770e-01,  3.4669e-02,  2.4004e-01, -1.4663e-01,
          1.5871e-01,  2.1293e-02, -1.0915e-01, -1.3125e-03,  1.1841e-01,
          3.1321e-02,  2.2289e-01, -4.5725e-02, -1.6853e-01,  2.2433e-01,
         -6.9806e-02],
        [ 1.6022e-01,  1.6331e-01,  4.5859e-02, -2.0654e-01, -2.4388e-01,
          1.1711e-01,  5.9533e-02,  1.4387e-01, -2.2194e-01, -3.5919e-02,
          2.1758e-01,  1.3293e-01,  2.0935e-01,  1.9469e-01, -6.2923e-02,
         -1.6865e-01],
        [-1.5067e-01,  8.6502e-02, -1.0082e-01,  2.4639e-03,  3.8338e-02,
          1.5677e-01,  1.4102e-01,  1.4428e-01,  1.1751e-02,  1.4239e-01,
         -1.1862e-01, -1.0165e-01, -4.1177e-02, -1.4359e-01,  2.2458e-01,
         -3.9905e-02],
        [ 7.1136e-02, -6.2224e-03, -4.8646e-03, -1.3252e-01, -1.9704e-02,
         -2.2221e-01, -1.1803e-01,  1.9392e-01, -2.3298e-01,  4.2108e-02,
          3.8361e-02, -2.4079e-01,  4.7299e-02,  1.1760e-01,  1.8251e-01,
          4.5235e-02],
        [ 1.9697e-01,  7.8512e-03,  9.6727e-02,  7.2923e-02, -1.8295e-01,
         -5.6320e-02, -1.7759e-01,  1.9271e-01,  1.1774e-01, -1.0709e-01,
         -4.4265e-02,  6.8263e-02, -2.1644e-01,  5.5257e-03,  1.1779e-01,
          3.2891e-02],
        [-2.4600e-02,  1.6232e-01,  1.0716e-01, -2.2073e-01,  1.4556e-01,
         -1.9560e-01,  1.4203e-01,  2.1211e-01,  2.4635e-02, -8.2969e-02,
         -1.3073e-01, -1.1260e-01, -4.7679e-02, -1.0205e-01,  2.4977e-01,
         -1.0943e-01],
        [ 1.0220e-01, -2.3024e-01,  1.2512e-01,  2.1426e-01, -1.8078e-01,
         -6.2203e-02,  6.1179e-02, -2.3771e-01, -1.5659e-01,  8.7456e-02,
          2.3383e-01, -7.6277e-02, -3.8719e-03, -2.3974e-01, -2.3838e-01,
          2.1582e-01],
        [ 2.1375e-01, -7.7788e-02, -9.7265e-02, -1.7631e-02,  1.1757e-01,
         -2.4318e-01, -1.4007e-01, -8.4013e-02, -1.1041e-01, -8.1285e-03,
          1.8394e-01,  5.6177e-02, -2.2465e-01,  2.2963e-01,  1.9971e-01,
          8.0311e-02],
        [ 1.2397e-01,  9.1860e-02,  2.0651e-01, -2.4193e-01, -1.5406e-01,
         -3.3330e-02, -4.9148e-02, -1.6763e-01, -2.4134e-01, -1.9245e-01,
         -3.7237e-02,  2.1381e-01,  1.6734e-01,  7.0469e-02, -1.5514e-01,
         -9.8976e-02],
        [ 2.5677e-02, -2.3332e-01, -9.8330e-03,  4.9405e-02,  2.2757e-01,
         -6.7195e-02,  2.4380e-01,  1.7269e-02, -1.7503e-01,  2.3487e-01,
          2.1832e-01, -1.9595e-01, -1.4343e-01,  1.1795e-01, -1.5540e-01,
          1.7158e-01],
        [-1.1769e-01, -7.9186e-02, -7.0179e-02,  2.3718e-01, -8.2973e-02,
         -5.0187e-02,  1.4968e-01, -1.7264e-01, -2.7969e-03, -1.9465e-01,
         -2.2916e-01, -5.5487e-02,  2.9230e-02,  2.1160e-01, -2.4134e-01,
         -7.0340e-02],
        [ 6.7384e-02,  9.2809e-02,  1.4765e-01, -2.0243e-01, -5.9562e-02,
          5.6236e-02, -2.0199e-01,  1.2439e-01, -2.4013e-01,  1.5452e-01,
          8.2862e-02, -6.9424e-02,  8.2697e-02,  2.1016e-01,  1.8233e-01,
          1.5323e-01],
        [-1.4713e-01,  7.3432e-02,  1.8603e-01,  4.5455e-02,  1.6397e-01,
         -1.5348e-01,  1.7730e-01, -6.7016e-03, -2.2271e-01, -6.3634e-02,
          2.1939e-01, -8.8921e-02, -4.4890e-02, -9.8423e-02, -1.3436e-01,
          4.1717e-02],
        [ 1.5325e-01,  2.7968e-02, -1.3836e-02,  1.3890e-02, -1.8591e-01,
         -1.3329e-01,  1.0927e-02, -2.0141e-01,  1.2223e-01,  3.6578e-02,
          4.2223e-03, -1.4454e-02,  2.1274e-01,  2.2657e-01,  1.2048e-01,
          1.2576e-01],
        [-1.2282e-01,  1.0379e-01, -1.7068e-01,  1.0956e-01, -1.7909e-01,
          2.1579e-04,  1.8279e-01,  1.6760e-01,  2.2265e-01,  8.6572e-02,
          9.5459e-02,  6.5449e-02,  1.8096e-01,  1.3278e-01,  7.5352e-02,
         -8.8827e-02],
        [-1.2258e-01, -6.0219e-02,  1.1774e-01, -1.3487e-01,  6.6768e-02,
          2.2028e-01,  2.1327e-01, -1.8248e-01,  7.2840e-02,  1.6490e-01,
         -2.2865e-01,  1.5820e-01, -1.5736e-01, -1.7918e-01, -1.0440e-01,
         -9.5626e-02],
        [-1.0487e-01,  7.3496e-02,  9.5487e-02,  9.7729e-02,  1.7137e-01,
         -1.5686e-01, -2.3591e-01, -1.9907e-01, -1.3595e-01, -1.1357e-01,
          1.0846e-01, -1.8237e-01, -1.8427e-01,  1.3536e-01, -1.5771e-01,
          4.5356e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1917,  0.0939,  0.1572, -0.2093,  0.0863, -0.1295,  0.1573,  0.2233,
        -0.2124,  0.0924,  0.1673,  0.2288,  0.1904,  0.0507,  0.0134,  0.0517,
        -0.1476, -0.0474, -0.0042, -0.1589, -0.0096, -0.0316, -0.0860, -0.0756,
        -0.2505,  0.2398,  0.1223,  0.1823, -0.2112, -0.2432,  0.1845, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0260,  0.0870,  0.0129, -0.0075,  0.1035,  0.1428, -0.0509, -0.1525,
         -0.0953,  0.1279,  0.0170,  0.1498, -0.0602, -0.1659,  0.0533, -0.0767,
         -0.1041,  0.1118,  0.0107, -0.0135,  0.1738,  0.1524, -0.1460, -0.1641,
         -0.0890, -0.1357, -0.0945,  0.1177, -0.1192,  0.1637,  0.0568,  0.0061]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0259,  0.0354,  0.0503,  ...,  0.0354, -0.1588, -0.1137],
        [-0.0427, -0.1212,  0.0834,  ..., -0.0271, -0.1555,  0.0871],
        [-0.0900,  0.0711,  0.1146,  ...,  0.1532,  0.0707,  0.0345],
        ...,
        [ 0.0819, -0.0802,  0.0070,  ..., -0.1163, -0.0709, -0.1180],
        [ 0.0102, -0.1230, -0.0059,  ..., -0.1360, -0.0334,  0.1557],
        [-0.1353,  0.0645,  0.0425,  ..., -0.0271, -0.1428, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0571,  0.0677, -0.1058, -0.1144, -0.0472,  0.0086, -0.1302,  0.0721,
        -0.0285,  0.0916,  0.0461, -0.0240, -0.0140,  0.0476, -0.0816, -0.0399,
         0.0717, -0.1445, -0.0334,  0.0349, -0.0810,  0.0774,  0.0809, -0.0216,
        -0.0499,  0.0760,  0.0106, -0.1222,  0.0939,  0.1561,  0.1386, -0.0867],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1625, -0.0721, -0.1355,  ..., -0.0176, -0.1345,  0.1715],
        [-0.0972,  0.0941,  0.0392,  ...,  0.0679, -0.1339,  0.1686],
        [ 0.0236, -0.1659, -0.1005,  ..., -0.0599,  0.1155,  0.0568],
        ...,
        [ 0.0246, -0.0159,  0.1386,  ...,  0.1376, -0.1002,  0.1474],
        [ 0.0968, -0.0186, -0.0071,  ...,  0.1537,  0.1025, -0.0478],
        [ 0.0995, -0.0116,  0.1657,  ...,  0.1607,  0.0331,  0.0632]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0707,  0.1046,  0.0011, -0.0471, -0.0593, -0.1151, -0.0084, -0.0976,
         0.1071, -0.1282,  0.1521, -0.1545,  0.1488,  0.0184, -0.1650,  0.0546,
        -0.1154, -0.1416,  0.0109, -0.0487,  0.0420,  0.1382, -0.1637,  0.1774,
        -0.0964, -0.0333,  0.1130, -0.0722, -0.0907, -0.0430,  0.0707, -0.0061],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1626,  0.0779, -0.1629, -0.1288,  0.0155, -0.0084, -0.0522,  0.0565,
          0.0758, -0.1042, -0.0337,  0.0618,  0.0657, -0.0175,  0.0873,  0.0648,
         -0.1675, -0.1673,  0.0043,  0.0589, -0.1276, -0.0926, -0.1705,  0.0351,
          0.1297,  0.1572, -0.1424,  0.1381, -0.0692, -0.1541,  0.1119,  0.1470]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0075], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.5117e-01,  2.3702e-01,  1.6108e-01, -1.7820e-01, -1.3557e-03,
         -3.9014e-03,  1.2073e-01, -2.1255e-01,  5.2733e-03,  8.4580e-02,
          1.2568e-01,  2.4583e-02, -1.2549e-01, -2.3844e-01,  1.3666e-01,
          2.2666e-01],
        [-7.7073e-02, -2.2182e-01,  7.1567e-02, -1.7398e-01, -1.6490e-01,
          6.9713e-02, -2.2154e-02, -1.5415e-02,  2.2583e-01, -4.2366e-02,
          1.5059e-01, -7.9392e-02,  1.8444e-01,  7.7854e-02,  2.2436e-01,
          8.5601e-02],
        [-9.0102e-02,  1.1052e-01,  2.1155e-01,  4.8111e-02,  1.1391e-01,
         -1.7446e-01,  1.3699e-01, -2.3479e-01,  2.2251e-01,  1.0396e-01,
          1.5007e-02, -2.3550e-01,  2.2580e-01,  1.6094e-01,  2.3189e-01,
          9.6714e-02],
        [ 8.5701e-02, -6.6273e-02, -1.0112e-01,  9.8696e-02,  8.7902e-02,
         -9.3682e-03,  3.8319e-02,  8.4409e-02, -2.4303e-01, -2.2194e-01,
         -6.5147e-02,  1.7171e-01,  1.2344e-01, -2.4008e-01, -7.6426e-02,
         -2.4895e-02],
        [ 8.0516e-02,  2.0612e-01,  3.8842e-03, -1.9317e-01,  1.3781e-02,
         -9.4967e-02, -1.5120e-01,  1.4007e-01, -3.1998e-02,  1.1961e-01,
          1.9308e-01,  2.2982e-02,  1.3922e-01, -1.1648e-01,  1.4114e-01,
          8.3920e-03],
        [ 1.6454e-01,  2.4061e-01, -1.9070e-01,  2.3881e-01,  1.8928e-01,
         -1.9981e-01,  7.4879e-02, -2.0193e-01,  8.2688e-02,  3.9598e-02,
         -2.4023e-01,  8.9165e-02, -7.0265e-02,  2.5079e-01,  2.4558e-01,
          8.4705e-02],
        [ 1.9865e-01,  8.8708e-02,  2.3808e-01, -2.4297e-02,  6.3299e-02,
         -4.2836e-02, -5.9514e-03, -7.6998e-02, -1.0051e-01,  1.4343e-01,
          1.0883e-01, -1.0879e-01, -2.1874e-01,  1.2066e-01, -2.3151e-01,
         -9.4732e-03],
        [-2.1351e-01,  2.0774e-01,  2.0516e-01, -2.0693e-01, -2.3087e-01,
         -1.4939e-01,  6.7392e-02, -1.2661e-01, -6.1130e-02, -6.4848e-02,
          4.7447e-02, -1.1666e-01,  1.1530e-01, -1.8049e-01, -2.3841e-02,
          2.1115e-01],
        [-1.3645e-01,  1.9021e-01,  1.3170e-01, -8.2213e-02,  8.8245e-02,
         -1.7047e-01,  1.8530e-02,  6.9223e-02,  2.1465e-01, -1.4132e-01,
         -1.4060e-01, -1.2319e-01, -2.4195e-01,  4.8969e-02, -2.0852e-01,
         -6.5516e-02],
        [-1.1314e-01,  1.5573e-02,  7.4250e-02, -1.8025e-01, -7.5369e-02,
         -2.2457e-02, -1.4293e-01,  5.9347e-02,  9.4142e-02, -1.7670e-01,
          1.9499e-01,  1.7606e-01, -7.6700e-02,  3.8789e-02,  3.2025e-02,
         -3.6090e-02],
        [-1.6934e-01,  2.0756e-01,  1.2155e-01, -2.0966e-01, -1.9517e-01,
          2.3912e-01,  4.1337e-02, -5.5919e-02,  1.7097e-01,  7.3130e-02,
          8.8200e-02,  1.9680e-01, -2.1025e-02,  2.3974e-01, -1.7408e-01,
         -1.5369e-01],
        [ 4.0766e-02, -2.8758e-02,  1.4108e-01, -6.6626e-02,  3.7754e-02,
         -5.0374e-02,  1.8928e-01, -1.4806e-02,  5.4262e-03,  1.8306e-01,
          2.4147e-01,  2.3763e-01, -2.4602e-01, -1.3968e-01, -5.2711e-02,
         -5.3206e-02],
        [ 1.4620e-01,  1.1132e-01, -1.8998e-02,  6.6081e-03,  5.5102e-02,
          2.1398e-01,  1.2799e-01, -1.2768e-01, -1.2965e-01,  7.7561e-02,
         -2.3707e-02, -1.5881e-01, -2.4039e-01,  3.4233e-02, -7.4582e-02,
         -1.4387e-01],
        [ 4.8624e-02,  2.4185e-01,  2.0924e-01,  1.4138e-01, -1.8698e-01,
          1.4110e-01,  1.2771e-01,  8.1816e-02, -6.3870e-02, -5.8959e-03,
         -1.3401e-01, -5.4722e-02, -3.9559e-02, -3.7006e-02, -2.5039e-01,
          8.9794e-02],
        [-2.0614e-01, -1.8537e-01,  1.0003e-01, -2.0340e-01,  2.3696e-01,
          2.4094e-01, -7.7865e-02, -4.1500e-02, -1.8968e-01,  1.6863e-02,
          4.4138e-02, -1.3872e-01,  7.6811e-02, -8.0410e-03, -7.2129e-02,
         -2.4561e-03],
        [-2.4074e-01, -1.7770e-01,  3.4669e-02,  2.4004e-01, -1.4663e-01,
          1.5871e-01,  2.1293e-02, -1.0915e-01, -1.3125e-03,  1.1841e-01,
          3.1321e-02,  2.2289e-01, -4.5725e-02, -1.6853e-01,  2.2433e-01,
         -6.9806e-02],
        [ 1.6022e-01,  1.6331e-01,  4.5859e-02, -2.0654e-01, -2.4388e-01,
          1.1711e-01,  5.9533e-02,  1.4387e-01, -2.2194e-01, -3.5919e-02,
          2.1758e-01,  1.3293e-01,  2.0935e-01,  1.9469e-01, -6.2923e-02,
         -1.6865e-01],
        [-1.5067e-01,  8.6502e-02, -1.0082e-01,  2.4639e-03,  3.8338e-02,
          1.5677e-01,  1.4102e-01,  1.4428e-01,  1.1751e-02,  1.4239e-01,
         -1.1862e-01, -1.0165e-01, -4.1177e-02, -1.4359e-01,  2.2458e-01,
         -3.9905e-02],
        [ 7.1136e-02, -6.2224e-03, -4.8646e-03, -1.3252e-01, -1.9704e-02,
         -2.2221e-01, -1.1803e-01,  1.9392e-01, -2.3298e-01,  4.2108e-02,
          3.8361e-02, -2.4079e-01,  4.7299e-02,  1.1760e-01,  1.8251e-01,
          4.5235e-02],
        [ 1.9697e-01,  7.8512e-03,  9.6727e-02,  7.2923e-02, -1.8295e-01,
         -5.6320e-02, -1.7759e-01,  1.9271e-01,  1.1774e-01, -1.0709e-01,
         -4.4265e-02,  6.8263e-02, -2.1644e-01,  5.5257e-03,  1.1779e-01,
          3.2891e-02],
        [-2.4600e-02,  1.6232e-01,  1.0716e-01, -2.2073e-01,  1.4556e-01,
         -1.9560e-01,  1.4203e-01,  2.1211e-01,  2.4635e-02, -8.2969e-02,
         -1.3073e-01, -1.1260e-01, -4.7679e-02, -1.0205e-01,  2.4977e-01,
         -1.0943e-01],
        [ 1.0220e-01, -2.3024e-01,  1.2512e-01,  2.1426e-01, -1.8078e-01,
         -6.2203e-02,  6.1179e-02, -2.3771e-01, -1.5659e-01,  8.7456e-02,
          2.3383e-01, -7.6277e-02, -3.8719e-03, -2.3974e-01, -2.3838e-01,
          2.1582e-01],
        [ 2.1375e-01, -7.7788e-02, -9.7265e-02, -1.7631e-02,  1.1757e-01,
         -2.4318e-01, -1.4007e-01, -8.4013e-02, -1.1041e-01, -8.1285e-03,
          1.8394e-01,  5.6177e-02, -2.2465e-01,  2.2963e-01,  1.9971e-01,
          8.0311e-02],
        [ 1.2397e-01,  9.1860e-02,  2.0651e-01, -2.4193e-01, -1.5406e-01,
         -3.3330e-02, -4.9148e-02, -1.6763e-01, -2.4134e-01, -1.9245e-01,
         -3.7237e-02,  2.1381e-01,  1.6734e-01,  7.0469e-02, -1.5514e-01,
         -9.8976e-02],
        [ 2.5677e-02, -2.3332e-01, -9.8330e-03,  4.9405e-02,  2.2757e-01,
         -6.7195e-02,  2.4380e-01,  1.7269e-02, -1.7503e-01,  2.3487e-01,
          2.1832e-01, -1.9595e-01, -1.4343e-01,  1.1795e-01, -1.5540e-01,
          1.7158e-01],
        [-1.1769e-01, -7.9186e-02, -7.0179e-02,  2.3718e-01, -8.2973e-02,
         -5.0187e-02,  1.4968e-01, -1.7264e-01, -2.7969e-03, -1.9465e-01,
         -2.2916e-01, -5.5487e-02,  2.9230e-02,  2.1160e-01, -2.4134e-01,
         -7.0340e-02],
        [ 6.7384e-02,  9.2809e-02,  1.4765e-01, -2.0243e-01, -5.9562e-02,
          5.6236e-02, -2.0199e-01,  1.2439e-01, -2.4013e-01,  1.5452e-01,
          8.2862e-02, -6.9424e-02,  8.2697e-02,  2.1016e-01,  1.8233e-01,
          1.5323e-01],
        [-1.4713e-01,  7.3432e-02,  1.8603e-01,  4.5455e-02,  1.6397e-01,
         -1.5348e-01,  1.7730e-01, -6.7016e-03, -2.2271e-01, -6.3634e-02,
          2.1939e-01, -8.8921e-02, -4.4890e-02, -9.8423e-02, -1.3436e-01,
          4.1717e-02],
        [ 1.5325e-01,  2.7968e-02, -1.3836e-02,  1.3890e-02, -1.8591e-01,
         -1.3329e-01,  1.0927e-02, -2.0141e-01,  1.2223e-01,  3.6578e-02,
          4.2223e-03, -1.4454e-02,  2.1274e-01,  2.2657e-01,  1.2048e-01,
          1.2576e-01],
        [-1.2282e-01,  1.0379e-01, -1.7068e-01,  1.0956e-01, -1.7909e-01,
          2.1579e-04,  1.8279e-01,  1.6760e-01,  2.2265e-01,  8.6572e-02,
          9.5459e-02,  6.5449e-02,  1.8096e-01,  1.3278e-01,  7.5352e-02,
         -8.8827e-02],
        [-1.2258e-01, -6.0219e-02,  1.1774e-01, -1.3487e-01,  6.6768e-02,
          2.2028e-01,  2.1327e-01, -1.8248e-01,  7.2840e-02,  1.6490e-01,
         -2.2865e-01,  1.5820e-01, -1.5736e-01, -1.7918e-01, -1.0440e-01,
         -9.5626e-02],
        [-1.0487e-01,  7.3496e-02,  9.5487e-02,  9.7729e-02,  1.7137e-01,
         -1.5686e-01, -2.3591e-01, -1.9907e-01, -1.3595e-01, -1.1357e-01,
          1.0846e-01, -1.8237e-01, -1.8427e-01,  1.3536e-01, -1.5771e-01,
          4.5356e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1917,  0.0939,  0.1572, -0.2093,  0.0863, -0.1295,  0.1573,  0.2233,
        -0.2124,  0.0924,  0.1673,  0.2288,  0.1904,  0.0507,  0.0134,  0.0517,
        -0.1476, -0.0474, -0.0042, -0.1589, -0.0096, -0.0316, -0.0860, -0.0756,
        -0.2505,  0.2398,  0.1223,  0.1823, -0.2112, -0.2432,  0.1845, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0260,  0.0870,  0.0129, -0.0075,  0.1035,  0.1428, -0.0509, -0.1525,
         -0.0953,  0.1279,  0.0170,  0.1498, -0.0602, -0.1659,  0.0533, -0.0767,
         -0.1041,  0.1118,  0.0107, -0.0135,  0.1738,  0.1524, -0.1460, -0.1641,
         -0.0890, -0.1357, -0.0945,  0.1177, -0.1192,  0.1637,  0.0568,  0.0061]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0259,  0.0354,  0.0503,  ...,  0.0354, -0.1588, -0.1137],
        [-0.0427, -0.1212,  0.0834,  ..., -0.0271, -0.1555,  0.0871],
        [-0.0900,  0.0711,  0.1146,  ...,  0.1532,  0.0707,  0.0345],
        ...,
        [ 0.0819, -0.0802,  0.0070,  ..., -0.1163, -0.0709, -0.1180],
        [ 0.0102, -0.1230, -0.0059,  ..., -0.1360, -0.0334,  0.1557],
        [-0.1353,  0.0645,  0.0425,  ..., -0.0271, -0.1428, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0571,  0.0677, -0.1058, -0.1144, -0.0472,  0.0086, -0.1302,  0.0721,
        -0.0285,  0.0916,  0.0461, -0.0240, -0.0140,  0.0476, -0.0816, -0.0399,
         0.0717, -0.1445, -0.0334,  0.0349, -0.0810,  0.0774,  0.0809, -0.0216,
        -0.0499,  0.0760,  0.0106, -0.1222,  0.0939,  0.1561,  0.1386, -0.0867],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1625, -0.0721, -0.1355,  ..., -0.0176, -0.1345,  0.1715],
        [-0.0972,  0.0941,  0.0392,  ...,  0.0679, -0.1339,  0.1686],
        [ 0.0236, -0.1659, -0.1005,  ..., -0.0599,  0.1155,  0.0568],
        ...,
        [ 0.0246, -0.0159,  0.1386,  ...,  0.1376, -0.1002,  0.1474],
        [ 0.0968, -0.0186, -0.0071,  ...,  0.1537,  0.1025, -0.0478],
        [ 0.0995, -0.0116,  0.1657,  ...,  0.1607,  0.0331,  0.0632]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0707,  0.1046,  0.0011, -0.0471, -0.0593, -0.1151, -0.0084, -0.0976,
         0.1071, -0.1282,  0.1521, -0.1545,  0.1488,  0.0184, -0.1650,  0.0546,
        -0.1154, -0.1416,  0.0109, -0.0487,  0.0420,  0.1382, -0.1637,  0.1774,
        -0.0964, -0.0333,  0.1130, -0.0722, -0.0907, -0.0430,  0.0707, -0.0061],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1626,  0.0779, -0.1629, -0.1288,  0.0155, -0.0084, -0.0522,  0.0565,
          0.0758, -0.1042, -0.0337,  0.0618,  0.0657, -0.0175,  0.0873,  0.0648,
         -0.1675, -0.1673,  0.0043,  0.0589, -0.1276, -0.0926, -0.1705,  0.0351,
          0.1297,  0.1572, -0.1424,  0.1381, -0.0692, -0.1541,  0.1119,  0.1470]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0075], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.5117e-01,  2.3702e-01,  1.6108e-01, -1.7820e-01, -1.3557e-03,
         -3.9014e-03,  1.2073e-01, -2.1255e-01,  5.2733e-03,  8.4580e-02,
          1.2568e-01,  2.4583e-02, -1.2549e-01, -2.3844e-01,  1.3666e-01,
          2.2666e-01],
        [-7.7073e-02, -2.2182e-01,  7.1567e-02, -1.7398e-01, -1.6490e-01,
          6.9713e-02, -2.2154e-02, -1.5415e-02,  2.2583e-01, -4.2366e-02,
          1.5059e-01, -7.9392e-02,  1.8444e-01,  7.7854e-02,  2.2436e-01,
          8.5601e-02],
        [-9.0102e-02,  1.1052e-01,  2.1155e-01,  4.8111e-02,  1.1391e-01,
         -1.7446e-01,  1.3699e-01, -2.3479e-01,  2.2251e-01,  1.0396e-01,
          1.5007e-02, -2.3550e-01,  2.2580e-01,  1.6094e-01,  2.3189e-01,
          9.6714e-02],
        [ 8.5701e-02, -6.6273e-02, -1.0112e-01,  9.8696e-02,  8.7902e-02,
         -9.3682e-03,  3.8319e-02,  8.4409e-02, -2.4303e-01, -2.2194e-01,
         -6.5147e-02,  1.7171e-01,  1.2344e-01, -2.4008e-01, -7.6426e-02,
         -2.4895e-02],
        [ 8.0516e-02,  2.0612e-01,  3.8842e-03, -1.9317e-01,  1.3781e-02,
         -9.4967e-02, -1.5120e-01,  1.4007e-01, -3.1998e-02,  1.1961e-01,
          1.9308e-01,  2.2982e-02,  1.3922e-01, -1.1648e-01,  1.4114e-01,
          8.3920e-03],
        [ 1.6454e-01,  2.4061e-01, -1.9070e-01,  2.3881e-01,  1.8928e-01,
         -1.9981e-01,  7.4879e-02, -2.0193e-01,  8.2688e-02,  3.9598e-02,
         -2.4023e-01,  8.9165e-02, -7.0265e-02,  2.5079e-01,  2.4558e-01,
          8.4705e-02],
        [ 1.9865e-01,  8.8708e-02,  2.3808e-01, -2.4297e-02,  6.3299e-02,
         -4.2836e-02, -5.9514e-03, -7.6998e-02, -1.0051e-01,  1.4343e-01,
          1.0883e-01, -1.0879e-01, -2.1874e-01,  1.2066e-01, -2.3151e-01,
         -9.4732e-03],
        [-2.1351e-01,  2.0774e-01,  2.0516e-01, -2.0693e-01, -2.3087e-01,
         -1.4939e-01,  6.7392e-02, -1.2661e-01, -6.1130e-02, -6.4848e-02,
          4.7447e-02, -1.1666e-01,  1.1530e-01, -1.8049e-01, -2.3841e-02,
          2.1115e-01],
        [-1.3645e-01,  1.9021e-01,  1.3170e-01, -8.2213e-02,  8.8245e-02,
         -1.7047e-01,  1.8530e-02,  6.9223e-02,  2.1465e-01, -1.4132e-01,
         -1.4060e-01, -1.2319e-01, -2.4195e-01,  4.8969e-02, -2.0852e-01,
         -6.5516e-02],
        [-1.1314e-01,  1.5573e-02,  7.4250e-02, -1.8025e-01, -7.5369e-02,
         -2.2457e-02, -1.4293e-01,  5.9347e-02,  9.4142e-02, -1.7670e-01,
          1.9499e-01,  1.7606e-01, -7.6700e-02,  3.8789e-02,  3.2025e-02,
         -3.6090e-02],
        [-1.6934e-01,  2.0756e-01,  1.2155e-01, -2.0966e-01, -1.9517e-01,
          2.3912e-01,  4.1337e-02, -5.5919e-02,  1.7097e-01,  7.3130e-02,
          8.8200e-02,  1.9680e-01, -2.1025e-02,  2.3974e-01, -1.7408e-01,
         -1.5369e-01],
        [ 4.0766e-02, -2.8758e-02,  1.4108e-01, -6.6626e-02,  3.7754e-02,
         -5.0374e-02,  1.8928e-01, -1.4806e-02,  5.4262e-03,  1.8306e-01,
          2.4147e-01,  2.3763e-01, -2.4602e-01, -1.3968e-01, -5.2711e-02,
         -5.3206e-02],
        [ 1.4620e-01,  1.1132e-01, -1.8998e-02,  6.6081e-03,  5.5102e-02,
          2.1398e-01,  1.2799e-01, -1.2768e-01, -1.2965e-01,  7.7561e-02,
         -2.3707e-02, -1.5881e-01, -2.4039e-01,  3.4233e-02, -7.4582e-02,
         -1.4387e-01],
        [ 4.8624e-02,  2.4185e-01,  2.0924e-01,  1.4138e-01, -1.8698e-01,
          1.4110e-01,  1.2771e-01,  8.1816e-02, -6.3870e-02, -5.8959e-03,
         -1.3401e-01, -5.4722e-02, -3.9559e-02, -3.7006e-02, -2.5039e-01,
          8.9794e-02],
        [-2.0614e-01, -1.8537e-01,  1.0003e-01, -2.0340e-01,  2.3696e-01,
          2.4094e-01, -7.7865e-02, -4.1500e-02, -1.8968e-01,  1.6863e-02,
          4.4138e-02, -1.3872e-01,  7.6811e-02, -8.0410e-03, -7.2129e-02,
         -2.4561e-03],
        [-2.4074e-01, -1.7770e-01,  3.4669e-02,  2.4004e-01, -1.4663e-01,
          1.5871e-01,  2.1293e-02, -1.0915e-01, -1.3125e-03,  1.1841e-01,
          3.1321e-02,  2.2289e-01, -4.5725e-02, -1.6853e-01,  2.2433e-01,
         -6.9806e-02],
        [ 1.6022e-01,  1.6331e-01,  4.5859e-02, -2.0654e-01, -2.4388e-01,
          1.1711e-01,  5.9533e-02,  1.4387e-01, -2.2194e-01, -3.5919e-02,
          2.1758e-01,  1.3293e-01,  2.0935e-01,  1.9469e-01, -6.2923e-02,
         -1.6865e-01],
        [-1.5067e-01,  8.6502e-02, -1.0082e-01,  2.4639e-03,  3.8338e-02,
          1.5677e-01,  1.4102e-01,  1.4428e-01,  1.1751e-02,  1.4239e-01,
         -1.1862e-01, -1.0165e-01, -4.1177e-02, -1.4359e-01,  2.2458e-01,
         -3.9905e-02],
        [ 7.1136e-02, -6.2224e-03, -4.8646e-03, -1.3252e-01, -1.9704e-02,
         -2.2221e-01, -1.1803e-01,  1.9392e-01, -2.3298e-01,  4.2108e-02,
          3.8361e-02, -2.4079e-01,  4.7299e-02,  1.1760e-01,  1.8251e-01,
          4.5235e-02],
        [ 1.9697e-01,  7.8512e-03,  9.6727e-02,  7.2923e-02, -1.8295e-01,
         -5.6320e-02, -1.7759e-01,  1.9271e-01,  1.1774e-01, -1.0709e-01,
         -4.4265e-02,  6.8263e-02, -2.1644e-01,  5.5257e-03,  1.1779e-01,
          3.2891e-02],
        [-2.4600e-02,  1.6232e-01,  1.0716e-01, -2.2073e-01,  1.4556e-01,
         -1.9560e-01,  1.4203e-01,  2.1211e-01,  2.4635e-02, -8.2969e-02,
         -1.3073e-01, -1.1260e-01, -4.7679e-02, -1.0205e-01,  2.4977e-01,
         -1.0943e-01],
        [ 1.0220e-01, -2.3024e-01,  1.2512e-01,  2.1426e-01, -1.8078e-01,
         -6.2203e-02,  6.1179e-02, -2.3771e-01, -1.5659e-01,  8.7456e-02,
          2.3383e-01, -7.6277e-02, -3.8719e-03, -2.3974e-01, -2.3838e-01,
          2.1582e-01],
        [ 2.1375e-01, -7.7788e-02, -9.7265e-02, -1.7631e-02,  1.1757e-01,
         -2.4318e-01, -1.4007e-01, -8.4013e-02, -1.1041e-01, -8.1285e-03,
          1.8394e-01,  5.6177e-02, -2.2465e-01,  2.2963e-01,  1.9971e-01,
          8.0311e-02],
        [ 1.2397e-01,  9.1860e-02,  2.0651e-01, -2.4193e-01, -1.5406e-01,
         -3.3330e-02, -4.9148e-02, -1.6763e-01, -2.4134e-01, -1.9245e-01,
         -3.7237e-02,  2.1381e-01,  1.6734e-01,  7.0469e-02, -1.5514e-01,
         -9.8976e-02],
        [ 2.5677e-02, -2.3332e-01, -9.8330e-03,  4.9405e-02,  2.2757e-01,
         -6.7195e-02,  2.4380e-01,  1.7269e-02, -1.7503e-01,  2.3487e-01,
          2.1832e-01, -1.9595e-01, -1.4343e-01,  1.1795e-01, -1.5540e-01,
          1.7158e-01],
        [-1.1769e-01, -7.9186e-02, -7.0179e-02,  2.3718e-01, -8.2973e-02,
         -5.0187e-02,  1.4968e-01, -1.7264e-01, -2.7969e-03, -1.9465e-01,
         -2.2916e-01, -5.5487e-02,  2.9230e-02,  2.1160e-01, -2.4134e-01,
         -7.0340e-02],
        [ 6.7384e-02,  9.2809e-02,  1.4765e-01, -2.0243e-01, -5.9562e-02,
          5.6236e-02, -2.0199e-01,  1.2439e-01, -2.4013e-01,  1.5452e-01,
          8.2862e-02, -6.9424e-02,  8.2697e-02,  2.1016e-01,  1.8233e-01,
          1.5323e-01],
        [-1.4713e-01,  7.3432e-02,  1.8603e-01,  4.5455e-02,  1.6397e-01,
         -1.5348e-01,  1.7730e-01, -6.7016e-03, -2.2271e-01, -6.3634e-02,
          2.1939e-01, -8.8921e-02, -4.4890e-02, -9.8423e-02, -1.3436e-01,
          4.1717e-02],
        [ 1.5325e-01,  2.7968e-02, -1.3836e-02,  1.3890e-02, -1.8591e-01,
         -1.3329e-01,  1.0927e-02, -2.0141e-01,  1.2223e-01,  3.6578e-02,
          4.2223e-03, -1.4454e-02,  2.1274e-01,  2.2657e-01,  1.2048e-01,
          1.2576e-01],
        [-1.2282e-01,  1.0379e-01, -1.7068e-01,  1.0956e-01, -1.7909e-01,
          2.1579e-04,  1.8279e-01,  1.6760e-01,  2.2265e-01,  8.6572e-02,
          9.5459e-02,  6.5449e-02,  1.8096e-01,  1.3278e-01,  7.5352e-02,
         -8.8827e-02],
        [-1.2258e-01, -6.0219e-02,  1.1774e-01, -1.3487e-01,  6.6768e-02,
          2.2028e-01,  2.1327e-01, -1.8248e-01,  7.2840e-02,  1.6490e-01,
         -2.2865e-01,  1.5820e-01, -1.5736e-01, -1.7918e-01, -1.0440e-01,
         -9.5626e-02],
        [-1.0487e-01,  7.3496e-02,  9.5487e-02,  9.7729e-02,  1.7137e-01,
         -1.5686e-01, -2.3591e-01, -1.9907e-01, -1.3595e-01, -1.1357e-01,
          1.0846e-01, -1.8237e-01, -1.8427e-01,  1.3536e-01, -1.5771e-01,
          4.5356e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1917,  0.0939,  0.1572, -0.2093,  0.0863, -0.1295,  0.1573,  0.2233,
        -0.2124,  0.0924,  0.1673,  0.2288,  0.1904,  0.0507,  0.0134,  0.0517,
        -0.1476, -0.0474, -0.0042, -0.1589, -0.0096, -0.0316, -0.0860, -0.0756,
        -0.2505,  0.2398,  0.1223,  0.1823, -0.2112, -0.2432,  0.1845, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0260,  0.0870,  0.0129, -0.0075,  0.1035,  0.1428, -0.0509, -0.1525,
         -0.0953,  0.1279,  0.0170,  0.1498, -0.0602, -0.1659,  0.0533, -0.0767,
         -0.1041,  0.1118,  0.0107, -0.0135,  0.1738,  0.1524, -0.1460, -0.1641,
         -0.0890, -0.1357, -0.0945,  0.1177, -0.1192,  0.1637,  0.0568,  0.0061]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0259,  0.0354,  0.0503,  ...,  0.0354, -0.1588, -0.1137],
        [-0.0427, -0.1212,  0.0834,  ..., -0.0271, -0.1555,  0.0871],
        [-0.0900,  0.0711,  0.1146,  ...,  0.1532,  0.0707,  0.0345],
        ...,
        [ 0.0819, -0.0802,  0.0070,  ..., -0.1163, -0.0709, -0.1180],
        [ 0.0102, -0.1230, -0.0059,  ..., -0.1360, -0.0334,  0.1557],
        [-0.1353,  0.0645,  0.0425,  ..., -0.0271, -0.1428, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0571,  0.0677, -0.1058, -0.1144, -0.0472,  0.0086, -0.1302,  0.0721,
        -0.0285,  0.0916,  0.0461, -0.0240, -0.0140,  0.0476, -0.0816, -0.0399,
         0.0717, -0.1445, -0.0334,  0.0349, -0.0810,  0.0774,  0.0809, -0.0216,
        -0.0499,  0.0760,  0.0106, -0.1222,  0.0939,  0.1561,  0.1386, -0.0867],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1625, -0.0721, -0.1355,  ..., -0.0176, -0.1345,  0.1715],
        [-0.0972,  0.0941,  0.0392,  ...,  0.0679, -0.1339,  0.1686],
        [ 0.0236, -0.1659, -0.1005,  ..., -0.0599,  0.1155,  0.0568],
        ...,
        [ 0.0246, -0.0159,  0.1386,  ...,  0.1376, -0.1002,  0.1474],
        [ 0.0968, -0.0186, -0.0071,  ...,  0.1537,  0.1025, -0.0478],
        [ 0.0995, -0.0116,  0.1657,  ...,  0.1607,  0.0331,  0.0632]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0707,  0.1046,  0.0011, -0.0471, -0.0593, -0.1151, -0.0084, -0.0976,
         0.1071, -0.1282,  0.1521, -0.1545,  0.1488,  0.0184, -0.1650,  0.0546,
        -0.1154, -0.1416,  0.0109, -0.0487,  0.0420,  0.1382, -0.1637,  0.1774,
        -0.0964, -0.0333,  0.1130, -0.0722, -0.0907, -0.0430,  0.0707, -0.0061],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1626,  0.0779, -0.1629, -0.1288,  0.0155, -0.0084, -0.0522,  0.0565,
          0.0758, -0.1042, -0.0337,  0.0618,  0.0657, -0.0175,  0.0873,  0.0648,
         -0.1675, -0.1673,  0.0043,  0.0589, -0.1276, -0.0926, -0.1705,  0.0351,
          0.1297,  0.1572, -0.1424,  0.1381, -0.0692, -0.1541,  0.1119,  0.1470]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0075], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.5117e-01,  2.3702e-01,  1.6117e-01, -1.8083e-01,  1.5996e-03,
         -3.8688e-03,  1.2075e-01, -2.1253e-01,  3.5190e-03,  8.1818e-02,
          1.2844e-01,  2.4582e-02, -1.2549e-01, -2.3842e-01,  1.3652e-01,
          2.2666e-01],
        [-7.7075e-02, -2.2182e-01,  7.1594e-02, -1.7686e-01, -1.6178e-01,
          6.9724e-02, -2.2148e-02, -1.5408e-02,  2.2530e-01, -4.5396e-02,
          1.5079e-01, -7.9392e-02,  1.8443e-01,  7.7860e-02,  2.2433e-01,
          8.5600e-02],
        [-9.0098e-02,  1.1053e-01,  2.1172e-01,  4.5864e-02,  1.1658e-01,
         -1.7442e-01,  1.3701e-01, -2.3475e-01,  2.2086e-01,  1.0190e-01,
          1.7394e-02, -2.3549e-01,  2.2580e-01,  1.6096e-01,  2.3161e-01,
          9.6720e-02],
        [ 8.5704e-02, -6.6304e-02, -1.0136e-01,  1.0058e-01,  8.5535e-02,
         -9.4861e-03,  3.8240e-02,  8.4325e-02, -2.4190e-01, -2.1988e-01,
         -6.6203e-02,  1.7172e-01,  1.2348e-01, -2.4015e-01, -7.6173e-02,
         -2.4892e-02],
        [ 8.0514e-02,  2.0613e-01,  3.9090e-03, -1.9619e-01,  1.6908e-02,
         -9.4958e-02, -1.5119e-01,  1.4007e-01, -3.3974e-02,  1.1657e-01,
          1.9617e-01,  2.2982e-02,  1.3922e-01, -1.1648e-01,  1.4108e-01,
          8.3909e-03],
        [ 1.6454e-01,  2.4061e-01, -1.9068e-01,  2.3574e-01,  1.9241e-01,
         -1.9981e-01,  7.4882e-02, -2.0193e-01,  8.0523e-02,  3.7098e-02,
         -2.3712e-01,  8.9165e-02, -7.0266e-02,  2.5079e-01,  2.4554e-01,
          8.4705e-02],
        [ 1.9865e-01,  8.8705e-02,  2.3803e-01, -2.1506e-02,  6.0289e-02,
         -4.2853e-02, -5.9589e-03, -7.7009e-02, -1.0023e-01,  1.4611e-01,
          1.0868e-01, -1.0879e-01, -2.1874e-01,  1.2065e-01, -2.3149e-01,
         -9.4739e-03],
        [-2.1351e-01,  2.0774e-01,  2.0514e-01, -2.0387e-01, -2.3401e-01,
         -1.4940e-01,  6.7388e-02, -1.2662e-01, -5.8675e-02, -6.1803e-02,
          4.4296e-02, -1.1666e-01,  1.1530e-01, -1.8049e-01, -2.3769e-02,
          2.1115e-01],
        [-1.3645e-01,  1.9021e-01,  1.3167e-01, -7.9167e-02,  8.5124e-02,
         -1.7048e-01,  1.8525e-02,  6.9218e-02,  2.1749e-01, -1.3834e-01,
         -1.4374e-01, -1.2319e-01, -2.4195e-01,  4.8964e-02, -2.0769e-01,
         -6.5515e-02],
        [-1.1314e-01,  1.5575e-02,  7.4269e-02, -1.8326e-01, -7.2234e-02,
         -2.2450e-02, -1.4292e-01,  5.9352e-02,  9.3426e-02, -1.7973e-01,
          1.9538e-01,  1.7606e-01, -7.6702e-02,  3.8793e-02,  3.2006e-02,
         -3.6090e-02],
        [-1.6935e-01,  2.0758e-01,  1.2165e-01, -2.1046e-01, -1.9247e-01,
          2.3920e-01,  4.1439e-02, -5.5861e-02,  1.7082e-01,  7.0666e-02,
          8.8224e-02,  1.9680e-01, -2.1048e-02,  2.3978e-01, -1.7409e-01,
         -1.5369e-01],
        [ 4.0763e-02, -2.8755e-02,  1.4110e-01, -6.9571e-02,  4.0871e-02,
         -5.0366e-02,  1.8928e-01, -1.4801e-02,  5.1114e-03,  1.8160e-01,
          2.4161e-01,  2.3763e-01, -2.4602e-01, -1.3967e-01, -5.2724e-02,
         -5.3207e-02],
        [ 1.4620e-01,  1.1132e-01, -1.9034e-02,  7.5046e-03,  5.2049e-02,
          2.1395e-01,  1.2797e-01, -1.2770e-01, -1.2957e-01,  8.0546e-02,
         -2.3727e-02, -1.5881e-01, -2.4038e-01,  3.4222e-02, -7.4576e-02,
         -1.4387e-01],
        [ 4.8625e-02,  2.4185e-01,  2.0922e-01,  1.4413e-01, -1.9013e-01,
          1.4110e-01,  1.2771e-01,  8.1812e-02, -6.3798e-02, -2.7933e-03,
         -1.3404e-01, -5.4723e-02, -3.9557e-02, -3.7009e-02, -2.5038e-01,
          8.9794e-02],
        [-2.0614e-01, -1.8537e-01,  1.0007e-01, -2.0623e-01,  2.4004e-01,
          2.4095e-01, -7.7855e-02, -4.1491e-02, -1.9171e-01,  1.3923e-02,
          4.7158e-02, -1.3872e-01,  7.6807e-02, -8.0322e-03, -7.2226e-02,
         -2.4568e-03],
        [-2.4074e-01, -1.7770e-01,  3.4642e-02,  2.4302e-01, -1.4973e-01,
          1.5869e-01,  2.1286e-02, -1.0916e-01, -1.0171e-03,  1.2140e-01,
          3.1157e-02,  2.2289e-01, -4.5722e-02, -1.6854e-01,  2.2436e-01,
         -6.9805e-02],
        [ 1.6022e-01,  1.6330e-01,  4.5844e-02, -2.0360e-01, -2.4699e-01,
          1.1710e-01,  5.9528e-02,  1.4387e-01, -2.2188e-01, -3.2905e-02,
          2.1756e-01,  1.3293e-01,  2.0935e-01,  1.9469e-01, -6.2923e-02,
         -1.6865e-01],
        [-1.5067e-01,  8.6503e-02, -1.0079e-01, -5.9829e-04,  4.1467e-02,
          1.5678e-01,  1.4102e-01,  1.4428e-01,  8.8507e-03,  1.3957e-01,
         -1.1547e-01, -1.0165e-01, -4.1179e-02, -1.4359e-01,  2.2233e-01,
         -3.9906e-02],
        [ 7.1127e-02, -6.1986e-03, -4.7003e-03, -1.3478e-01, -1.6987e-02,
         -2.2213e-01, -1.1799e-01,  1.9397e-01, -2.3510e-01,  3.9738e-02,
          4.1107e-02, -2.4080e-01,  4.7270e-02,  1.1764e-01,  1.8197e-01,
          4.5225e-02],
        [ 1.9698e-01,  7.8381e-03,  9.6578e-02,  7.5340e-02, -1.8573e-01,
         -5.6374e-02, -1.7762e-01,  1.9267e-01,  1.1970e-01, -1.0462e-01,
         -4.6950e-02,  6.8264e-02, -2.1642e-01,  5.4952e-03,  1.1810e-01,
          3.2893e-02],
        [-2.4601e-02,  1.6232e-01,  1.0717e-01, -2.2384e-01,  1.4871e-01,
         -1.9559e-01,  1.4203e-01,  2.1211e-01,  2.2388e-02, -8.6061e-02,
         -1.2758e-01, -1.1260e-01, -4.7680e-02, -1.0205e-01,  2.4972e-01,
         -1.0943e-01],
        [ 1.0220e-01, -2.3023e-01,  1.2515e-01,  2.1114e-01, -1.7764e-01,
         -6.2198e-02,  6.1182e-02, -2.3771e-01, -1.5969e-01,  8.5374e-02,
          2.3700e-01, -7.6275e-02, -3.8732e-03, -2.3974e-01, -2.4151e-01,
          2.1582e-01],
        [ 2.1375e-01, -7.7789e-02, -9.7285e-02, -1.4592e-02,  1.1442e-01,
         -2.4318e-01, -1.4008e-01, -8.4017e-02, -1.0857e-01, -5.0405e-03,
          1.8084e-01,  5.6176e-02, -2.2465e-01,  2.2963e-01,  1.9974e-01,
          8.0311e-02],
        [ 1.2397e-01,  9.1859e-02,  2.0649e-01, -2.3886e-01, -1.5721e-01,
         -3.3335e-02, -4.9151e-02, -1.6763e-01, -2.3941e-01, -1.8937e-01,
         -4.0349e-02,  2.1381e-01,  1.6734e-01,  7.0465e-02, -1.5510e-01,
         -9.8976e-02],
        [ 2.5678e-02, -2.3332e-01, -9.8618e-03,  5.2425e-02,  2.2446e-01,
         -6.7203e-02,  2.4380e-01,  1.7264e-02, -1.7310e-01,  2.3783e-01,
          2.1526e-01, -1.9595e-01, -1.4343e-01,  1.1795e-01, -1.5535e-01,
          1.7158e-01],
        [-1.1769e-01, -7.9187e-02, -7.0204e-02,  2.4010e-01, -8.6116e-02,
         -5.0196e-02,  1.4967e-01, -1.7265e-01, -6.7297e-04, -1.9154e-01,
         -2.3226e-01, -5.5489e-02,  2.9232e-02,  2.1160e-01, -2.4130e-01,
         -7.0340e-02],
        [ 6.7384e-02,  9.2807e-02,  1.4762e-01, -1.9943e-01, -6.2683e-02,
          5.6228e-02, -2.0200e-01,  1.2438e-01, -2.3808e-01,  1.5755e-01,
          7.9774e-02, -6.9426e-02,  8.2699e-02,  2.1015e-01,  1.8239e-01,
          1.5323e-01],
        [-1.4713e-01,  7.3435e-02,  1.8605e-01,  4.2504e-02,  1.6706e-01,
         -1.5347e-01,  1.7731e-01, -6.6956e-03, -2.2279e-01, -6.6333e-02,
          2.1940e-01, -8.8924e-02, -4.4892e-02, -9.8417e-02, -1.3435e-01,
          4.1716e-02],
        [ 1.5325e-01,  2.7966e-02, -1.3852e-02,  1.6052e-02, -1.8902e-01,
         -1.3330e-01,  1.0919e-02, -2.0142e-01,  1.2228e-01,  3.9617e-02,
          4.2166e-03, -1.4453e-02,  2.1274e-01,  2.2656e-01,  1.2048e-01,
          1.2576e-01],
        [-1.2282e-01,  1.0379e-01, -1.7066e-01,  1.0645e-01, -1.7594e-01,
          2.2046e-04,  1.8279e-01,  1.6761e-01,  2.1969e-01,  8.3711e-02,
          9.8625e-02,  6.5450e-02,  1.8096e-01,  1.3278e-01,  7.2755e-02,
         -8.8827e-02],
        [-1.2258e-01, -6.0216e-02,  1.1779e-01, -1.3767e-01,  6.9841e-02,
          2.2029e-01,  2.1328e-01, -1.8247e-01,  7.0806e-02,  1.6193e-01,
         -2.2564e-01,  1.5820e-01, -1.5736e-01, -1.7917e-01, -1.0451e-01,
         -9.5626e-02],
        [-1.0488e-01,  7.3521e-02,  9.5705e-02,  9.5677e-02,  1.7384e-01,
         -1.5677e-01, -2.3585e-01, -1.9900e-01, -1.3762e-01, -1.1562e-01,
          1.1077e-01, -1.8238e-01, -1.8430e-01,  1.3542e-01, -1.5812e-01,
          4.5353e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1918,  0.0938,  0.1555, -0.2092,  0.0838, -0.1319,  0.1602,  0.2233,
        -0.2125,  0.0920,  0.1673,  0.2257,  0.1904,  0.0507,  0.0139,  0.0531,
        -0.1475, -0.0474, -0.0028, -0.1586, -0.0096, -0.0316, -0.0860, -0.0753,
        -0.2477,  0.2397,  0.1243,  0.1792, -0.2112, -0.2432,  0.1850, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0260,  0.0870,  0.0097, -0.0075,  0.1066,  0.1400, -0.0477, -0.1525,
         -0.0953,  0.1279,  0.0170,  0.1530, -0.0602, -0.1659,  0.0533, -0.0769,
         -0.1041,  0.1118,  0.0139, -0.0136,  0.1738,  0.1524, -0.1460, -0.1641,
         -0.0858, -0.1358, -0.0913,  0.1209, -0.1192,  0.1637,  0.0567,  0.0061]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0260,  0.0353,  0.0503,  ...,  0.0354, -0.1588, -0.1137],
        [-0.0426, -0.1212,  0.0834,  ..., -0.0270, -0.1555,  0.0871],
        [-0.0901,  0.0712,  0.1146,  ...,  0.1531,  0.0707,  0.0345],
        ...,
        [ 0.0821, -0.0803,  0.0070,  ..., -0.1162, -0.0709, -0.1180],
        [ 0.0101, -0.1230, -0.0059,  ..., -0.1361, -0.0334,  0.1557],
        [-0.1354,  0.0645,  0.0425,  ..., -0.0272, -0.1428, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0572,  0.0677, -0.1059, -0.1143, -0.0471,  0.0087, -0.1302,  0.0722,
        -0.0285,  0.0916,  0.0462, -0.0240, -0.0138,  0.0477, -0.0817, -0.0400,
         0.0718, -0.1444, -0.0334,  0.0349, -0.0811,  0.0773,  0.0808, -0.0217,
        -0.0499,  0.0761,  0.0105, -0.1223,  0.0938,  0.1562,  0.1386, -0.0868],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1626, -0.0722, -0.1355,  ..., -0.0177, -0.1344,  0.1715],
        [-0.0972,  0.0940,  0.0393,  ...,  0.0678, -0.1338,  0.1686],
        [ 0.0235, -0.1658, -0.1006,  ..., -0.0598,  0.1154,  0.0569],
        ...,
        [ 0.0245, -0.0158,  0.1385,  ...,  0.1377, -0.1003,  0.1474],
        [ 0.0969, -0.0187, -0.0070,  ...,  0.1536,  0.1025, -0.0478],
        [ 0.0995, -0.0116,  0.1658,  ...,  0.1606,  0.0331,  0.0632]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0706,  0.1045,  0.0012, -0.0470, -0.0594, -0.1150, -0.0083, -0.0977,
         0.1070, -0.1281,  0.1522, -0.1546,  0.1487,  0.0185, -0.1651,  0.0545,
        -0.1153, -0.1416,  0.0108, -0.0488,  0.0421,  0.1383, -0.1636,  0.1774,
        -0.0965, -0.0334,  0.1131, -0.0723, -0.0906, -0.0429,  0.0706, -0.0061],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1626,  0.0779, -0.1628, -0.1287,  0.0155, -0.0083, -0.0523,  0.0566,
          0.0757, -0.1041, -0.0337,  0.0618,  0.0656, -0.0168,  0.0874,  0.0647,
         -0.1674, -0.1674,  0.0044,  0.0590, -0.1276, -0.0926, -0.1705,  0.0350,
          0.1297,  0.1580, -0.1425,  0.1380, -0.0693, -0.1542,  0.1119,  0.1470]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0075], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.5118e-01,  2.3693e-01,  1.6103e-01, -1.7770e-01, -1.4442e-03,
         -3.8376e-03,  1.2070e-01, -2.1526e-01,  2.7444e-03,  8.4870e-02,
          1.2570e-01,  2.4567e-02, -1.2251e-01, -2.3843e-01,  1.3357e-01,
          2.2665e-01],
        [-7.7075e-02, -2.2185e-01,  7.1551e-02, -1.7368e-01, -1.6493e-01,
          6.9737e-02, -2.2156e-02, -1.6990e-02,  2.2275e-01, -4.2259e-02,
          1.5062e-01, -7.9397e-02,  1.8749e-01,  7.7858e-02,  2.2119e-01,
          8.5599e-02],
        [-9.0110e-02,  1.1036e-01,  2.1144e-01,  4.8902e-02,  1.1374e-01,
         -1.7435e-01,  1.3694e-01, -2.3560e-01,  2.1989e-01,  1.0478e-01,
          1.5149e-02, -2.3552e-01,  2.2784e-01,  1.6094e-01,  2.2896e-01,
          9.6712e-02],
        [ 8.5727e-02, -6.6008e-02, -1.0092e-01,  9.7629e-02,  8.8176e-02,
         -9.6005e-03,  3.8387e-02,  8.6106e-02, -2.4071e-01, -2.2257e-01,
         -6.5337e-02,  1.7176e-01,  1.2117e-01, -2.4011e-01, -7.3603e-02,
         -2.4877e-02],
        [ 8.0515e-02,  2.0610e-01,  3.8719e-03, -1.9300e-01,  1.3752e-02,
         -9.4948e-02, -1.5120e-01,  1.3999e-01, -3.5123e-02,  1.1972e-01,
          1.9316e-01,  2.2978e-02,  1.3945e-01, -1.1648e-01,  1.3797e-01,
          8.3909e-03],
        [ 1.6454e-01,  2.4059e-01, -1.9071e-01,  2.3892e-01,  1.8925e-01,
         -1.9980e-01,  7.4876e-02, -2.0213e-01,  7.9600e-02,  4.0255e-02,
         -2.4022e-01,  8.9161e-02, -6.7246e-02,  2.5079e-01,  2.4241e-01,
          8.4705e-02],
        [ 1.9865e-01,  8.8744e-02,  2.3811e-01, -2.4659e-02,  6.3362e-02,
         -4.2878e-02, -5.9491e-03, -7.6916e-02, -9.7436e-02,  1.4304e-01,
          1.0643e-01, -1.0878e-01, -2.1889e-01,  1.2066e-01, -2.2839e-01,
         -9.4710e-03],
        [-2.1351e-01,  2.0775e-01,  2.0517e-01, -2.0706e-01, -2.3084e-01,
         -1.4941e-01,  6.7390e-02, -1.2658e-01, -5.7976e-02, -6.4965e-02,
          4.6550e-02, -1.1666e-01,  1.1523e-01, -1.8049e-01, -2.0661e-02,
          2.1115e-01],
        [-1.3645e-01,  1.9024e-01,  1.3171e-01, -8.2346e-02,  8.8278e-02,
         -1.7049e-01,  1.8534e-02,  6.9652e-02,  2.1771e-01, -1.4149e-01,
         -1.4062e-01, -1.2318e-01, -2.4484e-01,  4.8966e-02, -2.0536e-01,
         -6.5515e-02],
        [-1.1314e-01,  1.5557e-02,  7.4241e-02, -1.8008e-01, -7.5393e-02,
         -2.2442e-02, -1.4293e-01,  5.9309e-02,  9.0997e-02, -1.7658e-01,
          1.9555e-01,  1.7606e-01, -7.6618e-02,  3.8790e-02,  2.8849e-02,
         -3.6090e-02],
        [-1.6936e-01,  2.0717e-01,  1.2146e-01, -2.0738e-01, -1.9529e-01,
          2.3929e-01,  4.0405e-02, -5.8827e-02,  1.7036e-01,  7.3371e-02,
          8.8218e-02,  1.9678e-01, -1.8049e-02,  2.3976e-01, -1.7709e-01,
         -1.5370e-01],
        [ 4.0764e-02, -2.8770e-02,  1.4107e-01, -6.6391e-02,  3.7724e-02,
         -5.0355e-02,  1.8928e-01, -1.4819e-02,  2.2721e-03,  1.8474e-01,
          2.4462e-01,  2.3762e-01, -2.4600e-01, -1.3967e-01, -5.5877e-02,
         -5.3207e-02],
        [ 1.4620e-01,  1.1146e-01, -1.8972e-02,  4.3400e-03,  5.5143e-02,
          2.1393e-01,  1.2816e-01, -1.2459e-01, -1.2931e-01,  7.7476e-02,
         -2.3712e-02, -1.5880e-01, -2.4353e-01,  3.4228e-02, -7.1442e-02,
         -1.4387e-01],
        [ 4.8624e-02,  2.4187e-01,  2.0924e-01,  1.4095e-01, -1.8696e-01,
          1.4109e-01,  1.2771e-01,  8.3729e-02, -6.0746e-02, -5.9487e-03,
         -1.3403e-01, -5.4720e-02, -4.2696e-02, -3.7008e-02, -2.4721e-01,
          8.9795e-02],
        [-2.0614e-01, -1.8540e-01,  1.0000e-01, -2.0306e-01,  2.3691e-01,
          2.4097e-01, -7.7867e-02, -4.1806e-02, -1.9274e-01,  1.7043e-02,
          4.4201e-02, -1.3873e-01,  7.9000e-02, -8.0345e-03, -7.5277e-02,
         -2.4596e-03],
        [-2.4074e-01, -1.7768e-01,  3.4686e-02,  2.3984e-01, -1.4660e-01,
          1.5868e-01,  2.1293e-02, -1.0909e-01,  1.8107e-03,  1.1827e-01,
          3.0199e-02,  2.2289e-01, -4.5850e-02, -1.6853e-01,  2.2750e-01,
         -6.9805e-02],
        [ 1.6022e-01,  1.6333e-01,  4.5872e-02, -2.0678e-01, -2.4385e-01,
          1.1709e-01,  5.9536e-02,  1.4414e-01, -2.1885e-01, -3.6036e-02,
          2.1756e-01,  1.3294e-01,  2.0629e-01,  1.9469e-01, -5.9755e-02,
         -1.6865e-01],
        [-1.5067e-01,  8.6486e-02, -1.0083e-01,  2.5845e-03,  3.8307e-02,
          1.5679e-01,  1.4102e-01,  1.4423e-01,  8.6224e-03,  1.4273e-01,
         -1.1848e-01, -1.0166e-01, -4.1088e-02, -1.4359e-01,  2.2141e-01,
         -3.9906e-02],
        [ 7.1121e-02, -6.3628e-03, -4.9791e-03, -1.3172e-01, -1.9879e-02,
         -2.2208e-01, -1.1806e-01,  1.9279e-01, -2.3564e-01,  4.2675e-02,
          3.8515e-02, -2.4082e-01,  4.9494e-02,  1.1762e-01,  1.7955e-01,
          4.5225e-02],
        [ 1.9699e-01,  7.9848e-03,  9.6828e-02,  7.2257e-02, -1.8279e-01,
         -5.6433e-02, -1.7753e-01,  1.9523e-01,  1.2010e-01, -1.0758e-01,
         -4.4276e-02,  6.8297e-02, -2.1926e-01,  5.5046e-03,  1.2079e-01,
          3.2905e-02],
        [-2.4600e-02,  1.6230e-01,  1.0715e-01, -2.2065e-01,  1.4554e-01,
         -1.9559e-01,  1.4202e-01,  2.1055e-01,  2.1555e-02, -8.2896e-02,
         -1.3072e-01, -1.1261e-01, -4.4567e-02, -1.0205e-01,  2.4659e-01,
         -1.0943e-01],
        [ 1.0220e-01, -2.3025e-01,  1.2512e-01,  2.1432e-01, -1.8081e-01,
         -6.2192e-02,  6.1179e-02, -2.3779e-01, -1.5969e-01,  8.8542e-02,
          2.3385e-01, -7.6281e-02, -3.7352e-03, -2.3974e-01, -2.4155e-01,
          2.1582e-01],
        [ 2.1375e-01, -7.7770e-02, -9.7257e-02, -1.7779e-02,  1.1759e-01,
         -2.4319e-01, -1.4007e-01, -8.3764e-02, -1.0728e-01, -8.2003e-03,
          1.8392e-01,  5.6180e-02, -2.2766e-01,  2.2963e-01,  2.0289e-01,
          8.0312e-02],
        [ 1.2397e-01,  9.1876e-02,  2.0651e-01, -2.4204e-01, -1.5404e-01,
         -3.3343e-02, -4.9149e-02, -1.6747e-01, -2.3821e-01, -1.9253e-01,
         -3.7263e-02,  2.1381e-01,  1.6446e-01,  7.0466e-02, -1.5195e-01,
         -9.8976e-02],
        [ 2.5679e-02, -2.3329e-01, -9.8175e-03,  4.9248e-02,  2.2761e-01,
         -6.7215e-02,  2.4381e-01,  1.7421e-02, -1.7195e-01,  2.3469e-01,
          2.1829e-01, -1.9595e-01, -1.4597e-01,  1.1795e-01, -1.5224e-01,
          1.7158e-01],
        [-1.1769e-01, -7.9146e-02, -7.0170e-02,  2.3691e-01, -8.2951e-02,
         -5.0204e-02,  1.4969e-01, -1.6951e-01, -2.5709e-03, -1.9470e-01,
         -2.2916e-01, -5.5484e-02,  2.6058e-02,  2.1160e-01, -2.3816e-01,
         -7.0339e-02],
        [ 6.7385e-02,  9.2830e-02,  1.4766e-01, -2.0261e-01, -5.9530e-02,
          5.6216e-02, -2.0199e-01,  1.2448e-01, -2.3701e-01,  1.5440e-01,
          8.2784e-02, -6.9420e-02,  8.2408e-02,  2.1015e-01,  1.8550e-01,
          1.5324e-01],
        [-1.4713e-01,  7.3415e-02,  1.8602e-01,  4.5682e-02,  1.6393e-01,
         -1.5346e-01,  1.7730e-01, -6.7253e-03, -2.2585e-01, -6.3216e-02,
          2.2249e-01, -8.8927e-02, -4.4836e-02, -9.8419e-02, -1.3752e-01,
          4.1716e-02],
        [ 1.5325e-01,  2.8002e-02, -1.3823e-02,  1.2869e-02, -1.8588e-01,
         -1.3332e-01,  1.0927e-02, -1.9872e-01,  1.2531e-01,  3.6511e-02,
          4.2079e-03, -1.4450e-02,  2.0961e-01,  2.2656e-01,  1.2365e-01,
          1.2576e-01],
        [-1.2282e-01,  1.0378e-01, -1.7069e-01,  1.0964e-01, -1.7911e-01,
          2.2743e-04,  1.8279e-01,  1.6759e-01,  2.1949e-01,  8.6877e-02,
          9.8596e-02,  6.5446e-02,  1.8099e-01,  1.3278e-01,  7.2174e-02,
         -8.8827e-02],
        [-1.2258e-01, -6.0262e-02,  1.1772e-01, -1.3450e-01,  6.6720e-02,
          2.2031e-01,  2.1326e-01, -1.8445e-01,  6.9816e-02,  1.6506e-01,
         -2.2862e-01,  1.5819e-01, -1.5438e-01, -1.7918e-01, -1.0755e-01,
         -9.5628e-02],
        [-1.0490e-01,  7.3301e-02,  9.5315e-02,  9.8647e-02,  1.7112e-01,
         -1.5667e-01, -2.3595e-01, -1.9995e-01, -1.3844e-01, -1.1286e-01,
          1.0873e-01, -1.8242e-01, -1.8257e-01,  1.3539e-01, -1.6055e-01,
          4.5341e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1921,  0.0939,  0.1553, -0.2093,  0.0866, -0.1326,  0.1571,  0.2233,
        -0.2094,  0.0951,  0.1673,  0.2289,  0.1904,  0.0507,  0.0156,  0.0500,
        -0.1475, -0.0474, -0.0046, -0.1568, -0.0126, -0.0317, -0.0861, -0.0758,
        -0.2476,  0.2398,  0.1217,  0.1823, -0.2112, -0.2432,  0.1845, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0260,  0.0870,  0.0097, -0.0075,  0.1034,  0.1396, -0.0509, -0.1525,
         -0.0953,  0.1247,  0.0170,  0.1498, -0.0602, -0.1659,  0.0565, -0.0737,
         -0.1041,  0.1118,  0.0107, -0.0167,  0.1706,  0.1524, -0.1460, -0.1641,
         -0.0858, -0.1357, -0.0945,  0.1177, -0.1192,  0.1637,  0.0568,  0.0061]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0263,  0.0325,  0.0528,  ...,  0.0384, -0.1591, -0.1137],
        [-0.0427, -0.1242,  0.0864,  ..., -0.0240, -0.1557,  0.0871],
        [-0.0900,  0.0741,  0.1116,  ...,  0.1501,  0.0709,  0.0345],
        ...,
        [ 0.0821, -0.0832,  0.0098,  ..., -0.1132, -0.0712, -0.1180],
        [ 0.0102, -0.1200, -0.0089,  ..., -0.1391, -0.0332,  0.1557],
        [-0.1354,  0.0675,  0.0395,  ..., -0.0302, -0.1426, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0602,  0.0707, -0.1089, -0.1113, -0.0441,  0.0117, -0.1332,  0.0752,
        -0.0315,  0.0946,  0.0492, -0.0270, -0.0159,  0.0507, -0.0847, -0.0430,
         0.0748, -0.1414, -0.0304,  0.0319, -0.0841,  0.0743,  0.0778, -0.0247,
        -0.0529,  0.0790,  0.0075, -0.1253,  0.0908,  0.1591,  0.1356, -0.0898],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1656, -0.0752, -0.1325,  ..., -0.0206, -0.1314,  0.1684],
        [-0.0942,  0.0910,  0.0422,  ...,  0.0648, -0.1308,  0.1656],
        [ 0.0205, -0.1628, -0.1035,  ..., -0.0569,  0.1124,  0.0599],
        ...,
        [ 0.0215, -0.0128,  0.1355,  ...,  0.1406, -0.1033,  0.1505],
        [ 0.0999, -0.0217, -0.0040,  ...,  0.1506,  0.1056, -0.0508],
        [ 0.1025, -0.0147,  0.1688,  ...,  0.1576,  0.0362,  0.0601]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0676,  0.1015,  0.0042, -0.0440, -0.0624, -0.1120, -0.0053, -0.1007,
         0.1040, -0.1251,  0.1552, -0.1576,  0.1457,  0.0215, -0.1681,  0.0515,
        -0.1123, -0.1386,  0.0078, -0.0518,  0.0451,  0.1413, -0.1606,  0.1744,
        -0.0995, -0.0364,  0.1161, -0.0753, -0.0876, -0.0399,  0.0676, -0.0091],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1599,  0.0749, -0.1598, -0.1257,  0.0155, -0.0053, -0.0553,  0.0595,
          0.0727, -0.1011, -0.0368,  0.0648,  0.0626, -0.0143,  0.0904,  0.0617,
         -0.1644, -0.1704,  0.0074,  0.0620, -0.1245, -0.0897, -0.1674,  0.0320,
          0.1268,  0.1582, -0.1455,  0.1354, -0.0723, -0.1572,  0.1149,  0.1500]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0106], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.5118e-01,  2.3693e-01,  1.6103e-01, -1.7770e-01, -1.4442e-03,
         -3.8376e-03,  1.2070e-01, -2.1526e-01,  2.7444e-03,  8.4870e-02,
          1.2570e-01,  2.4567e-02, -1.2251e-01, -2.3843e-01,  1.3357e-01,
          2.2665e-01],
        [-7.7075e-02, -2.2185e-01,  7.1551e-02, -1.7368e-01, -1.6493e-01,
          6.9737e-02, -2.2156e-02, -1.6990e-02,  2.2275e-01, -4.2259e-02,
          1.5062e-01, -7.9397e-02,  1.8749e-01,  7.7858e-02,  2.2119e-01,
          8.5599e-02],
        [-9.0110e-02,  1.1036e-01,  2.1144e-01,  4.8902e-02,  1.1374e-01,
         -1.7435e-01,  1.3694e-01, -2.3560e-01,  2.1989e-01,  1.0478e-01,
          1.5149e-02, -2.3552e-01,  2.2784e-01,  1.6094e-01,  2.2896e-01,
          9.6712e-02],
        [ 8.5727e-02, -6.6008e-02, -1.0092e-01,  9.7629e-02,  8.8176e-02,
         -9.6005e-03,  3.8387e-02,  8.6106e-02, -2.4071e-01, -2.2257e-01,
         -6.5337e-02,  1.7176e-01,  1.2117e-01, -2.4011e-01, -7.3603e-02,
         -2.4877e-02],
        [ 8.0515e-02,  2.0610e-01,  3.8719e-03, -1.9300e-01,  1.3752e-02,
         -9.4948e-02, -1.5120e-01,  1.3999e-01, -3.5123e-02,  1.1972e-01,
          1.9316e-01,  2.2978e-02,  1.3945e-01, -1.1648e-01,  1.3797e-01,
          8.3909e-03],
        [ 1.6454e-01,  2.4059e-01, -1.9071e-01,  2.3892e-01,  1.8925e-01,
         -1.9980e-01,  7.4876e-02, -2.0213e-01,  7.9600e-02,  4.0255e-02,
         -2.4022e-01,  8.9161e-02, -6.7246e-02,  2.5079e-01,  2.4241e-01,
          8.4705e-02],
        [ 1.9865e-01,  8.8744e-02,  2.3811e-01, -2.4659e-02,  6.3362e-02,
         -4.2878e-02, -5.9491e-03, -7.6916e-02, -9.7436e-02,  1.4304e-01,
          1.0643e-01, -1.0878e-01, -2.1889e-01,  1.2066e-01, -2.2839e-01,
         -9.4710e-03],
        [-2.1351e-01,  2.0775e-01,  2.0517e-01, -2.0706e-01, -2.3084e-01,
         -1.4941e-01,  6.7390e-02, -1.2658e-01, -5.7976e-02, -6.4965e-02,
          4.6550e-02, -1.1666e-01,  1.1523e-01, -1.8049e-01, -2.0661e-02,
          2.1115e-01],
        [-1.3645e-01,  1.9024e-01,  1.3171e-01, -8.2346e-02,  8.8278e-02,
         -1.7049e-01,  1.8534e-02,  6.9652e-02,  2.1771e-01, -1.4149e-01,
         -1.4062e-01, -1.2318e-01, -2.4484e-01,  4.8966e-02, -2.0536e-01,
         -6.5515e-02],
        [-1.1314e-01,  1.5557e-02,  7.4241e-02, -1.8008e-01, -7.5393e-02,
         -2.2442e-02, -1.4293e-01,  5.9309e-02,  9.0997e-02, -1.7658e-01,
          1.9555e-01,  1.7606e-01, -7.6618e-02,  3.8790e-02,  2.8849e-02,
         -3.6090e-02],
        [-1.6936e-01,  2.0717e-01,  1.2146e-01, -2.0738e-01, -1.9529e-01,
          2.3929e-01,  4.0405e-02, -5.8827e-02,  1.7036e-01,  7.3371e-02,
          8.8218e-02,  1.9678e-01, -1.8049e-02,  2.3976e-01, -1.7709e-01,
         -1.5370e-01],
        [ 4.0764e-02, -2.8770e-02,  1.4107e-01, -6.6391e-02,  3.7724e-02,
         -5.0355e-02,  1.8928e-01, -1.4819e-02,  2.2721e-03,  1.8474e-01,
          2.4462e-01,  2.3762e-01, -2.4600e-01, -1.3967e-01, -5.5877e-02,
         -5.3207e-02],
        [ 1.4620e-01,  1.1146e-01, -1.8972e-02,  4.3400e-03,  5.5143e-02,
          2.1393e-01,  1.2816e-01, -1.2459e-01, -1.2931e-01,  7.7476e-02,
         -2.3712e-02, -1.5880e-01, -2.4353e-01,  3.4228e-02, -7.1442e-02,
         -1.4387e-01],
        [ 4.8624e-02,  2.4187e-01,  2.0924e-01,  1.4095e-01, -1.8696e-01,
          1.4109e-01,  1.2771e-01,  8.3729e-02, -6.0746e-02, -5.9487e-03,
         -1.3403e-01, -5.4720e-02, -4.2696e-02, -3.7008e-02, -2.4721e-01,
          8.9795e-02],
        [-2.0614e-01, -1.8540e-01,  1.0000e-01, -2.0306e-01,  2.3691e-01,
          2.4097e-01, -7.7867e-02, -4.1806e-02, -1.9274e-01,  1.7043e-02,
          4.4201e-02, -1.3873e-01,  7.9000e-02, -8.0345e-03, -7.5277e-02,
         -2.4596e-03],
        [-2.4074e-01, -1.7768e-01,  3.4686e-02,  2.3984e-01, -1.4660e-01,
          1.5868e-01,  2.1293e-02, -1.0909e-01,  1.8107e-03,  1.1827e-01,
          3.0199e-02,  2.2289e-01, -4.5850e-02, -1.6853e-01,  2.2750e-01,
         -6.9805e-02],
        [ 1.6022e-01,  1.6333e-01,  4.5872e-02, -2.0678e-01, -2.4385e-01,
          1.1709e-01,  5.9536e-02,  1.4414e-01, -2.1885e-01, -3.6036e-02,
          2.1756e-01,  1.3294e-01,  2.0629e-01,  1.9469e-01, -5.9755e-02,
         -1.6865e-01],
        [-1.5067e-01,  8.6486e-02, -1.0083e-01,  2.5845e-03,  3.8307e-02,
          1.5679e-01,  1.4102e-01,  1.4423e-01,  8.6224e-03,  1.4273e-01,
         -1.1848e-01, -1.0166e-01, -4.1088e-02, -1.4359e-01,  2.2141e-01,
         -3.9906e-02],
        [ 7.1121e-02, -6.3628e-03, -4.9791e-03, -1.3172e-01, -1.9879e-02,
         -2.2208e-01, -1.1806e-01,  1.9279e-01, -2.3564e-01,  4.2675e-02,
          3.8515e-02, -2.4082e-01,  4.9494e-02,  1.1762e-01,  1.7955e-01,
          4.5225e-02],
        [ 1.9699e-01,  7.9848e-03,  9.6828e-02,  7.2257e-02, -1.8279e-01,
         -5.6433e-02, -1.7753e-01,  1.9523e-01,  1.2010e-01, -1.0758e-01,
         -4.4276e-02,  6.8297e-02, -2.1926e-01,  5.5046e-03,  1.2079e-01,
          3.2905e-02],
        [-2.4600e-02,  1.6230e-01,  1.0715e-01, -2.2065e-01,  1.4554e-01,
         -1.9559e-01,  1.4202e-01,  2.1055e-01,  2.1555e-02, -8.2896e-02,
         -1.3072e-01, -1.1261e-01, -4.4567e-02, -1.0205e-01,  2.4659e-01,
         -1.0943e-01],
        [ 1.0220e-01, -2.3025e-01,  1.2512e-01,  2.1432e-01, -1.8081e-01,
         -6.2192e-02,  6.1179e-02, -2.3779e-01, -1.5969e-01,  8.8542e-02,
          2.3385e-01, -7.6281e-02, -3.7352e-03, -2.3974e-01, -2.4155e-01,
          2.1582e-01],
        [ 2.1375e-01, -7.7770e-02, -9.7257e-02, -1.7779e-02,  1.1759e-01,
         -2.4319e-01, -1.4007e-01, -8.3764e-02, -1.0728e-01, -8.2003e-03,
          1.8392e-01,  5.6180e-02, -2.2766e-01,  2.2963e-01,  2.0289e-01,
          8.0312e-02],
        [ 1.2397e-01,  9.1876e-02,  2.0651e-01, -2.4204e-01, -1.5404e-01,
         -3.3343e-02, -4.9149e-02, -1.6747e-01, -2.3821e-01, -1.9253e-01,
         -3.7263e-02,  2.1381e-01,  1.6446e-01,  7.0466e-02, -1.5195e-01,
         -9.8976e-02],
        [ 2.5679e-02, -2.3329e-01, -9.8175e-03,  4.9248e-02,  2.2761e-01,
         -6.7215e-02,  2.4381e-01,  1.7421e-02, -1.7195e-01,  2.3469e-01,
          2.1829e-01, -1.9595e-01, -1.4597e-01,  1.1795e-01, -1.5224e-01,
          1.7158e-01],
        [-1.1769e-01, -7.9146e-02, -7.0170e-02,  2.3691e-01, -8.2951e-02,
         -5.0204e-02,  1.4969e-01, -1.6951e-01, -2.5709e-03, -1.9470e-01,
         -2.2916e-01, -5.5484e-02,  2.6058e-02,  2.1160e-01, -2.3816e-01,
         -7.0339e-02],
        [ 6.7385e-02,  9.2830e-02,  1.4766e-01, -2.0261e-01, -5.9530e-02,
          5.6216e-02, -2.0199e-01,  1.2448e-01, -2.3701e-01,  1.5440e-01,
          8.2784e-02, -6.9420e-02,  8.2408e-02,  2.1015e-01,  1.8550e-01,
          1.5324e-01],
        [-1.4713e-01,  7.3415e-02,  1.8602e-01,  4.5682e-02,  1.6393e-01,
         -1.5346e-01,  1.7730e-01, -6.7253e-03, -2.2585e-01, -6.3216e-02,
          2.2249e-01, -8.8927e-02, -4.4836e-02, -9.8419e-02, -1.3752e-01,
          4.1716e-02],
        [ 1.5325e-01,  2.8002e-02, -1.3823e-02,  1.2869e-02, -1.8588e-01,
         -1.3332e-01,  1.0927e-02, -1.9872e-01,  1.2531e-01,  3.6511e-02,
          4.2079e-03, -1.4450e-02,  2.0961e-01,  2.2656e-01,  1.2365e-01,
          1.2576e-01],
        [-1.2282e-01,  1.0378e-01, -1.7069e-01,  1.0964e-01, -1.7911e-01,
          2.2743e-04,  1.8279e-01,  1.6759e-01,  2.1949e-01,  8.6877e-02,
          9.8596e-02,  6.5446e-02,  1.8099e-01,  1.3278e-01,  7.2174e-02,
         -8.8827e-02],
        [-1.2258e-01, -6.0262e-02,  1.1772e-01, -1.3450e-01,  6.6720e-02,
          2.2031e-01,  2.1326e-01, -1.8445e-01,  6.9816e-02,  1.6506e-01,
         -2.2862e-01,  1.5819e-01, -1.5438e-01, -1.7918e-01, -1.0755e-01,
         -9.5628e-02],
        [-1.0490e-01,  7.3301e-02,  9.5315e-02,  9.8647e-02,  1.7112e-01,
         -1.5667e-01, -2.3595e-01, -1.9995e-01, -1.3844e-01, -1.1286e-01,
          1.0873e-01, -1.8242e-01, -1.8257e-01,  1.3539e-01, -1.6055e-01,
          4.5341e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1921,  0.0939,  0.1553, -0.2093,  0.0866, -0.1326,  0.1571,  0.2233,
        -0.2094,  0.0951,  0.1673,  0.2289,  0.1904,  0.0507,  0.0156,  0.0500,
        -0.1475, -0.0474, -0.0046, -0.1568, -0.0126, -0.0317, -0.0861, -0.0758,
        -0.2476,  0.2398,  0.1217,  0.1823, -0.2112, -0.2432,  0.1845, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0260,  0.0870,  0.0097, -0.0075,  0.1034,  0.1396, -0.0509, -0.1525,
         -0.0953,  0.1247,  0.0170,  0.1498, -0.0602, -0.1659,  0.0565, -0.0737,
         -0.1041,  0.1118,  0.0107, -0.0167,  0.1706,  0.1524, -0.1460, -0.1641,
         -0.0858, -0.1357, -0.0945,  0.1177, -0.1192,  0.1637,  0.0568,  0.0061]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0263,  0.0325,  0.0528,  ...,  0.0384, -0.1591, -0.1137],
        [-0.0427, -0.1242,  0.0864,  ..., -0.0240, -0.1557,  0.0871],
        [-0.0900,  0.0741,  0.1116,  ...,  0.1501,  0.0709,  0.0345],
        ...,
        [ 0.0821, -0.0832,  0.0098,  ..., -0.1132, -0.0712, -0.1180],
        [ 0.0102, -0.1200, -0.0089,  ..., -0.1391, -0.0332,  0.1557],
        [-0.1354,  0.0675,  0.0395,  ..., -0.0302, -0.1426, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0602,  0.0707, -0.1089, -0.1113, -0.0441,  0.0117, -0.1332,  0.0752,
        -0.0315,  0.0946,  0.0492, -0.0270, -0.0159,  0.0507, -0.0847, -0.0430,
         0.0748, -0.1414, -0.0304,  0.0319, -0.0841,  0.0743,  0.0778, -0.0247,
        -0.0529,  0.0790,  0.0075, -0.1253,  0.0908,  0.1591,  0.1356, -0.0898],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1656, -0.0752, -0.1325,  ..., -0.0206, -0.1314,  0.1684],
        [-0.0942,  0.0910,  0.0422,  ...,  0.0648, -0.1308,  0.1656],
        [ 0.0205, -0.1628, -0.1035,  ..., -0.0569,  0.1124,  0.0599],
        ...,
        [ 0.0215, -0.0128,  0.1355,  ...,  0.1406, -0.1033,  0.1505],
        [ 0.0999, -0.0217, -0.0040,  ...,  0.1506,  0.1056, -0.0508],
        [ 0.1025, -0.0147,  0.1688,  ...,  0.1576,  0.0362,  0.0601]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0676,  0.1015,  0.0042, -0.0440, -0.0624, -0.1120, -0.0053, -0.1007,
         0.1040, -0.1251,  0.1552, -0.1576,  0.1457,  0.0215, -0.1681,  0.0515,
        -0.1123, -0.1386,  0.0078, -0.0518,  0.0451,  0.1413, -0.1606,  0.1744,
        -0.0995, -0.0364,  0.1161, -0.0753, -0.0876, -0.0399,  0.0676, -0.0091],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1599,  0.0749, -0.1598, -0.1257,  0.0155, -0.0053, -0.0553,  0.0595,
          0.0727, -0.1011, -0.0368,  0.0648,  0.0626, -0.0143,  0.0904,  0.0617,
         -0.1644, -0.1704,  0.0074,  0.0620, -0.1245, -0.0897, -0.1674,  0.0320,
          0.1268,  0.1582, -0.1455,  0.1354, -0.0723, -0.1572,  0.1149,  0.1500]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0106], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.5118e-01,  2.3693e-01,  1.6103e-01, -1.7770e-01, -1.4442e-03,
         -3.8376e-03,  1.2070e-01, -2.1526e-01,  2.7444e-03,  8.4870e-02,
          1.2570e-01,  2.4567e-02, -1.2251e-01, -2.3843e-01,  1.3357e-01,
          2.2665e-01],
        [-7.7075e-02, -2.2185e-01,  7.1551e-02, -1.7368e-01, -1.6493e-01,
          6.9737e-02, -2.2156e-02, -1.6990e-02,  2.2275e-01, -4.2259e-02,
          1.5062e-01, -7.9397e-02,  1.8749e-01,  7.7858e-02,  2.2119e-01,
          8.5599e-02],
        [-9.0110e-02,  1.1036e-01,  2.1144e-01,  4.8902e-02,  1.1374e-01,
         -1.7435e-01,  1.3694e-01, -2.3560e-01,  2.1989e-01,  1.0478e-01,
          1.5149e-02, -2.3552e-01,  2.2784e-01,  1.6094e-01,  2.2896e-01,
          9.6712e-02],
        [ 8.5727e-02, -6.6008e-02, -1.0092e-01,  9.7629e-02,  8.8176e-02,
         -9.6005e-03,  3.8387e-02,  8.6106e-02, -2.4071e-01, -2.2257e-01,
         -6.5337e-02,  1.7176e-01,  1.2117e-01, -2.4011e-01, -7.3603e-02,
         -2.4877e-02],
        [ 8.0515e-02,  2.0610e-01,  3.8719e-03, -1.9300e-01,  1.3752e-02,
         -9.4948e-02, -1.5120e-01,  1.3999e-01, -3.5123e-02,  1.1972e-01,
          1.9316e-01,  2.2978e-02,  1.3945e-01, -1.1648e-01,  1.3797e-01,
          8.3909e-03],
        [ 1.6454e-01,  2.4059e-01, -1.9071e-01,  2.3892e-01,  1.8925e-01,
         -1.9980e-01,  7.4876e-02, -2.0213e-01,  7.9600e-02,  4.0255e-02,
         -2.4022e-01,  8.9161e-02, -6.7246e-02,  2.5079e-01,  2.4241e-01,
          8.4705e-02],
        [ 1.9865e-01,  8.8744e-02,  2.3811e-01, -2.4659e-02,  6.3362e-02,
         -4.2878e-02, -5.9491e-03, -7.6916e-02, -9.7436e-02,  1.4304e-01,
          1.0643e-01, -1.0878e-01, -2.1889e-01,  1.2066e-01, -2.2839e-01,
         -9.4710e-03],
        [-2.1351e-01,  2.0775e-01,  2.0517e-01, -2.0706e-01, -2.3084e-01,
         -1.4941e-01,  6.7390e-02, -1.2658e-01, -5.7976e-02, -6.4965e-02,
          4.6550e-02, -1.1666e-01,  1.1523e-01, -1.8049e-01, -2.0661e-02,
          2.1115e-01],
        [-1.3645e-01,  1.9024e-01,  1.3171e-01, -8.2346e-02,  8.8278e-02,
         -1.7049e-01,  1.8534e-02,  6.9652e-02,  2.1771e-01, -1.4149e-01,
         -1.4062e-01, -1.2318e-01, -2.4484e-01,  4.8966e-02, -2.0536e-01,
         -6.5515e-02],
        [-1.1314e-01,  1.5557e-02,  7.4241e-02, -1.8008e-01, -7.5393e-02,
         -2.2442e-02, -1.4293e-01,  5.9309e-02,  9.0997e-02, -1.7658e-01,
          1.9555e-01,  1.7606e-01, -7.6618e-02,  3.8790e-02,  2.8849e-02,
         -3.6090e-02],
        [-1.6936e-01,  2.0717e-01,  1.2146e-01, -2.0738e-01, -1.9529e-01,
          2.3929e-01,  4.0405e-02, -5.8827e-02,  1.7036e-01,  7.3371e-02,
          8.8218e-02,  1.9678e-01, -1.8049e-02,  2.3976e-01, -1.7709e-01,
         -1.5370e-01],
        [ 4.0764e-02, -2.8770e-02,  1.4107e-01, -6.6391e-02,  3.7724e-02,
         -5.0355e-02,  1.8928e-01, -1.4819e-02,  2.2721e-03,  1.8474e-01,
          2.4462e-01,  2.3762e-01, -2.4600e-01, -1.3967e-01, -5.5877e-02,
         -5.3207e-02],
        [ 1.4620e-01,  1.1146e-01, -1.8972e-02,  4.3400e-03,  5.5143e-02,
          2.1393e-01,  1.2816e-01, -1.2459e-01, -1.2931e-01,  7.7476e-02,
         -2.3712e-02, -1.5880e-01, -2.4353e-01,  3.4228e-02, -7.1442e-02,
         -1.4387e-01],
        [ 4.8624e-02,  2.4187e-01,  2.0924e-01,  1.4095e-01, -1.8696e-01,
          1.4109e-01,  1.2771e-01,  8.3729e-02, -6.0746e-02, -5.9487e-03,
         -1.3403e-01, -5.4720e-02, -4.2696e-02, -3.7008e-02, -2.4721e-01,
          8.9795e-02],
        [-2.0614e-01, -1.8540e-01,  1.0000e-01, -2.0306e-01,  2.3691e-01,
          2.4097e-01, -7.7867e-02, -4.1806e-02, -1.9274e-01,  1.7043e-02,
          4.4201e-02, -1.3873e-01,  7.9000e-02, -8.0345e-03, -7.5277e-02,
         -2.4596e-03],
        [-2.4074e-01, -1.7768e-01,  3.4686e-02,  2.3984e-01, -1.4660e-01,
          1.5868e-01,  2.1293e-02, -1.0909e-01,  1.8107e-03,  1.1827e-01,
          3.0199e-02,  2.2289e-01, -4.5850e-02, -1.6853e-01,  2.2750e-01,
         -6.9805e-02],
        [ 1.6022e-01,  1.6333e-01,  4.5872e-02, -2.0678e-01, -2.4385e-01,
          1.1709e-01,  5.9536e-02,  1.4414e-01, -2.1885e-01, -3.6036e-02,
          2.1756e-01,  1.3294e-01,  2.0629e-01,  1.9469e-01, -5.9755e-02,
         -1.6865e-01],
        [-1.5067e-01,  8.6486e-02, -1.0083e-01,  2.5845e-03,  3.8307e-02,
          1.5679e-01,  1.4102e-01,  1.4423e-01,  8.6224e-03,  1.4273e-01,
         -1.1848e-01, -1.0166e-01, -4.1088e-02, -1.4359e-01,  2.2141e-01,
         -3.9906e-02],
        [ 7.1121e-02, -6.3628e-03, -4.9791e-03, -1.3172e-01, -1.9879e-02,
         -2.2208e-01, -1.1806e-01,  1.9279e-01, -2.3564e-01,  4.2675e-02,
          3.8515e-02, -2.4082e-01,  4.9494e-02,  1.1762e-01,  1.7955e-01,
          4.5225e-02],
        [ 1.9699e-01,  7.9848e-03,  9.6828e-02,  7.2257e-02, -1.8279e-01,
         -5.6433e-02, -1.7753e-01,  1.9523e-01,  1.2010e-01, -1.0758e-01,
         -4.4276e-02,  6.8297e-02, -2.1926e-01,  5.5046e-03,  1.2079e-01,
          3.2905e-02],
        [-2.4600e-02,  1.6230e-01,  1.0715e-01, -2.2065e-01,  1.4554e-01,
         -1.9559e-01,  1.4202e-01,  2.1055e-01,  2.1555e-02, -8.2896e-02,
         -1.3072e-01, -1.1261e-01, -4.4567e-02, -1.0205e-01,  2.4659e-01,
         -1.0943e-01],
        [ 1.0220e-01, -2.3025e-01,  1.2512e-01,  2.1432e-01, -1.8081e-01,
         -6.2192e-02,  6.1179e-02, -2.3779e-01, -1.5969e-01,  8.8542e-02,
          2.3385e-01, -7.6281e-02, -3.7352e-03, -2.3974e-01, -2.4155e-01,
          2.1582e-01],
        [ 2.1375e-01, -7.7770e-02, -9.7257e-02, -1.7779e-02,  1.1759e-01,
         -2.4319e-01, -1.4007e-01, -8.3764e-02, -1.0728e-01, -8.2003e-03,
          1.8392e-01,  5.6180e-02, -2.2766e-01,  2.2963e-01,  2.0289e-01,
          8.0312e-02],
        [ 1.2397e-01,  9.1876e-02,  2.0651e-01, -2.4204e-01, -1.5404e-01,
         -3.3343e-02, -4.9149e-02, -1.6747e-01, -2.3821e-01, -1.9253e-01,
         -3.7263e-02,  2.1381e-01,  1.6446e-01,  7.0466e-02, -1.5195e-01,
         -9.8976e-02],
        [ 2.5679e-02, -2.3329e-01, -9.8175e-03,  4.9248e-02,  2.2761e-01,
         -6.7215e-02,  2.4381e-01,  1.7421e-02, -1.7195e-01,  2.3469e-01,
          2.1829e-01, -1.9595e-01, -1.4597e-01,  1.1795e-01, -1.5224e-01,
          1.7158e-01],
        [-1.1769e-01, -7.9146e-02, -7.0170e-02,  2.3691e-01, -8.2951e-02,
         -5.0204e-02,  1.4969e-01, -1.6951e-01, -2.5709e-03, -1.9470e-01,
         -2.2916e-01, -5.5484e-02,  2.6058e-02,  2.1160e-01, -2.3816e-01,
         -7.0339e-02],
        [ 6.7385e-02,  9.2830e-02,  1.4766e-01, -2.0261e-01, -5.9530e-02,
          5.6216e-02, -2.0199e-01,  1.2448e-01, -2.3701e-01,  1.5440e-01,
          8.2784e-02, -6.9420e-02,  8.2408e-02,  2.1015e-01,  1.8550e-01,
          1.5324e-01],
        [-1.4713e-01,  7.3415e-02,  1.8602e-01,  4.5682e-02,  1.6393e-01,
         -1.5346e-01,  1.7730e-01, -6.7253e-03, -2.2585e-01, -6.3216e-02,
          2.2249e-01, -8.8927e-02, -4.4836e-02, -9.8419e-02, -1.3752e-01,
          4.1716e-02],
        [ 1.5325e-01,  2.8002e-02, -1.3823e-02,  1.2869e-02, -1.8588e-01,
         -1.3332e-01,  1.0927e-02, -1.9872e-01,  1.2531e-01,  3.6511e-02,
          4.2079e-03, -1.4450e-02,  2.0961e-01,  2.2656e-01,  1.2365e-01,
          1.2576e-01],
        [-1.2282e-01,  1.0378e-01, -1.7069e-01,  1.0964e-01, -1.7911e-01,
          2.2743e-04,  1.8279e-01,  1.6759e-01,  2.1949e-01,  8.6877e-02,
          9.8596e-02,  6.5446e-02,  1.8099e-01,  1.3278e-01,  7.2174e-02,
         -8.8827e-02],
        [-1.2258e-01, -6.0262e-02,  1.1772e-01, -1.3450e-01,  6.6720e-02,
          2.2031e-01,  2.1326e-01, -1.8445e-01,  6.9816e-02,  1.6506e-01,
         -2.2862e-01,  1.5819e-01, -1.5438e-01, -1.7918e-01, -1.0755e-01,
         -9.5628e-02],
        [-1.0490e-01,  7.3301e-02,  9.5315e-02,  9.8647e-02,  1.7112e-01,
         -1.5667e-01, -2.3595e-01, -1.9995e-01, -1.3844e-01, -1.1286e-01,
          1.0873e-01, -1.8242e-01, -1.8257e-01,  1.3539e-01, -1.6055e-01,
          4.5341e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1921,  0.0939,  0.1553, -0.2093,  0.0866, -0.1326,  0.1571,  0.2233,
        -0.2094,  0.0951,  0.1673,  0.2289,  0.1904,  0.0507,  0.0156,  0.0500,
        -0.1475, -0.0474, -0.0046, -0.1568, -0.0126, -0.0317, -0.0861, -0.0758,
        -0.2476,  0.2398,  0.1217,  0.1823, -0.2112, -0.2432,  0.1845, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0260,  0.0870,  0.0097, -0.0075,  0.1034,  0.1396, -0.0509, -0.1525,
         -0.0953,  0.1247,  0.0170,  0.1498, -0.0602, -0.1659,  0.0565, -0.0737,
         -0.1041,  0.1118,  0.0107, -0.0167,  0.1706,  0.1524, -0.1460, -0.1641,
         -0.0858, -0.1357, -0.0945,  0.1177, -0.1192,  0.1637,  0.0568,  0.0061]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0263,  0.0325,  0.0528,  ...,  0.0384, -0.1591, -0.1137],
        [-0.0427, -0.1242,  0.0864,  ..., -0.0240, -0.1557,  0.0871],
        [-0.0900,  0.0741,  0.1116,  ...,  0.1501,  0.0709,  0.0345],
        ...,
        [ 0.0821, -0.0832,  0.0098,  ..., -0.1132, -0.0712, -0.1180],
        [ 0.0102, -0.1200, -0.0089,  ..., -0.1391, -0.0332,  0.1557],
        [-0.1354,  0.0675,  0.0395,  ..., -0.0302, -0.1426, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0602,  0.0707, -0.1089, -0.1113, -0.0441,  0.0117, -0.1332,  0.0752,
        -0.0315,  0.0946,  0.0492, -0.0270, -0.0159,  0.0507, -0.0847, -0.0430,
         0.0748, -0.1414, -0.0304,  0.0319, -0.0841,  0.0743,  0.0778, -0.0247,
        -0.0529,  0.0790,  0.0075, -0.1253,  0.0908,  0.1591,  0.1356, -0.0898],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1656, -0.0752, -0.1325,  ..., -0.0206, -0.1314,  0.1684],
        [-0.0942,  0.0910,  0.0422,  ...,  0.0648, -0.1308,  0.1656],
        [ 0.0205, -0.1628, -0.1035,  ..., -0.0569,  0.1124,  0.0599],
        ...,
        [ 0.0215, -0.0128,  0.1355,  ...,  0.1406, -0.1033,  0.1505],
        [ 0.0999, -0.0217, -0.0040,  ...,  0.1506,  0.1056, -0.0508],
        [ 0.1025, -0.0147,  0.1688,  ...,  0.1576,  0.0362,  0.0601]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0676,  0.1015,  0.0042, -0.0440, -0.0624, -0.1120, -0.0053, -0.1007,
         0.1040, -0.1251,  0.1552, -0.1576,  0.1457,  0.0215, -0.1681,  0.0515,
        -0.1123, -0.1386,  0.0078, -0.0518,  0.0451,  0.1413, -0.1606,  0.1744,
        -0.0995, -0.0364,  0.1161, -0.0753, -0.0876, -0.0399,  0.0676, -0.0091],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1599,  0.0749, -0.1598, -0.1257,  0.0155, -0.0053, -0.0553,  0.0595,
          0.0727, -0.1011, -0.0368,  0.0648,  0.0626, -0.0143,  0.0904,  0.0617,
         -0.1644, -0.1704,  0.0074,  0.0620, -0.1245, -0.0897, -0.1674,  0.0320,
          0.1268,  0.1582, -0.1455,  0.1354, -0.0723, -0.1572,  0.1149,  0.1500]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0106], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.5118e-01,  2.3693e-01,  1.6103e-01, -1.7770e-01, -1.4442e-03,
         -3.8376e-03,  1.2070e-01, -2.1524e-01,  2.8354e-03,  8.4870e-02,
          1.2570e-01,  2.4567e-02, -1.2252e-01, -2.3843e-01,  1.3357e-01,
          2.2665e-01],
        [-7.7075e-02, -2.2185e-01,  7.1551e-02, -1.7368e-01, -1.6493e-01,
          6.9737e-02, -2.2156e-02, -1.6874e-02,  2.2276e-01, -4.2259e-02,
          1.5062e-01, -7.9397e-02,  1.8749e-01,  7.7858e-02,  2.2119e-01,
          8.5599e-02],
        [-9.0110e-02,  1.1037e-01,  2.1144e-01,  4.8902e-02,  1.1374e-01,
         -1.7435e-01,  1.3694e-01, -2.3557e-01,  2.1991e-01,  1.0478e-01,
          1.5145e-02, -2.3552e-01,  2.2777e-01,  1.6094e-01,  2.2896e-01,
          9.6712e-02],
        [ 8.5728e-02, -6.6014e-02, -1.0092e-01,  9.7629e-02,  8.8176e-02,
         -9.6004e-03,  3.8387e-02,  8.6072e-02, -2.4074e-01, -2.2257e-01,
         -6.5332e-02,  1.7176e-01,  1.2119e-01, -2.4011e-01, -7.3604e-02,
         -2.4877e-02],
        [ 8.0515e-02,  2.0610e-01,  3.8719e-03, -1.9300e-01,  1.3752e-02,
         -9.4948e-02, -1.5120e-01,  1.3999e-01, -3.5120e-02,  1.1972e-01,
          1.9315e-01,  2.2978e-02,  1.3943e-01, -1.1648e-01,  1.3797e-01,
          8.3909e-03],
        [ 1.6454e-01,  2.4059e-01, -1.9071e-01,  2.3892e-01,  1.8925e-01,
         -1.9980e-01,  7.4876e-02, -2.0211e-01,  7.9610e-02,  4.0255e-02,
         -2.4022e-01,  8.9161e-02, -6.7274e-02,  2.5079e-01,  2.4241e-01,
          8.4705e-02],
        [ 1.9865e-01,  8.8743e-02,  2.3811e-01, -2.4659e-02,  6.3362e-02,
         -4.2878e-02, -5.9492e-03, -7.6918e-02, -9.7440e-02,  1.4304e-01,
          1.0659e-01, -1.0878e-01, -2.1889e-01,  1.2066e-01, -2.2839e-01,
         -9.4709e-03],
        [-2.1351e-01,  2.0775e-01,  2.0517e-01, -2.0706e-01, -2.3084e-01,
         -1.4941e-01,  6.7390e-02, -1.2658e-01, -5.7977e-02, -6.4965e-02,
          4.6758e-02, -1.1666e-01,  1.1524e-01, -1.8049e-01, -2.0661e-02,
          2.1115e-01],
        [-1.3645e-01,  1.9023e-01,  1.3171e-01, -8.2346e-02,  8.8278e-02,
         -1.7049e-01,  1.8534e-02,  6.9593e-02,  2.1770e-01, -1.4149e-01,
         -1.4062e-01, -1.2318e-01, -2.4478e-01,  4.8966e-02, -2.0536e-01,
         -6.5515e-02],
        [-1.1314e-01,  1.5557e-02,  7.4241e-02, -1.8008e-01, -7.5393e-02,
         -2.2442e-02, -1.4293e-01,  5.9310e-02,  9.0999e-02, -1.7658e-01,
          1.9540e-01,  1.7606e-01, -7.6621e-02,  3.8790e-02,  2.8849e-02,
         -3.6090e-02],
        [-1.6936e-01,  2.0719e-01,  1.2146e-01, -2.0738e-01, -1.9529e-01,
          2.3929e-01,  4.0438e-02, -5.8825e-02,  1.7041e-01,  7.3371e-02,
          8.8218e-02,  1.9678e-01, -1.8050e-02,  2.3976e-01, -1.7709e-01,
         -1.5370e-01],
        [ 4.0764e-02, -2.8770e-02,  1.4107e-01, -6.6391e-02,  3.7724e-02,
         -5.0355e-02,  1.8928e-01, -1.4819e-02,  2.2729e-03,  1.8474e-01,
          2.4462e-01,  2.3762e-01, -2.4600e-01, -1.3967e-01, -5.5877e-02,
         -5.3207e-02],
        [ 1.4620e-01,  1.1145e-01, -1.8972e-02,  4.3400e-03,  5.5143e-02,
          2.1393e-01,  1.2816e-01, -1.2459e-01, -1.2936e-01,  7.7476e-02,
         -2.3712e-02, -1.5880e-01, -2.4353e-01,  3.4228e-02, -7.1442e-02,
         -1.4387e-01],
        [ 4.8624e-02,  2.4187e-01,  2.0924e-01,  1.4095e-01, -1.8696e-01,
          1.4109e-01,  1.2771e-01,  8.3642e-02, -6.0751e-02, -5.9487e-03,
         -1.3403e-01, -5.4720e-02, -4.2694e-02, -3.7008e-02, -2.4721e-01,
          8.9795e-02],
        [-2.0614e-01, -1.8540e-01,  1.0000e-01, -2.0306e-01,  2.3691e-01,
          2.4097e-01, -7.7867e-02, -4.1788e-02, -1.9273e-01,  1.7043e-02,
          4.4198e-02, -1.3873e-01,  7.8713e-02, -8.0345e-03, -7.5277e-02,
         -2.4597e-03],
        [-2.4074e-01, -1.7768e-01,  3.4686e-02,  2.3984e-01, -1.4660e-01,
          1.5868e-01,  2.1293e-02, -1.0909e-01,  1.8084e-03,  1.1827e-01,
          3.0450e-02,  2.2289e-01, -4.5845e-02, -1.6853e-01,  2.2750e-01,
         -6.9805e-02],
        [ 1.6022e-01,  1.6333e-01,  4.5872e-02, -2.0678e-01, -2.4385e-01,
          1.1709e-01,  5.9536e-02,  1.4412e-01, -2.1886e-01, -3.6036e-02,
          2.1756e-01,  1.3294e-01,  2.0630e-01,  1.9469e-01, -5.9755e-02,
         -1.6865e-01],
        [-1.5067e-01,  8.6486e-02, -1.0083e-01,  2.5845e-03,  3.8307e-02,
          1.5679e-01,  1.4102e-01,  1.4423e-01,  8.6253e-03,  1.4273e-01,
         -1.1849e-01, -1.0166e-01, -4.1093e-02, -1.4359e-01,  2.2141e-01,
         -3.9906e-02],
        [ 7.1121e-02, -6.3594e-03, -4.9791e-03, -1.3172e-01, -1.9879e-02,
         -2.2209e-01, -1.1806e-01,  1.9285e-01, -2.3562e-01,  4.2675e-02,
          3.8510e-02, -2.4082e-01,  4.9443e-02,  1.1762e-01,  1.7955e-01,
          4.5225e-02],
        [ 1.9699e-01,  7.9809e-03,  9.6828e-02,  7.2257e-02, -1.8279e-01,
         -5.6433e-02, -1.7753e-01,  1.9521e-01,  1.2002e-01, -1.0758e-01,
         -4.4275e-02,  6.8297e-02, -2.1925e-01,  5.5047e-03,  1.2078e-01,
          3.2905e-02],
        [-2.4600e-02,  1.6230e-01,  1.0715e-01, -2.2065e-01,  1.4554e-01,
         -1.9559e-01,  1.4202e-01,  2.1070e-01,  2.1568e-02, -8.2896e-02,
         -1.3072e-01, -1.1261e-01, -4.4576e-02, -1.0205e-01,  2.4659e-01,
         -1.0943e-01],
        [ 1.0220e-01, -2.3025e-01,  1.2512e-01,  2.1432e-01, -1.8081e-01,
         -6.2192e-02,  6.1179e-02, -2.3778e-01, -1.5969e-01,  8.8542e-02,
          2.3385e-01, -7.6281e-02, -3.7488e-03, -2.3974e-01, -2.4155e-01,
          2.1582e-01],
        [ 2.1375e-01, -7.7771e-02, -9.7257e-02, -1.7779e-02,  1.1759e-01,
         -2.4319e-01, -1.4007e-01, -8.3788e-02, -1.0729e-01, -8.2003e-03,
          1.8392e-01,  5.6180e-02, -2.2763e-01,  2.2963e-01,  2.0289e-01,
          8.0312e-02],
        [ 1.2397e-01,  9.1875e-02,  2.0651e-01, -2.4204e-01, -1.5404e-01,
         -3.3343e-02, -4.9149e-02, -1.6748e-01, -2.3821e-01, -1.9253e-01,
         -3.7262e-02,  2.1381e-01,  1.6457e-01,  7.0466e-02, -1.5195e-01,
         -9.8976e-02],
        [ 2.5679e-02, -2.3329e-01, -9.8175e-03,  4.9248e-02,  2.2761e-01,
         -6.7215e-02,  2.4381e-01,  1.7412e-02, -1.7196e-01,  2.3469e-01,
          2.1829e-01, -1.9595e-01, -1.4567e-01,  1.1795e-01, -1.5224e-01,
          1.7158e-01],
        [-1.1769e-01, -7.9148e-02, -7.0170e-02,  2.3691e-01, -8.2951e-02,
         -5.0204e-02,  1.4969e-01, -1.6951e-01, -2.6198e-03, -1.9470e-01,
         -2.2916e-01, -5.5484e-02,  2.6058e-02,  2.1160e-01, -2.3816e-01,
         -7.0339e-02],
        [ 6.7385e-02,  9.2829e-02,  1.4766e-01, -2.0261e-01, -5.9531e-02,
          5.6216e-02, -2.0199e-01,  1.2447e-01, -2.3701e-01,  1.5440e-01,
          8.2788e-02, -6.9419e-02,  8.2439e-02,  2.1015e-01,  1.8550e-01,
          1.5324e-01],
        [-1.4713e-01,  7.3416e-02,  1.8602e-01,  4.5682e-02,  1.6393e-01,
         -1.5346e-01,  1.7730e-01, -6.7249e-03, -2.2585e-01, -6.3216e-02,
          2.2248e-01, -8.8927e-02, -4.4838e-02, -9.8419e-02, -1.3752e-01,
          4.1716e-02],
        [ 1.5325e-01,  2.8001e-02, -1.3823e-02,  1.2869e-02, -1.8588e-01,
         -1.3332e-01,  1.0927e-02, -1.9878e-01,  1.2530e-01,  3.6511e-02,
          4.2083e-03, -1.4450e-02,  2.0961e-01,  2.2656e-01,  1.2365e-01,
          1.2576e-01],
        [-1.2282e-01,  1.0378e-01, -1.7069e-01,  1.0964e-01, -1.7911e-01,
          2.2742e-04,  1.8279e-01,  1.6759e-01,  2.1949e-01,  8.6877e-02,
          9.8593e-02,  6.5446e-02,  1.8099e-01,  1.3278e-01,  7.2174e-02,
         -8.8827e-02],
        [-1.2258e-01, -6.0261e-02,  1.1772e-01, -1.3450e-01,  6.6720e-02,
          2.2031e-01,  2.1326e-01, -1.8436e-01,  6.9827e-02,  1.6506e-01,
         -2.2862e-01,  1.5819e-01, -1.5439e-01, -1.7918e-01, -1.0755e-01,
         -9.5628e-02],
        [-1.0490e-01,  7.3305e-02,  9.5315e-02,  9.8647e-02,  1.7113e-01,
         -1.5667e-01, -2.3595e-01, -1.9993e-01, -1.3842e-01, -1.1286e-01,
          1.0872e-01, -1.8242e-01, -1.8264e-01,  1.3539e-01, -1.6055e-01,
          4.5341e-02]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1921,  0.0939,  0.1553, -0.2093,  0.0866, -0.1326,  0.1571,  0.2233,
        -0.2094,  0.0951,  0.1673,  0.2289,  0.1904,  0.0507,  0.0156,  0.0500,
        -0.1475, -0.0474, -0.0046, -0.1568, -0.0126, -0.0317, -0.0861, -0.0758,
        -0.2476,  0.2398,  0.1217,  0.1823, -0.2112, -0.2432,  0.1845, -0.0439],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.0260,  0.0870,  0.0097, -0.0075,  0.1034,  0.1396, -0.0509, -0.1525,
         -0.0953,  0.1247,  0.0170,  0.1498, -0.0602, -0.1659,  0.0565, -0.0737,
         -0.1041,  0.1118,  0.0107, -0.0167,  0.1706,  0.1524, -0.1460, -0.1641,
         -0.0858, -0.1357, -0.0945,  0.1177, -0.1192,  0.1637,  0.0568,  0.0061]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0263,  0.0325,  0.0528,  ...,  0.0384, -0.1591, -0.1137],
        [-0.0427, -0.1242,  0.0864,  ..., -0.0240, -0.1557,  0.0871],
        [-0.0900,  0.0741,  0.1116,  ...,  0.1501,  0.0709,  0.0345],
        ...,
        [ 0.0821, -0.0832,  0.0098,  ..., -0.1132, -0.0712, -0.1180],
        [ 0.0102, -0.1200, -0.0089,  ..., -0.1391, -0.0332,  0.1557],
        [-0.1354,  0.0675,  0.0395,  ..., -0.0302, -0.1426, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0602,  0.0707, -0.1089, -0.1113, -0.0441,  0.0117, -0.1332,  0.0752,
        -0.0315,  0.0946,  0.0492, -0.0270, -0.0159,  0.0507, -0.0847, -0.0430,
         0.0748, -0.1414, -0.0304,  0.0319, -0.0841,  0.0743,  0.0778, -0.0247,
        -0.0529,  0.0790,  0.0075, -0.1253,  0.0908,  0.1591,  0.1356, -0.0898],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1656, -0.0752, -0.1325,  ..., -0.0206, -0.1314,  0.1684],
        [-0.0942,  0.0910,  0.0422,  ...,  0.0648, -0.1308,  0.1656],
        [ 0.0205, -0.1628, -0.1035,  ..., -0.0569,  0.1124,  0.0599],
        ...,
        [ 0.0215, -0.0128,  0.1355,  ...,  0.1406, -0.1033,  0.1505],
        [ 0.0999, -0.0217, -0.0040,  ...,  0.1506,  0.1056, -0.0508],
        [ 0.1025, -0.0147,  0.1688,  ...,  0.1576,  0.0362,  0.0601]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0676,  0.1015,  0.0042, -0.0440, -0.0624, -0.1120, -0.0053, -0.1007,
         0.1040, -0.1251,  0.1552, -0.1576,  0.1457,  0.0215, -0.1681,  0.0515,
        -0.1123, -0.1386,  0.0078, -0.0518,  0.0451,  0.1413, -0.1606,  0.1744,
        -0.0995, -0.0364,  0.1161, -0.0753, -0.0876, -0.0399,  0.0676, -0.0091],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1599,  0.0749, -0.1598, -0.1257,  0.0155, -0.0053, -0.0553,  0.0595,
          0.0727, -0.1011, -0.0368,  0.0648,  0.0626, -0.0143,  0.0904,  0.0617,
         -0.1644, -0.1704,  0.0074,  0.0620, -0.1245, -0.0897, -0.1674,  0.0320,
          0.1268,  0.1582, -0.1455,  0.1354, -0.0723, -0.1572,  0.1149,  0.1500]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0106], device='cuda:0', requires_grad=True)

