Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-6.8368e-03,  4.0474e-01,  3.0699e-01, -3.3387e-01, -1.7673e-01,
         -1.4779e-01, -4.7401e-02, -3.6462e-01, -2.1085e-01, -6.8566e-02,
         -3.3141e-02,  1.7284e-01, -2.9233e-01, -6.6816e-02,  1.6346e-02,
          3.7903e-01],
        [-2.4579e-01, -3.9842e-01, -1.0159e-01, -2.8709e-03, -3.5921e-02,
          2.4220e-01,  1.4473e-01,  1.4030e-01,  3.9686e-01,  1.3169e-01,
          3.0351e-01, -2.4306e-01,  3.5181e-01, -3.3649e-02,  2.9899e-01,
         -8.8344e-02],
        [ 8.4779e-02,  3.0269e-01,  3.8775e-01, -1.3474e-01, -8.2304e-02,
         -3.4003e-01, -6.1455e-02, -4.1475e-01, -1.5003e-02, -7.7515e-02,
         -1.5978e-01, -6.3223e-02,  3.7577e-02,  3.4842e-01,  3.4262e-02,
          2.7861e-01],
        [ 2.8182e-01,  1.3076e-01,  9.9140e-02, -9.8318e-02, -5.7940e-02,
         -2.0972e-01, -1.5536e-01, -9.7282e-02, -4.3698e-01, -4.2348e-01,
         -2.2429e-01,  3.6520e-01, -6.7325e-02, -1.0870e-01, -1.6692e-01,
          1.7830e-01],
        [-9.2271e-02,  2.4730e-02, -1.7275e-01, -1.6122e-02,  1.5324e-01,
          8.1864e-02,  2.6341e-02,  3.0340e-01,  1.4791e-01,  2.9762e-01,
          3.5177e-01, -1.4508e-01,  3.1220e-01, -2.3592e-01,  2.4861e-01,
         -1.7024e-01],
        [-1.3174e-02,  5.3250e-02, -3.7198e-01,  4.2099e-01,  3.4062e-01,
         -1.7819e-02,  2.6131e-01, -3.0313e-02,  2.7266e-01,  2.2412e-01,
         -7.4520e-02, -8.5097e-02,  1.1126e-01,  1.1973e-01,  3.7633e-01,
         -9.8584e-02],
        [ 3.6537e-01,  2.5731e-01,  4.0934e-01, -1.9238e-01, -5.0193e-02,
         -2.0673e-01, -1.6960e-01, -2.2200e-01, -2.6151e-01, -2.8253e-02,
         -5.2434e-02,  4.8553e-02, -3.5004e-01,  2.1217e-01, -2.5696e-01,
          1.6145e-01],
        [-6.0592e-02,  3.7092e-01,  3.6316e-01, -3.6631e-01, -3.3822e-01,
         -2.9822e-01, -8.7357e-02, -2.5786e-01, -2.1137e-01, -2.2397e-01,
         -9.8531e-02,  2.5008e-02, -3.0697e-02, -9.1770e-02, -8.2974e-02,
          3.6900e-01],
        [ 2.8320e-02,  3.6273e-01,  3.0171e-01, -2.4879e-01, -3.9429e-02,
         -3.4307e-01, -1.3593e-01, -8.4687e-02,  4.6633e-02, -3.1303e-01,
         -2.8630e-01,  3.8892e-02, -4.0740e-01,  1.6019e-01, -2.4843e-01,
          1.0339e-01],
        [-2.9307e-01, -1.7225e-01, -1.0877e-01,  3.5442e-03,  7.4505e-02,
          1.6093e-01,  4.8515e-02,  2.3169e-01,  2.8086e-01,  8.1297e-03,
          3.6495e-01,  3.5213e-04,  1.0230e-01, -9.1736e-02,  1.5131e-01,
         -2.2107e-01],
        [-3.6505e-01,  5.6483e-03, -7.7995e-02, -1.2191e-02, -4.3042e-02,
          4.3620e-01,  2.3955e-01,  1.2438e-01,  3.7093e-01,  2.7281e-01,
          2.3125e-01,  5.7437e-03,  1.8283e-01,  9.8748e-02, -2.4756e-02,
         -3.5759e-01],
        [-1.3381e-01, -2.0904e-01, -3.6777e-02,  1.0389e-01,  1.7498e-01,
          1.3195e-01,  3.6347e-01,  1.5050e-01,  1.7817e-01,  3.6314e-01,
          4.0947e-01,  6.4452e-02, -7.0387e-02, -2.6392e-01, -9.0082e-03,
         -2.3006e-01],
        [ 3.3093e-01,  3.0237e-01,  1.6911e-01, -1.8123e-01, -9.1031e-02,
          2.9402e-02, -6.3882e-02, -3.0047e-01, -3.2250e-01, -1.0907e-01,
         -1.8275e-01,  1.5827e-02, -4.2264e-01,  1.6079e-01, -1.9965e-01,
          4.8752e-02],
        [ 2.0605e-01,  4.0878e-01,  3.7127e-01, -1.7589e-02, -3.0354e-01,
         -2.0432e-02, -2.2105e-02, -6.0757e-02, -2.1719e-01, -1.6914e-01,
         -2.8456e-01,  9.7539e-02, -1.9214e-01,  6.1758e-02, -2.8678e-01,
          2.5028e-01],
        [-3.7563e-01, -3.6316e-01, -7.4369e-02, -2.7153e-02,  3.6184e-01,
          4.0360e-01,  9.5340e-02,  1.0598e-01, -1.8751e-02,  1.9157e-01,
          1.9764e-01, -2.9714e-01,  2.4409e-01, -1.1860e-01,  2.8915e-02,
         -1.7934e-01],
        [-6.6129e-02,  2.7847e-02,  2.1297e-01,  4.5518e-02, -3.3328e-01,
         -2.1755e-02, -1.8226e-01, -2.9084e-01, -2.2836e-01, -7.6297e-02,
         -1.5565e-01,  4.0365e-01, -2.5743e-01, -1.8538e-02,  8.1215e-02,
          1.1465e-01],
        [ 3.2536e-01,  3.3708e-01,  2.1558e-01, -3.7210e-01, -3.7249e-01,
         -5.5609e-02, -9.8956e-02, -1.1526e-02, -3.8687e-01, -2.0739e-01,
          6.4573e-02,  2.9558e-01,  4.4322e-02,  3.0405e-01, -9.7326e-02,
         -4.1831e-04],
        [-3.0088e-01, -7.4268e-02, -2.5705e-01,  1.5821e-01,  1.3937e-01,
          3.0722e-01,  2.8806e-01,  2.7219e-01,  1.5729e-01,  2.9983e-01,
          2.0652e-02, -2.4232e-01,  1.0669e-01, -2.2683e-01,  2.5984e-01,
         -1.9505e-01],
        [ 2.1885e-01,  1.6443e-01,  1.4387e-01, -2.9018e-01, -2.0059e-01,
         -3.6599e-01, -2.9312e-01,  3.7935e-02, -4.5447e-01, -1.1371e-01,
         -1.2170e-01, -8.8776e-02, -1.2788e-01,  2.9637e-01,  1.0521e-04,
          2.0229e-01],
        [ 3.7287e-01,  1.9098e-01,  2.7869e-01, -1.0517e-01, -3.0514e-01,
         -2.3244e-01, -3.4336e-01,  3.9940e-02, -5.5090e-02, -2.8863e-01,
         -1.8030e-01,  2.3510e-01, -3.9397e-01,  1.1604e-01,  7.5316e-02,
          2.1588e-01],
        [-1.8758e-01, -9.8317e-03, -6.0824e-02, -5.1917e-02,  2.7842e-01,
         -2.7053e-02,  3.0395e-01,  3.6504e-01,  1.9882e-01,  8.7456e-02,
          1.5631e-02, -2.7272e-01,  1.1774e-01, -2.1454e-01,  3.5137e-01,
         -2.7757e-01],
        [-7.0146e-02, -4.1068e-01, -5.1234e-02,  3.9424e-01, -3.5714e-02,
          1.1066e-01,  2.4065e-01, -7.4086e-02,  2.8121e-02,  2.6711e-01,
          3.9845e-01, -2.4272e-01,  1.6687e-01, -3.6432e-01, -1.2114e-01,
          3.8081e-02],
        [ 3.6725e-01,  8.9102e-02,  6.1953e-02, -1.7808e-01,  6.9690e-03,
         -3.9594e-01, -2.9189e-01, -2.1718e-01, -2.6448e-01, -1.6806e-01,
          4.8234e-02,  2.0005e-01, -3.8290e-01,  3.2361e-01,  1.2903e-01,
          2.3998e-01],
        [ 2.6336e-01,  2.4688e-01,  3.5364e-01, -3.8619e-01, -2.4029e-01,
         -1.7642e-01, -1.7443e-01, -2.8204e-01, -3.6630e-01, -3.3995e-01,
         -1.4833e-01,  3.4117e-01,  1.9121e-02,  1.4276e-01, -1.5674e-01,
          4.5454e-02],
        [ 2.1356e-01, -3.4843e-02,  1.8097e-01, -1.4294e-01,  5.9717e-02,
         -2.6675e-01,  4.5146e-02, -1.7266e-01, -3.7990e-01,  3.8936e-02,
          4.0901e-02, -5.4562e-03, -3.3691e-01,  2.6001e-01, -2.8034e-01,
          3.6515e-01],
        [ 4.7832e-02,  9.7705e-02,  1.0022e-01,  6.2369e-02, -2.1702e-01,
         -2.1109e-01, -2.1362e-02, -3.2324e-01, -1.8071e-01, -3.6640e-01,
         -3.7133e-01,  1.0044e-01, -1.4111e-01,  3.2533e-01, -3.6054e-01,
          1.0415e-01],
        [ 2.2710e-01,  2.6252e-01,  3.1255e-01, -3.6471e-01, -1.7671e-01,
         -1.0521e-01, -3.5318e-01, -1.8821e-02, -3.9889e-01, -1.1114e-02,
         -6.3538e-02,  8.3293e-02, -7.5630e-02,  3.0925e-01,  1.4383e-01,
          3.1738e-01],
        [-3.2152e-01, -1.0868e-01,  7.8067e-03,  2.1985e-01,  2.9976e-01,
          2.5206e-02,  3.5591e-01,  1.5499e-01, -4.7675e-02,  1.1482e-01,
          3.8152e-01, -2.5804e-01,  1.2941e-01, -2.2160e-01, -5.7462e-02,
         -1.3703e-01],
        [ 3.1443e-01,  2.0278e-01,  1.5333e-01, -1.5214e-01, -3.0454e-01,
         -2.9748e-01, -1.4809e-01, -3.4339e-01, -3.7327e-02, -1.3014e-01,
         -1.1059e-01,  1.3918e-01,  4.0307e-02,  3.3449e-01,  3.9557e-02,
          2.9363e-01],
        [-2.6966e-01, -5.3428e-02, -3.2316e-01,  2.6220e-01, -8.0839e-02,
          1.4535e-01,  3.2703e-01,  2.9197e-01,  3.6439e-01,  2.4058e-01,
          2.3527e-01, -7.0518e-02,  3.1986e-01,  5.3846e-02,  1.0660e-01,
         -2.3990e-01],
        [-2.9761e-01, -2.4274e-01, -6.1885e-02,  4.2232e-02,  2.0141e-01,
          3.9962e-01,  3.8483e-01, -2.0834e-02,  2.4916e-01,  3.4518e-01,
         -8.1011e-02, -1.3280e-02,  2.0568e-02, -2.9940e-01, -1.8170e-02,
         -2.7629e-01],
        [ 4.8150e-02,  2.4658e-01,  2.5288e-01, -6.0502e-02,  1.3700e-02,
         -3.1066e-01, -3.9448e-01, -3.5092e-01, -3.3879e-01, -2.7555e-01,
         -4.8556e-02, -2.8218e-02, -3.4700e-01,  2.8141e-01, -2.1508e-01,
          2.0396e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0632, -0.0170, -0.0003, -0.0379,  0.0144, -0.2335,  0.0997,  0.1308,
        -0.0484, -0.0051,  0.0446,  0.0764,  0.1343,  0.0789,  0.0571, -0.0217,
        -0.0180, -0.0388,  0.0874, -0.0235, -0.0953, -0.0889, -0.0304,  0.0393,
        -0.0568,  0.1354,  0.1659,  0.0415, -0.0944, -0.1835,  0.0238,  0.0184],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1956,  0.2882, -0.2057, -0.2344,  0.2745,  0.3206, -0.2639, -0.3583,
         -0.3049,  0.3088,  0.2396,  0.3524, -0.2390, -0.3783,  0.2665, -0.1699,
         -0.2984,  0.3141, -0.2049, -0.2210,  0.3662,  0.2970, -0.3530, -0.3604,
         -0.2444, -0.3025, -0.3024,  0.3195, -0.3322,  0.3640,  0.2799, -0.2146]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0030,  0.0836,  0.0764,  ...,  0.1914, -0.3043, -0.1137],
        [-0.0793, -0.0716,  0.1199,  ...,  0.1034, -0.2813,  0.0871],
        [-0.1012,  0.1195,  0.1002,  ...,  0.1899,  0.0467,  0.0345],
        ...,
        [ 0.1068, -0.1262, -0.0349,  ..., -0.1750, -0.0319, -0.1180],
        [ 0.0436, -0.1726, -0.0432,  ..., -0.2609,  0.0870,  0.1557],
        [-0.1916,  0.1250,  0.0554,  ...,  0.0681, -0.2356, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0489,  0.0336, -0.1008, -0.1540, -0.0802,  0.0064, -0.1037,  0.0374,
        -0.0303,  0.0582,  0.0248,  0.0015,  0.0005,  0.1006, -0.0471, -0.0075,
         0.0442, -0.1656,  0.0015,  0.0794, -0.0602,  0.0197,  0.1106,  0.0200,
        -0.1119,  0.0983,  0.0442, -0.0916,  0.0423,  0.1978,  0.1679, -0.1294],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0542, -0.1640, -0.1841,  ...,  0.0358, -0.0465,  0.0645],
        [-0.2174, -0.0134, -0.0179,  ...,  0.1367, -0.0315,  0.0479],
        [ 0.1455, -0.0526, -0.0423,  ..., -0.1390,  0.0066,  0.1852],
        ...,
        [ 0.1326,  0.0657,  0.1928,  ...,  0.0964, -0.1798,  0.2477],
        [-0.0175, -0.1285, -0.0518,  ...,  0.2306,  0.2072, -0.1705],
        [-0.0055, -0.1050,  0.1241,  ...,  0.2168,  0.1222, -0.0442]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1010,  0.1463, -0.0448, -0.0945, -0.1122, -0.1729, -0.0568, -0.0332,
         0.1338, -0.1621,  0.1251, -0.1234,  0.1920,  0.0841, -0.1169,  0.1138,
        -0.1400, -0.1738,  0.0722,  0.0085, -0.0105,  0.0878, -0.2077,  0.2111,
        -0.0487, -0.0066,  0.0764, -0.0365, -0.1428, -0.0660,  0.1162,  0.0261],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3459,  0.2681, -0.3051, -0.3373, -0.1870, -0.1829, -0.2521,  0.2122,
          0.2491, -0.2651, -0.2143,  0.2308,  0.2404,  0.1976,  0.2545,  0.2372,
         -0.3384, -0.3444,  0.1870,  0.2288, -0.2914, -0.2426, -0.3444,  0.1948,
          0.3067,  0.3622, -0.3172,  0.3309, -0.2517, -0.3422,  0.3051,  0.3471]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1071], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.6423e-02,  3.7899e-01,  3.3106e-01, -3.4952e-01, -1.9588e-02,
         -1.8677e-01, -7.3244e-02, -3.9116e-01, -1.7318e-01, -9.3060e-02,
          1.7907e-02,  1.6923e-01,  3.7886e-02, -7.7670e-02,  3.2031e-01,
          3.7069e-01],
        [-2.7434e-01, -3.6221e-01, -1.3008e-01,  1.1374e-02, -1.7426e-01,
          2.8651e-01,  1.8764e-01,  1.6008e-01,  3.8919e-01,  1.3840e-01,
          2.3553e-01, -2.5961e-01,  2.9208e-02, -2.0717e-02,  5.4752e-03,
         -8.8272e-02],
        [ 1.0475e-01,  2.6853e-01,  4.0988e-01, -1.4439e-01,  1.4425e-01,
         -3.8373e-01, -7.0075e-02, -4.1806e-01,  5.4212e-02, -8.9687e-02,
         -1.0468e-01, -6.1836e-02,  3.7746e-01,  2.8633e-01,  4.3858e-01,
          2.7113e-01],
        [ 2.9919e-01,  9.5955e-02,  1.1772e-01, -9.8744e-02,  1.1352e-01,
         -2.4147e-01, -1.7987e-01, -9.4705e-02, -4.0555e-01, -4.1544e-01,
         -1.2429e-01,  3.5917e-01,  2.6446e-01, -1.4175e-01,  1.4895e-01,
          1.7116e-01],
        [-1.1309e-01,  8.1904e-02, -1.9378e-01, -7.3306e-03,  1.7941e-02,
          1.2367e-01,  6.4544e-02,  3.2144e-01,  1.3756e-01,  3.0039e-01,
          2.6668e-01, -1.5926e-01, -1.4442e-02, -2.0755e-01, -7.6739e-02,
         -1.4900e-01],
        [-2.1901e-02,  1.1033e-01, -3.8181e-01,  4.1258e-01,  1.2406e-01,
          6.9918e-03,  2.7703e-01, -4.6730e-02,  2.3390e-01,  2.1461e-01,
         -1.0815e-01, -6.7957e-02, -2.1417e-01,  1.4003e-01,  3.5586e-02,
         -8.2165e-02],
        [ 3.9560e-01,  2.2135e-01,  4.3729e-01, -2.0462e-01,  1.3467e-01,
         -2.5560e-01, -2.1321e-01, -2.3924e-01, -2.4684e-01, -3.3020e-02,
         -2.8835e-02,  6.1703e-02, -5.3335e-02,  2.0747e-01, -1.1549e-02,
          1.6632e-01],
        [-4.1405e-02,  3.3251e-01,  3.8012e-01, -3.6553e-01, -1.4192e-01,
         -3.3713e-01, -1.1282e-01, -2.4877e-01, -1.7764e-01, -2.2001e-01,
         -8.0061e-02,  1.8811e-02,  2.3960e-01, -1.0056e-01,  1.6423e-01,
          3.6909e-01],
        [ 5.1501e-02,  3.2060e-01,  3.2419e-01, -2.6266e-01,  3.7689e-02,
         -3.8000e-01, -1.7904e-01, -1.0793e-01,  5.3017e-02, -3.1280e-01,
         -1.2031e-01,  6.5134e-02, -1.0782e-01,  1.1182e-01,  3.2367e-03,
          9.4358e-02],
        [-3.0357e-01, -1.1420e-01, -1.1974e-01, -9.1247e-05, -6.7035e-02,
          1.8994e-01,  6.5167e-02,  2.3599e-01,  2.5661e-01, -1.6093e-03,
          2.6265e-01, -4.4835e-03, -2.2891e-01, -4.7171e-02, -1.8139e-01,
         -1.9617e-01],
        [-3.7329e-01,  4.9522e-02, -8.7058e-02, -2.2659e-02, -1.8150e-01,
          4.6296e-01,  2.5058e-01,  1.2196e-01,  3.3625e-01,  2.5655e-01,
          7.8784e-02,  1.0280e-02, -1.4187e-01,  1.5734e-01, -3.9314e-01,
         -3.3709e-01],
        [-1.4494e-01, -1.6444e-01, -4.6986e-02,  1.0533e-01,  1.0539e-01,
          1.5582e-01,  3.8904e-01,  1.6026e-01,  1.6326e-01,  3.4878e-01,
          1.6655e-01,  5.3620e-02, -3.7785e-01, -1.7824e-01, -2.5755e-01,
         -2.0383e-01],
        [ 3.6710e-01,  2.5805e-01,  2.0869e-01, -2.0297e-01,  9.5468e-02,
         -3.1817e-02, -1.1457e-01, -3.2451e-01, -3.2602e-01, -1.3063e-01,
         -1.4241e-01,  2.5172e-02, -5.8097e-02,  1.6792e-01,  1.6786e-01,
          4.6112e-02],
        [ 2.3330e-01,  3.7419e-01,  3.9708e-01, -3.0328e-02, -1.6518e-01,
         -6.1670e-02, -6.9304e-02, -7.7374e-02, -2.1013e-01, -1.7350e-01,
         -2.2762e-01,  1.1380e-01,  1.0387e-01,  4.8787e-02, -4.2489e-02,
          2.5290e-01],
        [-3.9784e-01, -3.2516e-01, -9.6043e-02, -2.5091e-02,  1.9430e-01,
          4.5105e-01,  1.2331e-01,  1.1874e-01, -4.2075e-02,  1.9135e-01,
          1.4153e-01, -3.0835e-01, -6.5045e-02, -9.9391e-02, -2.8408e-01,
         -1.7617e-01],
        [-9.6103e-02, -9.7890e-02,  1.8292e-01,  9.9347e-02, -1.3407e-01,
         -1.0195e-02, -1.4866e-01, -2.3419e-01, -1.2000e-01, -1.9527e-02,
         -4.9136e-02,  3.6320e-01,  5.7053e-02, -1.0125e-01,  3.9604e-01,
          4.6769e-02],
        [ 3.3851e-01,  2.9605e-01,  2.2827e-01, -3.7290e-01, -1.9631e-01,
         -8.0145e-02, -1.2821e-01, -1.6332e-03, -3.5628e-01, -1.9760e-01,
          1.2411e-01,  2.8427e-01,  3.3066e-01,  2.7345e-01,  1.3368e-01,
         -9.0357e-03],
        [-3.2202e-01, -4.1496e-02, -2.7563e-01,  1.6128e-01, -2.0237e-02,
          3.4638e-01,  3.1914e-01,  2.7836e-01,  1.3515e-01,  2.9601e-01,
         -2.4220e-02, -2.4616e-01, -1.5393e-01, -2.1055e-01,  3.4784e-02,
         -1.9416e-01],
        [ 2.5783e-01,  1.4932e-01,  1.8514e-01, -3.1851e-01, -9.1768e-03,
         -4.2323e-01, -3.1568e-01,  1.9109e-02, -3.9271e-01, -1.4398e-01,
         -4.9117e-02, -7.5325e-02,  1.8194e-01,  2.3439e-01,  3.7783e-01,
          2.1291e-01],
        [ 3.9363e-01,  1.5680e-01,  2.9874e-01, -1.1007e-01, -1.7045e-01,
         -2.7296e-01, -3.7872e-01,  2.6214e-02, -3.6185e-02, -2.8465e-01,
         -7.4988e-02,  2.4716e-01, -9.2662e-02,  8.2432e-02,  3.3187e-01,
          2.1100e-01],
        [-2.0184e-01,  3.9737e-02, -7.5643e-02, -5.0764e-02,  1.0952e-01,
          4.1527e-03,  3.3266e-01,  3.6534e-01,  1.7250e-01,  8.4674e-02,
         -3.3467e-02, -2.7023e-01, -1.6898e-01, -2.0303e-01,  4.7087e-02,
         -2.6706e-01],
        [-7.8772e-02, -3.5611e-01, -6.0033e-02,  3.8711e-01, -1.5782e-01,
          1.3946e-01,  2.5114e-01, -7.0700e-02, -1.0130e-03,  2.5426e-01,
          2.6055e-01, -2.4950e-01, -1.3017e-01, -3.1297e-01, -4.4323e-01,
          5.9564e-02],
        [ 3.8116e-01,  5.0137e-02,  7.4422e-02, -1.7337e-01,  1.6303e-01,
         -4.2953e-01, -3.1425e-01, -2.1443e-01, -2.3181e-01, -1.5829e-01,
          1.1030e-01,  1.9980e-01, -1.2309e-01,  2.9432e-01,  3.8442e-01,
          2.3165e-01],
        [ 2.8354e-01,  2.1991e-01,  3.7090e-01, -3.8973e-01, -8.4056e-02,
         -2.1202e-01, -2.1250e-01, -2.7584e-01, -3.4762e-01, -3.3518e-01,
         -1.1248e-01,  3.3745e-01,  2.4602e-01,  1.3486e-01,  1.6286e-02,
          4.9254e-02],
        [ 2.2458e-01, -1.0072e-01,  1.9338e-01, -1.4040e-01,  2.2192e-01,
         -2.8949e-01,  2.5993e-02, -1.7101e-01, -3.4744e-01,  5.0543e-02,
          1.4217e-01, -7.7591e-03,  1.4419e-02,  2.1415e-01,  6.8408e-02,
          3.3837e-01],
        [ 7.0104e-02,  4.9332e-02,  1.2401e-01,  5.8110e-02, -4.7740e-02,
         -2.6258e-01, -5.3800e-02, -3.3931e-01, -1.6375e-01, -3.7117e-01,
         -3.2240e-01,  1.1348e-01,  1.6216e-01,  3.1688e-01, -2.6349e-02,
          9.5289e-02],
        [ 2.3919e-01,  2.2366e-01,  3.2348e-01, -3.6168e-01, -3.4037e-03,
         -1.3360e-01, -3.8053e-01, -6.9687e-03, -3.6254e-01,  9.9479e-04,
         -3.7957e-03,  7.4686e-02,  1.8859e-01,  2.7858e-01,  3.7123e-01,
          3.0983e-01],
        [-3.3725e-01, -6.6424e-02, -7.2287e-03,  2.2053e-01,  1.8329e-01,
          5.6319e-02,  3.8303e-01,  1.6249e-01, -6.6207e-02,  1.0705e-01,
          2.4121e-01, -2.6336e-01, -1.8443e-01, -1.7220e-01, -3.4556e-01,
         -1.2036e-01],
        [ 3.2768e-01,  1.6593e-01,  1.6556e-01, -1.4713e-01, -1.7419e-01,
         -3.2816e-01, -1.6957e-01, -3.4344e-01, -1.1553e-02, -1.1981e-01,
         -1.1508e-02,  1.3908e-01,  2.9865e-01,  2.9404e-01,  3.0608e-01,
          2.8303e-01],
        [-2.9069e-01, -1.9046e-02, -3.4154e-01,  2.6532e-01, -2.4240e-01,
          1.8530e-01,  3.5735e-01,  2.9447e-01,  3.4064e-01,  2.3745e-01,
          1.9625e-01, -7.4312e-02,  6.5272e-02,  6.5757e-02, -1.0855e-01,
         -2.3995e-01],
        [-3.0582e-01, -1.9813e-01, -6.9993e-02,  3.5821e-02,  5.0471e-02,
          4.2293e-01,  4.0315e-01, -2.6058e-02,  2.1399e-01,  3.2916e-01,
         -1.8263e-01, -9.1457e-03, -2.7171e-01, -2.4754e-01, -3.0486e-01,
         -2.6011e-01],
        [ 8.9535e-02,  2.2838e-01,  2.9330e-01, -9.3342e-02,  1.8221e-01,
         -3.6754e-01, -4.4079e-01, -3.8197e-01, -2.9928e-01, -3.0251e-01,
          2.0139e-02, -2.6059e-03, -3.1431e-02,  2.4089e-01,  5.3838e-02,
          2.1843e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0854, -0.0663,  0.1909, -0.0276, -0.0664, -0.0206,  0.0797,  0.0681,
        -0.0173, -0.0536, -0.0374,  0.0523,  0.1318,  0.1087, -0.0211, -0.0601,
        -0.1414,  0.0210,  0.1269,  0.0283,  0.0153, -0.1848, -0.0053, -0.0433,
        -0.0489,  0.2144,  0.1326,  0.0222, -0.0466, -0.1535,  0.0076,  0.0378],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1883,  0.2782, -0.2052, -0.2342,  0.2420,  0.2946, -0.2571, -0.3611,
         -0.2832,  0.2903,  0.2415,  0.3493, -0.2093, -0.3578,  0.2785, -0.1053,
         -0.2734,  0.3172, -0.2094, -0.2248,  0.3106,  0.3332, -0.3545, -0.3619,
         -0.2385, -0.2730, -0.3011,  0.3140, -0.3423,  0.3678,  0.2777, -0.2184]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0202, -0.0146,  0.0286,  ...,  0.2057, -0.3304, -0.1137],
        [-0.0918, -0.2021,  0.0862,  ...,  0.1419, -0.3145,  0.0871],
        [-0.0444,  0.1696,  0.0874,  ...,  0.0158,  0.2163,  0.0345],
        ...,
        [ 0.0327, -0.1673,  0.0157,  ...,  0.0634, -0.2563, -0.1180],
        [ 0.0459, -0.0568,  0.0006,  ..., -0.2967,  0.1132,  0.1557],
        [-0.0759,  0.1727,  0.0094,  ..., -0.1686,  0.0361, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0505,  0.0532, -0.0915, -0.1207, -0.0586,  0.0460, -0.1278,  0.0617,
        -0.0469,  0.0913,  0.0314,  0.0091,  0.0100,  0.0633, -0.0783, -0.0206,
         0.0468, -0.1430, -0.0320, -0.0161, -0.1116,  0.0457,  0.0828, -0.0058,
        -0.0850,  0.0655,  0.0246, -0.0967,  0.0633,  0.1468,  0.1402, -0.0653],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0500, -0.1900, -0.0875,  ..., -0.1278, -0.0257,  0.2535],
        [-0.2226, -0.0407,  0.0999,  ..., -0.0586, -0.0110,  0.2647],
        [ 0.1543, -0.0260, -0.1687,  ...,  0.0724, -0.0151, -0.0595],
        ...,
        [ 0.1396,  0.1056,  0.0886,  ...,  0.2504, -0.2112,  0.0636],
        [-0.0407, -0.1661,  0.0678,  ...,  0.0146,  0.2394,  0.0760],
        [-0.0065, -0.1173,  0.2060,  ...,  0.0627,  0.1302,  0.1245]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0844,  0.1208, -0.0330, -0.0534, -0.0304, -0.0348, -0.0318, -0.0625,
         0.1096, -0.1722,  0.1231, -0.1329,  0.1651, -0.0188, -0.1434,  0.1031,
        -0.1259, -0.1522,  0.0135, -0.0291,  0.0099,  0.1100, -0.1864,  0.2016,
        -0.0719, -0.0299,  0.0890, -0.0406, -0.1113, -0.0584,  0.1077, -0.0006],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4501,  0.3737, -0.4497, -0.4557,  0.2992,  0.3063, -0.3557,  0.3628,
          0.3659, -0.3852, -0.3772,  0.3392,  0.3609, -0.3007,  0.3818,  0.3280,
         -0.4600, -0.4520,  0.3289,  0.3451, -0.4114, -0.3847, -0.4486,  0.2852,
          0.4234,  0.4519, -0.4243,  0.4912, -0.3599, -0.4425,  0.4246,  0.4429]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1782], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.6423e-02,  3.7899e-01,  3.3106e-01, -3.4952e-01, -1.9588e-02,
         -1.8677e-01, -7.3244e-02, -3.9116e-01, -1.7318e-01, -9.3060e-02,
          1.7907e-02,  1.6923e-01,  3.7886e-02, -7.7670e-02,  3.2031e-01,
          3.7069e-01],
        [-2.7434e-01, -3.6221e-01, -1.3008e-01,  1.1374e-02, -1.7426e-01,
          2.8651e-01,  1.8764e-01,  1.6008e-01,  3.8919e-01,  1.3840e-01,
          2.3553e-01, -2.5961e-01,  2.9208e-02, -2.0717e-02,  5.4752e-03,
         -8.8272e-02],
        [ 1.0475e-01,  2.6853e-01,  4.0988e-01, -1.4439e-01,  1.4425e-01,
         -3.8373e-01, -7.0075e-02, -4.1806e-01,  5.4212e-02, -8.9687e-02,
         -1.0468e-01, -6.1836e-02,  3.7746e-01,  2.8633e-01,  4.3858e-01,
          2.7113e-01],
        [ 2.9919e-01,  9.5955e-02,  1.1772e-01, -9.8744e-02,  1.1352e-01,
         -2.4147e-01, -1.7987e-01, -9.4705e-02, -4.0555e-01, -4.1544e-01,
         -1.2429e-01,  3.5917e-01,  2.6446e-01, -1.4175e-01,  1.4895e-01,
          1.7116e-01],
        [-1.1309e-01,  8.1904e-02, -1.9378e-01, -7.3306e-03,  1.7941e-02,
          1.2367e-01,  6.4544e-02,  3.2144e-01,  1.3756e-01,  3.0039e-01,
          2.6668e-01, -1.5926e-01, -1.4442e-02, -2.0755e-01, -7.6739e-02,
         -1.4900e-01],
        [-2.1901e-02,  1.1033e-01, -3.8181e-01,  4.1258e-01,  1.2406e-01,
          6.9917e-03,  2.7703e-01, -4.6730e-02,  2.3390e-01,  2.1461e-01,
         -1.0815e-01, -6.7957e-02, -2.1417e-01,  1.4003e-01,  3.5586e-02,
         -8.2165e-02],
        [ 3.9560e-01,  2.2135e-01,  4.3729e-01, -2.0462e-01,  1.3467e-01,
         -2.5560e-01, -2.1321e-01, -2.3924e-01, -2.4684e-01, -3.3020e-02,
         -2.8835e-02,  6.1703e-02, -5.3335e-02,  2.0747e-01, -1.1549e-02,
          1.6632e-01],
        [-4.1405e-02,  3.3251e-01,  3.8012e-01, -3.6553e-01, -1.4192e-01,
         -3.3713e-01, -1.1282e-01, -2.4877e-01, -1.7764e-01, -2.2001e-01,
         -8.0061e-02,  1.8811e-02,  2.3960e-01, -1.0056e-01,  1.6423e-01,
          3.6909e-01],
        [ 5.1501e-02,  3.2060e-01,  3.2419e-01, -2.6266e-01,  3.7689e-02,
         -3.8000e-01, -1.7904e-01, -1.0793e-01,  5.3017e-02, -3.1280e-01,
         -1.2031e-01,  6.5134e-02, -1.0782e-01,  1.1182e-01,  3.2367e-03,
          9.4358e-02],
        [-3.0357e-01, -1.1420e-01, -1.1974e-01, -9.1277e-05, -6.7034e-02,
          1.8994e-01,  6.5167e-02,  2.3599e-01,  2.5661e-01, -1.6093e-03,
          2.6265e-01, -4.4836e-03, -2.2891e-01, -4.7171e-02, -1.8139e-01,
         -1.9617e-01],
        [-3.7329e-01,  4.9522e-02, -8.7058e-02, -2.2659e-02, -1.8150e-01,
          4.6296e-01,  2.5058e-01,  1.2196e-01,  3.3625e-01,  2.5655e-01,
          7.8784e-02,  1.0280e-02, -1.4187e-01,  1.5734e-01, -3.9314e-01,
         -3.3709e-01],
        [-1.4494e-01, -1.6444e-01, -4.6986e-02,  1.0533e-01,  1.0539e-01,
          1.5582e-01,  3.8904e-01,  1.6026e-01,  1.6326e-01,  3.4878e-01,
          1.6655e-01,  5.3620e-02, -3.7785e-01, -1.7824e-01, -2.5755e-01,
         -2.0383e-01],
        [ 3.6710e-01,  2.5805e-01,  2.0869e-01, -2.0297e-01,  9.5468e-02,
         -3.1817e-02, -1.1457e-01, -3.2451e-01, -3.2602e-01, -1.3063e-01,
         -1.4241e-01,  2.5172e-02, -5.8097e-02,  1.6792e-01,  1.6786e-01,
          4.6112e-02],
        [ 2.3330e-01,  3.7419e-01,  3.9708e-01, -3.0328e-02, -1.6518e-01,
         -6.1670e-02, -6.9304e-02, -7.7374e-02, -2.1013e-01, -1.7350e-01,
         -2.2762e-01,  1.1380e-01,  1.0387e-01,  4.8787e-02, -4.2489e-02,
          2.5290e-01],
        [-3.9784e-01, -3.2516e-01, -9.6043e-02, -2.5091e-02,  1.9430e-01,
          4.5105e-01,  1.2331e-01,  1.1874e-01, -4.2075e-02,  1.9135e-01,
          1.4153e-01, -3.0835e-01, -6.5045e-02, -9.9391e-02, -2.8408e-01,
         -1.7617e-01],
        [-9.6103e-02, -9.7890e-02,  1.8292e-01,  9.9347e-02, -1.3407e-01,
         -1.0195e-02, -1.4866e-01, -2.3419e-01, -1.2000e-01, -1.9527e-02,
         -4.9136e-02,  3.6320e-01,  5.7053e-02, -1.0125e-01,  3.9604e-01,
          4.6769e-02],
        [ 3.3851e-01,  2.9605e-01,  2.2827e-01, -3.7290e-01, -1.9631e-01,
         -8.0145e-02, -1.2821e-01, -1.6332e-03, -3.5628e-01, -1.9760e-01,
          1.2411e-01,  2.8427e-01,  3.3066e-01,  2.7345e-01,  1.3368e-01,
         -9.0357e-03],
        [-3.2202e-01, -4.1496e-02, -2.7563e-01,  1.6128e-01, -2.0237e-02,
          3.4638e-01,  3.1914e-01,  2.7836e-01,  1.3515e-01,  2.9601e-01,
         -2.4220e-02, -2.4616e-01, -1.5393e-01, -2.1055e-01,  3.4784e-02,
         -1.9416e-01],
        [ 2.5783e-01,  1.4932e-01,  1.8514e-01, -3.1851e-01, -9.1768e-03,
         -4.2323e-01, -3.1568e-01,  1.9109e-02, -3.9271e-01, -1.4398e-01,
         -4.9117e-02, -7.5325e-02,  1.8194e-01,  2.3439e-01,  3.7783e-01,
          2.1291e-01],
        [ 3.9363e-01,  1.5680e-01,  2.9874e-01, -1.1007e-01, -1.7045e-01,
         -2.7296e-01, -3.7872e-01,  2.6214e-02, -3.6185e-02, -2.8465e-01,
         -7.4988e-02,  2.4716e-01, -9.2662e-02,  8.2432e-02,  3.3187e-01,
          2.1100e-01],
        [-2.0184e-01,  3.9737e-02, -7.5643e-02, -5.0764e-02,  1.0952e-01,
          4.1527e-03,  3.3266e-01,  3.6534e-01,  1.7250e-01,  8.4674e-02,
         -3.3467e-02, -2.7023e-01, -1.6898e-01, -2.0303e-01,  4.7087e-02,
         -2.6706e-01],
        [-7.8772e-02, -3.5611e-01, -6.0033e-02,  3.8711e-01, -1.5782e-01,
          1.3946e-01,  2.5114e-01, -7.0700e-02, -1.0130e-03,  2.5426e-01,
          2.6055e-01, -2.4950e-01, -1.3017e-01, -3.1297e-01, -4.4323e-01,
          5.9564e-02],
        [ 3.8116e-01,  5.0137e-02,  7.4422e-02, -1.7337e-01,  1.6303e-01,
         -4.2953e-01, -3.1425e-01, -2.1443e-01, -2.3181e-01, -1.5829e-01,
          1.1030e-01,  1.9980e-01, -1.2309e-01,  2.9432e-01,  3.8442e-01,
          2.3165e-01],
        [ 2.8354e-01,  2.1991e-01,  3.7090e-01, -3.8973e-01, -8.4056e-02,
         -2.1202e-01, -2.1250e-01, -2.7584e-01, -3.4762e-01, -3.3518e-01,
         -1.1248e-01,  3.3745e-01,  2.4602e-01,  1.3486e-01,  1.6286e-02,
          4.9254e-02],
        [ 2.2458e-01, -1.0072e-01,  1.9338e-01, -1.4040e-01,  2.2192e-01,
         -2.8949e-01,  2.5993e-02, -1.7101e-01, -3.4744e-01,  5.0543e-02,
          1.4217e-01, -7.7592e-03,  1.4419e-02,  2.1415e-01,  6.8408e-02,
          3.3837e-01],
        [ 7.0104e-02,  4.9332e-02,  1.2401e-01,  5.8110e-02, -4.7740e-02,
         -2.6258e-01, -5.3800e-02, -3.3931e-01, -1.6375e-01, -3.7117e-01,
         -3.2240e-01,  1.1348e-01,  1.6216e-01,  3.1688e-01, -2.6349e-02,
          9.5289e-02],
        [ 2.3919e-01,  2.2366e-01,  3.2348e-01, -3.6168e-01, -3.4037e-03,
         -1.3360e-01, -3.8053e-01, -6.9687e-03, -3.6254e-01,  9.9476e-04,
         -3.7956e-03,  7.4686e-02,  1.8859e-01,  2.7858e-01,  3.7123e-01,
          3.0983e-01],
        [-3.3725e-01, -6.6424e-02, -7.2287e-03,  2.2053e-01,  1.8329e-01,
          5.6319e-02,  3.8303e-01,  1.6249e-01, -6.6207e-02,  1.0705e-01,
          2.4121e-01, -2.6336e-01, -1.8443e-01, -1.7220e-01, -3.4556e-01,
         -1.2036e-01],
        [ 3.2768e-01,  1.6593e-01,  1.6556e-01, -1.4713e-01, -1.7419e-01,
         -3.2816e-01, -1.6957e-01, -3.4344e-01, -1.1553e-02, -1.1981e-01,
         -1.1508e-02,  1.3908e-01,  2.9865e-01,  2.9404e-01,  3.0608e-01,
          2.8303e-01],
        [-2.9069e-01, -1.9046e-02, -3.4154e-01,  2.6532e-01, -2.4240e-01,
          1.8530e-01,  3.5735e-01,  2.9447e-01,  3.4064e-01,  2.3745e-01,
          1.9625e-01, -7.4312e-02,  6.5272e-02,  6.5757e-02, -1.0855e-01,
         -2.3995e-01],
        [-3.0582e-01, -1.9813e-01, -6.9993e-02,  3.5821e-02,  5.0472e-02,
          4.2293e-01,  4.0315e-01, -2.6058e-02,  2.1399e-01,  3.2916e-01,
         -1.8263e-01, -9.1457e-03, -2.7171e-01, -2.4754e-01, -3.0486e-01,
         -2.6011e-01],
        [ 8.9535e-02,  2.2838e-01,  2.9330e-01, -9.3342e-02,  1.8221e-01,
         -3.6754e-01, -4.4079e-01, -3.8197e-01, -2.9928e-01, -3.0251e-01,
          2.0139e-02, -2.6060e-03, -3.1431e-02,  2.4089e-01,  5.3838e-02,
          2.1843e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0854, -0.0663,  0.1909, -0.0276, -0.0664, -0.0206,  0.0797,  0.0681,
        -0.0173, -0.0536, -0.0374,  0.0523,  0.1318,  0.1087, -0.0211, -0.0601,
        -0.1414,  0.0210,  0.1269,  0.0283,  0.0153, -0.1848, -0.0053, -0.0433,
        -0.0489,  0.2144,  0.1326,  0.0222, -0.0466, -0.1535,  0.0076,  0.0378],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1883,  0.2782, -0.2052, -0.2342,  0.2420,  0.2946, -0.2571, -0.3611,
         -0.2832,  0.2903,  0.2415,  0.3493, -0.2093, -0.3578,  0.2785, -0.1053,
         -0.2734,  0.3172, -0.2094, -0.2248,  0.3106,  0.3332, -0.3545, -0.3619,
         -0.2385, -0.2730, -0.3011,  0.3140, -0.3423,  0.3678,  0.2777, -0.2184]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0202, -0.0146,  0.0286,  ...,  0.2057, -0.3304, -0.1137],
        [-0.0918, -0.2021,  0.0862,  ...,  0.1419, -0.3145,  0.0871],
        [-0.0444,  0.1696,  0.0874,  ...,  0.0158,  0.2163,  0.0345],
        ...,
        [ 0.0327, -0.1673,  0.0157,  ...,  0.0634, -0.2563, -0.1180],
        [ 0.0459, -0.0568,  0.0006,  ..., -0.2967,  0.1132,  0.1557],
        [-0.0759,  0.1727,  0.0094,  ..., -0.1686,  0.0361, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0505,  0.0532, -0.0915, -0.1207, -0.0586,  0.0460, -0.1278,  0.0617,
        -0.0469,  0.0913,  0.0314,  0.0091,  0.0100,  0.0633, -0.0783, -0.0206,
         0.0468, -0.1430, -0.0320, -0.0161, -0.1116,  0.0457,  0.0828, -0.0058,
        -0.0850,  0.0655,  0.0246, -0.0967,  0.0633,  0.1468,  0.1402, -0.0653],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0500, -0.1900, -0.0875,  ..., -0.1278, -0.0257,  0.2535],
        [-0.2226, -0.0407,  0.0999,  ..., -0.0586, -0.0110,  0.2647],
        [ 0.1543, -0.0260, -0.1687,  ...,  0.0724, -0.0151, -0.0595],
        ...,
        [ 0.1396,  0.1056,  0.0886,  ...,  0.2504, -0.2112,  0.0636],
        [-0.0407, -0.1661,  0.0678,  ...,  0.0146,  0.2394,  0.0760],
        [-0.0065, -0.1173,  0.2060,  ...,  0.0627,  0.1302,  0.1245]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0844,  0.1208, -0.0330, -0.0534, -0.0304, -0.0348, -0.0318, -0.0625,
         0.1096, -0.1722,  0.1231, -0.1329,  0.1651, -0.0188, -0.1434,  0.1031,
        -0.1259, -0.1522,  0.0135, -0.0291,  0.0099,  0.1100, -0.1864,  0.2016,
        -0.0719, -0.0299,  0.0890, -0.0406, -0.1113, -0.0584,  0.1077, -0.0006],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4501,  0.3737, -0.4497, -0.4557,  0.2992,  0.3063, -0.3557,  0.3628,
          0.3659, -0.3852, -0.3772,  0.3392,  0.3609, -0.3007,  0.3818,  0.3280,
         -0.4600, -0.4520,  0.3289,  0.3451, -0.4114, -0.3847, -0.4486,  0.2852,
          0.4234,  0.4519, -0.4243,  0.4912, -0.3599, -0.4425,  0.4246,  0.4429]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1782], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.6719e-02,  3.9328e-01,  3.3032e-01, -3.4100e-01, -2.6172e-01,
         -1.9339e-01, -7.6931e-02, -4.3787e-01, -2.3057e-01, -9.4409e-02,
         -3.9406e-02,  2.3021e-01,  8.7787e-02, -1.9878e-02,  2.4603e-03,
          3.8725e-01],
        [-2.6555e-01, -3.6275e-01, -1.2043e-01,  6.7590e-03,  1.5620e-02,
          2.7847e-01,  1.8535e-01,  1.9887e-01,  4.3562e-01,  1.5672e-01,
          2.9605e-01, -2.9700e-01, -3.9996e-03, -8.5502e-02,  2.8049e-01,
         -9.3775e-02],
        [ 9.8504e-02,  2.7801e-01,  4.0217e-01, -1.3214e-01, -1.2143e-01,
         -3.7582e-01, -7.0142e-02, -4.6164e-01, -1.2522e-02, -9.3545e-02,
         -1.5130e-01, -2.0544e-02,  4.1970e-01,  3.7708e-01,  1.1207e-01,
          2.8082e-01],
        [ 2.9423e-01,  1.0043e-01,  1.1127e-01, -9.4741e-02, -1.0061e-01,
         -2.3556e-01, -1.8242e-01, -1.4531e-01, -4.7400e-01, -4.3579e-01,
         -1.3487e-01,  4.1203e-01,  2.9648e-01, -6.2589e-02, -1.5238e-01,
          1.7804e-01],
        [-1.1075e-01,  5.6126e-02, -1.9100e-01, -8.7161e-03,  2.0470e-01,
          1.1830e-01,  6.4266e-02,  3.6279e-01,  1.8719e-01,  3.2340e-01,
          3.3416e-01, -1.9894e-01, -5.7180e-02, -2.8874e-01,  2.1818e-01,
         -1.7327e-01],
        [-2.2898e-02,  9.6998e-02, -3.8117e-01,  4.2007e-01,  3.7627e-01,
          7.1139e-03,  2.8383e-01,  9.3745e-03,  2.9533e-01,  2.4031e-01,
         -8.1863e-02, -1.2376e-01, -2.5456e-01,  8.2340e-02,  3.2850e-01,
         -9.4286e-02],
        [ 3.9084e-01,  1.4232e-01,  4.3100e-01, -2.0458e-01, -9.2047e-02,
         -2.4763e-01, -2.0644e-01, -2.8386e-01, -3.0317e-01, -5.5317e-02,
         -6.6257e-02,  1.0444e-01, -4.5539e-02,  2.7797e-01, -2.1113e-01,
          1.7413e-01],
        [-4.4914e-02,  2.9044e-01,  3.7542e-01, -3.6980e-01, -3.5758e-01,
         -3.2721e-01, -1.0827e-01, -2.9977e-01, -2.3660e-01, -2.4169e-01,
         -1.1290e-01,  6.3757e-02,  2.6331e-01, -3.9528e-02, -1.7166e-02,
          3.7305e-01],
        [ 4.8520e-02,  3.2683e-01,  3.2057e-01, -2.5864e-01, -9.3379e-02,
         -3.8010e-01, -1.8682e-01, -1.4670e-01,  3.7684e-03, -3.3777e-01,
         -2.6318e-01,  9.5753e-02, -5.6903e-02,  2.0797e-01, -2.6102e-01,
          1.0809e-01],
        [-3.0491e-01, -1.3445e-01, -1.2067e-01,  4.4536e-03,  1.1809e-01,
          1.9163e-01,  7.3985e-02,  2.8353e-01,  3.1407e-01,  2.8137e-02,
          3.4194e-01, -4.6515e-02, -2.7942e-01, -1.3389e-01,  1.1398e-01,
         -2.1722e-01],
        [-3.7836e-01,  2.0061e-02, -9.1426e-02, -1.2403e-02,  9.1533e-03,
          4.6776e-01,  2.6126e-01,  1.7396e-01,  4.0454e-01,  2.8959e-01,
          1.4632e-01, -4.2884e-02, -1.7082e-01,  5.7003e-02, -5.1936e-02,
         -3.5709e-01],
        [-1.4436e-01, -1.8295e-01, -4.8088e-02,  1.0867e-01,  2.1925e-01,
          1.5867e-01,  3.9664e-01,  2.0361e-01,  2.1262e-01,  3.8076e-01,
          2.6051e-01,  1.8158e-02, -3.8990e-01, -2.9440e-01,  8.5511e-03,
         -2.2599e-01],
        [ 3.6144e-01,  2.8622e-01,  2.0078e-01, -2.0101e-01, -1.8133e-01,
         -2.8367e-02, -1.2101e-01, -3.8999e-01, -3.8346e-01, -1.5149e-01,
         -1.7621e-01,  8.9402e-02, -2.9876e-02,  2.3510e-01, -1.9948e-01,
          6.4080e-02],
        [ 2.2476e-01,  3.5641e-01,  3.8798e-01, -2.8269e-02, -3.4505e-01,
         -5.3442e-02, -6.4218e-02, -1.1351e-01, -2.5516e-01, -1.9238e-01,
         -2.8229e-01,  1.4572e-01,  1.3341e-01,  1.1090e-01, -2.7018e-01,
          2.5612e-01],
        [-3.9410e-01, -3.2289e-01, -9.0832e-02, -2.4160e-02,  4.0476e-01,
          4.4431e-01,  1.2388e-01,  1.6322e-01,  1.4927e-02,  2.1306e-01,
          1.9800e-01, -3.5062e-01, -1.0170e-01, -1.6992e-01, -2.4218e-02,
         -1.8361e-01],
        [-4.1465e-02, -1.4487e-02,  2.3688e-01,  4.3745e-02, -3.7407e-01,
         -7.7397e-02, -2.2264e-01, -3.6245e-01, -2.6458e-01, -1.0861e-01,
         -1.4594e-01,  4.6297e-01,  1.8722e-01,  4.5481e-02,  1.2432e-01,
          1.1227e-01],
        [ 3.3478e-01,  2.9329e-01,  2.2394e-01, -3.7386e-01, -4.0344e-01,
         -7.6157e-02, -1.3122e-01, -5.1207e-02, -4.1459e-01, -2.2090e-01,
          8.6470e-02,  3.3358e-01,  3.7592e-01,  3.4188e-01, -9.1627e-02,
         -3.5343e-03],
        [-3.1488e-01, -3.1027e-02, -2.6824e-01,  1.6154e-01,  1.6526e-01,
          3.3271e-01,  3.1267e-01,  3.1424e-01,  1.8552e-01,  3.1524e-01,
          1.2804e-02, -2.8169e-01, -1.7721e-01, -2.8026e-01,  2.3296e-01,
         -1.9776e-01],
        [ 2.3800e-01,  1.4857e-01,  1.6317e-01, -2.9218e-01, -2.6727e-01,
         -4.0520e-01, -3.0760e-01, -2.0461e-02, -4.5869e-01, -1.3299e-01,
         -1.2336e-01, -4.0211e-02,  2.4348e-01,  3.2964e-01,  6.2838e-02,
          2.0667e-01],
        [ 3.9435e-01,  1.6174e-01,  2.9737e-01, -1.1122e-01, -3.6201e-01,
         -2.7190e-01, -3.8616e-01, -2.4092e-02, -1.0108e-01, -3.1098e-01,
         -1.6155e-01,  2.9537e-01, -4.3506e-02,  1.7155e-01,  6.7436e-02,
          2.2337e-01],
        [-1.9807e-01,  2.7617e-02, -7.0467e-02, -4.9480e-02,  3.0553e-01,
         -5.6198e-03,  3.3002e-01,  3.9889e-01,  2.1555e-01,  1.0242e-01,
          5.4369e-03, -3.0612e-01, -2.0602e-01, -2.5646e-01,  3.1817e-01,
         -2.7650e-01],
        [-8.2428e-02, -3.5854e-01, -6.2766e-02,  3.9335e-01,  8.9654e-03,
          1.4488e-01,  2.6984e-01, -1.9559e-02,  5.8897e-02,  2.8760e-01,
          3.8585e-01, -2.9079e-01, -1.9557e-01, -4.0777e-01, -1.6314e-01,
          4.2702e-02],
        [ 3.8322e-01,  5.5072e-02,  7.5641e-02, -1.8201e-01, -2.9568e-02,
         -4.2914e-01, -3.2202e-01, -2.6614e-01, -2.9485e-01, -1.8724e-01,
          5.5156e-02,  2.4692e-01, -7.7318e-02,  3.7463e-01,  1.6723e-01,
          2.4255e-01],
        [ 2.7628e-01,  2.2266e-01,  3.6349e-01, -3.9148e-01, -2.6087e-01,
         -1.9730e-01, -2.0773e-01, -3.2035e-01, -3.9983e-01, -3.5337e-01,
         -1.1019e-01,  3.7798e-01,  2.6536e-01,  1.9645e-01, -1.6911e-01,
          4.8394e-02],
        [ 2.2492e-01, -8.2348e-02,  1.9260e-01, -1.4039e-01,  2.5657e-02,
         -2.9128e-01,  2.0076e-02, -2.1579e-01, -4.0490e-01,  2.3436e-02,
          6.4037e-02,  3.8551e-02,  6.3164e-02,  2.9631e-01, -2.4214e-01,
          3.5994e-01],
        [ 6.0324e-02,  5.8082e-02,  1.1224e-01,  6.1394e-02, -2.5056e-01,
         -2.4433e-01, -4.1601e-02, -3.6506e-01, -1.9987e-01, -3.8423e-01,
         -3.7109e-01,  1.4214e-01,  1.8818e-01,  3.7189e-01, -3.0963e-01,
          1.0295e-01],
        [ 2.4011e-01,  2.2006e-01,  3.2358e-01, -3.6857e-01, -2.0637e-01,
         -1.3134e-01, -3.8578e-01, -6.0870e-02, -4.2651e-01, -2.6682e-02,
         -5.2899e-02,  1.2381e-01,  2.3224e-01,  3.5539e-01,  1.6096e-01,
          3.1884e-01],
        [-3.3800e-01, -8.0459e-02, -8.3605e-03,  2.2622e-01,  3.4949e-01,
          5.9301e-02,  3.9148e-01,  2.1629e-01, -7.0748e-03,  1.3808e-01,
          3.0778e-01, -3.1141e-01, -2.2844e-01, -2.6298e-01, -6.7043e-02,
         -1.3858e-01],
        [ 3.2397e-01,  1.8638e-01,  1.6247e-01, -1.5225e-01, -3.3954e-01,
         -3.2357e-01, -1.7355e-01, -3.8675e-01, -6.4759e-02, -1.4358e-01,
         -1.7444e-02,  1.8196e-01,  3.0556e-01,  3.7339e-01,  5.2085e-02,
          2.9044e-01],
        [-2.8939e-01, -1.3052e-04, -3.3933e-01,  2.7132e-01, -5.0338e-02,
          1.7762e-01,  3.5718e-01,  3.4055e-01,  3.9793e-01,  2.6200e-01,
          2.4806e-01, -1.1541e-01,  3.3998e-02, -6.6738e-03,  8.1939e-02,
         -2.4821e-01],
        [-3.0650e-01, -2.1033e-01, -7.0054e-02,  4.0409e-02,  2.3621e-01,
          4.2302e-01,  4.0995e-01,  2.0261e-02,  2.7476e-01,  3.5720e-01,
         -1.1563e-01, -5.4010e-02, -3.1754e-01, -3.3518e-01, -5.4044e-02,
         -2.7223e-01],
        [ 7.7630e-02,  2.0543e-01,  2.7955e-01, -7.1741e-02, -3.2853e-02,
         -3.5576e-01, -4.3265e-01, -4.2059e-01, -3.6034e-01, -3.0169e-01,
         -4.7559e-02,  3.2779e-02, -1.6323e-04,  3.2948e-01, -2.0151e-01,
          2.2022e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0712, -0.0019,  0.0954, -0.0449, -0.0407, -0.0660,  0.0646,  0.0714,
        -0.0259, -0.0396,  0.0086,  0.0671,  0.1296,  0.0704,  0.0303, -0.0739,
        -0.0611, -0.0007,  0.0760, -0.0015, -0.0257, -0.1288, -0.0421,  0.0014,
        -0.0354,  0.1492,  0.1072,  0.0343, -0.0734, -0.1319,  0.0413, -0.0487],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2177,  0.3101, -0.2175, -0.2500,  0.3033,  0.3420, -0.2748, -0.3766,
         -0.3087,  0.3273,  0.2515,  0.3619, -0.2458, -0.3901,  0.2928, -0.2328,
         -0.3115,  0.3246, -0.2176, -0.2425,  0.3798,  0.3041, -0.3631, -0.3731,
         -0.3116, -0.3229, -0.3072,  0.3352, -0.3503,  0.3763,  0.2810, -0.2283]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0129, -0.0059,  0.0412,  ...,  0.2356, -0.3599, -0.1137],
        [-0.0851, -0.1886,  0.0846,  ...,  0.1476, -0.3396,  0.0871],
        [-0.0418,  0.1722,  0.0764,  ..., -0.0048,  0.2559,  0.0345],
        ...,
        [ 0.0270, -0.1872,  0.0396,  ...,  0.0653, -0.2804, -0.1180],
        [ 0.0500, -0.0525, -0.0168,  ..., -0.3036,  0.1454,  0.1557],
        [-0.2023,  0.0542, -0.0018,  ...,  0.0419, -0.2227, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0572,  0.0584, -0.0892, -0.1177, -0.0565,  0.0522, -0.1285,  0.0620,
        -0.0492,  0.0821,  0.0319,  0.0082,  0.0248,  0.0726, -0.0790, -0.0167,
         0.0513, -0.1491, -0.0273, -0.0232, -0.0751,  0.0431,  0.0882, -0.0082,
        -0.0865,  0.0862,  0.0332, -0.0872,  0.0490,  0.1390,  0.1472, -0.1036],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0114, -0.1889, -0.0764,  ..., -0.1216, -0.0279,  0.0656],
        [-0.2736, -0.0425,  0.1196,  ..., -0.0540, -0.0074,  0.0535],
        [ 0.1884, -0.0331, -0.1773,  ...,  0.0576, -0.0063,  0.1697],
        ...,
        [ 0.1739,  0.0958,  0.0850,  ...,  0.2343, -0.2012,  0.2476],
        [-0.0824, -0.1584,  0.0764,  ...,  0.0304,  0.2321, -0.1663],
        [-0.0566, -0.1247,  0.2205,  ...,  0.0651,  0.1353, -0.0379]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0817,  0.1192, -0.0197, -0.0570, -0.0362, -0.0621, -0.0235, -0.0608,
         0.0919, -0.1313,  0.1347, -0.1269,  0.1479,  0.0553, -0.1354,  0.0837,
        -0.1153, -0.1422,  0.0011, -0.0151,  0.0096,  0.1114, -0.1802,  0.1695,
        -0.0653, -0.0322,  0.0921, -0.0435, -0.1064, -0.0513,  0.0905,  0.0017],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4357,  0.3561, -0.4331, -0.4374,  0.3004,  0.2916, -0.3482,  0.3423,
          0.3696, -0.3705, -0.3347,  0.3303,  0.3281,  0.3378,  0.3665,  0.3165,
         -0.4362, -0.4416,  0.3070,  0.3312, -0.3896, -0.3685, -0.4333,  0.2959,
          0.4177,  0.4451, -0.4190,  0.4670, -0.3467, -0.4338,  0.4110,  0.4362]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1594], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.4493e-02,  1.7518e-01,  3.2264e-01, -3.5852e-01, -2.3822e-01,
         -1.6924e-01, -6.4400e-02, -4.0594e-01, -1.8006e-01, -8.7556e-02,
          1.7613e-01,  2.0596e-01,  6.8391e-02, -1.6378e-02, -1.0086e-01,
          3.9562e-01],
        [-2.6351e-01, -1.5703e-01, -1.1384e-01,  3.0382e-02,  1.2061e-02,
          2.5838e-01,  1.6995e-01,  1.7886e-01,  4.2115e-01,  1.5636e-01,
          6.4983e-02, -2.7859e-01, -1.3804e-02, -8.2162e-02,  4.0436e-01,
         -9.8756e-02],
        [ 9.1427e-02,  9.1558e-02,  3.8871e-01, -1.4484e-01, -9.5734e-02,
         -3.5168e-01, -4.1506e-02, -4.2385e-01,  2.8079e-02, -8.1438e-02,
         -9.0331e-02, -4.4539e-02,  4.0472e-01,  3.4864e-01,  2.1622e-02,
          2.7719e-01],
        [ 2.7939e-01,  7.6033e-03,  9.1435e-02, -1.0771e-01, -8.1485e-02,
         -2.0103e-01, -1.5076e-01, -1.0504e-01, -4.3188e-01, -4.2113e-01,
          3.1315e-02,  3.7501e-01,  3.1141e-01, -8.3234e-02, -2.3228e-01,
          1.6847e-01],
        [-1.0297e-01,  2.4746e-01, -1.7839e-01,  1.0452e-02,  1.9216e-01,
          9.1590e-02,  4.0254e-02,  3.3529e-01,  1.6017e-01,  3.1763e-01,
          7.0587e-02, -1.7489e-01, -5.8830e-02, -2.7462e-01,  3.1551e-01,
         -1.7269e-01],
        [-6.5911e-03,  2.5799e-01, -3.6198e-01,  4.2923e-01,  3.4588e-01,
         -3.1629e-02,  2.5061e-01, -2.6713e-02,  2.6488e-01,  2.2472e-01,
         -1.0691e-01, -9.5083e-02, -2.3736e-01,  1.0302e-01,  3.7717e-01,
         -8.5677e-02],
        [ 3.7985e-01,  4.5709e-02,  4.1603e-01, -2.1933e-01, -8.6629e-02,
         -2.1973e-01, -1.7692e-01, -2.5158e-01, -2.6921e-01, -4.6589e-02,
          5.1329e-04,  7.9078e-02, -5.0673e-02,  2.1279e-01, -3.0183e-01,
          1.6853e-01],
        [-5.4990e-02,  1.8289e-01,  3.6338e-01, -3.8529e-01, -3.5723e-01,
         -3.0558e-01, -8.5723e-02, -2.7854e-01, -2.1996e-01, -2.3708e-01,
         -6.9329e-02,  5.1137e-02,  2.5969e-01, -7.5135e-02, -8.7328e-02,
          3.6688e-01],
        [ 4.8774e-02,  1.0944e-01,  3.1637e-01, -2.8650e-01, -8.8260e-02,
         -3.5766e-01, -1.7113e-01, -1.2411e-01,  2.2117e-02, -3.3998e-01,
          1.2603e-02,  7.5842e-02, -4.6628e-02,  2.0803e-01, -3.8239e-01,
          1.1706e-01],
        [-2.9904e-01,  7.5830e-02, -1.1081e-01,  2.4805e-02,  1.0598e-01,
          1.6596e-01,  5.1266e-02,  2.5652e-01,  2.8825e-01,  2.3295e-02,
          1.0618e-01, -2.4473e-02, -2.7852e-01, -1.2421e-01,  2.1553e-01,
         -2.1977e-01],
        [-3.6670e-01,  1.3711e-01, -7.4633e-02,  1.3042e-03, -9.1769e-03,
          4.3635e-01,  2.3682e-01,  1.3891e-01,  3.7174e-01,  2.7745e-01,
          8.2385e-03, -1.3127e-02, -2.1866e-01,  5.9064e-02,  2.3251e-02,
         -3.5128e-01],
        [-1.3054e-01, -4.7182e-02, -3.0217e-02,  1.2427e-01,  1.8711e-01,
          1.2613e-01,  3.5721e-01,  1.5834e-01,  1.7179e-01,  3.6757e-01,
          9.0835e-02,  5.3505e-02, -4.2430e-01, -2.6393e-01,  9.5978e-02,
         -2.1931e-01],
        [ 3.5161e-01,  9.3777e-02,  1.8375e-01, -2.1862e-01, -1.5565e-01,
          2.8711e-03, -9.7269e-02, -3.5416e-01, -3.5281e-01, -1.3958e-01,
         -9.3759e-02,  6.1625e-02, -5.2289e-03,  2.3894e-01, -3.1755e-01,
          6.0367e-02],
        [ 2.1809e-01,  1.7892e-01,  3.7796e-01, -4.7383e-02, -3.3741e-01,
         -3.1311e-02, -4.0555e-02, -8.8748e-02, -2.3982e-01, -1.8834e-01,
         -1.0807e-01,  1.2645e-01,  1.3545e-01,  8.8022e-02, -3.8521e-01,
          2.5546e-01],
        [-3.8757e-01, -1.4026e-01, -8.0085e-02, -5.1247e-03,  4.0355e-01,
          4.2326e-01,  1.0350e-01,  1.4298e-01, -5.3892e-03,  2.0906e-01,
          3.8479e-02, -3.3266e-01, -1.0926e-01, -1.5691e-01,  9.4346e-02,
         -1.8167e-01],
        [-2.9592e-02, -2.8362e-01,  2.3881e-01,  1.9630e-03, -3.9135e-01,
         -5.2482e-02, -2.0999e-01, -3.5266e-01, -2.4159e-01, -1.1579e-01,
         -5.1943e-02,  4.5678e-01,  1.9917e-01,  2.9436e-02,  7.6674e-05,
          1.3275e-01],
        [ 3.2437e-01,  1.4796e-01,  2.0978e-01, -3.8985e-01, -3.7125e-01,
         -4.7422e-02, -9.7211e-02, -1.0559e-02, -3.8941e-01, -2.1132e-01,
          1.9974e-01,  3.0497e-01,  3.6451e-01,  2.9962e-01, -1.5312e-01,
         -8.7178e-03],
        [-3.0114e-01,  7.8311e-02, -2.5142e-01,  1.7431e-01,  1.3543e-01,
          3.0309e-01,  2.7765e-01,  2.7672e-01,  1.5355e-01,  3.0591e-01,
         -4.3011e-02, -2.5839e-01, -1.6386e-01, -2.2337e-01,  2.5122e-01,
         -1.8746e-01],
        [ 2.4365e-01, -1.2898e-02,  1.6360e-01, -3.1743e-01, -2.1456e-01,
         -3.9031e-01, -2.8286e-01,  1.9338e-02, -4.1798e-01, -1.3457e-01,
          1.2822e-02, -5.9431e-02,  2.1209e-01,  2.8809e-01, -1.6885e-03,
          2.1598e-01],
        [ 3.8382e-01,  1.3225e-02,  2.8135e-01, -1.2849e-01, -3.4732e-01,
         -2.4306e-01, -3.5812e-01,  8.5247e-03, -7.1011e-02, -3.0111e-01,
          8.7687e-02,  2.6659e-01, -3.1748e-02,  1.4938e-01, -5.0672e-02,
          2.1705e-01],
        [-1.8269e-01,  1.8303e-01, -5.0994e-02, -4.1106e-02,  2.8274e-01,
         -3.6032e-02,  2.9917e-01,  3.6947e-01,  1.9067e-01,  8.9312e-02,
         -9.9439e-02, -2.8203e-01, -2.0279e-01, -2.2617e-01,  3.7308e-01,
         -2.6576e-01],
        [-8.5005e-02, -8.5424e-02, -6.1200e-02,  4.2522e-01,  1.3348e-02,
          1.2745e-01,  2.5529e-01, -3.8151e-02,  4.4963e-02,  2.9499e-01,
          2.0671e-01, -2.8226e-01, -2.0873e-01, -4.0158e-01, -6.7337e-02,
          3.4468e-02],
        [ 3.7475e-01, -9.1594e-02,  6.3014e-02, -1.9974e-01, -1.8984e-02,
         -4.0638e-01, -2.9609e-01, -2.4318e-01, -2.7384e-01, -1.8244e-01,
          2.0254e-01,  2.2991e-01, -6.4538e-02,  3.4489e-01,  7.7627e-02,
          2.3660e-01],
        [ 2.6444e-01,  1.4652e-01,  3.4948e-01, -4.0746e-01, -2.2619e-01,
         -1.7363e-01, -1.7690e-01, -2.8600e-01, -3.7275e-01, -3.4589e-01,
          1.7994e-02,  3.6120e-01,  2.8514e-01,  1.5439e-01, -2.0331e-01,
          3.7670e-02],
        [ 2.1477e-01, -2.8432e-01,  1.7838e-01, -1.5720e-01,  4.3771e-02,
         -2.5734e-01,  5.0000e-02, -1.7894e-01, -3.6995e-01,  3.3600e-02,
          1.9686e-01,  8.0001e-03,  5.7368e-02,  2.8336e-01, -3.4082e-01,
          3.5959e-01],
        [ 5.0710e-02, -1.0851e-01,  9.8020e-02,  4.8184e-02, -2.3539e-01,
         -2.2155e-01, -2.3859e-02, -3.4234e-01, -1.8106e-01, -3.7657e-01,
         -2.7737e-01,  1.2469e-01,  2.0198e-01,  3.5868e-01, -4.0668e-01,
          9.6428e-02],
        [ 2.2891e-01,  5.1706e-02,  3.0640e-01, -3.8270e-01, -1.8813e-01,
         -1.0715e-01, -3.5130e-01, -3.1980e-02, -3.9936e-01, -1.7922e-02,
          4.2202e-02,  1.0082e-01,  2.3820e-01,  2.9905e-01,  8.3115e-02,
          3.0767e-01],
        [-3.3047e-01,  8.5848e-02,  3.9519e-03,  2.4613e-01,  3.2895e-01,
          3.1993e-02,  3.5960e-01,  1.8144e-01, -4.3026e-02,  1.3129e-01,
          7.5818e-02, -2.8370e-01, -2.3445e-01, -2.3689e-01,  2.3433e-02,
         -1.3787e-01],
        [ 3.0999e-01,  1.0243e-01,  1.4389e-01, -1.6530e-01, -3.0781e-01,
         -2.9526e-01, -1.4258e-01, -3.4991e-01, -3.4741e-02, -1.3126e-01,
          1.0560e-01,  1.5464e-01,  3.6508e-01,  3.4908e-01, -6.9219e-03,
          2.7895e-01],
        [-2.7864e-01,  1.0698e-01, -3.2630e-01,  2.8669e-01, -5.6090e-02,
          1.5554e-01,  3.3152e-01,  3.1623e-01,  3.7577e-01,  2.5653e-01,
          1.5533e-01, -1.0112e-01,  3.5446e-02,  2.9351e-02,  1.5839e-01,
         -2.4110e-01],
        [-2.9269e-01, -4.8404e-02, -5.1202e-02,  5.3340e-02,  2.0887e-01,
          3.9052e-01,  3.7662e-01, -1.6207e-02,  2.4372e-01,  3.4541e-01,
         -2.2481e-01, -2.2488e-02, -3.2058e-01, -3.0323e-01,  2.0751e-02,
         -2.6201e-01],
        [ 7.1917e-02,  5.5643e-02,  2.6833e-01, -9.2164e-02, -1.0939e-02,
         -3.2987e-01, -4.0080e-01, -3.7162e-01, -3.1934e-01, -2.9446e-01,
          8.7734e-02,  1.0976e-03, -1.9297e-02,  2.6561e-01, -2.8550e-01,
          2.2041e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0571, -0.0709,  0.1155, -0.0662, -0.0551, -0.0266,  0.0899,  0.1310,
        -0.0423, -0.0721,  0.0232,  0.0669,  0.2029,  0.1142, -0.0588,  0.1096,
        -0.1379, -0.0010,  0.0257,  0.0016, -0.0165, -0.1188, -0.0595, -0.0177,
        -0.1532,  0.2552,  0.1033,  0.0238, -0.0850, -0.2252,  0.1620, -0.0291],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2165,  0.3034, -0.2227, -0.2358,  0.2996,  0.3487, -0.2759, -0.3652,
         -0.3049,  0.3417,  0.2398,  0.3658, -0.2424, -0.3954,  0.2958, -0.2463,
         -0.3070,  0.3118, -0.2173, -0.2378,  0.3868,  0.3062, -0.3550, -0.3617,
         -0.3418, -0.3244, -0.3037,  0.3340, -0.3295,  0.3675,  0.2713, -0.2176]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0602,  0.1329,  0.0630,  ...,  0.2142, -0.3073, -0.1137],
        [-0.1315, -0.0203,  0.1200,  ...,  0.1529, -0.3133,  0.0871],
        [ 0.0208, -0.0675,  0.0155,  ...,  0.0324,  0.2113,  0.0345],
        ...,
        [-0.0118,  0.0409,  0.0614,  ...,  0.0813, -0.2923, -0.1180],
        [ 0.1078, -0.2380, -0.0576,  ..., -0.3240,  0.1314,  0.1557],
        [-0.2287,  0.1821,  0.0414,  ...,  0.0950, -0.2501, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0379,  0.0415, -0.0672, -0.1342, -0.0715,  0.0637, -0.1106,  0.0444,
        -0.0368,  0.0801,  0.0144,  0.0126,  0.0310,  0.0783, -0.0538, -0.0189,
         0.0581, -0.1586,  0.0042,  0.0265, -0.0464,  0.0297,  0.1089,  0.0040,
        -0.0956,  0.1058,  0.0470, -0.0901,  0.0524,  0.1388,  0.1678, -0.1228],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0763, -0.1754, -0.1269,  ..., -0.1292, -0.0183,  0.0756],
        [-0.2031, -0.0303,  0.0702,  ..., -0.0606,  0.0039,  0.0507],
        [ 0.1308, -0.0356, -0.1417,  ...,  0.0739, -0.0171,  0.1825],
        ...,
        [ 0.1141,  0.0888,  0.1301,  ...,  0.2501, -0.2202,  0.2449],
        [-0.0039, -0.1403,  0.0216,  ...,  0.0232,  0.2326, -0.1644],
        [-0.0004, -0.1272,  0.1854,  ...,  0.0404,  0.1590, -0.0481]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0984,  0.1426, -0.0521, -0.0802, -0.0019, -0.0391, -0.0544, -0.0447,
         0.1206, -0.1650,  0.1202, -0.1181,  0.1693,  0.0868, -0.1245,  0.1160,
        -0.1389, -0.1698, -0.0632, -0.0043,  0.0006,  0.0879, -0.2043,  0.2075,
        -0.0479, -0.0046,  0.0775, -0.0283, -0.1338, -0.0708,  0.1115,  0.0362],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3779,  0.2945, -0.3724, -0.3695,  0.2413,  0.2264, -0.2898,  0.2570,
          0.2990, -0.3168, -0.2651,  0.2802,  0.2662,  0.2442,  0.3049,  0.2951,
         -0.3739, -0.3858, -0.2357,  0.2807, -0.3261, -0.3019, -0.3772,  0.2295,
          0.3473,  0.3881, -0.3696,  0.3716, -0.2914, -0.3753,  0.3536,  0.3800]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1476], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-0.0006,  0.4103,  0.3088, -0.3311, -0.2173, -0.1489, -0.0434, -0.3927,
         -0.1696, -0.0684,  0.1432,  0.1825,  0.0440, -0.0355, -0.0836,  0.3770],
        [-0.2499, -0.3866, -0.1006,  0.0104, -0.0084,  0.2456,  0.1596,  0.1649,
          0.4041,  0.1444,  0.0800, -0.2607,  0.0009, -0.0730,  0.3843, -0.0829],
        [ 0.0747,  0.2847,  0.3743, -0.1231, -0.0814, -0.3397, -0.0306, -0.4134,
          0.0372, -0.0672, -0.1020, -0.0626,  0.3888,  0.3422,  0.0378,  0.2598],
        [ 0.2679,  0.1157,  0.0822, -0.0918, -0.0644, -0.1922, -0.1455, -0.0949,
         -0.4216, -0.4121,  0.0205,  0.3614,  0.3021, -0.0838, -0.2257,  0.1556],
        [-0.0993,  0.0398, -0.1741, -0.0018,  0.1892,  0.0869,  0.0432,  0.3374,
          0.1580,  0.3149,  0.0986, -0.1662, -0.0613, -0.2817,  0.3189, -0.1661],
        [-0.0028,  0.0865, -0.3585,  0.4191,  0.3439, -0.0300,  0.2525, -0.0303,
          0.2596,  0.2227, -0.1120, -0.0882, -0.2443,  0.0978,  0.4096, -0.0803],
        [ 0.3658,  0.1638,  0.4040, -0.2007, -0.0692, -0.2117, -0.1700, -0.2380,
         -0.2493, -0.0361, -0.0065,  0.0641, -0.0621,  0.2089, -0.2931,  0.1541],
        [-0.0696,  0.3074,  0.3506, -0.3657, -0.3324, -0.2972, -0.0758, -0.2607,
         -0.2006, -0.2260, -0.0854,  0.0344,  0.2457, -0.0811, -0.0695,  0.3529],
        [ 0.0349,  0.3552,  0.3022, -0.2661, -0.0684, -0.3455, -0.1608, -0.1108,
          0.0368, -0.3272,  0.0045,  0.0581, -0.0592,  0.1977, -0.3681,  0.0997],
        [-0.2927, -0.1508, -0.1040,  0.0107,  0.0972,  0.1592,  0.0494,  0.2532,
          0.2824,  0.0181,  0.1360, -0.0134, -0.2753, -0.1245,  0.2102, -0.2106],
        [-0.3590,  0.0055, -0.0681, -0.0098, -0.0175,  0.4302,  0.2327,  0.1346,
          0.3659,  0.2716,  0.0010, -0.0030, -0.2084,  0.0561,  0.0291, -0.3415],
        [-0.1209, -0.1886, -0.0208,  0.1081,  0.1736,  0.1163,  0.3546,  0.1547,
          0.1615,  0.3597,  0.1131,  0.0658, -0.4149, -0.2662,  0.0819, -0.2076],
        [ 0.3386,  0.3046,  0.1715, -0.1984, -0.1423,  0.0184, -0.0883, -0.3445,
         -0.3415, -0.1270, -0.1090,  0.0419, -0.0224,  0.2318, -0.3033,  0.0466],
        [ 0.2042,  0.3755,  0.3642, -0.0284, -0.3183, -0.0200, -0.0325, -0.0752,
         -0.2212, -0.1766, -0.1192,  0.1104,  0.1224,  0.0814, -0.3670,  0.2401],
        [-0.3743, -0.3434, -0.0675, -0.0236,  0.3844,  0.4127,  0.0950,  0.1292,
         -0.0201,  0.1980,  0.0469, -0.3165, -0.0962, -0.1499,  0.0753, -0.1670],
        [-0.3091, -0.3181, -0.0208,  0.3080,  0.0452,  0.2082,  0.0996, -0.0043,
          0.1047,  0.1825,  0.0623,  0.1423, -0.1338, -0.3332,  0.4730, -0.1319],
        [ 0.3101,  0.2826,  0.1986, -0.3713, -0.3508, -0.0372, -0.0911,  0.0056,
         -0.3726, -0.2007,  0.1770,  0.2898,  0.3509,  0.3013, -0.1287, -0.0228],
        [-0.2887, -0.0011, -0.2414,  0.1565,  0.1212,  0.2990,  0.2739,  0.2649,
          0.1389,  0.2977, -0.0372, -0.2448, -0.1599, -0.2209,  0.2424, -0.1751],
        [ 0.2291,  0.1623,  0.1523, -0.2978, -0.2013, -0.3807, -0.2764,  0.0267,
         -0.4106, -0.1228,  0.0169, -0.0753,  0.2014,  0.2863,  0.0122,  0.1999],
        [ 0.3713,  0.1844,  0.2706, -0.1120, -0.3326, -0.2338, -0.3544,  0.0189,
         -0.0586, -0.2913,  0.0850,  0.2525, -0.0416,  0.1507, -0.0372,  0.2028],
        [-0.1752,  0.0236, -0.0439, -0.0543,  0.2771, -0.0399,  0.2998,  0.3644,
          0.1822,  0.0845, -0.0787, -0.2721, -0.2030, -0.2321,  0.3879, -0.2571],
        [-0.0754, -0.3736, -0.0509,  0.4058, -0.0048,  0.1180,  0.2503, -0.0447,
          0.0349,  0.2844,  0.2160, -0.2658, -0.2016, -0.3961, -0.0748,  0.0476],
        [ 0.3658,  0.0573,  0.0551, -0.1854, -0.0078, -0.4012, -0.2956, -0.2355,
         -0.2636, -0.1765,  0.1853,  0.2196, -0.0687,  0.3453,  0.0909,  0.2266],
        [ 0.2477,  0.2215,  0.3368, -0.3861, -0.2005, -0.1633, -0.1684, -0.2641,
         -0.3534, -0.3338,  0.0026,  0.3430,  0.2703,  0.1514, -0.1742,  0.0231],
        [ 0.2129, -0.0596,  0.1763, -0.1480,  0.0467, -0.2556,  0.0474, -0.1794,
         -0.3683,  0.0345,  0.1973,  0.0027,  0.0598,  0.2907, -0.3452,  0.3553],
        [ 0.0408,  0.0798,  0.0882,  0.0630, -0.2259, -0.2146, -0.0165, -0.3351,
         -0.1712, -0.3691, -0.2933,  0.1117,  0.1943,  0.3584, -0.4095,  0.0857],
        [ 0.2151,  0.2051,  0.2951, -0.3650, -0.1713, -0.0979, -0.3490, -0.0182,
         -0.3843, -0.0081,  0.0251,  0.0874,  0.2264,  0.3066,  0.1021,  0.2945],
        [-0.3238, -0.0908,  0.0105,  0.2313,  0.3202,  0.0246,  0.3598,  0.1798,
         -0.0501,  0.1259,  0.0976, -0.2730, -0.2306, -0.2432,  0.0185, -0.1286],
        [ 0.2967,  0.1957,  0.1328, -0.1486, -0.2904, -0.2843, -0.1381, -0.3362,
         -0.0204, -0.1216,  0.0844,  0.1405,  0.3512,  0.3492,  0.0128,  0.2661],
        [-0.2683, -0.0165, -0.3170,  0.2706, -0.0695,  0.1507,  0.3287,  0.3073,
          0.3633,  0.2494,  0.1621, -0.0890,  0.0401,  0.0279,  0.1555, -0.2303],
        [-0.2804, -0.2036, -0.0413,  0.0369,  0.1929,  0.3830,  0.3729, -0.0292,
          0.2312,  0.3364, -0.2140, -0.0095, -0.3126, -0.3018,  0.0025, -0.2487],
        [ 0.0555,  0.1856,  0.2554, -0.0703,  0.0097, -0.3187, -0.3937, -0.3629,
         -0.3078, -0.2821,  0.0775, -0.0154, -0.0343,  0.2594, -0.2586,  0.2033]],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0811, -0.0412,  0.1098, -0.0658, -0.0574, -0.0354,  0.0900,  0.1283,
        -0.0480, -0.0562,  0.0010,  0.0841,  0.1659,  0.0948, -0.0399, -0.0514,
        -0.1579,  0.0013,  0.0200, -0.0027, -0.0161, -0.1095, -0.0614, -0.0304,
        -0.1205,  0.2590,  0.0896,  0.0342, -0.1010, -0.2272,  0.1763, -0.0427],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2178,  0.3018, -0.2209, -0.2367,  0.3093,  0.3533, -0.2758, -0.3614,
         -0.3180,  0.3393,  0.2423,  0.3610, -0.2460, -0.3971,  0.2936,  0.2300,
         -0.3032,  0.3112, -0.2160, -0.2363,  0.3829,  0.3054, -0.3543, -0.3588,
         -0.3571, -0.3259, -0.3015,  0.3295, -0.3287,  0.3665,  0.2715, -0.2179]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0263,  0.1077,  0.0827,  ...,  0.1545, -0.2364, -0.1137],
        [-0.1245, -0.0323,  0.1211,  ...,  0.1294, -0.2980,  0.0871],
        [ 0.0076, -0.0457,  0.0279,  ...,  0.0306,  0.2097,  0.0345],
        ...,
        [-0.0009,  0.0232,  0.0596,  ...,  0.0615, -0.2849, -0.1180],
        [ 0.1030, -0.2254, -0.0585,  ..., -0.2983,  0.1201,  0.1557],
        [-0.2099,  0.1726,  0.0435,  ...,  0.0644, -0.2446, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0455,  0.0424, -0.0715, -0.1356, -0.0724,  0.0567, -0.1115,  0.0492,
        -0.0368,  0.0778,  0.0190,  0.0132,  0.0283,  0.0752, -0.0529, -0.0177,
         0.0564, -0.1604, -0.0587,  0.0352, -0.0508,  0.0285,  0.1067,  0.0046,
        -0.0926,  0.0541,  0.0441, -0.1091,  0.0526,  0.1411,  0.1679, -0.1255],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0728, -0.1747, -0.1180,  ..., -0.1174, -0.0321,  0.0788],
        [-0.2064, -0.0293,  0.0895,  ..., -0.0474, -0.0137,  0.0530],
        [ 0.1306, -0.0385, -0.1489,  ...,  0.0612, -0.0034,  0.1757],
        ...,
        [ 0.1045,  0.0753,  0.1316,  ...,  0.2298, -0.1959,  0.2287],
        [-0.0044, -0.1394,  0.0331,  ...,  0.0393,  0.2156, -0.1609],
        [ 0.0055, -0.1168,  0.1837,  ...,  0.0608,  0.1368, -0.0330]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1034,  0.1544, -0.0525, -0.0804, -0.0092, -0.0373, -0.0538, -0.0453,
         0.1296, -0.1723,  0.1096, -0.1293,  0.1862,  0.0995, -0.1309,  0.1231,
        -0.1375, -0.1690,  0.0388, -0.0110, -0.0029,  0.0897, -0.1953,  0.2251,
        -0.0457, -0.0086,  0.0820, -0.0258, -0.1316, -0.0679,  0.1183,  0.0314],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3971,  0.3169, -0.3903, -0.3742,  0.2548,  0.2533, -0.3048,  0.2654,
          0.2995, -0.3372, -0.2852,  0.2859,  0.2805,  0.2688,  0.3147,  0.3191,
         -0.3843, -0.3969,  0.2471,  0.2910, -0.3386, -0.3175, -0.3908,  0.2405,
          0.3613,  0.3978, -0.3785,  0.3815, -0.3052, -0.3850,  0.3681,  0.3873]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1578], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-0.0006,  0.4103,  0.3088, -0.3311, -0.2173, -0.1489, -0.0434, -0.3927,
         -0.1696, -0.0684,  0.1432,  0.1825,  0.0440, -0.0355, -0.0836,  0.3770],
        [-0.2499, -0.3866, -0.1006,  0.0104, -0.0084,  0.2456,  0.1596,  0.1649,
          0.4041,  0.1444,  0.0800, -0.2607,  0.0009, -0.0730,  0.3843, -0.0829],
        [ 0.0747,  0.2847,  0.3743, -0.1231, -0.0814, -0.3397, -0.0306, -0.4134,
          0.0372, -0.0672, -0.1020, -0.0626,  0.3888,  0.3422,  0.0378,  0.2598],
        [ 0.2679,  0.1157,  0.0822, -0.0918, -0.0644, -0.1922, -0.1455, -0.0949,
         -0.4216, -0.4121,  0.0205,  0.3614,  0.3021, -0.0838, -0.2257,  0.1556],
        [-0.0993,  0.0398, -0.1741, -0.0018,  0.1892,  0.0869,  0.0432,  0.3374,
          0.1580,  0.3149,  0.0986, -0.1662, -0.0613, -0.2817,  0.3189, -0.1661],
        [-0.0028,  0.0865, -0.3585,  0.4191,  0.3439, -0.0300,  0.2525, -0.0303,
          0.2596,  0.2227, -0.1120, -0.0882, -0.2443,  0.0978,  0.4096, -0.0803],
        [ 0.3658,  0.1638,  0.4040, -0.2007, -0.0692, -0.2117, -0.1700, -0.2380,
         -0.2493, -0.0361, -0.0065,  0.0641, -0.0621,  0.2089, -0.2931,  0.1541],
        [-0.0696,  0.3074,  0.3506, -0.3657, -0.3324, -0.2972, -0.0758, -0.2607,
         -0.2006, -0.2260, -0.0854,  0.0344,  0.2457, -0.0811, -0.0695,  0.3529],
        [ 0.0349,  0.3552,  0.3022, -0.2661, -0.0684, -0.3455, -0.1608, -0.1108,
          0.0368, -0.3272,  0.0045,  0.0581, -0.0592,  0.1977, -0.3681,  0.0997],
        [-0.2927, -0.1508, -0.1040,  0.0107,  0.0972,  0.1592,  0.0494,  0.2532,
          0.2824,  0.0181,  0.1360, -0.0134, -0.2753, -0.1245,  0.2102, -0.2106],
        [-0.3590,  0.0055, -0.0681, -0.0098, -0.0175,  0.4302,  0.2327,  0.1346,
          0.3659,  0.2716,  0.0010, -0.0030, -0.2084,  0.0561,  0.0291, -0.3415],
        [-0.1209, -0.1886, -0.0208,  0.1081,  0.1736,  0.1163,  0.3546,  0.1547,
          0.1615,  0.3597,  0.1131,  0.0658, -0.4149, -0.2662,  0.0819, -0.2076],
        [ 0.3386,  0.3046,  0.1715, -0.1984, -0.1423,  0.0184, -0.0883, -0.3445,
         -0.3415, -0.1270, -0.1090,  0.0419, -0.0224,  0.2318, -0.3033,  0.0466],
        [ 0.2042,  0.3755,  0.3642, -0.0284, -0.3183, -0.0200, -0.0325, -0.0752,
         -0.2212, -0.1766, -0.1192,  0.1104,  0.1224,  0.0814, -0.3670,  0.2401],
        [-0.3743, -0.3434, -0.0675, -0.0236,  0.3844,  0.4127,  0.0950,  0.1292,
         -0.0201,  0.1980,  0.0469, -0.3165, -0.0962, -0.1499,  0.0753, -0.1670],
        [-0.3091, -0.3181, -0.0208,  0.3080,  0.0452,  0.2082,  0.0996, -0.0043,
          0.1047,  0.1825,  0.0623,  0.1423, -0.1338, -0.3332,  0.4730, -0.1319],
        [ 0.3101,  0.2826,  0.1986, -0.3713, -0.3508, -0.0372, -0.0911,  0.0056,
         -0.3726, -0.2007,  0.1770,  0.2898,  0.3509,  0.3013, -0.1287, -0.0228],
        [-0.2887, -0.0011, -0.2414,  0.1565,  0.1212,  0.2990,  0.2739,  0.2649,
          0.1389,  0.2977, -0.0372, -0.2448, -0.1599, -0.2209,  0.2424, -0.1751],
        [ 0.2291,  0.1623,  0.1523, -0.2978, -0.2013, -0.3807, -0.2764,  0.0267,
         -0.4106, -0.1228,  0.0169, -0.0753,  0.2014,  0.2863,  0.0122,  0.1999],
        [ 0.3713,  0.1844,  0.2706, -0.1120, -0.3326, -0.2338, -0.3544,  0.0189,
         -0.0586, -0.2913,  0.0850,  0.2525, -0.0416,  0.1507, -0.0372,  0.2028],
        [-0.1752,  0.0236, -0.0439, -0.0543,  0.2771, -0.0399,  0.2998,  0.3644,
          0.1822,  0.0845, -0.0787, -0.2721, -0.2030, -0.2321,  0.3879, -0.2571],
        [-0.0754, -0.3736, -0.0509,  0.4058, -0.0048,  0.1180,  0.2503, -0.0447,
          0.0349,  0.2844,  0.2160, -0.2658, -0.2016, -0.3961, -0.0748,  0.0476],
        [ 0.3658,  0.0573,  0.0551, -0.1854, -0.0078, -0.4012, -0.2956, -0.2355,
         -0.2636, -0.1765,  0.1853,  0.2196, -0.0687,  0.3453,  0.0909,  0.2266],
        [ 0.2477,  0.2215,  0.3368, -0.3861, -0.2005, -0.1633, -0.1684, -0.2641,
         -0.3534, -0.3338,  0.0026,  0.3430,  0.2703,  0.1514, -0.1742,  0.0231],
        [ 0.2129, -0.0596,  0.1763, -0.1480,  0.0467, -0.2556,  0.0474, -0.1794,
         -0.3683,  0.0345,  0.1973,  0.0027,  0.0598,  0.2907, -0.3452,  0.3553],
        [ 0.0408,  0.0798,  0.0882,  0.0630, -0.2259, -0.2146, -0.0165, -0.3351,
         -0.1712, -0.3691, -0.2933,  0.1117,  0.1943,  0.3584, -0.4095,  0.0857],
        [ 0.2151,  0.2051,  0.2951, -0.3650, -0.1713, -0.0979, -0.3490, -0.0182,
         -0.3843, -0.0081,  0.0251,  0.0874,  0.2264,  0.3066,  0.1021,  0.2945],
        [-0.3238, -0.0908,  0.0105,  0.2313,  0.3202,  0.0246,  0.3598,  0.1798,
         -0.0501,  0.1259,  0.0976, -0.2730, -0.2306, -0.2432,  0.0185, -0.1286],
        [ 0.2967,  0.1957,  0.1328, -0.1486, -0.2904, -0.2843, -0.1381, -0.3362,
         -0.0204, -0.1216,  0.0844,  0.1405,  0.3512,  0.3492,  0.0128,  0.2661],
        [-0.2683, -0.0165, -0.3170,  0.2706, -0.0695,  0.1507,  0.3287,  0.3073,
          0.3633,  0.2494,  0.1621, -0.0890,  0.0401,  0.0279,  0.1555, -0.2303],
        [-0.2804, -0.2036, -0.0413,  0.0369,  0.1929,  0.3830,  0.3729, -0.0292,
          0.2312,  0.3364, -0.2140, -0.0095, -0.3126, -0.3018,  0.0025, -0.2487],
        [ 0.0555,  0.1856,  0.2554, -0.0703,  0.0097, -0.3187, -0.3937, -0.3629,
         -0.3077, -0.2821,  0.0775, -0.0154, -0.0343,  0.2594, -0.2586,  0.2033]],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0811, -0.0412,  0.1098, -0.0658, -0.0574, -0.0354,  0.0900,  0.1283,
        -0.0480, -0.0562,  0.0010,  0.0841,  0.1659,  0.0948, -0.0399, -0.0514,
        -0.1579,  0.0013,  0.0200, -0.0027, -0.0161, -0.1095, -0.0614, -0.0304,
        -0.1205,  0.2590,  0.0896,  0.0342, -0.1010, -0.2272,  0.1763, -0.0427],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2178,  0.3018, -0.2209, -0.2367,  0.3093,  0.3533, -0.2758, -0.3614,
         -0.3180,  0.3393,  0.2423,  0.3610, -0.2460, -0.3971,  0.2936,  0.2300,
         -0.3032,  0.3112, -0.2160, -0.2363,  0.3829,  0.3054, -0.3543, -0.3588,
         -0.3571, -0.3259, -0.3015,  0.3295, -0.3287,  0.3665,  0.2715, -0.2179]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0263,  0.1077,  0.0827,  ...,  0.1545, -0.2364, -0.1137],
        [-0.1245, -0.0323,  0.1211,  ...,  0.1294, -0.2980,  0.0871],
        [ 0.0076, -0.0457,  0.0279,  ...,  0.0306,  0.2097,  0.0345],
        ...,
        [-0.0009,  0.0232,  0.0596,  ...,  0.0615, -0.2849, -0.1180],
        [ 0.1030, -0.2254, -0.0585,  ..., -0.2983,  0.1201,  0.1557],
        [-0.2099,  0.1726,  0.0435,  ...,  0.0644, -0.2446, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0455,  0.0424, -0.0715, -0.1356, -0.0724,  0.0567, -0.1115,  0.0492,
        -0.0368,  0.0778,  0.0190,  0.0132,  0.0283,  0.0752, -0.0529, -0.0177,
         0.0564, -0.1604, -0.0587,  0.0352, -0.0508,  0.0285,  0.1067,  0.0046,
        -0.0926,  0.0541,  0.0441, -0.1091,  0.0526,  0.1411,  0.1679, -0.1255],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0728, -0.1747, -0.1180,  ..., -0.1174, -0.0321,  0.0788],
        [-0.2064, -0.0293,  0.0895,  ..., -0.0474, -0.0137,  0.0530],
        [ 0.1306, -0.0385, -0.1489,  ...,  0.0612, -0.0034,  0.1757],
        ...,
        [ 0.1045,  0.0753,  0.1316,  ...,  0.2298, -0.1959,  0.2287],
        [-0.0044, -0.1394,  0.0331,  ...,  0.0393,  0.2156, -0.1609],
        [ 0.0055, -0.1168,  0.1837,  ...,  0.0608,  0.1368, -0.0330]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1034,  0.1544, -0.0525, -0.0804, -0.0092, -0.0373, -0.0538, -0.0453,
         0.1296, -0.1723,  0.1096, -0.1293,  0.1862,  0.0995, -0.1309,  0.1231,
        -0.1375, -0.1690,  0.0388, -0.0110, -0.0029,  0.0897, -0.1953,  0.2251,
        -0.0457, -0.0086,  0.0820, -0.0258, -0.1316, -0.0679,  0.1183,  0.0314],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3971,  0.3169, -0.3903, -0.3742,  0.2548,  0.2533, -0.3048,  0.2654,
          0.2995, -0.3372, -0.2852,  0.2859,  0.2805,  0.2688,  0.3147,  0.3191,
         -0.3843, -0.3969,  0.2471,  0.2910, -0.3386, -0.3175, -0.3908,  0.2405,
          0.3613,  0.3978, -0.3785,  0.3815, -0.3052, -0.3850,  0.3681,  0.3873]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1578], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 8.0560e-02,  4.7803e-01,  3.9225e-01, -4.2376e-01,  2.1803e-01,
         -2.3020e-01, -1.4254e-01,  3.5443e-02,  2.5403e-01, -1.6027e-01,
          4.7331e-02, -2.6578e-01, -3.4152e-01,  3.3425e-02,  3.8648e-01,
          4.5614e-01],
        [-3.3999e-01, -4.9285e-01, -1.9147e-01,  9.9213e-02, -3.9900e-01,
          3.2874e-01,  2.1188e-01, -3.0184e-01, -2.0911e-02,  1.9588e-01,
          2.4741e-01,  2.3047e-01,  3.4164e-01, -1.5548e-01, -4.2365e-02,
         -1.7126e-01],
        [ 1.7780e-01,  3.9880e-01,  4.6410e-01, -2.3592e-01,  3.7535e-01,
         -4.3277e-01, -3.7302e-02,  4.0248e-02,  5.0266e-01, -1.9524e-01,
          2.1611e-02, -5.3740e-01, -7.2867e-03,  4.1280e-01,  5.1554e-01,
          3.5875e-01],
        [-1.9776e-01, -3.7094e-01, -3.6568e-01,  3.9429e-01, -1.8877e-01,
          2.6347e-01,  2.6026e-01, -2.0318e-01, -5.4328e-01,  9.4667e-02,
          8.2429e-02,  4.7676e-01,  3.1245e-01, -4.8348e-01, -3.8623e-01,
         -3.0137e-01],
        [-1.9385e-01, -7.4615e-02, -2.6182e-01,  8.1299e-02, -2.3459e-01,
          1.7306e-01,  1.1556e-01, -1.5144e-01, -2.7830e-01,  3.9919e-01,
          2.5299e-01,  3.3267e-01,  3.9579e-01, -3.5588e-01, -1.1245e-01,
         -2.5730e-01],
        [-1.1542e-01, -4.3538e-02, -4.6099e-01,  5.1878e-01, -7.6698e-02,
          7.4698e-02,  3.3499e-01, -4.9170e-01, -1.9525e-01,  3.2203e-01,
          2.9980e-02,  3.8983e-01,  5.7435e-02,  7.3733e-03, -3.2795e-02,
         -1.8959e-01],
        [ 3.8343e-01,  2.8177e-01,  4.9991e-01, -2.9823e-01,  2.6986e-01,
         -2.6062e-01, -3.0341e-01,  2.1271e-01,  1.6296e-01,  2.3263e-02,
         -8.6242e-02, -4.0134e-01, -2.2491e-01,  3.1861e-01,  5.3335e-02,
          2.4267e-01],
        [ 2.3608e-02,  4.4471e-01,  4.5978e-01, -4.7302e-01,  5.3673e-03,
         -3.9200e-01, -1.6876e-01,  1.5444e-01,  1.5820e-01, -2.5489e-01,
         -1.0212e-01, -4.0346e-01,  8.7585e-03,  2.5808e-02,  2.0656e-01,
          4.6502e-01],
        [ 9.2513e-02,  4.4381e-01,  3.5732e-01, -3.4104e-01,  2.9382e-01,
         -3.9255e-01, -1.6241e-01,  3.3184e-01,  4.1108e-01, -3.8052e-01,
         -9.7058e-02, -4.1663e-01, -4.6518e-01,  2.2784e-01,  3.3434e-02,
          1.5834e-01],
        [-3.8466e-01, -2.6318e-01, -1.8978e-01,  9.2152e-02, -3.2692e-01,
          2.4210e-01,  3.3684e-02, -2.2826e-01, -1.4421e-01,  1.0564e-01,
          2.0024e-01,  4.7887e-01,  1.9364e-01, -1.9581e-01, -2.1125e-01,
         -3.0022e-01],
        [-4.4926e-01, -9.6415e-02, -1.4696e-01,  9.0763e-02, -4.6277e-01,
          5.1141e-01,  2.3956e-01, -3.5336e-01, -1.2678e-01,  3.7832e-01,
          5.0183e-02,  5.1336e-01,  2.6146e-01,  1.3747e-02, -4.8831e-01,
         -4.2801e-01],
        [-2.2456e-01, -3.0710e-01, -1.1868e-01,  2.0494e-01, -2.0618e-01,
          2.0761e-01,  1.8035e-01, -3.0166e-01, -2.6527e-02,  4.5903e-01,
          1.3526e-01,  5.4184e-01,  3.8775e-02, -3.6088e-01, -1.2994e-01,
         -3.1128e-01],
        [ 4.2032e-01,  3.9343e-01,  2.6166e-01, -2.8473e-01,  3.0547e-01,
         -5.8726e-02, -1.1573e-01,  1.6859e-01,  1.4781e-01, -1.2226e-01,
         -2.5395e-01, -4.7250e-01, -2.8629e-01,  2.8724e-01,  2.0768e-01,
          1.3207e-01],
        [ 3.0396e-01,  5.0213e-01,  4.5991e-01, -1.2381e-01,  4.9884e-02,
         -1.0789e-01, -1.2160e-01,  3.5954e-01,  1.6588e-01, -2.3462e-01,
         -2.1398e-01, -3.4588e-01, -2.0881e-01,  1.7457e-01,  4.6063e-03,
          3.4172e-01],
        [-4.7183e-01, -4.6795e-01, -1.5830e-01,  7.5101e-02, -1.0593e-02,
          4.9950e-01,  7.6375e-02, -3.2783e-01, -4.0956e-01,  2.9350e-01,
          8.6953e-02,  1.6522e-01,  3.1512e-01, -2.2726e-01, -3.1190e-01,
         -2.6297e-01],
        [-4.2822e-01, -3.8563e-01, -8.7252e-02,  4.0203e-01, -2.7909e-01,
          3.2067e-01,  1.6574e-01, -2.5331e-01, -1.2883e-01,  3.1161e-01,
          6.4658e-02,  3.8624e-01,  6.4378e-02, -3.4674e-01,  7.2825e-02,
         -2.2130e-01],
        [ 4.2105e-01,  4.3008e-01,  3.0680e-01, -4.7994e-01,  3.8079e-03,
         -1.3987e-01, -1.7184e-01,  4.2815e-01,  3.2828e-02, -2.8365e-01,
          1.2279e-01, -1.6709e-01,  8.7337e-03,  4.2106e-01,  2.1122e-01,
          9.1500e-02],
        [-3.9195e-01, -1.5947e-01, -3.5190e-01,  2.6860e-01, -1.9029e-01,
          3.9752e-01,  3.8304e-01, -1.3321e-01, -2.2655e-01,  3.3986e-01,
          4.9834e-03,  1.9012e-01,  9.1337e-02, -3.5075e-01, -3.8533e-02,
         -2.8814e-01],
        [ 3.2374e-01,  2.7013e-01,  2.3295e-01, -4.1018e-01,  2.2075e-01,
         -4.6343e-01, -3.4111e-01,  4.6115e-01,  6.5812e-03, -2.3815e-01,
          6.0989e-03, -5.4057e-01, -1.6369e-01,  3.4671e-01,  4.3708e-01,
          2.9053e-01],
        [ 4.6245e-01,  3.0595e-01,  3.4712e-01, -2.2081e-01,  6.2182e-02,
         -3.1156e-01, -3.4068e-01,  4.8006e-01,  4.0769e-01, -4.0864e-01,
         -2.8234e-02, -2.4489e-01, -4.7991e-01,  2.0046e-01,  4.2278e-01,
          2.8915e-01],
        [-2.9552e-01, -1.1206e-01, -1.5276e-01,  4.5555e-02, -9.9716e-02,
          7.6223e-02,  3.2839e-01, -6.9314e-02, -2.3733e-01,  1.9037e-01,
          1.6733e-02,  1.9423e-01,  1.4433e-01, -3.5545e-01, -2.7207e-04,
         -3.7183e-01],
        [-1.4928e-01, -5.0401e-01, -1.1671e-01,  4.8114e-01, -4.1645e-01,
          1.8465e-01,  1.6858e-01, -5.0658e-01, -3.7416e-01,  3.6140e-01,
          1.6305e-01,  2.1577e-01,  2.2676e-01, -4.5227e-01, -4.6646e-01,
         -3.0058e-02],
        [ 4.4197e-01,  1.6595e-01,  1.3472e-01, -2.7401e-01,  3.2285e-01,
         -4.6679e-01, -3.5736e-01,  1.8110e-01,  1.0826e-01, -2.1378e-01,
          8.0548e-02, -2.3210e-01, -3.4584e-01,  4.1396e-01,  4.3939e-01,
          3.0948e-01],
        [ 3.6851e-01,  3.3662e-01,  4.5870e-01, -5.0455e-01,  7.6453e-02,
         -2.7793e-01, -2.4261e-01,  1.1096e-01, -4.7935e-02, -3.9749e-01,
         -7.5277e-02, -7.8948e-02, -6.1141e-03,  2.8236e-01,  7.3272e-02,
          1.5020e-01],
        [ 2.8823e-01,  3.2546e-02,  2.5309e-01, -2.2335e-01,  4.7512e-01,
         -3.2503e-01, -3.2264e-02,  3.0460e-01,  9.0577e-02,  2.6767e-03,
          1.0420e-01, -4.9626e-01, -2.8980e-01,  3.4266e-01,  1.3450e-01,
          4.3241e-01],
        [ 1.5039e-01,  1.9750e-01,  1.9561e-01, -3.7371e-02,  1.6219e-01,
         -3.2158e-01, -4.7061e-02,  1.1106e-01,  2.5516e-01, -4.4702e-01,
         -3.5779e-01, -3.6630e-01, -1.0569e-01,  4.7429e-01,  2.0972e-02,
          1.9516e-01],
        [ 3.1498e-01,  3.6159e-01,  3.8521e-01, -4.6941e-01,  1.6548e-01,
         -1.8210e-01, -3.7346e-01,  3.9635e-01, -3.8034e-02, -1.0073e-01,
         -8.6874e-03, -3.6274e-01, -6.9537e-02,  3.9809e-01,  3.9962e-01,
          3.9425e-01],
        [-4.2030e-01, -2.0900e-01, -8.4791e-02,  3.2569e-01, -8.1265e-02,
          1.1208e-01,  3.0597e-01, -3.0903e-01, -3.0759e-01,  2.0181e-01,
          1.7639e-01,  2.3339e-01,  2.1079e-01, -3.3868e-01, -2.8400e-01,
         -2.2429e-01],
        [ 4.1467e-01,  3.0619e-01,  2.3870e-01, -2.5543e-01,  5.8523e-02,
         -3.8931e-01, -2.4702e-02,  7.8197e-02,  2.5588e-01, -2.3914e-01,
          8.4574e-02, -3.1307e-01, -4.2802e-02,  4.5024e-01,  2.8488e-01,
          3.8087e-01],
        [-3.5445e-01, -1.2849e-01, -4.1869e-01,  3.7286e-01, -3.9867e-01,
          2.3523e-01,  4.5636e-01, -1.0777e-01, -1.9744e-02,  2.5142e-01,
          2.7738e-01,  3.5116e-01,  2.3918e-01, -6.5436e-02, -1.8251e-01,
         -3.3442e-01],
        [-3.7084e-01, -3.3630e-01, -1.2094e-01,  1.3653e-01, -1.5985e-01,
          4.5870e-01,  3.4678e-01, -4.5625e-01, -1.4021e-01,  4.3763e-01,
         -2.2531e-01,  4.5692e-01,  8.2284e-02, -3.6977e-01, -3.4108e-01,
         -3.3631e-01],
        [ 1.4131e-01,  3.3421e-01,  3.2930e-01, -1.6681e-01,  4.0685e-01,
         -3.9203e-01, -5.3722e-01,  5.9375e-02,  1.1865e-01, -2.8676e-01,
          8.6974e-03, -4.7069e-01, -2.8043e-01,  3.7766e-01,  1.3160e-01,
          2.8649e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1349,  0.0366,  0.2225, -0.1491,  0.0041,  0.0352,  0.0240,  0.1329,
        -0.0831, -0.0281,  0.0189,  0.0368,  0.0655,  0.0541, -0.0056, -0.0055,
        -0.1046, -0.0099,  0.0295, -0.0207,  0.0290, -0.1461, -0.1365, -0.0172,
        -0.2478,  0.2010,  0.0876,  0.0511, -0.0327, -0.1245,  0.1212, -0.0796],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2784,  0.3465, -0.3020,  0.3244,  0.3336,  0.4366, -0.3769, -0.4633,
         -0.4065,  0.3836,  0.3408,  0.4309, -0.3363, -0.5055,  0.3793,  0.2392,
         -0.4047,  0.4349, -0.3080, -0.3310,  0.3130,  0.4726, -0.4631, -0.4862,
         -0.3996, -0.3523, -0.4064,  0.3610, -0.4515,  0.4812,  0.3870, -0.3242]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0580,  0.1571,  0.0969,  ...,  0.0125, -0.0542, -0.1137],
        [ 0.0253, -0.2125,  0.0344,  ...,  0.0300, -0.3030,  0.0871],
        [-0.1658,  0.1692,  0.1603,  ...,  0.1164,  0.1673,  0.0345],
        ...,
        [ 0.1555, -0.1905, -0.0480,  ..., -0.0596, -0.2423, -0.1180],
        [-0.0338, -0.0469,  0.0546,  ..., -0.1654,  0.0688,  0.1557],
        [-0.2381,  0.1768,  0.0745,  ..., -0.0724, -0.0092, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0353,  0.0717, -0.1290, -0.1130, -0.0467,  0.0368, -0.1595,  0.0795,
        -0.0216,  0.0834,  0.0314, -0.0268, -0.0033,  0.1043, -0.0999, -0.0336,
         0.0599, -0.1183, -0.0293,  0.0467, -0.0809,  0.0891,  0.0895, -0.0354,
        -0.0898,  0.0840,  0.0262, -0.1270,  0.0649,  0.1531,  0.1518, -0.1089],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.1881, -0.1210, -0.0960,  ..., -0.1028, -0.1047,  0.2021],
        [-0.0042,  0.0010,  0.1394,  ..., -0.0408, -0.0537,  0.2490],
        [-0.0734, -0.0946, -0.1999,  ...,  0.0173,  0.0511, -0.0043],
        ...,
        [ 0.0113,  0.0390,  0.1066,  ...,  0.2446, -0.1319,  0.1101],
        [ 0.1805, -0.1109,  0.0869,  ...,  0.0330,  0.1812,  0.0377],
        [ 0.1559, -0.0656,  0.2308,  ...,  0.1000,  0.0713,  0.0943]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0612,  0.0343,  0.0781, -0.0206, -0.1324, -0.1870,  0.0467, -0.2041,
         0.0603, -0.0691,  0.2487, -0.1544,  0.0988,  0.0689, -0.2119, -0.0474,
        -0.0841, -0.0678, -0.0062, -0.0851,  0.0748,  0.1912, -0.1419,  0.1830,
        -0.1647, -0.0662,  0.1707, -0.1311, -0.0066, -0.0469,  0.0078, -0.0442],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3327,  0.2313, -0.3468, -0.3159,  0.1996,  0.1861, -0.2354,  0.2647,
          0.2472, -0.2453, -0.2222,  0.2364,  0.2235, -0.1954,  0.2653,  0.2093,
         -0.3264, -0.3325,  0.2044,  0.2312, -0.2893, -0.2706, -0.3413, -0.1438,
          0.3034,  0.3335, -0.3146,  0.3368, -0.2423, -0.3251,  0.3188,  0.3155]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.1596], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-3.0838e-01,  7.4438e-02, -1.5807e-03, -3.9072e-02, -1.4569e-01,
          1.6011e-01,  7.1885e-02, -3.6410e-01, -1.3264e-01,  2.4202e-01,
          2.1006e-01,  1.7661e-01, -5.5547e-02, -3.9397e-01, -7.7955e-03,
          7.3087e-02],
        [-2.2138e-01, -3.7283e-01, -1.0252e-01, -4.6845e-02, -3.0490e-01,
          2.4055e-01, -3.9636e-02, -1.8398e-01,  7.7174e-02,  1.0313e-01,
          2.8816e-01,  9.7390e-02,  2.3008e-01, -1.0283e-01,  7.7299e-02,
         -6.5557e-02],
        [ 6.7190e-02,  2.9174e-01,  3.8306e-01, -1.0572e-01,  2.4908e-01,
         -3.5265e-01,  2.0011e-01, -8.2530e-02,  3.5202e-01, -3.2258e-02,
         -1.9930e-02, -3.9101e-01,  1.3754e-01,  3.3453e-01,  3.7577e-01,
          2.5398e-01],
        [-6.5749e-02, -2.6790e-01, -2.8856e-01,  2.6783e-01, -6.7273e-02,
          1.8071e-01, -1.4920e-02, -8.5810e-02, -3.9582e-01, -8.5218e-02,
          3.0455e-02,  3.4057e-01,  2.1134e-01, -4.1368e-01, -2.4423e-01,
         -1.9784e-01],
        [-8.1724e-02,  4.3213e-02, -1.7029e-01, -5.5000e-02, -1.3746e-01,
          7.6704e-02, -2.1751e-01, -3.0750e-02, -1.8327e-01,  2.8086e-01,
          3.1712e-01,  1.9857e-01,  2.2305e-01, -2.8185e-01, -8.4940e-03,
         -1.5049e-01],
        [ 5.8266e-03,  7.6138e-02, -3.6931e-01,  3.8386e-01,  2.5268e-02,
         -2.7292e-02,  3.4497e-02, -3.7818e-01, -9.1963e-02,  1.9952e-01,
         -6.0160e-02,  2.7116e-01,  7.2173e-03,  7.6776e-02,  7.2244e-02,
         -8.1432e-02],
        [ 2.4160e-01,  1.8171e-01,  4.2744e-01, -1.5279e-01,  1.9339e-01,
         -1.2999e-01, -7.7017e-02,  1.0844e-01,  7.9555e-02,  1.2239e-01,
         -6.2437e-02, -2.9460e-01, -1.8996e-01,  2.7260e-01, -4.4567e-02,
          1.0026e-01],
        [-1.2039e-01,  3.3757e-01,  3.7755e-01, -3.3651e-01, -9.6363e-02,
         -2.7545e-01,  5.9356e-02,  4.2329e-02,  9.3611e-02, -1.3693e-01,
         -9.3817e-02, -2.8777e-01,  7.4522e-02, -3.3468e-02,  1.3642e-01,
          3.4553e-01],
        [-3.2499e-03,  3.4235e-01,  3.0040e-01, -2.1792e-01,  2.1930e-01,
         -3.2041e-01,  9.9101e-02,  2.2964e-01,  3.5544e-01, -2.5914e-01,
         -2.3177e-01, -2.8669e-01, -3.4713e-01,  2.0876e-01, -5.6706e-02,
          7.2556e-02],
        [-2.8277e-01, -1.4770e-01, -9.8233e-02, -4.1824e-02, -2.2470e-01,
          1.4809e-01, -2.5029e-01, -1.0951e-01, -5.2442e-02, -9.7810e-03,
          2.9967e-01,  3.4891e-01,  4.0369e-02, -1.2307e-01, -1.1421e-01,
         -1.9346e-01],
        [-3.5547e-01,  9.2603e-03, -7.0594e-02, -4.0884e-02, -3.6203e-01,
          4.2555e-01, -5.3972e-02, -2.3929e-01,  2.0464e-03,  2.4658e-01,
          2.2829e-01,  3.7930e-01,  1.0825e-01,  6.6896e-02, -3.5247e-01,
         -3.2956e-01],
        [-1.4837e-01, -2.0107e-01, -3.1543e-02,  8.0391e-02, -1.1674e-01,
          1.2833e-01,  3.7971e-03, -1.8200e-01, -5.0164e-02,  3.6796e-01,
          1.7675e-01,  4.0582e-01, -5.9512e-02, -2.9638e-01, -1.3167e-01,
         -2.1606e-01],
        [ 2.2810e-01,  2.7729e-01,  1.7156e-01, -1.4912e-01,  2.2215e-01,
          5.7014e-02,  6.2281e-02,  5.8253e-02,  5.5382e-02,  3.4419e-02,
         -2.1399e-01, -3.4840e-01, -2.0511e-01,  2.1229e-01,  1.1264e-01,
          2.4350e-02],
        [ 1.7680e-01,  3.9641e-01,  3.8341e-01,  2.8802e-03, -3.8142e-02,
         -8.1203e-03,  1.3369e-01,  2.5306e-01,  9.7819e-02, -1.1730e-01,
         -2.9176e-01, -2.2789e-01, -9.6277e-02,  1.1973e-01, -8.4793e-02,
          2.3941e-01],
        [-3.6074e-01, -3.6190e-01, -8.2539e-02, -5.2249e-02,  8.2831e-02,
          4.1426e-01, -1.2676e-01, -2.1831e-01, -3.5344e-01,  1.5871e-01,
          2.0265e-01,  3.9635e-02,  1.5451e-01, -1.7470e-01, -2.4090e-01,
         -1.6521e-01],
        [-3.3608e-01, -2.4942e-01,  3.7041e-02,  2.6634e-01, -1.9213e-01,
          2.5381e-01, -7.4684e-03, -1.1082e-01, -1.2594e-03,  2.2188e-01,
          3.1015e-02,  2.2254e-01, -2.9970e-02, -1.9241e-01,  2.1536e-01,
         -1.3405e-01],
        [ 3.0221e-01,  3.1926e-01,  2.2535e-01, -3.5016e-01, -8.7017e-02,
         -3.6457e-02,  1.1703e-01,  3.1885e-01, -5.2379e-02, -1.6481e-01,
          6.4999e-02, -4.5534e-02,  1.1118e-01,  3.6279e-01,  1.1106e-01,
         -1.3127e-02],
        [-2.6941e-01, -5.1195e-02, -2.7716e-01,  1.3736e-01, -1.0219e-01,
          2.9600e-01,  1.2512e-01, -2.5668e-02, -1.5604e-01,  2.3950e-01,
          5.7264e-02,  7.4461e-02,  1.2069e-02, -3.1322e-01,  5.4545e-02,
         -1.8444e-01],
        [ 2.1797e-01,  1.6406e-01,  1.6751e-01, -2.8142e-01,  1.2366e-01,
         -3.8261e-01, -4.4274e-02,  3.4705e-01, -9.6974e-02, -8.6859e-02,
         -4.1027e-02, -3.9697e-01, -6.0048e-02,  2.9151e-01,  3.3567e-01,
          1.9728e-01],
        [ 3.6346e-01,  2.0887e-01,  2.8708e-01, -9.5734e-02, -2.4911e-02,
         -2.4741e-01, -9.4236e-02,  3.7352e-01,  2.8195e-01, -2.6212e-01,
         -1.5881e-01, -1.1111e-01, -3.2620e-01,  1.7819e-01,  2.9251e-01,
          2.0590e-01],
        [-1.3388e-01,  3.7673e-02, -4.7307e-02, -1.0554e-01,  1.2178e-02,
         -4.2924e-02,  1.0762e-01,  5.8442e-02, -1.3530e-01,  3.7950e-02,
          1.8516e-02,  5.3068e-02, -6.2300e-04, -2.7506e-01,  9.6538e-02,
         -2.4670e-01],
        [-3.9788e-02, -3.8664e-01, -3.9106e-02,  3.5033e-01, -3.0099e-01,
          1.0520e-01, -3.1380e-02, -3.9292e-01, -2.8550e-01,  2.1901e-01,
          2.0319e-01,  8.3440e-02,  9.6803e-02, -4.1013e-01, -3.7338e-01,
          7.6306e-02],
        [ 3.2672e-01,  6.0152e-02,  7.2366e-02, -1.4655e-01,  2.4829e-01,
         -3.7872e-01, -1.2942e-01,  8.0940e-02,  4.3040e-02, -9.4392e-02,
          3.4014e-02, -1.1256e-01, -2.7563e-01,  3.8433e-01,  3.5712e-01,
          2.1687e-01],
        [ 2.5106e-01,  2.3179e-01,  3.7990e-01, -3.7569e-01, -9.4751e-03,
         -1.7869e-01, -1.9512e-04,  2.7343e-03, -7.8033e-02, -3.0419e-01,
         -1.9211e-01,  3.8706e-02,  8.2893e-02,  2.3362e-01,  1.0274e-02,
          4.7572e-02],
        [ 1.5509e-01, -8.5573e-02,  1.6684e-01, -8.8520e-02,  3.7883e-01,
         -2.1051e-01,  2.7951e-01,  1.8888e-01, -7.1344e-03,  1.2625e-01,
          5.7820e-02, -3.7243e-01, -2.2419e-01,  2.8505e-01,  1.5720e-02,
          3.2075e-01],
        [ 2.6514e-03,  6.7845e-02,  1.0137e-01,  1.0350e-01,  5.8434e-02,
         -2.1101e-01,  1.4439e-01, -7.0582e-03,  1.6565e-01, -3.0740e-01,
         -3.5163e-01, -2.3148e-01,  6.8093e-03,  4.0116e-01, -7.2727e-02,
          7.8554e-02],
        [ 2.0607e-01,  2.5558e-01,  3.1979e-01, -3.4320e-01,  7.9600e-02,
         -1.0157e-01, -1.2470e-01,  2.9072e-01, -1.0225e-01,  2.9903e-02,
         -6.7447e-03, -2.3519e-01, -2.4445e-02,  3.5707e-01,  3.2900e-01,
          3.0013e-01],
        [-3.1250e-01, -8.3194e-02,  1.0227e-02,  1.8197e-01,  1.7750e-02,
          1.0557e-02,  1.3312e-02, -1.7537e-01, -3.1681e-01,  9.5923e-02,
          2.1947e-01,  8.1374e-02,  1.1643e-01, -2.6194e-01, -2.5154e-01,
         -1.1076e-01],
        [ 3.3126e-01,  2.0411e-01,  1.6134e-01, -1.3605e-01, -3.3408e-02,
         -3.1263e-01,  1.5606e-01, -3.1243e-02,  2.6352e-01, -1.3731e-01,
         -4.6127e-03, -1.8562e-01,  6.3444e-02,  3.8921e-01,  2.6760e-01,
          2.8742e-01],
        [-2.0693e-01, -2.6962e-02, -3.4483e-01,  2.3993e-01, -3.1262e-01,
          1.3083e-01,  2.3477e-01, -3.3530e-03,  5.8237e-02,  1.4338e-01,
          2.6732e-01,  2.4065e-01,  1.6912e-01, -2.4198e-02, -8.9379e-02,
         -2.2848e-01],
        [-2.9011e-01, -2.3429e-01, -5.8142e-02,  1.2963e-02, -8.3778e-02,
          3.8925e-01,  9.0672e-02, -3.5161e-01, -7.5295e-02,  3.2141e-01,
         -1.2439e-01,  3.2790e-01, -1.4049e-02, -3.3789e-01, -2.6200e-01,
         -2.5310e-01],
        [-2.8103e-01, -1.3911e-01, -1.1293e-01,  2.7801e-01, -1.1890e-02,
          4.1694e-02, -3.1998e-01, -3.9676e-01, -3.1044e-01,  5.8246e-02,
          1.8118e-01,  1.2829e-02, -7.4286e-02, -5.1383e-02, -3.3979e-01,
         -1.4528e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.2616,  0.0538,  0.2301, -0.2323,  0.0399, -0.1401,  0.0862,  0.1981,
        -0.1607, -0.0109,  0.1131,  0.0474,  0.0855,  0.0048,  0.0639, -0.0396,
        -0.1078, -0.0416,  0.0487, -0.0842, -0.0630, -0.1453, -0.1335, -0.0636,
        -0.2426,  0.2258,  0.1489,  0.0426, -0.0368, -0.1526,  0.1234, -0.1235],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.1347,  0.1839, -0.1842,  0.1981,  0.2299,  0.2929, -0.2547, -0.3387,
         -0.2803,  0.2716,  0.2147,  0.3229, -0.2623, -0.3782,  0.2506,  0.0943,
         -0.2745,  0.2775, -0.1832, -0.2085,  0.1437,  0.3391, -0.3389, -0.3313,
         -0.2624, -0.2476, -0.2852,  0.2424, -0.3187,  0.3571,  0.2634,  0.1800]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[ 0.0174,  0.1419,  0.2521,  ..., -0.0154,  0.1614, -0.1137],
        [-0.0199, -0.1648, -0.0364,  ...,  0.0802, -0.5253,  0.0871],
        [-0.0984,  0.1487,  0.2569,  ...,  0.0744,  0.5163,  0.0345],
        ...,
        [ 0.0428, -0.1620, -0.0973,  ...,  0.0073, -0.5855, -0.1180],
        [ 0.0535, -0.0733,  0.0400,  ..., -0.2315,  0.4619,  0.1557],
        [-0.1375,  0.1137,  0.1110,  ..., -0.1343,  0.3498, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0359,  0.1091, -0.1245, -0.1092, -0.0083,  0.0277, -0.1760,  0.0968,
        -0.0619,  0.1145,  0.0609, -0.0070,  0.0016,  0.0907, -0.1033, -0.0383,
         0.0650, -0.1056, -0.0048, -0.0134, -0.0834,  0.0610,  0.0971, -0.0311,
        -0.0648,  0.0624,  0.0165, -0.1060,  0.0589,  0.1347,  0.1571, -0.0935],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.2579, -0.1893, -0.0680,  ..., -0.0709, -0.0926,  0.1738],
        [ 0.0220, -0.0390,  0.1336,  ..., -0.0329, -0.0499,  0.2253],
        [-0.0804, -0.0516, -0.1815,  ...,  0.0158,  0.0556,  0.0317],
        ...,
        [-0.0266,  0.0487,  0.1035,  ...,  0.2138, -0.1566,  0.1284],
        [ 0.1984, -0.1258,  0.0739,  ...,  0.0577,  0.1832,  0.0068],
        [ 0.1892, -0.1190,  0.2293,  ...,  0.0935,  0.0835,  0.0779]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0416,  0.0493,  0.0406, -0.0211, -0.1176, -0.1079,  0.0225, -0.1378,
         0.0794, -0.0913,  0.1810, -0.1741,  0.1251,  0.0273, -0.1817,  0.0121,
        -0.0969, -0.1003, -0.0107, -0.0536,  0.0552,  0.1662, -0.1373,  0.1321,
        -0.1278, -0.0592,  0.1604, -0.1247, -0.0434, -0.0423,  0.0220, -0.0245],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.2926,  0.1977, -0.3010, -0.2873,  0.1622,  0.1579, -0.1910,  0.2299,
          0.2148, -0.1988, -0.1901,  0.1814,  0.2018, -0.1683,  0.2150,  0.1690,
         -0.2872, -0.2861,  0.1596,  0.1804, -0.2461, -0.2208, -0.2943, -0.0873,
          0.2607,  0.2899, -0.2766,  0.3158, -0.1977, -0.2695,  0.2816,  0.2633]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([-0.0838], device='cuda:0', requires_grad=True)

