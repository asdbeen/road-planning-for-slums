Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-1.7800e-03,  4.0024e-01,  3.0900e-01, -3.2951e-01, -1.8964e-01,
         -1.5228e-01, -7.4072e-02, -3.8618e-01, -2.4668e-01, -7.6615e-02,
         -3.3228e-02,  1.8932e-01, -3.0595e-01, -6.7373e-02, -2.2450e-02,
          3.8588e-01],
        [-2.4768e-01, -3.9270e-01, -1.0121e-01, -8.2896e-03, -2.7504e-02,
          2.4570e-01,  1.6154e-01,  1.5610e-01,  4.2420e-01,  1.3643e-01,
          3.0153e-01, -2.5583e-01,  3.6106e-01, -3.0571e-02,  3.3188e-01,
         -9.1241e-02],
        [ 9.1756e-02,  2.9961e-01,  3.9119e-01, -1.3298e-01, -9.8663e-02,
         -3.4536e-01, -8.7687e-02, -4.4098e-01, -5.2545e-02, -8.7752e-02,
         -1.6118e-01, -4.2643e-02,  2.1317e-02,  3.5098e-01, -7.3275e-03,
          2.8704e-01],
        [ 2.8400e-01,  1.2414e-01,  9.8638e-02, -9.1451e-02, -6.7651e-02,
         -2.1429e-01, -1.7528e-01, -1.1664e-01, -4.6743e-01, -4.2895e-01,
         -2.2216e-01,  3.8019e-01, -7.7772e-02, -1.1209e-01, -2.0206e-01,
          1.8159e-01],
        [-9.5514e-02,  2.9782e-02, -1.7344e-01, -2.0638e-02,  1.6453e-01,
          8.7021e-02,  4.5202e-02,  3.2308e-01,  1.7685e-01,  3.0396e-01,
          3.5118e-01, -1.6080e-01,  3.2352e-01, -2.3481e-01,  2.8386e-01,
         -1.7433e-01],
        [-1.8988e-02,  5.6404e-02, -3.7498e-01,  4.1872e-01,  3.5523e-01,
         -1.0592e-02,  2.8456e-01, -8.3919e-03,  3.0618e-01,  2.3299e-01,
         -7.2532e-02, -1.0341e-01,  1.2553e-01,  1.1685e-01,  4.1898e-01,
         -1.0531e-01],
        [ 3.6641e-01,  2.5123e-01,  4.0823e-01, -1.8685e-01, -5.7013e-02,
         -2.0830e-01, -1.8478e-01, -2.3589e-01, -2.8876e-01, -3.2033e-02,
         -4.9393e-02,  5.9656e-02, -3.5835e-01,  2.0735e-01, -2.8880e-01,
          1.6373e-01],
        [-5.8534e-02,  3.6692e-01,  3.6328e-01, -3.6310e-01, -3.4642e-01,
         -2.9948e-01, -1.0205e-01, -2.7083e-01, -2.3741e-01, -2.2842e-01,
         -9.7074e-02,  3.5896e-02, -3.9636e-02, -9.3378e-02, -1.1515e-01,
          3.7217e-01],
        [ 3.2095e-02,  3.6054e-01,  3.0371e-01, -2.4705e-01, -4.9144e-02,
         -3.4534e-01, -1.5591e-01, -9.7627e-02,  1.8921e-02, -3.1884e-01,
         -2.8724e-01,  4.9775e-02, -4.1744e-01,  1.6063e-01, -2.8378e-01,
          1.0856e-01],
        [-2.9908e-01, -1.7003e-01, -1.1221e-01,  2.1990e-03,  8.8908e-02,
          1.6773e-01,  7.1610e-02,  2.5263e-01,  3.1282e-01,  1.6903e-02,
          3.6753e-01, -1.6988e-02,  1.1608e-01, -9.5024e-02,  1.9158e-01,
         -2.2800e-01],
        [-3.6906e-01,  1.0198e-02, -7.9273e-02, -1.6243e-02, -3.1082e-02,
          4.4157e-01,  2.6075e-01,  1.4490e-01,  4.0257e-01,  2.7986e-01,
          2.3102e-01, -1.0713e-02,  1.9491e-01,  9.8817e-02,  1.3061e-02,
         -3.6270e-01],
        [-1.3846e-01, -2.0721e-01, -3.9562e-02,  1.0251e-01,  1.8624e-01,
          1.3600e-01,  3.8603e-01,  1.6555e-01,  2.0570e-01,  3.6975e-01,
          4.1202e-01,  5.2280e-02, -5.9802e-02, -2.6521e-01,  2.7997e-02,
         -2.3580e-01],
        [ 3.3417e-01,  2.9643e-01,  1.6936e-01, -1.7608e-01, -1.0231e-01,
          2.4697e-02, -8.4322e-02, -3.2187e-01, -3.5431e-01, -1.1572e-01,
         -1.8111e-01,  3.2521e-02, -4.3463e-01,  1.5851e-01, -2.3573e-01,
          5.3217e-02],
        [ 2.0868e-01,  4.0562e-01,  3.7220e-01, -1.4969e-02, -3.1187e-01,
         -2.2610e-02, -3.8144e-02, -7.2916e-02, -2.4220e-01, -1.7389e-01,
         -2.8442e-01,  1.0781e-01, -2.0093e-01,  6.0713e-02, -3.1968e-01,
          2.5394e-01],
        [-3.7824e-01, -3.5907e-01, -7.4795e-02, -3.0526e-02,  3.7164e-01,
          4.0556e-01,  1.1160e-01,  1.2228e-01,  8.3642e-03,  1.9694e-01,
          1.9652e-01, -3.1052e-01,  2.5438e-01, -1.1713e-01,  6.0827e-02,
         -1.8307e-01],
        [-5.3400e-02,  1.9444e-02,  2.1910e-01,  5.1844e-02, -3.6438e-01,
         -3.8479e-02, -2.2442e-01, -3.3872e-01, -2.9068e-01, -9.7182e-02,
         -1.5864e-01,  4.4262e-01, -2.9134e-01, -1.3744e-02,  2.6180e-02,
          1.2868e-01],
        [ 3.2914e-01,  3.3421e-01,  2.1745e-01, -3.6943e-01, -3.8244e-01,
         -5.9522e-02, -1.1831e-01, -2.6251e-02, -4.1533e-01, -2.1338e-01,
          6.3718e-02,  3.0793e-01,  3.3967e-02,  3.0407e-01, -1.3260e-01,
          4.4882e-03],
        [-3.0063e-01, -6.7255e-02, -2.5483e-01,  1.5151e-01,  1.4455e-01,
          3.0853e-01,  3.0035e-01,  2.8497e-01,  1.8166e-01,  3.0230e-01,
          1.6384e-02, -2.5245e-01,  1.1338e-01, -2.2053e-01,  2.8830e-01,
         -1.9580e-01],
        [ 2.2402e-01,  1.5846e-01,  1.4532e-01, -2.8508e-01, -2.1435e-01,
         -3.7147e-01, -3.1977e-01,  1.2997e-02, -4.9302e-01, -1.2251e-01,
         -1.2082e-01, -6.9572e-02, -1.4276e-01,  2.9486e-01, -4.0958e-02,
          2.0924e-01],
        [ 3.7461e-01,  1.8617e-01,  2.7840e-01, -1.0055e-01, -3.1284e-01,
         -2.3254e-01, -3.6233e-01,  2.6530e-02, -8.3034e-02, -2.9292e-01,
         -1.7827e-01,  2.4536e-01, -4.0286e-01,  1.1206e-01,  4.2734e-02,
          2.1924e-01],
        [-1.8942e-01, -3.7188e-03, -6.0369e-02, -5.7480e-02,  2.8718e-01,
         -2.2494e-02,  3.1931e-01,  3.8141e-01,  2.2492e-01,  9.2142e-02,
          1.3819e-02, -2.8606e-01,  1.2684e-01, -2.1211e-01,  3.8619e-01,
         -2.8004e-01],
        [-7.7077e-02, -4.1105e-01, -5.5996e-02,  3.9577e-01, -2.1042e-02,
          1.1515e-01,  2.6427e-01, -5.6267e-02,  5.9787e-02,  2.7633e-01,
          4.0250e-01, -2.5816e-01,  1.8113e-01, -3.6977e-01, -8.0880e-02,
          2.9834e-02],
        [ 3.6853e-01,  8.4077e-02,  6.1328e-02, -1.7356e-01,  6.4373e-05,
         -3.9816e-01, -3.0505e-01, -2.3027e-01, -2.8915e-01, -1.7177e-01,
          5.0610e-02,  2.1102e-01, -3.9090e-01,  3.2066e-01,  9.9630e-02,
          2.4221e-01],
        [ 2.6272e-01,  2.4043e-01,  3.5136e-01, -3.7969e-01, -2.4404e-01,
         -1.7613e-01, -1.8653e-01, -2.9184e-01, -3.8958e-01, -3.4173e-01,
         -1.4375e-01,  3.4885e-01,  1.3554e-02,  1.3590e-01, -1.8167e-01,
          4.5996e-02],
        [ 2.2242e-01, -3.8185e-02,  1.8612e-01, -1.4024e-01,  4.0772e-02,
         -2.7993e-01,  1.6566e-02, -2.0244e-01, -4.2144e-01,  2.6361e-02,
          3.7354e-02,  1.9445e-02, -3.5615e-01,  2.6460e-01, -3.2452e-01,
          3.7485e-01],
        [ 5.0197e-02,  9.1794e-02,  9.9889e-02,  6.7069e-02, -2.2741e-01,
         -2.1490e-01, -3.7174e-02, -3.4244e-01, -2.0908e-01, -3.7213e-01,
         -3.6919e-01,  1.1626e-01, -1.5221e-01,  3.2337e-01, -3.9291e-01,
          1.0747e-01],
        [ 2.2968e-01,  2.5874e-01,  3.1318e-01, -3.6170e-01, -1.8483e-01,
         -1.0669e-01, -3.7049e-01, -3.1352e-02, -4.2695e-01, -1.5900e-02,
         -6.2591e-02,  9.3676e-02, -8.4731e-02,  3.0764e-01,  1.0878e-01,
          3.2131e-01],
        [-3.2561e-01, -1.0624e-01,  5.6855e-03,  2.1791e-01,  3.1075e-01,
          2.8266e-02,  3.7745e-01,  1.7024e-01, -2.0351e-02,  1.2102e-01,
          3.8311e-01, -2.7011e-01,  1.3977e-01, -2.2230e-01, -1.9563e-02,
         -1.4221e-01],
        [ 3.1700e-01,  1.9930e-01,  1.5407e-01, -1.4905e-01, -3.1329e-01,
         -2.9956e-01, -1.6536e-01, -3.5713e-01, -6.3613e-02, -1.3492e-01,
         -1.1014e-01,  1.5035e-01,  3.1481e-02,  3.3330e-01,  5.6853e-03,
          2.9729e-01],
        [-2.6962e-01, -4.6934e-02, -3.2122e-01,  2.5632e-01, -7.5660e-02,
          1.4609e-01,  3.3902e-01,  3.0362e-01,  3.8839e-01,  2.4311e-01,
          2.3125e-01, -7.9821e-02,  3.2655e-01,  5.9384e-02,  1.3450e-01,
         -2.4092e-01],
        [-3.0128e-01, -2.3912e-01, -6.3367e-02,  3.9076e-02,  2.1178e-01,
          4.0391e-01,  4.0426e-01, -4.4635e-03,  2.7838e-01,  3.5135e-01,
         -8.0688e-02, -2.6868e-02,  3.1278e-02, -2.9915e-01,  1.9177e-02,
         -2.8103e-01],
        [ 4.7768e-02,  2.3729e-01,  2.4986e-01, -5.1011e-02,  7.5086e-03,
         -3.1324e-01, -4.1135e-01, -3.6792e-01, -3.6806e-01, -2.7883e-01,
         -4.3453e-02, -1.5616e-02, -3.5517e-01,  2.7314e-01, -2.4652e-01,
          2.0481e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0672, -0.0183, -0.0115, -0.0341,  0.0121, -0.2359,  0.0966,  0.1239,
        -0.0547, -0.0051,  0.0444,  0.0778,  0.1326,  0.0743,  0.0635, -0.0199,
        -0.0184, -0.0389,  0.0830, -0.0313, -0.1032, -0.0735, -0.0315,  0.0366,
        -0.0399,  0.1333,  0.1589,  0.0467, -0.0992, -0.1812,  0.0243,  0.0209],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2143,  0.3075, -0.2248, -0.2549,  0.2978,  0.3516, -0.2787, -0.3717,
         -0.3195,  0.3350,  0.2604,  0.3730, -0.2599, -0.3939,  0.2817, -0.2244,
         -0.3164,  0.3293, -0.2264, -0.2346,  0.3952,  0.3145, -0.3688, -0.3733,
         -0.2787, -0.3257, -0.3170,  0.3394, -0.3476,  0.3784,  0.2984, -0.2325]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0027,  0.1022,  0.0713,  ...,  0.1958, -0.3092, -0.1137],
        [-0.0727, -0.0715,  0.1191,  ...,  0.1026, -0.2855,  0.0871],
        [-0.1035,  0.1438,  0.0949,  ...,  0.1963,  0.0314,  0.0345],
        ...,
        [ 0.0964, -0.1171, -0.0362,  ..., -0.1716, -0.0262, -0.1180],
        [ 0.0375, -0.1764, -0.0411,  ..., -0.2614,  0.0911,  0.1557],
        [-0.1834,  0.1273,  0.0517,  ...,  0.0702, -0.2423, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0522,  0.0316, -0.0969, -0.1546, -0.0809, -0.0038, -0.1027,  0.0399,
        -0.0322,  0.0580,  0.0271, -0.0017,  0.0058,  0.1015, -0.0449, -0.0110,
         0.0469, -0.1662,  0.0036,  0.0810, -0.0620,  0.0183,  0.1109,  0.0223,
        -0.1109,  0.0983,  0.0442, -0.0964,  0.0448,  0.2023,  0.1686, -0.1286],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0512, -0.1645, -0.1868,  ...,  0.0358, -0.0454,  0.0649],
        [-0.2192, -0.0155, -0.0183,  ...,  0.1384, -0.0294,  0.0481],
        [ 0.1489, -0.0497, -0.0397,  ..., -0.1412,  0.0037,  0.1867],
        ...,
        [ 0.1408,  0.0613,  0.2038,  ...,  0.1019, -0.1778,  0.2466],
        [-0.0165, -0.1350, -0.0472,  ...,  0.2373,  0.2123, -0.1723],
        [-0.0050, -0.1088,  0.1267,  ...,  0.2207,  0.1255, -0.0444]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1011,  0.1479, -0.0464, -0.0989, -0.1086, -0.1755, -0.0620, -0.0283,
         0.1390, -0.1678,  0.1307, -0.1265,  0.1967,  0.0907, -0.1113,  0.1214,
        -0.1379, -0.1778,  0.0757,  0.0104, -0.0142,  0.0828, -0.2081,  0.2160,
        -0.0461, -0.0088,  0.0760, -0.0398, -0.1490, -0.0614,  0.1217,  0.0293],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.3710,  0.2944, -0.3332, -0.3643, -0.2172, -0.2122, -0.2786,  0.2439,
          0.2725, -0.2891, -0.2410,  0.2569,  0.2659,  0.2224,  0.2816,  0.2644,
         -0.3630, -0.3688,  0.2145,  0.2590, -0.3199, -0.2703, -0.3720,  0.2184,
          0.3345,  0.3872, -0.3429,  0.3588, -0.2787, -0.3674,  0.3317,  0.3722]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.1275], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.3158e-02,  3.6482e-01,  3.2542e-01, -3.4399e-01, -1.0744e-02,
         -1.7897e-01, -6.9559e-02, -3.8396e-01, -1.6757e-01, -8.8155e-02,
          1.1016e-02,  1.6358e-01,  5.2959e-02, -4.6673e-02,  3.1438e-01,
          3.7148e-01],
        [-2.7541e-01, -3.4779e-01, -1.2842e-01,  1.0454e-02, -1.7577e-01,
          2.8452e-01,  1.8907e-01,  1.6275e-01,  3.9132e-01,  1.3631e-01,
          2.3917e-01, -2.6211e-01,  8.5373e-03, -4.8352e-02,  4.9152e-03,
         -8.9022e-02],
        [ 1.0137e-01,  2.5861e-01,  4.0529e-01, -1.3884e-01,  1.5570e-01,
         -3.7620e-01, -6.7107e-02, -4.0713e-01,  6.2414e-02, -8.6276e-02,
         -1.1238e-01, -7.1781e-02,  3.8846e-01,  3.1639e-01,  4.3216e-01,
          2.7311e-01],
        [ 2.9300e-01,  7.8315e-02,  1.0907e-01, -9.0181e-02,  1.1489e-01,
         -2.3143e-01, -1.7331e-01, -9.2147e-02, -3.9949e-01, -4.0603e-01,
         -1.2443e-01,  3.5596e-01,  2.7843e-01, -1.2189e-01,  1.3920e-01,
          1.6643e-01],
        [-1.1384e-01,  1.1103e-01, -1.8909e-01, -9.7324e-03,  3.5188e-02,
          1.2071e-01,  6.5684e-02,  3.4010e-01,  1.4813e-01,  2.9174e-01,
          2.5400e-01, -1.7534e-01, -4.4909e-02, -2.2712e-01, -7.6097e-02,
         -1.4217e-01],
        [-1.9120e-02,  1.3842e-01, -3.7478e-01,  4.0746e-01,  1.4558e-01,
          1.4640e-03,  2.7423e-01, -2.6708e-02,  2.4188e-01,  2.0429e-01,
         -1.2214e-01, -8.4948e-02, -2.3979e-01,  1.3389e-01,  3.9917e-02,
         -7.3049e-02],
        [ 3.9445e-01,  2.1173e-01,  4.3475e-01, -2.0172e-01,  1.4288e-01,
         -2.5130e-01, -2.1258e-01, -2.3305e-01, -2.4268e-01, -3.1199e-02,
         -3.5276e-02,  5.6266e-02, -4.0414e-02,  2.3451e-01, -1.4087e-02,
          1.6809e-01],
        [-4.3777e-02,  3.2370e-01,  3.7666e-01, -3.6157e-01, -1.3456e-01,
         -3.3177e-01, -1.1029e-01, -2.4165e-01, -1.7168e-01, -2.1716e-01,
         -8.5001e-02,  1.2493e-02,  2.4832e-01, -7.9760e-02,  1.5960e-01,
          3.6961e-01],
        [ 5.6498e-02,  3.1422e-01,  3.2716e-01, -2.6683e-01,  4.5044e-02,
         -3.8259e-01, -1.8461e-01, -1.0747e-01,  4.8640e-02, -3.1620e-01,
         -1.2966e-01,  6.6699e-02, -8.8592e-02,  1.4557e-01,  1.0175e-02,
          1.0059e-01],
        [-3.0435e-01, -9.3645e-02, -1.1680e-01, -1.8001e-03, -5.9400e-02,
          1.8757e-01,  6.6445e-02,  2.4594e-01,  2.6219e-01, -6.6940e-03,
          2.5862e-01, -1.2741e-02, -2.5328e-01, -6.9804e-02, -1.8138e-01,
         -1.9345e-01],
        [-3.6988e-01,  6.1112e-02, -8.2005e-02, -2.8239e-02, -1.9044e-01,
          4.5579e-01,  2.4710e-01,  1.1436e-01,  3.2936e-01,  2.5211e-01,
          8.5482e-02,  1.7684e-02, -1.5396e-01,  1.2833e-01, -3.8638e-01,
         -3.3759e-01],
        [-1.4573e-01, -1.5518e-01, -4.5901e-02,  1.0427e-01,  9.8240e-02,
          1.5348e-01,  3.9063e-01,  1.5720e-01,  1.6229e-01,  3.4750e-01,
          1.7335e-01,  5.6585e-02, -3.9425e-01, -2.0881e-01, -2.5701e-01,
         -2.0678e-01],
        [ 3.6627e-01,  2.3357e-01,  2.0319e-01, -1.9886e-01,  9.4036e-02,
         -2.5934e-02, -1.1406e-01, -3.2929e-01, -3.2904e-01, -1.2408e-01,
         -1.4276e-01,  3.0273e-02, -3.2854e-02,  1.9966e-01,  1.6515e-01,
          4.3790e-02],
        [ 2.3609e-01,  3.6296e-01,  3.9756e-01, -3.1691e-02, -1.6382e-01,
         -6.2193e-02, -7.2706e-02, -8.0992e-02, -2.1432e-01, -1.7382e-01,
         -2.3194e-01,  1.1762e-01,  1.2409e-01,  7.4821e-02, -3.8969e-02,
          2.5488e-01],
        [-3.9611e-01, -3.1294e-01, -9.2383e-02, -2.8689e-02,  1.8941e-01,
          4.4615e-01,  1.2139e-01,  1.1567e-01, -4.4997e-02,  1.8764e-01,
          1.4540e-01, -3.0575e-01, -7.9392e-02, -1.2361e-01, -2.8012e-01,
         -1.7603e-01],
        [-9.4399e-02, -1.4540e-01,  1.7606e-01,  1.0010e-01, -1.8124e-01,
         -9.9542e-03, -1.5157e-01, -2.8313e-01, -1.5051e-01, -4.7865e-03,
         -1.1897e-02,  4.0894e-01,  1.0397e-01, -9.8945e-02,  3.9945e-01,
          3.1049e-02],
        [ 3.3427e-01,  2.8307e-01,  2.2229e-01, -3.6673e-01, -1.9262e-01,
         -7.2485e-02, -1.2350e-01,  2.8463e-03, -3.5010e-01, -1.9137e-01,
          1.2201e-01,  2.7969e-01,  3.4079e-01,  2.9266e-01,  1.2670e-01,
         -1.1110e-02],
        [-3.1741e-01, -2.9995e-02, -2.6971e-01,  1.5471e-01, -2.5277e-02,
          3.3853e-01,  3.1426e-01,  2.7233e-01,  1.2752e-01,  2.9002e-01,
         -2.1204e-02, -2.3971e-01, -1.6217e-01, -2.2931e-01,  4.2836e-02,
         -1.9234e-01],
        [ 2.5402e-01,  1.4295e-01,  1.8080e-01, -3.1285e-01,  5.6313e-03,
         -4.1519e-01, -3.1192e-01,  3.4340e-02, -3.8129e-01, -1.4198e-01,
         -5.9432e-02, -8.9045e-02,  1.8880e-01,  2.6523e-01,  3.7071e-01,
          2.1669e-01],
        [ 3.9144e-01,  1.4963e-01,  2.9561e-01, -1.0621e-01, -1.5773e-01,
         -2.6714e-01, -3.7645e-01,  3.7439e-02, -2.8671e-02, -2.8309e-01,
         -8.4632e-02,  2.3746e-01, -8.2600e-02,  1.1292e-01,  3.2689e-01,
          2.1444e-01],
        [-1.9873e-01,  6.9857e-02, -6.8069e-02, -5.6228e-02,  1.3773e-01,
         -1.3054e-03,  3.2964e-01,  3.9019e-01,  1.8263e-01,  7.2779e-02,
         -5.3874e-02, -2.9124e-01, -1.9568e-01, -2.0384e-01,  5.1696e-02,
         -2.5585e-01],
        [-8.0979e-02, -3.4959e-01, -6.0777e-02,  3.8833e-01, -1.6763e-01,
          1.3901e-01,  2.5357e-01, -7.5108e-02, -8.0091e-04,  2.5563e-01,
          2.6971e-01, -2.4702e-01, -1.4496e-01, -3.4455e-01, -4.4560e-01,
          5.4918e-02],
        [ 3.7791e-01,  4.2656e-02,  7.0360e-02, -1.6856e-01,  1.7292e-01,
         -4.2321e-01, -3.1052e-01, -2.0472e-01, -2.2354e-01, -1.5504e-01,
          1.0348e-01,  1.9081e-01, -1.1670e-01,  3.1744e-01,  3.7805e-01,
          2.3242e-01],
        [ 2.7758e-01,  2.1047e-01,  3.6398e-01, -3.8186e-01, -7.6144e-02,
         -2.0249e-01, -2.0538e-01, -2.6544e-01, -3.3628e-01, -3.2887e-01,
         -1.1732e-01,  3.2736e-01,  2.4983e-01,  1.5274e-01,  6.0152e-03,
          4.7840e-02],
        [ 2.2649e-01, -1.2389e-01,  1.9097e-01, -1.3961e-01,  2.1112e-01,
         -2.8810e-01,  2.3303e-02, -1.8385e-01, -3.5530e-01,  5.5509e-02,
          1.4802e-01,  2.9494e-03,  4.1245e-02,  2.3832e-01,  7.0482e-02,
          3.3531e-01],
        [ 7.0112e-02,  2.4236e-02,  1.1961e-01,  6.0732e-02, -6.2484e-02,
         -2.5943e-01, -5.4185e-02, -3.5606e-01, -1.7215e-01, -3.6401e-01,
         -3.1404e-01,  1.2756e-01,  1.8908e-01,  3.3281e-01, -2.7348e-02,
          8.9734e-02],
        [ 2.3590e-01,  2.1814e-01,  3.1986e-01, -3.5687e-01,  9.4756e-03,
         -1.2699e-01, -3.7705e-01,  6.2729e-03, -3.5221e-01,  2.9796e-03,
         -1.2519e-02,  6.2627e-02,  1.9346e-01,  3.0440e-01,  3.6491e-01,
          3.1211e-01],
        [-3.3452e-01, -4.9792e-02, -1.8998e-03,  2.1546e-01,  1.8392e-01,
          5.0282e-02,  3.8027e-01,  1.6395e-01, -6.7476e-02,  1.0026e-01,
          2.3996e-01, -2.6384e-01, -2.0206e-01, -1.9418e-01, -3.3978e-01,
         -1.1715e-01],
        [ 3.2351e-01,  1.5503e-01,  1.5999e-01, -1.4103e-01, -1.6811e-01,
         -3.2079e-01, -1.6477e-01, -3.3733e-01, -4.3916e-03, -1.1422e-01,
         -1.5470e-02,  1.3273e-01,  3.0763e-01,  3.1500e-01,  2.9812e-01,
          2.8154e-01],
        [-2.8769e-01, -1.0009e-02, -3.3761e-01,  2.6060e-01, -2.4979e-01,
          1.7943e-01,  3.5444e-01,  2.8745e-01,  3.3408e-01,  2.3395e-01,
          2.0134e-01, -6.7368e-02,  5.6859e-02,  4.4486e-02, -1.0283e-01,
         -2.4000e-01],
        [-3.0398e-01, -1.9160e-01, -6.7277e-02,  3.2333e-02,  3.8931e-02,
          4.1777e-01,  4.0151e-01, -3.6245e-02,  2.0665e-01,  3.2766e-01,
         -1.7411e-01,  2.1155e-04, -2.8048e-01, -2.7546e-01, -3.0056e-01,
         -2.6289e-01],
        [ 8.7727e-02,  2.1961e-01,  2.9024e-01, -8.9455e-02,  1.9327e-01,
         -3.6193e-01, -4.3978e-01, -3.7275e-01, -2.9286e-01, -3.0060e-01,
          1.1526e-02, -1.1187e-02, -1.8837e-02,  2.7155e-01,  4.9658e-02,
          2.2144e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1088, -0.0446,  0.1707, -0.0413, -0.0613, -0.0242,  0.0604,  0.0516,
        -0.0349, -0.0393, -0.0187,  0.0660,  0.1097,  0.0866, -0.0019, -0.0163,
        -0.1546,  0.0351,  0.1057,  0.0075, -0.0032, -0.1646, -0.0238, -0.0587,
        -0.0577,  0.2048,  0.1130,  0.0341, -0.0618, -0.1365,  0.0264,  0.0179],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1903,  0.2817, -0.2082, -0.2376,  0.2560,  0.3044, -0.2597, -0.3620,
         -0.2862,  0.2999,  0.2444,  0.3561, -0.2153, -0.3606,  0.2813, -0.1347,
         -0.2777,  0.3203, -0.2120, -0.2268,  0.3304,  0.3377, -0.3572, -0.3632,
         -0.2515, -0.2842, -0.3033,  0.3213, -0.3462,  0.3692,  0.2813, -0.2212]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0118, -0.0042,  0.0258,  ...,  0.2088, -0.3487, -0.1137],
        [-0.0829, -0.1911,  0.0831,  ...,  0.1450, -0.3265,  0.0871],
        [-0.0531,  0.1588,  0.0908,  ...,  0.0113,  0.2321,  0.0345],
        ...,
        [ 0.0411, -0.1570,  0.0129,  ...,  0.0669, -0.2759, -0.1180],
        [ 0.0359, -0.0688,  0.0055,  ..., -0.3021,  0.1249,  0.1557],
        [-0.0842,  0.1624,  0.0122,  ..., -0.1722,  0.0583, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0512,  0.0541, -0.0928, -0.1202, -0.0576,  0.0456, -0.1290,  0.0622,
        -0.0466,  0.0923,  0.0329,  0.0081,  0.0093,  0.0628, -0.0786, -0.0206,
         0.0468, -0.1420, -0.0321, -0.0151, -0.1095,  0.0476,  0.0819, -0.0066,
        -0.0848,  0.0667,  0.0240, -0.0963,  0.0641,  0.1474,  0.1373, -0.0660],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0398, -0.1954, -0.0815,  ..., -0.1386, -0.0167,  0.2616],
        [-0.2343, -0.0443,  0.1042,  ..., -0.0691, -0.0032,  0.2704],
        [ 0.1635, -0.0203, -0.1756,  ...,  0.0818, -0.0231, -0.0677],
        ...,
        [ 0.1503,  0.1108,  0.0825,  ...,  0.2617, -0.2211,  0.0562],
        [-0.0514, -0.1728,  0.0756,  ...,  0.0039,  0.2483,  0.0852],
        [-0.0167, -0.1211,  0.2106,  ...,  0.0525,  0.1388,  0.1306]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0864,  0.1221, -0.0349, -0.0545, -0.0312, -0.0353, -0.0323, -0.0626,
         0.1098, -0.1746,  0.1226, -0.1330,  0.1650, -0.0184, -0.1431,  0.1049,
        -0.1269, -0.1536,  0.0133, -0.0296,  0.0089,  0.1089, -0.1886,  0.2022,
        -0.0702, -0.0290,  0.0883, -0.0380, -0.1119, -0.0597,  0.1104,  0.0005],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5117,  0.4359, -0.5139, -0.5173,  0.3622,  0.3702, -0.4184,  0.4270,
          0.4272, -0.4498, -0.4399,  0.4010,  0.4231, -0.3639,  0.4440,  0.3923,
         -0.5219, -0.5132,  0.3901,  0.4072, -0.4749, -0.4479, -0.5115,  0.3471,
          0.4862,  0.5128, -0.4866,  0.5545, -0.4222, -0.5040,  0.4886,  0.5039]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2339], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.3158e-02,  3.6482e-01,  3.2542e-01, -3.4399e-01, -1.0744e-02,
         -1.7897e-01, -6.9559e-02, -3.8396e-01, -1.6757e-01, -8.8154e-02,
          1.1016e-02,  1.6358e-01,  5.2959e-02, -4.6674e-02,  3.1438e-01,
          3.7148e-01],
        [-2.7541e-01, -3.4779e-01, -1.2842e-01,  1.0453e-02, -1.7577e-01,
          2.8452e-01,  1.8907e-01,  1.6275e-01,  3.9132e-01,  1.3631e-01,
          2.3917e-01, -2.6211e-01,  8.5372e-03, -4.8351e-02,  4.9153e-03,
         -8.9022e-02],
        [ 1.0137e-01,  2.5861e-01,  4.0529e-01, -1.3884e-01,  1.5570e-01,
         -3.7620e-01, -6.7107e-02, -4.0713e-01,  6.2414e-02, -8.6276e-02,
         -1.1238e-01, -7.1781e-02,  3.8847e-01,  3.1639e-01,  4.3216e-01,
          2.7311e-01],
        [ 2.9300e-01,  7.8315e-02,  1.0907e-01, -9.0181e-02,  1.1489e-01,
         -2.3143e-01, -1.7331e-01, -9.2147e-02, -3.9949e-01, -4.0603e-01,
         -1.2443e-01,  3.5596e-01,  2.7843e-01, -1.2189e-01,  1.3920e-01,
          1.6643e-01],
        [-1.1384e-01,  1.1103e-01, -1.8908e-01, -9.7327e-03,  3.5188e-02,
          1.2071e-01,  6.5684e-02,  3.4010e-01,  1.4813e-01,  2.9174e-01,
          2.5400e-01, -1.7534e-01, -4.4909e-02, -2.2711e-01, -7.6097e-02,
         -1.4217e-01],
        [-1.9119e-02,  1.3842e-01, -3.7478e-01,  4.0746e-01,  1.4558e-01,
          1.4638e-03,  2.7423e-01, -2.6708e-02,  2.4188e-01,  2.0429e-01,
         -1.2214e-01, -8.4949e-02, -2.3979e-01,  1.3389e-01,  3.9917e-02,
         -7.3049e-02],
        [ 3.9445e-01,  2.1173e-01,  4.3475e-01, -2.0172e-01,  1.4288e-01,
         -2.5130e-01, -2.1258e-01, -2.3305e-01, -2.4268e-01, -3.1199e-02,
         -3.5276e-02,  5.6266e-02, -4.0414e-02,  2.3451e-01, -1.4087e-02,
          1.6809e-01],
        [-4.3777e-02,  3.2370e-01,  3.7666e-01, -3.6157e-01, -1.3456e-01,
         -3.3177e-01, -1.1029e-01, -2.4165e-01, -1.7168e-01, -2.1716e-01,
         -8.5001e-02,  1.2493e-02,  2.4832e-01, -7.9760e-02,  1.5960e-01,
          3.6961e-01],
        [ 5.6498e-02,  3.1422e-01,  3.2716e-01, -2.6683e-01,  4.5044e-02,
         -3.8259e-01, -1.8461e-01, -1.0747e-01,  4.8640e-02, -3.1620e-01,
         -1.2966e-01,  6.6699e-02, -8.8592e-02,  1.4557e-01,  1.0175e-02,
          1.0059e-01],
        [-3.0435e-01, -9.3644e-02, -1.1680e-01, -1.8003e-03, -5.9400e-02,
          1.8757e-01,  6.6445e-02,  2.4594e-01,  2.6219e-01, -6.6944e-03,
          2.5862e-01, -1.2741e-02, -2.5328e-01, -6.9803e-02, -1.8138e-01,
         -1.9345e-01],
        [-3.6988e-01,  6.1113e-02, -8.2005e-02, -2.8239e-02, -1.9044e-01,
          4.5579e-01,  2.4710e-01,  1.1436e-01,  3.2936e-01,  2.5211e-01,
          8.5481e-02,  1.7683e-02, -1.5396e-01,  1.2833e-01, -3.8638e-01,
         -3.3759e-01],
        [-1.4573e-01, -1.5518e-01, -4.5901e-02,  1.0427e-01,  9.8240e-02,
          1.5348e-01,  3.9063e-01,  1.5720e-01,  1.6229e-01,  3.4750e-01,
          1.7335e-01,  5.6584e-02, -3.9425e-01, -2.0881e-01, -2.5701e-01,
         -2.0678e-01],
        [ 3.6627e-01,  2.3357e-01,  2.0319e-01, -1.9886e-01,  9.4035e-02,
         -2.5934e-02, -1.1406e-01, -3.2929e-01, -3.2904e-01, -1.2408e-01,
         -1.4276e-01,  3.0273e-02, -3.2854e-02,  1.9966e-01,  1.6515e-01,
          4.3789e-02],
        [ 2.3609e-01,  3.6296e-01,  3.9756e-01, -3.1691e-02, -1.6382e-01,
         -6.2193e-02, -7.2706e-02, -8.0993e-02, -2.1432e-01, -1.7382e-01,
         -2.3194e-01,  1.1762e-01,  1.2409e-01,  7.4821e-02, -3.8969e-02,
          2.5488e-01],
        [-3.9611e-01, -3.1293e-01, -9.2382e-02, -2.8689e-02,  1.8941e-01,
          4.4615e-01,  1.2139e-01,  1.1567e-01, -4.4997e-02,  1.8764e-01,
          1.4540e-01, -3.0575e-01, -7.9393e-02, -1.2361e-01, -2.8012e-01,
         -1.7603e-01],
        [-9.4399e-02, -1.4541e-01,  1.7606e-01,  1.0010e-01, -1.8124e-01,
         -9.9540e-03, -1.5157e-01, -2.8313e-01, -1.5051e-01, -4.7861e-03,
         -1.1897e-02,  4.0894e-01,  1.0397e-01, -9.8946e-02,  3.9945e-01,
          3.1048e-02],
        [ 3.3427e-01,  2.8307e-01,  2.2229e-01, -3.6673e-01, -1.9262e-01,
         -7.2485e-02, -1.2350e-01,  2.8460e-03, -3.5010e-01, -1.9137e-01,
          1.2201e-01,  2.7969e-01,  3.4079e-01,  2.9266e-01,  1.2670e-01,
         -1.1111e-02],
        [-3.1741e-01, -2.9994e-02, -2.6971e-01,  1.5471e-01, -2.5277e-02,
          3.3853e-01,  3.1426e-01,  2.7233e-01,  1.2752e-01,  2.9002e-01,
         -2.1205e-02, -2.3971e-01, -1.6217e-01, -2.2931e-01,  4.2836e-02,
         -1.9234e-01],
        [ 2.5402e-01,  1.4295e-01,  1.8080e-01, -3.1285e-01,  5.6310e-03,
         -4.1519e-01, -3.1192e-01,  3.4340e-02, -3.8129e-01, -1.4198e-01,
         -5.9432e-02, -8.9045e-02,  1.8880e-01,  2.6523e-01,  3.7071e-01,
          2.1669e-01],
        [ 3.9144e-01,  1.4963e-01,  2.9561e-01, -1.0621e-01, -1.5773e-01,
         -2.6714e-01, -3.7645e-01,  3.7439e-02, -2.8671e-02, -2.8309e-01,
         -8.4631e-02,  2.3747e-01, -8.2600e-02,  1.1292e-01,  3.2689e-01,
          2.1443e-01],
        [-1.9873e-01,  6.9857e-02, -6.8069e-02, -5.6228e-02,  1.3773e-01,
         -1.3055e-03,  3.2964e-01,  3.9019e-01,  1.8263e-01,  7.2778e-02,
         -5.3875e-02, -2.9124e-01, -1.9568e-01, -2.0384e-01,  5.1696e-02,
         -2.5584e-01],
        [-8.0979e-02, -3.4959e-01, -6.0777e-02,  3.8833e-01, -1.6763e-01,
          1.3901e-01,  2.5357e-01, -7.5108e-02, -8.0092e-04,  2.5563e-01,
          2.6971e-01, -2.4702e-01, -1.4496e-01, -3.4455e-01, -4.4560e-01,
          5.4918e-02],
        [ 3.7791e-01,  4.2656e-02,  7.0360e-02, -1.6856e-01,  1.7292e-01,
         -4.2321e-01, -3.1052e-01, -2.0472e-01, -2.2354e-01, -1.5504e-01,
          1.0348e-01,  1.9081e-01, -1.1670e-01,  3.1744e-01,  3.7805e-01,
          2.3242e-01],
        [ 2.7758e-01,  2.1047e-01,  3.6398e-01, -3.8186e-01, -7.6145e-02,
         -2.0249e-01, -2.0538e-01, -2.6545e-01, -3.3628e-01, -3.2887e-01,
         -1.1732e-01,  3.2736e-01,  2.4984e-01,  1.5274e-01,  6.0151e-03,
          4.7840e-02],
        [ 2.2649e-01, -1.2389e-01,  1.9097e-01, -1.3961e-01,  2.1112e-01,
         -2.8810e-01,  2.3303e-02, -1.8385e-01, -3.5530e-01,  5.5510e-02,
          1.4802e-01,  2.9496e-03,  4.1245e-02,  2.3832e-01,  7.0482e-02,
          3.3531e-01],
        [ 7.0112e-02,  2.4236e-02,  1.1961e-01,  6.0732e-02, -6.2485e-02,
         -2.5943e-01, -5.4185e-02, -3.5606e-01, -1.7215e-01, -3.6401e-01,
         -3.1404e-01,  1.2756e-01,  1.8908e-01,  3.3281e-01, -2.7348e-02,
          8.9734e-02],
        [ 2.3590e-01,  2.1814e-01,  3.1986e-01, -3.5687e-01,  9.4753e-03,
         -1.2699e-01, -3.7705e-01,  6.2727e-03, -3.5221e-01,  2.9798e-03,
         -1.2519e-02,  6.2628e-02,  1.9346e-01,  3.0440e-01,  3.6491e-01,
          3.1211e-01],
        [-3.3452e-01, -4.9792e-02, -1.8996e-03,  2.1546e-01,  1.8392e-01,
          5.0282e-02,  3.8027e-01,  1.6395e-01, -6.7476e-02,  1.0026e-01,
          2.3996e-01, -2.6384e-01, -2.0206e-01, -1.9418e-01, -3.3978e-01,
         -1.1715e-01],
        [ 3.2351e-01,  1.5503e-01,  1.5999e-01, -1.4103e-01, -1.6811e-01,
         -3.2079e-01, -1.6477e-01, -3.3733e-01, -4.3916e-03, -1.1422e-01,
         -1.5469e-02,  1.3273e-01,  3.0763e-01,  3.1500e-01,  2.9812e-01,
          2.8154e-01],
        [-2.8769e-01, -1.0009e-02, -3.3761e-01,  2.6060e-01, -2.4979e-01,
          1.7943e-01,  3.5444e-01,  2.8745e-01,  3.3408e-01,  2.3395e-01,
          2.0134e-01, -6.7368e-02,  5.6858e-02,  4.4487e-02, -1.0283e-01,
         -2.4000e-01],
        [-3.0398e-01, -1.9160e-01, -6.7277e-02,  3.2332e-02,  3.8932e-02,
          4.1777e-01,  4.0151e-01, -3.6245e-02,  2.0665e-01,  3.2766e-01,
         -1.7411e-01,  2.1146e-04, -2.8048e-01, -2.7546e-01, -3.0056e-01,
         -2.6289e-01],
        [ 8.7727e-02,  2.1961e-01,  2.9024e-01, -8.9454e-02,  1.9327e-01,
         -3.6193e-01, -4.3978e-01, -3.7275e-01, -2.9286e-01, -3.0060e-01,
          1.1527e-02, -1.1186e-02, -1.8837e-02,  2.7155e-01,  4.9658e-02,
          2.2143e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.1088, -0.0446,  0.1707, -0.0413, -0.0613, -0.0242,  0.0604,  0.0516,
        -0.0349, -0.0393, -0.0187,  0.0660,  0.1097,  0.0866, -0.0019, -0.0163,
        -0.1546,  0.0351,  0.1057,  0.0075, -0.0032, -0.1646, -0.0238, -0.0587,
        -0.0577,  0.2048,  0.1130,  0.0341, -0.0618, -0.1365,  0.0264,  0.0179],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.1903,  0.2817, -0.2082, -0.2376,  0.2560,  0.3044, -0.2597, -0.3620,
         -0.2862,  0.2999,  0.2444,  0.3561, -0.2153, -0.3606,  0.2813, -0.1347,
         -0.2777,  0.3203, -0.2120, -0.2268,  0.3304,  0.3377, -0.3572, -0.3632,
         -0.2515, -0.2842, -0.3033,  0.3213, -0.3462,  0.3692,  0.2813, -0.2212]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0118, -0.0042,  0.0258,  ...,  0.2088, -0.3487, -0.1137],
        [-0.0829, -0.1911,  0.0831,  ...,  0.1450, -0.3265,  0.0871],
        [-0.0531,  0.1588,  0.0908,  ...,  0.0113,  0.2321,  0.0345],
        ...,
        [ 0.0411, -0.1570,  0.0129,  ...,  0.0669, -0.2759, -0.1180],
        [ 0.0359, -0.0688,  0.0055,  ..., -0.3021,  0.1249,  0.1557],
        [-0.0842,  0.1624,  0.0122,  ..., -0.1722,  0.0583, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0512,  0.0541, -0.0928, -0.1202, -0.0576,  0.0456, -0.1290,  0.0622,
        -0.0466,  0.0923,  0.0329,  0.0081,  0.0093,  0.0628, -0.0786, -0.0206,
         0.0468, -0.1420, -0.0321, -0.0151, -0.1095,  0.0476,  0.0819, -0.0066,
        -0.0848,  0.0667,  0.0240, -0.0963,  0.0641,  0.1474,  0.1373, -0.0660],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0398, -0.1954, -0.0815,  ..., -0.1386, -0.0167,  0.2616],
        [-0.2343, -0.0443,  0.1042,  ..., -0.0691, -0.0032,  0.2704],
        [ 0.1635, -0.0203, -0.1756,  ...,  0.0818, -0.0231, -0.0677],
        ...,
        [ 0.1503,  0.1108,  0.0825,  ...,  0.2617, -0.2211,  0.0562],
        [-0.0514, -0.1728,  0.0756,  ...,  0.0039,  0.2483,  0.0852],
        [-0.0167, -0.1211,  0.2106,  ...,  0.0525,  0.1388,  0.1306]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0864,  0.1221, -0.0349, -0.0545, -0.0312, -0.0353, -0.0323, -0.0626,
         0.1098, -0.1746,  0.1226, -0.1330,  0.1650, -0.0184, -0.1431,  0.1049,
        -0.1269, -0.1536,  0.0133, -0.0296,  0.0089,  0.1089, -0.1886,  0.2022,
        -0.0702, -0.0290,  0.0883, -0.0380, -0.1119, -0.0597,  0.1104,  0.0005],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5117,  0.4359, -0.5139, -0.5173,  0.3622,  0.3702, -0.4184,  0.4270,
          0.4272, -0.4498, -0.4399,  0.4010,  0.4231, -0.3639,  0.4440,  0.3923,
         -0.5219, -0.5132,  0.3901,  0.4072, -0.4749, -0.4479, -0.5115,  0.3471,
          0.4862,  0.5128, -0.4866,  0.5545, -0.4222, -0.5040,  0.4886,  0.5039]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2339], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 0.0070,  0.3613,  0.3206, -0.3146, -0.3077, -0.1983, -0.0874, -0.4735,
         -0.2458, -0.0862, -0.0284,  0.2457,  0.0992, -0.0324,  0.0291,  0.3674],
        [-0.2596, -0.3385, -0.1146, -0.0117,  0.0533,  0.2820,  0.1939,  0.2247,
          0.4474,  0.1518,  0.2879, -0.3085, -0.0140, -0.0773,  0.2602, -0.0813],
        [ 0.0888,  0.2496,  0.3928, -0.1095, -0.1646, -0.3781, -0.0779, -0.4928,
         -0.0240, -0.0847, -0.1407, -0.0088,  0.4279,  0.3654,  0.1402,  0.2640],
        [ 0.2845,  0.0740,  0.1017, -0.0721, -0.1394, -0.2367, -0.1882, -0.1724,
         -0.4837, -0.4270, -0.1228,  0.4226,  0.3030, -0.0754, -0.1273,  0.1612],
        [-0.1023,  0.0843, -0.1827, -0.0311,  0.2459,  0.1214,  0.0729,  0.3927,
          0.1988,  0.3162,  0.3233, -0.2111, -0.0665, -0.2775,  0.1943, -0.1574],
        [-0.0170,  0.1231, -0.3751,  0.4016,  0.4212,  0.0125,  0.2935,  0.0393,
          0.3098,  0.2351, -0.0913, -0.1383, -0.2669,  0.0905,  0.3092, -0.0821],
        [ 0.3840,  0.1187,  0.4245, -0.1864, -0.1308, -0.2501, -0.2133, -0.3084,
         -0.3139, -0.0491, -0.0581,  0.1147, -0.0389,  0.2689, -0.1890,  0.1614],
        [-0.0517,  0.2687,  0.3689, -0.3539, -0.3935, -0.3283, -0.1122, -0.3196,
         -0.2445, -0.2348, -0.1036,  0.0720,  0.2675, -0.0491,  0.0035,  0.3622],
        [ 0.0461,  0.3062,  0.3184, -0.2428, -0.1297, -0.3860, -0.1987, -0.1722,
         -0.0103, -0.3368, -0.2615,  0.1084, -0.0428,  0.2047, -0.2466,  0.0988],
        [-0.2986, -0.1077, -0.1144, -0.0156,  0.1599,  0.1966,  0.0845,  0.3139,
          0.3281,  0.0231,  0.3330, -0.0603, -0.2922, -0.1253,  0.0935, -0.2035],
        [-0.3704,  0.0458, -0.0835, -0.0333,  0.0489,  0.4707,  0.2694,  0.2024,
          0.4158,  0.2827,  0.1361, -0.0547, -0.1803,  0.0677, -0.0755, -0.3420],
        [-0.1381, -0.1621, -0.0422,  0.0900,  0.2508,  0.1611,  0.4048,  0.2267,
          0.2220,  0.3759,  0.2533,  0.0089, -0.3988, -0.2854, -0.0110, -0.2129],
        [ 0.3500,  0.2510,  0.1893, -0.1728, -0.2318, -0.0334, -0.1323, -0.4310,
         -0.3999, -0.1416, -0.1640,  0.1059, -0.0177,  0.2222, -0.1723,  0.0429],
        [ 0.2203,  0.3354,  0.3837, -0.0130, -0.3796, -0.0568, -0.0718, -0.1353,
         -0.2660, -0.1886, -0.2755,  0.1558,  0.1425,  0.1045, -0.2521,  0.2463],
        [-0.3864, -0.2987, -0.0833, -0.0432,  0.4418,  0.4457,  0.1295,  0.1871,
          0.0237,  0.2060,  0.1880, -0.3601, -0.1076, -0.1595, -0.0476, -0.1702],
        [-0.0622, -0.0695,  0.2163,  0.0906, -0.4329, -0.0817, -0.2362, -0.4150,
         -0.2822, -0.0919, -0.1280,  0.4821,  0.1983,  0.0241,  0.1549,  0.0782],
        [ 0.3282,  0.2710,  0.2175, -0.3559, -0.4389, -0.0785, -0.1371, -0.0735,
         -0.4249, -0.2148,  0.0965,  0.3437,  0.3842,  0.3322, -0.0703, -0.0159],
        [-0.3067, -0.0095, -0.2604,  0.1437,  0.1974,  0.3319,  0.3152,  0.3328,
          0.1912,  0.3072,  0.0023, -0.2879, -0.1793, -0.2690,  0.2105, -0.1853],
        [ 0.2275,  0.1189,  0.1530, -0.2678, -0.3098, -0.4078, -0.3153, -0.0516,
         -0.4713, -0.1236, -0.1112, -0.0280,  0.2527,  0.3167,  0.0929,  0.1880],
        [ 0.3865,  0.1374,  0.2899, -0.0909, -0.3984, -0.2734, -0.3930, -0.0487,
         -0.1102, -0.3041, -0.1527,  0.3047, -0.0370,  0.1612,  0.0926,  0.2090],
        [-0.1897,  0.0526, -0.0621, -0.0684,  0.3412, -0.0050,  0.3339,  0.4207,
          0.2227,  0.0943, -0.0074, -0.3147, -0.2102, -0.2447,  0.2951, -0.2632],
        [-0.0809, -0.3357, -0.0611,  0.3777,  0.0535,  0.1535,  0.2847,  0.0121,
          0.0777,  0.2872,  0.3834, -0.3073, -0.2143, -0.4061, -0.1754,  0.0513],
        [ 0.3772,  0.0338,  0.0698, -0.1657, -0.0645, -0.4311, -0.3276, -0.2873,
         -0.3036, -0.1815,  0.0640,  0.2561, -0.0709,  0.3655,  0.1879,  0.2316],
        [ 0.2684,  0.2034,  0.3560, -0.3747, -0.2887, -0.1956, -0.2089, -0.3358,
         -0.4042, -0.3453, -0.0999,  0.3827,  0.2658,  0.1858, -0.1502,  0.0369],
        [ 0.2212, -0.1086,  0.1887, -0.1214, -0.0207, -0.3001,  0.0057, -0.2499,
         -0.4240,  0.0256,  0.0706,  0.0566,  0.0819,  0.2901, -0.2256,  0.3477],
        [ 0.0514,  0.0317,  0.1035,  0.0813, -0.2892, -0.2450, -0.0463, -0.3894,
         -0.2080, -0.3757, -0.3594,  0.1511,  0.1930,  0.3604, -0.2848,  0.0889],
        [ 0.2337,  0.1982,  0.3174, -0.3520, -0.2419, -0.1334, -0.3914, -0.0824,
         -0.4362, -0.0204, -0.0434,  0.1330,  0.2395,  0.3462,  0.1840,  0.3074],
        [-0.3301, -0.0557, -0.0006,  0.2055,  0.3859,  0.0615,  0.3989,  0.2427,
          0.0027,  0.1312,  0.2975, -0.3218, -0.2363, -0.2517, -0.0911, -0.1236],
        [ 0.3166,  0.1663,  0.1552, -0.1346, -0.3710, -0.3241, -0.1777, -0.4071,
         -0.0717, -0.1366, -0.0071,  0.1899,  0.3103,  0.3623,  0.0717,  0.2780],
        [-0.2830,  0.0207, -0.3333,  0.2558, -0.0163,  0.1786,  0.3618,  0.3602,
          0.4054,  0.2557,  0.2394, -0.1231,  0.0295,  0.0023,  0.0615, -0.2377],
        [-0.2995, -0.1875, -0.0634,  0.0219,  0.2715,  0.4250,  0.4163,  0.0432,
          0.2843,  0.3510, -0.1249, -0.0635, -0.3253, -0.3255, -0.0770, -0.2593],
        [ 0.0683,  0.1794,  0.2708, -0.0495, -0.0685, -0.3563, -0.4389, -0.4455,
         -0.3687, -0.2938, -0.0377,  0.0414,  0.0051,  0.3177, -0.1746,  0.2037]],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0493, -0.0141,  0.1116, -0.0330, -0.0615, -0.0984,  0.0759,  0.0852,
        -0.0193, -0.0625, -0.0092,  0.0593,  0.1529,  0.0811,  0.0172, -0.0409,
        -0.0480, -0.0059,  0.0950,  0.0066, -0.0479, -0.1426, -0.0265,  0.0020,
         0.0006,  0.1648,  0.1217,  0.0182, -0.0638, -0.1428,  0.0289, -0.0432],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2306,  0.3221, -0.2284, -0.2619,  0.3231,  0.3608, -0.2830, -0.3850,
         -0.3160,  0.3462,  0.2640,  0.3744, -0.2637, -0.3994,  0.3044, -0.2816,
         -0.3210,  0.3327, -0.2284, -0.2511,  0.4001,  0.3136, -0.3723, -0.3798,
         -0.3287, -0.3399, -0.3144,  0.3514, -0.3603,  0.3842,  0.2902, -0.2380]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0135, -0.0085,  0.0428,  ...,  0.2362, -0.3625, -0.1137],
        [-0.0864, -0.1919,  0.0869,  ...,  0.1477, -0.3432,  0.0871],
        [-0.0405,  0.1757,  0.0741,  ..., -0.0051,  0.2611,  0.0345],
        ...,
        [ 0.0262, -0.1902,  0.0414,  ...,  0.0660, -0.2852, -0.1180],
        [ 0.0511, -0.0493, -0.0188,  ..., -0.3041,  0.1487,  0.1557],
        [-0.2044,  0.0501,  0.0011,  ...,  0.0416, -0.2295, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0573,  0.0578, -0.0887, -0.1184, -0.0570,  0.0523, -0.1282,  0.0616,
        -0.0495,  0.0822,  0.0317,  0.0088,  0.0252,  0.0728, -0.0786, -0.0172,
         0.0504, -0.1493, -0.0281, -0.0236, -0.0750,  0.0444,  0.0882, -0.0076,
        -0.0866,  0.0864,  0.0327, -0.0879,  0.0491,  0.1391,  0.1473, -0.1046],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0201, -0.1879, -0.0824,  ..., -0.1142, -0.0325,  0.0716],
        [-0.2630, -0.0416,  0.1129,  ..., -0.0460, -0.0124,  0.0597],
        [ 0.1818, -0.0323, -0.1737,  ...,  0.0517, -0.0039,  0.1657],
        ...,
        [ 0.1643,  0.0943,  0.0915,  ...,  0.2262, -0.1959,  0.2413],
        [-0.0763, -0.1609,  0.0747,  ...,  0.0351,  0.2312, -0.1638],
        [-0.0470, -0.1229,  0.2138,  ...,  0.0730,  0.1300, -0.0313]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0825,  0.1203, -0.0215, -0.0575, -0.0356, -0.0636, -0.0246, -0.0612,
         0.0932, -0.1336,  0.1362, -0.1279,  0.1503,  0.0565, -0.1356,  0.0860,
        -0.1166, -0.1444,  0.0018, -0.0153,  0.0086,  0.1111, -0.1820,  0.1717,
        -0.0654, -0.0321,  0.0920, -0.0438, -0.1079, -0.0522,  0.0934,  0.0021],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.5000,  0.4216, -0.4987, -0.5019,  0.3663,  0.3572, -0.4133,  0.4079,
          0.4331, -0.4366, -0.3975,  0.3935,  0.3922,  0.4023,  0.4311,  0.3838,
         -0.5003, -0.5059,  0.3703,  0.3957, -0.4551, -0.4335, -0.4994,  0.3604,
          0.4836,  0.5082, -0.4835,  0.5325, -0.4119, -0.4973,  0.4780,  0.5000]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2203], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[ 1.6370e-02,  9.6004e-02,  3.0973e-01, -3.4445e-01, -2.7557e-01,
         -1.5802e-01, -6.4680e-02, -4.3941e-01, -1.9860e-01, -7.1166e-02,
          1.7154e-01,  2.0631e-01,  6.7722e-02, -3.6713e-02, -1.5941e-01,
          3.8140e-01],
        [-2.6550e-01, -9.6542e-02, -1.0812e-01,  2.2899e-02,  3.7399e-02,
          2.5248e-01,  1.7069e-01,  1.9869e-01,  4.3344e-01,  1.4783e-01,
          7.1439e-02, -2.8003e-01, -1.4206e-02, -7.1972e-02,  4.4763e-01,
         -9.1209e-02],
        [ 9.2548e-02,  3.1310e-02,  3.8036e-01, -1.3517e-01, -1.2678e-01,
         -3.4469e-01, -4.2928e-02, -4.4872e-01,  1.6050e-02, -7.1444e-02,
         -9.0666e-02, -4.4407e-02,  4.0580e-01,  3.3634e-01, -3.3743e-02,
          2.6900e-01],
        [ 2.7684e-01, -3.6888e-02,  8.0798e-02, -9.4315e-02, -1.0262e-01,
         -1.8878e-01, -1.4498e-01, -1.2240e-01, -4.4002e-01, -4.0617e-01,
          2.7330e-02,  3.7015e-01,  3.0309e-01, -1.0073e-01, -2.7248e-01,
          1.5497e-01],
        [-1.0424e-01,  3.1420e-01, -1.7075e-01,  1.7879e-03,  2.1996e-01,
          8.5072e-02,  4.1004e-02,  3.5686e-01,  1.7172e-01,  3.0790e-01,
          7.1538e-02, -1.7520e-01, -5.9248e-02, -2.6231e-01,  3.6206e-01,
         -1.6446e-01],
        [-7.1192e-03,  3.0025e-01, -3.5542e-01,  4.2140e-01,  3.6855e-01,
         -3.8005e-02,  2.5096e-01, -9.6406e-03,  2.7340e-01,  2.1677e-01,
         -1.0824e-01, -9.4709e-02, -2.3756e-01,  1.1123e-01,  4.2852e-01,
         -7.9560e-02],
        [ 3.7784e-01,  7.0111e-03,  4.0670e-01, -2.0820e-01, -1.0647e-01,
         -2.1034e-01, -1.7333e-01, -2.6698e-01, -2.7580e-01, -3.4610e-02,
         -1.2601e-03,  7.5179e-02, -5.5905e-02,  1.9715e-01, -3.4130e-01,
          1.5828e-01],
        [-5.6608e-02,  1.4986e-01,  3.5556e-01, -3.7601e-01, -3.7662e-01,
         -2.9857e-01, -8.3797e-02, -2.9222e-01, -2.2478e-01, -2.2777e-01,
         -6.5835e-02,  4.7954e-02,  2.5654e-01, -8.6692e-02, -1.2502e-01,
          3.5973e-01],
        [ 5.2815e-02,  4.5625e-02,  3.1272e-01, -2.8094e-01, -1.1674e-01,
         -3.5450e-01, -1.7506e-01, -1.4635e-01,  7.6197e-03, -3.3393e-01,
          8.3042e-03,  8.0258e-02, -4.2873e-02,  2.0145e-01, -4.2370e-01,
          1.1184e-01],
        [-3.0306e-01,  1.4334e-01, -1.0706e-01,  1.9731e-02,  1.3502e-01,
          1.6255e-01,  5.5129e-02,  2.7899e-01,  3.0270e-01,  1.7496e-02,
          1.1121e-01, -2.8635e-02, -2.8289e-01, -1.1837e-01,  2.6435e-01,
         -2.1498e-01],
        [-3.6801e-01,  1.9313e-01, -6.7463e-02, -7.6486e-03,  1.9560e-02,
          4.2953e-01,  2.3721e-01,  1.6146e-01,  3.8375e-01,  2.6765e-01,
          9.3026e-03, -1.3571e-02, -2.1858e-01,  7.0234e-02,  7.2110e-02,
         -3.4290e-01],
        [-1.3129e-01,  2.2527e-04, -2.4092e-02,  1.1595e-01,  2.0941e-01,
          1.2087e-01,  3.5695e-01,  1.7505e-01,  1.8143e-01,  3.5844e-01,
          9.1678e-02,  5.3436e-02, -4.2367e-01, -2.5252e-01,  1.2413e-01,
         -2.1081e-01],
        [ 3.5187e-01,  2.1213e-02,  1.7181e-01, -2.0580e-01, -1.8711e-01,
          1.4416e-02, -9.6246e-02, -3.8164e-01, -3.6690e-01, -1.2508e-01,
         -9.9157e-02,  6.0128e-02, -7.3155e-03,  2.2123e-01, -3.7695e-01,
          4.8108e-02],
        [ 2.1886e-01,  1.2874e-01,  3.7241e-01, -4.0224e-02, -3.5768e-01,
         -2.6166e-02, -4.0456e-02, -1.0381e-01, -2.4860e-01, -1.8057e-01,
         -1.1162e-01,  1.2654e-01,  1.3494e-01,  7.7829e-02, -4.1950e-01,
          2.4877e-01],
        [-3.8891e-01, -8.4301e-02, -7.3934e-02, -1.2610e-02,  4.2907e-01,
          4.1800e-01,  1.0463e-01,  1.6230e-01,  4.9985e-03,  2.0121e-01,
          4.0449e-02, -3.3339e-01, -1.1011e-01, -1.4702e-01,  1.3912e-01,
         -1.7524e-01],
        [-2.8917e-02, -3.7336e-01,  2.1795e-01,  2.1473e-02, -4.3552e-01,
         -3.4877e-02, -2.0934e-01, -3.9365e-01, -2.6445e-01, -9.1085e-02,
         -5.6462e-02,  4.5461e-01,  1.9715e-01,  1.3297e-03, -7.4250e-02,
          1.1433e-01],
        [ 3.2140e-01,  1.1469e-01,  2.0052e-01, -3.7735e-01, -3.8564e-01,
         -3.6517e-02, -9.1224e-02, -2.2495e-02, -3.9548e-01, -1.9767e-01,
          1.9291e-01,  2.9970e-01,  3.5644e-01,  2.8239e-01, -1.8277e-01,
         -2.1050e-02],
        [-2.9489e-01,  1.0582e-01, -2.3874e-01,  1.5947e-01,  1.4746e-01,
          2.9087e-01,  2.6987e-01,  2.8574e-01,  1.5233e-01,  2.9045e-01,
         -4.7160e-02, -2.4839e-01, -1.5288e-01, -2.0472e-01,  2.7580e-01,
         -1.7519e-01],
        [ 2.4232e-01, -6.5868e-02,  1.5299e-01, -3.0485e-01, -2.4139e-01,
         -3.8055e-01, -2.8022e-01, -2.4043e-03, -4.2771e-01, -1.2112e-01,
          1.1344e-02, -6.2580e-02,  2.0823e-01,  2.7064e-01, -4.7597e-02,
          2.0418e-01],
        [ 3.8315e-01, -4.0073e-02,  2.7169e-01, -1.1728e-01, -3.7257e-01,
         -2.3551e-01, -3.5655e-01, -1.1437e-02, -8.0161e-02, -2.8913e-01,
          8.7200e-02,  2.6444e-01, -3.4067e-02,  1.3229e-01, -8.7651e-02,
          2.0658e-01],
        [-1.8038e-01,  2.2492e-01, -4.2028e-02, -5.0870e-02,  2.9898e-01,
         -4.3753e-02,  2.9634e-01,  3.8094e-01,  1.9406e-01,  7.9019e-02,
         -1.0421e-01, -2.7769e-01, -1.9867e-01, -2.1299e-01,  4.0843e-01,
         -2.5762e-01],
        [-9.5970e-02, -1.5843e-02, -6.3251e-02,  4.2425e-01,  5.3615e-02,
          1.2880e-01,  2.6723e-01, -5.8520e-03,  7.0603e-02,  2.9408e-01,
          2.1683e-01, -2.9566e-01, -2.2063e-01, -4.0480e-01, -1.5062e-02,
          3.4782e-02],
        [ 3.7469e-01, -1.3292e-01,  5.6357e-02, -1.9150e-01, -4.0561e-02,
         -4.0074e-01, -2.9549e-01, -2.5883e-01, -2.8155e-01, -1.7384e-01,
          2.0228e-01,  2.2880e-01, -6.5777e-02,  3.3339e-01,  4.2479e-02,
          2.2967e-01],
        [ 2.5682e-01,  1.2648e-01,  3.3650e-01, -3.9071e-01, -2.2859e-01,
         -1.5909e-01, -1.6551e-01, -2.9020e-01, -3.7057e-01, -3.2808e-01,
          1.5697e-02,  3.4856e-01,  2.6990e-01,  1.3332e-01, -2.1628e-01,
          2.2846e-02],
        [ 2.1899e-01, -3.4591e-01,  1.7528e-01, -1.5267e-01,  1.5265e-02,
         -2.5432e-01,  4.6159e-02, -2.0073e-01, -3.8427e-01,  3.8872e-02,
          1.9275e-01,  1.2475e-02,  6.2021e-02,  2.7856e-01, -3.9151e-01,
          3.5525e-01],
        [ 4.9432e-02, -1.6016e-01,  8.9298e-02,  5.7559e-02, -2.5601e-01,
         -2.1418e-01, -2.2501e-02, -3.5751e-01, -1.8669e-01, -3.6681e-01,
         -2.7301e-01,  1.2174e-01,  1.9970e-01,  3.4626e-01, -4.5131e-01,
          8.8734e-02],
        [ 2.2710e-01,  1.1168e-02,  2.9732e-01, -3.7193e-01, -2.0778e-01,
         -1.0002e-01, -3.4874e-01, -4.6712e-02, -4.0525e-01, -6.7442e-03,
          4.2933e-02,  9.7228e-02,  2.3493e-01,  2.8267e-01,  5.2143e-02,
          2.9835e-01],
        [-3.3201e-01,  1.4396e-01,  1.0571e-02,  2.3775e-01,  3.5523e-01,
          2.6644e-02,  3.6042e-01,  2.0166e-01, -3.1438e-02,  1.2200e-01,
          7.6781e-02, -2.8467e-01, -2.3483e-01, -2.2481e-01,  5.8249e-02,
         -1.2942e-01],
        [ 3.0700e-01,  6.4868e-02,  1.3421e-01, -1.5372e-01, -3.2461e-01,
         -2.8663e-01, -1.3806e-01, -3.6246e-01, -3.8521e-02, -1.1906e-01,
          1.0686e-01,  1.4915e-01,  3.5910e-01,  3.3290e-01, -3.5403e-02,
          2.6866e-01],
        [-2.7626e-01,  1.4104e-01, -3.1758e-01,  2.7645e-01, -3.8620e-02,
          1.4781e-01,  3.2833e-01,  3.2876e-01,  3.7967e-01,  2.4594e-01,
          1.5263e-01, -9.6687e-02,  4.0079e-02,  4.3136e-02,  1.9081e-01,
         -2.3275e-01],
        [-2.9167e-01, -5.3516e-03, -4.2911e-02,  4.2986e-02,  2.3208e-01,
          3.8295e-01,  3.7475e-01,  1.0188e-03,  2.5152e-01,  3.3456e-01,
         -2.2514e-01, -1.9977e-02, -3.1774e-01, -2.8955e-01,  6.0086e-02,
         -2.5280e-01],
        [ 6.7836e-02,  7.7945e-03,  2.5504e-01, -7.7487e-02, -3.3048e-02,
         -3.1800e-01, -3.9444e-01, -3.8910e-01, -3.2458e-01, -2.7821e-01,
          8.9124e-02, -5.9311e-03, -2.7409e-02,  2.4314e-01, -3.2427e-01,
          2.0609e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0670, -0.0599,  0.1107, -0.0766, -0.0497, -0.0244,  0.0822,  0.1307,
        -0.0492, -0.0640,  0.0286,  0.0707,  0.1905,  0.1065, -0.0525,  0.0982,
        -0.1512, -0.0006,  0.0190, -0.0032, -0.0169, -0.1080, -0.0635, -0.0262,
        -0.1606,  0.2546,  0.1001,  0.0280, -0.0883, -0.2236,  0.1660, -0.0332],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2474,  0.3338, -0.2437, -0.2574,  0.3353,  0.3776, -0.2956, -0.3815,
         -0.3297,  0.3789,  0.2618,  0.3892, -0.2789, -0.4201,  0.3187, -0.3032,
         -0.3256,  0.3272, -0.2360, -0.2560,  0.4151,  0.3378, -0.3722, -0.3750,
         -0.3758, -0.3538, -0.3189,  0.3624, -0.3465,  0.3844,  0.2884, -0.2373]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0546,  0.1290,  0.0578,  ...,  0.2196, -0.3235, -0.1137],
        [-0.1237, -0.0287,  0.1170,  ...,  0.1552, -0.3257,  0.0871],
        [ 0.0133, -0.0600,  0.0186,  ...,  0.0283,  0.2271,  0.0345],
        ...,
        [-0.0055,  0.0351,  0.0580,  ...,  0.0846, -0.3120, -0.1180],
        [ 0.1001, -0.2302, -0.0537,  ..., -0.3279,  0.1471,  0.1557],
        [-0.2197,  0.1724,  0.0377,  ...,  0.0978, -0.2712, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0410,  0.0411, -0.0669, -0.1337, -0.0717,  0.0602, -0.1107,  0.0457,
        -0.0386,  0.0802,  0.0172,  0.0115,  0.0298,  0.0786, -0.0531, -0.0189,
         0.0588, -0.1554,  0.0024,  0.0275, -0.0496,  0.0324,  0.1089,  0.0053,
        -0.0936,  0.1044,  0.0469, -0.0930,  0.0538,  0.1395,  0.1669, -0.1226],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0769, -0.1794, -0.1195,  ..., -0.1307, -0.0183,  0.0754],
        [-0.2034, -0.0352,  0.0804,  ..., -0.0634,  0.0050,  0.0501],
        [ 0.1343, -0.0284, -0.1546,  ...,  0.0811, -0.0235,  0.1862],
        ...,
        [ 0.1151,  0.0927,  0.1238,  ...,  0.2523, -0.2223,  0.2451],
        [-0.0037, -0.1464,  0.0339,  ...,  0.0187,  0.2337, -0.1662],
        [-0.0009, -0.1323,  0.1949,  ...,  0.0368,  0.1614, -0.0495]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1018,  0.1461, -0.0569, -0.0824, -0.0012, -0.0432, -0.0566, -0.0446,
         0.1227, -0.1681,  0.1269, -0.1179,  0.1710,  0.0863, -0.1238,  0.1231,
        -0.1385, -0.1716, -0.0586, -0.0040, -0.0015,  0.0861, -0.2088,  0.2116,
        -0.0466, -0.0050,  0.0756, -0.0291, -0.1350, -0.0720,  0.1184,  0.0405],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4430,  0.3622, -0.4457, -0.4368,  0.3134,  0.2962, -0.3596,  0.3310,
          0.3626, -0.3844, -0.3315,  0.3478,  0.3316,  0.3110,  0.3744,  0.3682,
         -0.4387, -0.4516, -0.3050,  0.3506, -0.3953, -0.3732, -0.4473,  0.2949,
          0.4172,  0.4530, -0.4361,  0.4407, -0.3613, -0.4401,  0.4232,  0.4488]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2068], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.weight
Shape: torch.Size([32, 16])
Values: Parameter containing:
tensor([[-3.6042e-03,  3.6861e-01,  2.9521e-01, -3.1056e-01, -2.6926e-01,
         -1.3665e-01, -4.4363e-02, -4.3366e-01, -1.9702e-01, -4.8957e-02,
          1.4522e-01,  1.8215e-01,  4.8842e-02, -5.2522e-02, -1.5529e-01,
          3.5724e-01],
        [-2.4740e-01, -3.5603e-01, -9.1897e-02, -3.4823e-03,  2.5237e-02,
          2.3718e-01,  1.5915e-01,  1.8810e-01,  4.2018e-01,  1.3114e-01,
          7.9969e-02, -2.5933e-01, -5.0649e-04, -6.0601e-02,  4.3940e-01,
         -7.0484e-02],
        [ 7.3617e-02,  2.5279e-01,  3.6480e-01, -1.0852e-01, -1.2740e-01,
         -3.3212e-01, -3.3465e-02, -4.4790e-01,  1.6017e-02, -5.4207e-02,
         -9.8025e-02, -6.1953e-02,  3.9631e-01,  3.3129e-01, -3.3080e-02,
          2.4825e-01],
        [ 2.6094e-01,  8.0805e-02,  6.9475e-02, -7.2455e-02, -9.8339e-02,
         -1.7829e-01, -1.3987e-01, -1.1708e-01, -4.3556e-01, -3.9334e-01,
          2.0675e-02,  3.5510e-01,  2.9643e-01, -1.0281e-01, -2.7742e-01,
          1.3672e-01],
        [-9.8634e-02,  7.4248e-02, -1.6540e-01, -1.6419e-02,  2.3262e-01,
          7.8815e-02,  4.5271e-02,  3.6898e-01,  1.8105e-01,  3.0078e-01,
          9.8964e-02, -1.6771e-01, -6.6546e-02, -2.7022e-01,  3.8442e-01,
         -1.5285e-01],
        [-1.9579e-03,  1.1516e-01, -3.5202e-01,  4.0743e-01,  3.7836e-01,
         -3.7075e-02,  2.5360e-01, -7.2140e-03,  2.7570e-01,  2.1206e-01,
         -1.1054e-01, -8.8692e-02, -2.4847e-01,  1.0573e-01,  4.7626e-01,
         -7.1318e-02],
        [ 3.6091e-01,  1.3314e-01,  3.9322e-01, -1.8519e-01, -1.0095e-01,
         -2.0146e-01, -1.6712e-01, -2.5888e-01, -2.6161e-01, -2.1268e-02,
         -3.7665e-03,  5.9692e-02, -6.3477e-02,  1.9312e-01, -3.4707e-01,
          1.4058e-01],
        [-7.3277e-02,  2.8282e-01,  3.4184e-01, -3.5288e-01, -3.6118e-01,
         -2.8934e-01, -7.4178e-02, -2.7899e-01, -2.1019e-01, -2.1438e-01,
         -7.8946e-02,  3.0660e-02,  2.4622e-01, -9.2687e-02, -1.2079e-01,
          3.4361e-01],
        [ 3.6242e-02,  3.2806e-01,  2.9784e-01, -2.5636e-01, -1.0312e-01,
         -3.4134e-01, -1.6445e-01, -1.3527e-01,  1.6929e-02, -3.1816e-01,
          1.0495e-03,  6.1870e-02, -5.3577e-02,  1.9158e-01, -4.1954e-01,
          9.1081e-02],
        [-2.9405e-01, -1.2186e-01, -9.8523e-02, -1.9336e-04,  1.3758e-01,
          1.5408e-01,  5.3206e-02,  2.8240e-01,  3.0443e-01,  7.8855e-03,
          1.3744e-01, -1.7048e-02, -2.8265e-01, -1.1779e-01,  2.7421e-01,
         -2.0134e-01],
        [-3.5835e-01,  3.5317e-02, -6.0768e-02, -2.2970e-02,  2.3854e-02,
          4.2317e-01,  2.3474e-01,  1.6400e-01,  3.8687e-01,  2.5928e-01,
          6.8782e-04, -4.6684e-03, -2.1329e-01,  6.5703e-02,  9.1584e-02,
         -3.2951e-01],
        [-1.1904e-01, -1.6170e-01, -1.3889e-02,  9.5804e-02,  2.0384e-01,
          1.0974e-01,  3.5461e-01,  1.7513e-01,  1.7701e-01,  3.4782e-01,
          1.1426e-01,  6.5881e-02, -4.1587e-01, -2.5560e-01,  1.2373e-01,
         -1.9534e-01],
        [ 3.3414e-01,  2.6177e-01,  1.5649e-01, -1.7693e-01, -1.9339e-01,
          3.2462e-02, -8.7742e-02, -3.8477e-01, -3.6575e-01, -1.0699e-01,
         -1.0663e-01,  3.9026e-02, -1.8209e-02,  2.1387e-01, -3.7973e-01,
          2.8070e-02],
        [ 2.0184e-01,  3.4888e-01,  3.5652e-01, -1.6751e-02, -3.4512e-01,
         -1.3316e-02, -3.1872e-02, -9.3020e-02, -2.3315e-01, -1.6542e-01,
         -1.1738e-01,  1.0875e-01,  1.2340e-01,  7.0102e-02, -4.1327e-01,
          2.3020e-01],
        [-3.7301e-01, -3.1609e-01, -6.0257e-02, -3.5598e-02,  4.1950e-01,
          4.0617e-01,  9.6160e-02,  1.5314e-01, -3.9132e-03,  1.8707e-01,
          4.5755e-02, -3.1651e-01, -9.9848e-02, -1.4018e-01,  1.3288e-01,
         -1.5726e-01],
        [-3.1058e-01, -2.4856e-01, -1.4166e-03,  2.7437e-01,  1.3016e-01,
          1.9030e-01,  1.0924e-01,  6.8813e-02,  1.6203e-01,  1.5185e-01,
          5.6480e-02,  1.3598e-01, -1.5409e-01, -3.1487e-01,  5.7368e-01,
         -1.0674e-01],
        [ 3.0321e-01,  2.5089e-01,  1.8791e-01, -3.5420e-01, -3.7452e-01,
         -2.4559e-02, -8.5097e-02, -8.1092e-03, -3.8200e-01, -1.8410e-01,
          1.7313e-01,  2.8293e-01,  3.4342e-01,  2.8260e-01, -1.6705e-01,
         -3.9101e-02],
        [-2.8001e-01,  2.9708e-02, -2.2789e-01,  1.3777e-01,  1.4382e-01,
          2.8571e-01,  2.6660e-01,  2.7884e-01,  1.4382e-01,  2.7983e-01,
         -4.3116e-02, -2.3483e-01, -1.5276e-01, -2.0088e-01,  2.8144e-01,
         -1.5955e-01],
        [ 2.2498e-01,  1.2795e-01,  1.4127e-01, -2.8060e-01, -2.4162e-01,
         -3.6986e-01, -2.7501e-01, -1.4853e-03, -4.2947e-01, -1.0655e-01,
          1.6329e-02, -7.7765e-02,  2.0151e-01,  2.6977e-01, -4.5593e-02,
          1.8331e-01],
        [ 3.6870e-01,  1.5234e-01,  2.6159e-01, -9.7205e-02, -3.6934e-01,
         -2.2526e-01, -3.5441e-01, -6.4246e-03, -7.7004e-02, -2.7720e-01,
          8.2699e-02,  2.5165e-01, -4.0404e-02,  1.3666e-01, -8.8774e-02,
          1.8849e-01],
        [-1.7113e-01,  5.3847e-02, -3.4105e-02, -6.8307e-02,  3.0270e-01,
         -4.8789e-02,  2.9752e-01,  3.8143e-01,  1.9176e-01,  7.1286e-02,
         -8.3222e-02, -2.6792e-01, -2.0233e-01, -2.1913e-01,  4.4157e-01,
         -2.4634e-01],
        [-8.4183e-02, -3.4797e-01, -5.4195e-02,  4.0150e-01,  4.0269e-02,
          1.1938e-01,  2.6184e-01, -1.1805e-02,  6.6701e-02,  2.8152e-01,
          2.3159e-01, -2.7909e-01, -2.1536e-01, -4.0083e-01, -1.3943e-02,
          5.0665e-02],
        [ 3.6453e-01,  3.1994e-02,  4.9167e-02, -1.7449e-01, -3.8504e-02,
         -3.9519e-01, -2.9627e-01, -2.5541e-01, -2.7837e-01, -1.6640e-01,
          1.8287e-01,  2.1973e-01, -6.6774e-02,  3.3593e-01,  4.2754e-02,
          2.1724e-01],
        [ 2.3644e-01,  1.9051e-01,  3.2212e-01, -3.6504e-01, -2.1258e-01,
         -1.4747e-01, -1.5722e-01, -2.7093e-01, -3.5353e-01, -3.1379e-01,
          4.8904e-03,  3.2848e-01,  2.5734e-01,  1.2839e-01, -1.9503e-01,
          5.1167e-03],
        [ 2.1557e-01, -8.6068e-02,  1.7278e-01, -1.3915e-01,  7.1939e-03,
         -2.5202e-01,  4.2562e-02, -2.0769e-01, -3.9055e-01,  4.2800e-02,
          1.9399e-01,  8.0705e-03,  6.8352e-02,  2.8659e-01, -4.0940e-01,
          3.4782e-01],
        [ 3.7861e-02,  5.0108e-02,  7.8538e-02,  7.6676e-02, -2.5838e-01,
         -2.0640e-01, -1.6013e-02, -3.5779e-01, -1.8407e-01, -3.5645e-01,
         -2.8768e-01,  1.0904e-01,  1.9678e-01,  3.4645e-01, -4.7174e-01,
          7.5488e-02],
        [ 2.1146e-01,  1.7696e-01,  2.8622e-01, -3.5131e-01, -2.0079e-01,
         -8.9765e-02, -3.4750e-01, -3.7326e-02, -3.9675e-01,  4.7333e-03,
          2.6010e-02,  8.4467e-02,  2.2600e-01,  2.9214e-01,  5.6066e-02,
          2.8264e-01],
        [-3.2388e-01, -6.2298e-02,  1.6397e-02,  2.1958e-01,  3.5799e-01,
          1.8729e-02,  3.6212e-01,  2.0617e-01, -2.9222e-02,  1.1460e-01,
          1.0042e-01, -2.7561e-01, -2.3475e-01, -2.3451e-01,  7.2079e-02,
         -1.1699e-01],
        [ 2.9103e-01,  1.6750e-01,  1.2209e-01, -1.3304e-01, -3.1672e-01,
         -2.7430e-01, -1.3402e-01, -3.5323e-01, -2.9273e-02, -1.0691e-01,
          8.8186e-02,  1.3458e-01,  3.4778e-01,  3.3335e-01, -2.9032e-02,
          2.5272e-01],
        [-2.6455e-01,  9.4495e-03, -3.0824e-01,  2.5754e-01, -4.1775e-02,
          1.4274e-01,  3.2684e-01,  3.2502e-01,  3.7360e-01,  2.3725e-01,
          1.5803e-01, -8.5469e-02,  4.0450e-02,  4.0322e-02,  2.0361e-01,
         -2.2005e-01],
        [-2.7692e-01, -1.7475e-01, -3.2740e-02,  2.2671e-02,  2.2569e-01,
          3.7426e-01,  3.7150e-01, -8.1041e-03,  2.4580e-01,  3.2301e-01,
         -2.1346e-01, -7.3528e-03, -3.1199e-01, -2.8844e-01,  5.2322e-02,
         -2.3557e-01],
        [ 4.7178e-02,  1.4932e-01,  2.3987e-01, -4.9451e-02, -2.6671e-02,
         -3.0466e-01, -3.8773e-01, -3.8800e-01, -3.2085e-01, -2.6189e-01,
          8.2566e-02, -2.3207e-02, -3.8871e-02,  2.3664e-01, -3.1286e-01,
          1.8339e-01]], device='cuda:0', requires_grad=True)

Parameter name: road_linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([-0.0911, -0.0291,  0.1054, -0.0788, -0.0444, -0.0235,  0.0824,  0.1285,
        -0.0604, -0.0431,  0.0119,  0.0938,  0.1559,  0.0869, -0.0311, -0.0453,
        -0.1742,  0.0042,  0.0082, -0.0152, -0.0102, -0.0849, -0.0730, -0.0374,
        -0.1355,  0.2548,  0.0819,  0.0470, -0.1063, -0.2226,  0.1869, -0.0486],
       device='cuda:0', requires_grad=True)

Parameter name: road_linear_1.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[-0.2480,  0.3326, -0.2430, -0.2615,  0.3555,  0.3907, -0.2979, -0.3784,
         -0.3424,  0.3825,  0.2681,  0.3864, -0.2861, -0.4230,  0.3166,  0.2895,
         -0.3236,  0.3291, -0.2363, -0.2556,  0.4182,  0.3321, -0.3732, -0.3735,
         -0.4014, -0.3605, -0.3176,  0.3614, -0.3474,  0.3855,  0.2898, -0.2399]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.weight
Shape: torch.Size([32, 39])
Values: Parameter containing:
tensor([[-0.0160,  0.1008,  0.0778,  ...,  0.1582, -0.2627, -0.1137],
        [-0.1132, -0.0422,  0.1174,  ...,  0.1312, -0.3106,  0.0871],
        [-0.0035, -0.0373,  0.0319,  ...,  0.0270,  0.2288,  0.0345],
        ...,
        [ 0.0077,  0.0191,  0.0549,  ...,  0.0659, -0.3119, -0.1180],
        [ 0.0927, -0.2182, -0.0536,  ..., -0.3025,  0.1378,  0.1557],
        [-0.1967,  0.1605,  0.0392,  ...,  0.0663, -0.2695, -0.0509]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_0.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.0468,  0.0418, -0.0713, -0.1351, -0.0726,  0.0524, -0.1116,  0.0502,
        -0.0396,  0.0786,  0.0226,  0.0117,  0.0258,  0.0748, -0.0523, -0.0195,
         0.0578, -0.1578, -0.0605,  0.0357, -0.0544,  0.0306,  0.1057,  0.0057,
        -0.0894,  0.0539,  0.0432, -0.1116,  0.0544,  0.1427,  0.1667, -0.1259],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.weight
Shape: torch.Size([32, 32])
Values: Parameter containing:
tensor([[ 0.0645, -0.1801, -0.1086,  ..., -0.1221, -0.0268,  0.0752],
        [-0.2146, -0.0354,  0.1032,  ..., -0.0518, -0.0101,  0.0491],
        [ 0.1395, -0.0312, -0.1629,  ...,  0.0672, -0.0087,  0.1808],
        ...,
        [ 0.1127,  0.0787,  0.1246,  ...,  0.2341, -0.2009,  0.2307],
        [-0.0104, -0.1466,  0.0470,  ...,  0.0360,  0.2171, -0.1652],
        [-0.0015, -0.1221,  0.1935,  ...,  0.0573,  0.1403, -0.0363]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_1.bias
Shape: torch.Size([32])
Values: Parameter containing:
tensor([ 0.1056,  0.1579, -0.0573, -0.0816, -0.0074, -0.0410, -0.0559, -0.0445,
         0.1322, -0.1759,  0.1139, -0.1295,  0.1896,  0.1015, -0.1284,  0.1306,
        -0.1373, -0.1705,  0.0421, -0.0118, -0.0047,  0.0881, -0.1983,  0.2321,
        -0.0441, -0.0084,  0.0789, -0.0270, -0.1334, -0.0681,  0.1245,  0.0343],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.weight
Shape: torch.Size([1, 32])
Values: Parameter containing:
tensor([[ 0.4644,  0.3888, -0.4648, -0.4431,  0.3273,  0.3298, -0.3758,  0.3414,
          0.3653, -0.4083, -0.3559,  0.3532,  0.3494,  0.3383,  0.3841,  0.3942,
         -0.4507, -0.4632,  0.3137,  0.3607, -0.4107, -0.3905, -0.4594,  0.3082,
          0.4345,  0.4635, -0.4456,  0.4537, -0.3755, -0.4505,  0.4396,  0.4557]],
       device='cuda:0', requires_grad=True)

Parameter name: linear_2.bias
Shape: torch.Size([1])
Values: Parameter containing:
tensor([0.2167], device='cuda:0', requires_grad=True)

